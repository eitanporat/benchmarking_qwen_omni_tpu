BufferAssignment:
allocation 0: size 17216, parameter 0, shape |f32[4304]| at ShapeIndex {}:
 value: <0 args_0_.1 @0> (size=17216,offset=0): f32[4304]{0}
allocation 1: size 8608, output shape is |bf16[4304]|, maybe-live-out:
 value: <1 convert_element_type.1 @0> (size=8608,offset=0): bf16[4304]{0}

Total bytes used: 25824 (25.2KiB)

Used values:
<0 args_0_.1 @0>
 positions:
  args_0_.1
 uses:
  convert_element_type.1, operand 0
 from instruction: %args_0_.1 = f32[4304]{0} parameter(0), metadata={op_name="args[0]"}
<1 convert_element_type.1 @0>
 positions:
  convert_element_type.1
 uses:
 from instruction: %convert_element_type.1 = bf16[4304]{0} convert(%args_0_.1), metadata={op_name="jit(convert_element_type)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/mappings.py" source_line=46 source_end_line=46 source_column=12 source_end_column=57}


HloLiveRange (max 2):
  InstructionSequence:
    0:args_0_.1
    1:convert_element_type.1
  BufferLiveRange:
    args_0_.1{}:0-2
    convert_element_type.1{}:1-2
  Live ranges at 1 (peak):
    args_0_.1{}: 17216 bytes (cumulative: 17216 bytes)
    convert_element_type.1{}: 8608 bytes (cumulative: 25824 bytes)
  Stack trace breakdown for peak usage: 25 824 bytes
    main.1 (100.0%, total: 25 824 bytes, current: 0 bytes, remaining: 25 824 bytes)
      ├── args[0] (66.7%, total: 17 216 bytes, current: 17 216 bytes, remaining: 8 608 bytes)
      └── jit(convert_element_type)/convert_element_type (33.3%, total: 8 608 bytes, current: 8 608 bytes, remaining: 0 bytes)
