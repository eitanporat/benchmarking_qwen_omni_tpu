#loc1 = loc("args[0]")
#loc2 = loc("args[1]")
#loc3 = loc("args[2]")
module @jit_concatenate attributes {mhlo.num_partitions = 1 : i32, mhlo.num_replicas = 1 : i32} {
  func.func public @main(%arg0: tensor<4x288x1152xbf16> loc("args[0]"), %arg1: tensor<4x288x1152xbf16> loc("args[1]"), %arg2: tensor<4x288x1152xbf16> loc("args[2]")) -> (tensor<4x864x1152xbf16> {jax.result_info = "result"}) {
    %0 = stablehlo.concatenate %arg0, %arg1, %arg2, dim = 1 : (tensor<4x288x1152xbf16>, tensor<4x288x1152xbf16>, tensor<4x288x1152xbf16>) -> tensor<4x864x1152xbf16> loc(#loc33)
    return %0 : tensor<4x864x1152xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc4 = loc("/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py":71:23 to :67)
#loc5 = loc("/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py":131:17 to 132:48)
#loc6 = loc("/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py":78:17 to 85:9)
#loc7 = loc("/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/vllm/model_executor/model_loader/utils.py":117:16 to :66)
#loc8 = loc("/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/vllm/model_executor/model_loader/base_loader.py":56:12 to :77)
#loc9 = loc("/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/vllm/model_executor/model_loader/__init__.py":130:11 to :80)
#loc10 = loc("/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/models/vllm/vllm_model_wrapper.py":118:25 to :73)
#loc11 = loc("/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/models/common/model_loader.py":291:27 to :47)
#loc12 = loc("/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/models/common/model_loader.py":322:19 to :57)
#loc13 = loc("/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/runner/tpu_jax_runner.py":293:222 to 297:9)
#loc14 = loc("reorder_concatenated_tensor_for_sharding"(#loc4))
#loc15 = loc("torch_to_jax_param"(#loc5))
#loc16 = loc("VllmUnquantizedLinearMethod.process_weights_after_loading"(#loc6))
#loc17 = loc("process_weights_after_loading"(#loc7))
#loc18 = loc("BaseModelLoader.load_model"(#loc8))
#loc19 = loc("get_model"(#loc9))
#loc20 = loc("VllmModelWrapper.load_weights"(#loc10))
#loc21 = loc("get_vllm_model"(#loc11))
#loc22 = loc("get_model"(#loc12))
#loc23 = loc("TPUModelRunner.load_model"(#loc13))
#loc24 = loc(callsite(#loc22 at #loc23))
#loc25 = loc(callsite(#loc21 at #loc24))
#loc26 = loc(callsite(#loc20 at #loc25))
#loc27 = loc(callsite(#loc19 at #loc26))
#loc28 = loc(callsite(#loc18 at #loc27))
#loc29 = loc(callsite(#loc17 at #loc28))
#loc30 = loc(callsite(#loc16 at #loc29))
#loc31 = loc(callsite(#loc15 at #loc30))
#loc32 = loc(callsite(#loc14 at #loc31))
#loc33 = loc("jit(concatenate)/concatenate"(#loc32))
