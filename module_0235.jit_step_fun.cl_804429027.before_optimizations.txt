HloModule jit_step_fun, buffer_donor={ (435, {}), (436, {}), (437, {}), (438, {}), (439, {}), (440, {}), (441, {}), (442, {}), (443, {}), (444, {}), (445, {}), (446, {}), (447, {}), (448, {}), (449, {}), (450, {}), (451, {}), (452, {}), (453, {}), (454, {}), (455, {}), (456, {}), (457, {}), (458, {}), (459, {}), (460, {}), (461, {}), (462, {}), (463, {}), (464, {}), (465, {}), (466, {}), (467, {}), (468, {}), (469, {}), (470, {}), (471, {}), (472, {}), (473, {}), (474, {}), (475, {}), (476, {}), (477, {}), (478, {}), (479, {}), (480, {}), (481, {}), (482, {}) }, entry_computation_layout={(bf16[152064,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, /*index=5*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, /*index=10*/bf16[262144,128]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, /*index=15*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, /*index=20*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=25*/bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=30*/bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=35*/bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, /*index=40*/bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, /*index=45*/bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, /*index=50*/bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=55*/bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, /*index=60*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, /*index=65*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=70*/bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=75*/bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=80*/bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, /*index=85*/bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, /*index=90*/bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, /*index=95*/bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=100*/bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, /*index=105*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, /*index=110*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=115*/bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=120*/bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=125*/bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, /*index=130*/bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, /*index=135*/bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, /*index=140*/bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=145*/bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, /*index=150*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, /*index=155*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=160*/bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=165*/bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=170*/bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, /*index=175*/bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, /*index=180*/bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, /*index=185*/bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=190*/bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, /*index=195*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, /*index=200*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=205*/bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=210*/bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=215*/bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, /*index=220*/bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, /*index=225*/bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, /*index=230*/bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=235*/bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, /*index=240*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, /*index=245*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=250*/bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=255*/bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=260*/bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, /*index=265*/bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, /*index=270*/bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, /*index=275*/bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=280*/bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, /*index=285*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, /*index=290*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=295*/bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=300*/bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=305*/bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, /*index=310*/bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, /*index=315*/bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, /*index=320*/bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=325*/bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, /*index=330*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, /*index=335*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=340*/bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=345*/bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=350*/bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, /*index=355*/bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, /*index=360*/bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, /*index=365*/bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=370*/bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, /*index=375*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, /*index=380*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=385*/bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=390*/bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=395*/bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, /*index=400*/bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, /*index=405*/bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, /*index=410*/bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=415*/bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, /*index=420*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, /*index=425*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=430*/bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=435*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=440*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=445*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=450*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=455*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=460*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=465*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=470*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=475*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=480*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, s32[16]{0:T(128)}, s32[16]{0:T(128)}, /*index=485*/s32[131072]{0:T(1024)}, s32[256]{0:T(256)}, s32[257]{0:T(512)}, s32[3]{0:T(128)})->(bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=5*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=10*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=15*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=20*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=25*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=30*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=35*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=40*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=45*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[16,2048]{1,0:T(8,128)(2,1)})}, allow_spmd_sharding_propagation_to_parameters={false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false}, allow_spmd_sharding_propagation_to_output={true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true}, num_partitions=4, frontend_attributes={xla.sdy.meshes={mesh = #sdy.mesh<["data"=1, "model"=4]>}}

%_where.532 (Arg_0.528: pred[16], Arg_1.529: s32[16], Arg_2.530: s32[16]) -> s32[16] {
  %Arg_0.528 = pred[16]{0} parameter(0)
  %Arg_1.529 = s32[16]{0} parameter(1)
  %Arg_2.530 = s32[16]{0} parameter(2)
  ROOT %select_n.531 = s32[16]{0} select(%Arg_0.528, %Arg_1.529, %Arg_2.530), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
}

%region_0.541 (reduce_and.538: pred[], reduce_and.539: pred[]) -> pred[] {
  %reduce_and.538 = pred[] parameter(0), metadata={op_name="reduce_and"}
  %reduce_and.539 = pred[] parameter(1), metadata={op_name="reduce_and"}
  ROOT %reduce_and.540 = pred[] and(%reduce_and.538, %reduce_and.539), metadata={op_name="reduce_and" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
}

%_take.546 (Arg_0.513: bf16[152064,2048], Arg_1.514: s32[16]) -> bf16[16,2048] {
  %Arg_1.514 = s32[16]{0} parameter(1)
  %constant.524 = s32[] constant(0)
  %broadcast.525 = s32[16]{0} broadcast(%constant.524), dimensions={}
  %lt.526 = pred[16]{0} compare(%Arg_1.514, %broadcast.525), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
  %constant.521 = s32[] constant(152064)
  %broadcast.522 = s32[16]{0} broadcast(%constant.521), dimensions={}
  %add.527 = s32[16]{0} add(%Arg_1.514, %broadcast.522), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
  %jit__where_.533 = s32[16]{0} call(%lt.526, %add.527, %Arg_1.514), to_apply=%_where.532, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
  %broadcast_in_dim.534 = s32[16,1]{1,0} reshape(%jit__where_.533), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
  %constant.519 = s32[] constant(0)
  %broadcast.520 = s32[16,1]{1,0} broadcast(%constant.519), dimensions={}
  %ge.535 = pred[16,1]{1,0} compare(%broadcast_in_dim.534, %broadcast.520), direction=GE, metadata={op_name="ge" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
  %constant.517 = s32[] constant(152063)
  %broadcast.518 = s32[16,1]{1,0} broadcast(%constant.517), dimensions={}
  %le.536 = pred[16,1]{1,0} compare(%broadcast_in_dim.534, %broadcast.518), direction=LE, metadata={op_name="le" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
  %and.537 = pred[16,1]{1,0} and(%ge.535, %le.536), metadata={op_name="and" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
  %constant.523 = pred[] constant(true)
  %reduce_and.542 = pred[16]{0} reduce(%and.537, %constant.523), dimensions={1}, to_apply=%region_0.541, metadata={op_name="reduce_and" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
  %broadcast_in_dim.544 = pred[16,2048]{1,0} broadcast(%reduce_and.542), dimensions={0}, metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
  %Arg_0.513 = bf16[152064,2048]{1,0} parameter(0)
  %gather.543 = bf16[16,2048]{1,0} gather(%Arg_0.513, %broadcast_in_dim.534), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,2048}, metadata={op_name="gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
  %constant.515 = bf16[] constant(nan)
  %broadcast_in_dim.516 = bf16[16,2048]{1,0} broadcast(%constant.515), dimensions={}, metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
  ROOT %select_n.545 = bf16[16,2048]{1,0} select(%broadcast_in_dim.544, %gather.543, %broadcast_in_dim.516), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
}

%region_1.553 (reduce_sum.550: f32[], reduce_sum.551: f32[]) -> f32[] {
  %reduce_sum.550 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.551 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.552 = f32[] add(%reduce_sum.550, %reduce_sum.551), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_2.581 (reduce_sum.578: f32[], reduce_sum.579: f32[]) -> f32[] {
  %reduce_sum.578 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.579 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.580 = f32[] add(%reduce_sum.578, %reduce_sum.579), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_3.602 (reduce_sum.599: f32[], reduce_sum.600: f32[]) -> f32[] {
  %reduce_sum.599 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.600 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.601 = f32[] add(%reduce_sum.599, %reduce_sum.600), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%_pad.727 (Arg_0.725: bf16[16,1,8,128], Arg_1.726: s32[]) -> bf16[16,1,8,128] {
  ROOT %Arg_0.725 = bf16[16,1,8,128]{3,2,1,0} parameter(0)
  %Arg_1.726 = s32[] parameter(1)
}

%_pad_67.734 (Arg_0.732: bf16[16,2,128], Arg_1.733: s32[]) -> bf16[16,2,128] {
  ROOT %Arg_0.732 = bf16[16,2,128]{2,1,0} parameter(0)
  %Arg_1.733 = s32[] parameter(1)
}

%ragged_paged_attention.744 (Arg_0.709: bf16[16,8,128], Arg_1.710: bf16[16,1,128], Arg_2.711: bf16[16,1,128], Arg_3.712: bf16[14813,32,1,2,128], Arg_4.713: s32[256], Arg_5.714: s32[131072], Arg_6.715: s32[257], Arg_7.716: s32[3]) -> (bf16[16,8,128], bf16[14813,32,1,2,128]) {
  %Arg_7.716 = s32[3]{0} parameter(7)
  %slice.737 = s32[1]{0} slice(%Arg_7.716), slice={[2:3]}, metadata={op_name="slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/kernels/ragged_paged_attention/v3/kernel.py" source_line=1338 source_end_line=1338 source_column=12 source_end_column=27}
  %squeeze.738 = s32[] reshape(%slice.737), metadata={op_name="squeeze" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/kernels/ragged_paged_attention/v3/kernel.py" source_line=1338 source_end_line=1338 source_column=12 source_end_column=27}
  %Arg_4.713 = s32[256]{0} parameter(4)
  %Arg_5.714 = s32[131072]{0} parameter(5)
  %Arg_6.715 = s32[257]{0} parameter(6)
  %constant.721 = s32[] constant(0)
  %broadcast.722 = s32[3]{0} broadcast(%constant.721), dimensions={}
  %constant.719 = s32[] constant(-1)
  %broadcast.720 = s32[4]{0} broadcast(%constant.719), dimensions={}
  %constant.717 = s32[] constant(-1)
  %broadcast.718 = s32[6]{0} broadcast(%constant.717), dimensions={}
  %Arg_0.709 = bf16[16,8,128]{2,1,0} parameter(0)
  %reshape.724 = bf16[16,1,8,128]{3,2,1,0} reshape(%Arg_0.709), metadata={op_name="reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/kernels/ragged_paged_attention/v3/kernel.py" source_line=920 source_end_line=925 source_column=12 source_end_column=13}
  %constant.723 = s32[] constant(0)
  %jit__pad_.728 = bf16[16,1,8,128]{3,2,1,0} call(%reshape.724, %constant.723), to_apply=%_pad.727, metadata={op_name="jit(_pad)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/kernels/ragged_paged_attention/v3/kernel.py" source_line=919 source_end_line=933 source_column=8 source_end_column=9}
  %transpose.729 = bf16[1,16,4,2,128]{4,3,2,1,0} reshape(%jit__pad_.728), metadata={op_name="transpose" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/kernels/ragged_paged_attention/v3/kernel.py" source_line=941 source_end_line=941 source_column=9 source_end_column=23}
  %Arg_1.710 = bf16[16,1,128]{2,1,0} parameter(1)
  %Arg_2.711 = bf16[16,1,128]{2,1,0} parameter(2)
  %concatenate.730 = bf16[16,1,256]{2,1,0} concatenate(%Arg_1.710, %Arg_2.711), dimensions={2}, metadata={op_name="concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/kernels/ragged_paged_attention/v3/kernel.py" source_line=885 source_end_line=886 source_column=8 source_end_column=27}
  %reshape.731 = bf16[16,2,128]{2,1,0} reshape(%concatenate.730), metadata={op_name="reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/kernels/ragged_paged_attention/v3/kernel.py" source_line=886 source_end_line=887 source_column=28 source_end_column=52}
  %jit__pad_.735 = bf16[16,2,128]{2,1,0} call(%reshape.731, %constant.723), to_apply=%_pad_67.734, metadata={op_name="jit(_pad)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/kernels/ragged_paged_attention/v3/kernel.py" source_line=884 source_end_line=894 source_column=9 source_end_column=5}
  %reshape.736 = bf16[16,1,2,128]{3,2,1,0} reshape(%jit__pad_.735), metadata={op_name="reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/kernels/ragged_paged_attention/v3/kernel.py" source_line=894 source_end_line=899 source_column=6 source_end_column=5}
  %Arg_3.712 = bf16[14813,32,1,2,128]{4,3,2,1,0} parameter(3)
  %pallas_call.739 = (bf16[1,16,4,2,128]{4,3,2,1,0}, bf16[14813,32,1,2,128]{4,3,2,1,0}) custom-call(%squeeze.738, %Arg_4.713, %Arg_5.714, %Arg_6.715, %Arg_7.716, /*index=5*/%broadcast.722, %broadcast.720, %broadcast.718, %transpose.729, %reshape.736, /*index=10*/%Arg_3.712), custom_call_target="tpu_custom_call", operand_layout_constraints={s32[], s32[256]{0}, s32[131072]{0}, s32[257]{0}, s32[3]{0}, s32[3]{0}, s32[4]{0}, s32[6]{0}, bf16[1,16,4,2,128]{4,3,2,1,0}, bf16[16,1,2,128]{3,2,1,0}, bf16[14813,32,1,2,128]{4,3,2,1,0}}, output_to_operand_aliasing={{0}: (8, {}), {1}: (10, {})}, metadata={op_name="RPA-bq_16-bkvp_64-p_32/pallas_call" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/kernels/ragged_paged_attention/v3/kernel.py" source_line=1442 source_end_line=1442 source_column=31 source_end_column=74}, backend_config={"custom_call_config": {"body": "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", "serialization_format": 1, "needs_layout_passes": true}, "scoped_memory_configs": [{"memory_space":1, "offset": 0, "size": 104857600}]}
  %pallas_call.740 = bf16[1,16,4,2,128]{4,3,2,1,0} get-tuple-element(%pallas_call.739), index=0, metadata={op_name="RPA-bq_16-bkvp_64-p_32/pallas_call" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/kernels/ragged_paged_attention/v3/kernel.py" source_line=1442 source_end_line=1442 source_column=31 source_end_column=74}
  %reshape.742 = bf16[16,8,128]{2,1,0} reshape(%pallas_call.740), metadata={op_name="reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/kernels/ragged_paged_attention/v3/kernel.py" source_line=965 source_end_line=966 source_column=63 source_end_column=60}
  %pallas_call.741 = bf16[14813,32,1,2,128]{4,3,2,1,0} get-tuple-element(%pallas_call.739), index=1, metadata={op_name="RPA-bq_16-bkvp_64-p_32/pallas_call" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/kernels/ragged_paged_attention/v3/kernel.py" source_line=1442 source_end_line=1442 source_column=31 source_end_column=74}
  ROOT %tuple.743 = (bf16[16,8,128]{2,1,0}, bf16[14813,32,1,2,128]{4,3,2,1,0}) tuple(%reshape.742, %pallas_call.741)
}

%xla.sdy.manual_computation_body.749 (shard_map.701: bf16[16,8,128], shard_map.702: bf16[16,1,128], shard_map.703: bf16[16,1,128], shard_map.704: bf16[14813,32,1,2,128], shard_map.705: s32[256], shard_map.706: s32[131072], shard_map.707: s32[257], shard_map.708: s32[3]) -> (bf16[16,8,128], bf16[14813,32,1,2,128]) {
  %shard_map.701 = bf16[16,8,128]{2,1,0} parameter(0), metadata={op_name="shard_map"}
  %shard_map.702 = bf16[16,1,128]{2,1,0} parameter(1), metadata={op_name="shard_map"}
  %shard_map.703 = bf16[16,1,128]{2,1,0} parameter(2), metadata={op_name="shard_map"}
  %shard_map.704 = bf16[14813,32,1,2,128]{4,3,2,1,0} parameter(3), metadata={op_name="shard_map"}
  %shard_map.705 = s32[256]{0} parameter(4), metadata={op_name="shard_map"}
  %shard_map.706 = s32[131072]{0} parameter(5), metadata={op_name="shard_map"}
  %shard_map.707 = s32[257]{0} parameter(6), metadata={op_name="shard_map"}
  %shard_map.708 = s32[3]{0} parameter(7), metadata={op_name="shard_map"}
  %jit_ragged_paged_attention_.745 = (bf16[16,8,128]{2,1,0}, bf16[14813,32,1,2,128]{4,3,2,1,0}) call(%shard_map.701, %shard_map.702, %shard_map.703, %shard_map.704, %shard_map.705, /*index=5*/%shard_map.706, %shard_map.707, %shard_map.708), to_apply=%ragged_paged_attention.744, metadata={op_name="jit(ragged_paged_attention)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=293 source_end_line=300 source_column=15 source_end_column=9}
  %jit_ragged_paged_attention_.746 = bf16[16,8,128]{2,1,0} get-tuple-element(%jit_ragged_paged_attention_.745), index=0, metadata={op_name="jit(ragged_paged_attention)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=293 source_end_line=300 source_column=15 source_end_column=9}
  %jit_ragged_paged_attention_.747 = bf16[14813,32,1,2,128]{4,3,2,1,0} get-tuple-element(%jit_ragged_paged_attention_.745), index=1, metadata={op_name="jit(ragged_paged_attention)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=293 source_end_line=300 source_column=15 source_end_column=9}
  ROOT %tuple.748 = (bf16[16,8,128]{2,1,0}, bf16[14813,32,1,2,128]{4,3,2,1,0}) tuple(%jit_ragged_paged_attention_.746, %jit_ragged_paged_attention_.747)
}

%_ragged_paged_attention.757 (Arg_0.684: bf16[16,32,128], Arg_1.685: bf16[16,4,128], Arg_2.686: bf16[16,4,128], Arg_3.687: bf16[14813,32,4,2,128], Arg_4.688: s32[256], Arg_5.689: s32[131072], Arg_6.690: s32[257], Arg_7.691: s32[3]) -> (bf16[16,32,128], bf16[14813,32,4,2,128]) {
  %Arg_0.684 = bf16[16,32,128]{2,1,0} parameter(0)
  %Arg_1.685 = bf16[16,4,128]{2,1,0} parameter(1)
  %Arg_2.686 = bf16[16,4,128]{2,1,0} parameter(2)
  %Arg_3.687 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(3)
  %Arg_4.688 = s32[256]{0} parameter(4)
  %Arg_5.689 = s32[131072]{0} parameter(5)
  %Arg_6.690 = s32[257]{0} parameter(6)
  %Arg_7.691 = s32[3]{0} parameter(7)
  %shard_map.692 = (bf16[16,8,128]{2,1,0}, bf16[16,1,128]{2,1,0}, bf16[16,1,128]{2,1,0}, bf16[14813,32,1,2,128]{4,3,2,1,0}, s32[256]{0}, /*index=5*/s32[131072]{0}, s32[257]{0}, s32[3]{0}) custom-call(%Arg_0.684, %Arg_1.685, %Arg_2.686, %Arg_3.687, %Arg_4.688, /*index=5*/%Arg_5.689, %Arg_6.690, %Arg_7.691), custom_call_target="xla.sdy.GlobalToLocalShape", custom_call_has_side_effect=true, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {}, {\"model\"}, {}, {}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %shard_map.693 = bf16[16,8,128]{2,1,0} get-tuple-element(%shard_map.692), index=0, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {}, {\"model\"}, {}, {}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %shard_map.694 = bf16[16,1,128]{2,1,0} get-tuple-element(%shard_map.692), index=1, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {}, {\"model\"}, {}, {}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %shard_map.695 = bf16[16,1,128]{2,1,0} get-tuple-element(%shard_map.692), index=2, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {}, {\"model\"}, {}, {}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %shard_map.696 = bf16[14813,32,1,2,128]{4,3,2,1,0} get-tuple-element(%shard_map.692), index=3, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {}, {\"model\"}, {}, {}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %shard_map.697 = s32[256]{0} get-tuple-element(%shard_map.692), index=4, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {}, {\"model\"}, {}, {}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %shard_map.698 = s32[131072]{0} get-tuple-element(%shard_map.692), index=5, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {}, {\"model\"}, {}, {}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %shard_map.699 = s32[257]{0} get-tuple-element(%shard_map.692), index=6, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {}, {\"model\"}, {}, {}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %shard_map.700 = s32[3]{0} get-tuple-element(%shard_map.692), index=7, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {}, {\"model\"}, {}, {}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %shard_map.750 = (bf16[16,8,128]{2,1,0}, bf16[14813,32,1,2,128]{4,3,2,1,0}) call(%shard_map.693, %shard_map.694, %shard_map.695, %shard_map.696, %shard_map.697, /*index=5*/%shard_map.698, %shard_map.699, %shard_map.700), to_apply=%xla.sdy.manual_computation_body.749, frontend_attributes={inlineable="false"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %shard_map.751 = bf16[16,8,128]{2,1,0} get-tuple-element(%shard_map.750), index=0, frontend_attributes={inlineable="false"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %shard_map.752 = bf16[14813,32,1,2,128]{4,3,2,1,0} get-tuple-element(%shard_map.750), index=1, frontend_attributes={inlineable="false"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %shard_map.753 = (bf16[16,32,128]{2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}) custom-call(%shard_map.751, %shard_map.752), custom_call_target="xla.sdy.LocalToGlobalShape", custom_call_has_side_effect=true, frontend_attributes={xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>",xla.sdy.out_shardings="#sdy.sharding_per_value<[<@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {}, {\"model\"}, {}, {}]>]>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %shard_map.754 = bf16[16,32,128]{2,1,0} get-tuple-element(%shard_map.753), index=0, frontend_attributes={xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>",xla.sdy.out_shardings="#sdy.sharding_per_value<[<@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {}, {\"model\"}, {}, {}]>]>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %shard_map.755 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%shard_map.753), index=1, frontend_attributes={xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>",xla.sdy.out_shardings="#sdy.sharding_per_value<[<@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {}, {\"model\"}, {}, {}]>]>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  ROOT %tuple.756 = (bf16[16,32,128]{2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}) tuple(%shard_map.754, %shard_map.755)
}

%_jax_attn_func.763 (Arg_0.673: bf16[14813,32,4,2,128], Arg_1.674: bf16[16,4096], Arg_2.675: bf16[16,512], Arg_3.676: bf16[16,512], Arg_4.677: s32[131072], Arg_5.678: s32[256], Arg_6.679: s32[257], Arg_7.680: s32[3]) -> (bf16[14813,32,4,2,128], bf16[16,4096]) {
  %Arg_1.674 = bf16[16,4096]{1,0} parameter(1)
  %reshape.681 = bf16[16,32,128]{2,1,0} reshape(%Arg_1.674), metadata={op_name="reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=161 source_end_line=161 source_column=8 source_end_column=46}
  %Arg_2.675 = bf16[16,512]{1,0} parameter(2)
  %reshape.682 = bf16[16,4,128]{2,1,0} reshape(%Arg_2.675), metadata={op_name="reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=163 source_end_line=163 source_column=8 source_end_column=49}
  %Arg_3.676 = bf16[16,512]{1,0} parameter(3)
  %reshape.683 = bf16[16,4,128]{2,1,0} reshape(%Arg_3.676), metadata={op_name="reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=164 source_end_line=164 source_column=8 source_end_column=49}
  %Arg_0.673 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(0)
  %Arg_5.678 = s32[256]{0} parameter(5)
  %Arg_4.677 = s32[131072]{0} parameter(4)
  %Arg_6.679 = s32[257]{0} parameter(6)
  %Arg_7.680 = s32[3]{0} parameter(7)
  %jit__ragged_paged_attention_.758 = (bf16[16,32,128]{2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}) call(%reshape.681, %reshape.682, %reshape.683, %Arg_0.673, %Arg_5.678, /*index=5*/%Arg_4.677, %Arg_6.679, %Arg_7.680), to_apply=%_ragged_paged_attention.757, metadata={op_name="jit(_ragged_paged_attention)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %jit__ragged_paged_attention_.760 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__ragged_paged_attention_.758), index=1, metadata={op_name="jit(_ragged_paged_attention)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %jit__ragged_paged_attention_.759 = bf16[16,32,128]{2,1,0} get-tuple-element(%jit__ragged_paged_attention_.758), index=0, metadata={op_name="jit(_ragged_paged_attention)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %reshape.761 = bf16[16,4096]{1,0} reshape(%jit__ragged_paged_attention_.759), metadata={op_name="reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=182 source_end_line=182 source_column=14 source_end_column=51}
  ROOT %tuple.762 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) tuple(%jit__ragged_paged_attention_.760, %reshape.761)
}

%region_4.776 (reduce_sum.773: f32[], reduce_sum.774: f32[]) -> f32[] {
  %reduce_sum.773 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.774 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.775 = f32[] add(%reduce_sum.773, %reduce_sum.774), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_5.814 (reduce_max.811: f32[], reduce_max.812: f32[]) -> f32[] {
  %reduce_max.811 = f32[] parameter(0), metadata={op_name="reduce_max"}
  %reduce_max.812 = f32[] parameter(1), metadata={op_name="reduce_max"}
  ROOT %reduce_max.813 = f32[] maximum(%reduce_max.811, %reduce_max.812), metadata={op_name="reduce_max" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
}

%region_6.826 (reduce_sum.823: f32[], reduce_sum.824: f32[]) -> f32[] {
  %reduce_sum.823 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.824 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.825 = f32[] add(%reduce_sum.823, %reduce_sum.824), metadata={op_name="reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
}

%region_7.839 (reduce_sum.836: f32[], reduce_sum.837: f32[]) -> f32[] {
  %reduce_sum.836 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.837 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.838 = f32[] add(%reduce_sum.836, %reduce_sum.837), metadata={op_name="reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=312 source_end_line=312 source_column=38 source_end_column=78}
}

%region_8.855 (sort.850: s32[], sort.851: s32[], sort.852: s32[], sort.853: s32[]) -> pred[] {
  %sort.852 = s32[] parameter(2), metadata={op_name="sort"}
  %sort.853 = s32[] parameter(3), metadata={op_name="sort"}
  %sort.850 = s32[] parameter(0), metadata={op_name="sort"}
  %sort.851 = s32[] parameter(1), metadata={op_name="sort"}
  ROOT %lt_to.854 = pred[] compare(%sort.850, %sort.851), direction=LT, metadata={op_name="lt_to" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=316 source_end_line=316 source_column=27 source_end_column=57}
}

%argsort.859 (Arg_0.848: s32[128]) -> s32[128] {
  %Arg_0.848 = s32[128]{0} parameter(0)
  %iota.849 = s32[128]{0} iota(), iota_dimension=0, metadata={op_name="iota" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=316 source_end_line=316 source_column=27 source_end_column=57}
  %sort.856 = (s32[128]{0}, s32[128]{0}) sort(%Arg_0.848, %iota.849), dimensions={0}, is_stable=true, to_apply=%region_8.855, metadata={op_name="sort" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=316 source_end_line=316 source_column=27 source_end_column=57}
  %sort.857 = s32[128]{0} get-tuple-element(%sort.856), index=0, metadata={op_name="sort" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=316 source_end_line=316 source_column=27 source_end_column=57}
  ROOT %sort.858 = s32[128]{0} get-tuple-element(%sort.856), index=1, metadata={op_name="sort" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=316 source_end_line=316 source_column=27 source_end_column=57}
}

%region_9.868 (sort.863: s32[], sort.864: s32[], sort.865: s32[], sort.866: s32[]) -> pred[] {
  %sort.865 = s32[] parameter(2), metadata={op_name="sort"}
  %sort.866 = s32[] parameter(3), metadata={op_name="sort"}
  %sort.863 = s32[] parameter(0), metadata={op_name="sort"}
  %sort.864 = s32[] parameter(1), metadata={op_name="sort"}
  ROOT %lt_to.867 = pred[] compare(%sort.863, %sort.864), direction=LT, metadata={op_name="lt_to" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=317 source_end_line=317 source_column=34 source_end_column=67}
}

%argsort_93.872 (Arg_0.861: s32[128]) -> s32[128] {
  %Arg_0.861 = s32[128]{0} parameter(0)
  %iota.862 = s32[128]{0} iota(), iota_dimension=0, metadata={op_name="iota" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=317 source_end_line=317 source_column=34 source_end_column=67}
  %sort.869 = (s32[128]{0}, s32[128]{0}) sort(%Arg_0.861, %iota.862), dimensions={0}, is_stable=true, to_apply=%region_9.868, metadata={op_name="sort" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=317 source_end_line=317 source_column=34 source_end_column=67}
  %sort.870 = s32[128]{0} get-tuple-element(%sort.869), index=0, metadata={op_name="sort" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=317 source_end_line=317 source_column=34 source_end_column=67}
  ROOT %sort.871 = s32[128]{0} get-tuple-element(%sort.869), index=1, metadata={op_name="sort" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=317 source_end_line=317 source_column=34 source_end_column=67}
}

%clip.886 (Arg_0.882: s32[128], Arg_1.883: s32[]) -> s32[128] {
  %Arg_1.883 = s32[] parameter(1)
  %max.884 = s32[128]{0} broadcast(%Arg_1.883), dimensions={}, metadata={op_name="max" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=320 source_end_line=320 source_column=18 source_end_column=76}
  %Arg_0.882 = s32[128]{0} parameter(0)
  ROOT %max.885 = s32[128]{0} maximum(%max.884, %Arg_0.882), metadata={op_name="max" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=320 source_end_line=320 source_column=18 source_end_column=76}
}

%region_10.895 (scatter-add.892: s32[], scatter-add.893: s32[]) -> s32[] {
  %scatter-add.892 = s32[] parameter(0), metadata={op_name="scatter-add"}
  %scatter-add.893 = s32[] parameter(1), metadata={op_name="scatter-add"}
  ROOT %add.894 = s32[] add(%scatter-add.892, %scatter-add.893), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=320 source_end_line=320 source_column=18 source_end_column=76}
}

%region_11.946 (reduce_window_sum.943: s32[], reduce_window_sum.944: s32[]) -> s32[] {
  %reduce_window_sum.943 = s32[] parameter(0), metadata={op_name="reduce_window_sum"}
  %reduce_window_sum.944 = s32[] parameter(1), metadata={op_name="reduce_window_sum"}
  ROOT %reduce_window_sum.945 = s32[] add(%reduce_window_sum.943, %reduce_window_sum.944), metadata={op_name="reduce_window_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=126 source_end_line=126 source_column=15 source_end_column=38}
}

%cumsum_119.948 (make_group_metadata.941: s32[128]) -> s32[128] {
  %make_group_metadata.941 = s32[128]{0} parameter(0), metadata={op_name="make_group_metadata"}
  %constant.942 = s32[] constant(0)
  ROOT %reduce_window_sum.947 = s32[128]{0} reduce-window(%make_group_metadata.941, %constant.942), window={size=128 pad=127_0}, to_apply=%region_11.946, metadata={op_name="reduce_window_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=126 source_end_line=126 source_column=15 source_end_column=38}
}

%cumsum.950 (Arg_0.940: s32[128]) -> s32[128] {
  %Arg_0.940 = s32[128]{0} parameter(0)
  ROOT %make_group_metadata.949 = s32[128]{0} call(%Arg_0.940), to_apply=%cumsum_119.948, metadata={op_name="make_group_metadata" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=126 source_end_line=126 source_column=15 source_end_column=38}
}

%_where_129.976 (Arg_0.972: pred[128], Arg_1.973: s32[128], Arg_2.974: s32[128]) -> s32[128] {
  %Arg_0.972 = pred[128]{0} parameter(0)
  %Arg_1.973 = s32[128]{0} parameter(1)
  %Arg_2.974 = s32[128]{0} parameter(2)
  ROOT %select_n.975 = s32[128]{0} select(%Arg_0.972, %Arg_1.973, %Arg_2.974), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
}

%floor_divide.978 (Arg_0.955: s32[128], Arg_1.956: s32[]) -> s32[128] {
  %Arg_0.955 = s32[128]{0} parameter(0)
  %sign.963 = s32[128]{0} sign(%Arg_0.955), metadata={op_name="sign" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  %Arg_1.956 = s32[] parameter(1)
  %sign.964 = s32[] sign(%Arg_1.956), metadata={op_name="sign" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  %ne.965 = s32[128]{0} broadcast(%sign.964), dimensions={}, metadata={op_name="ne" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  %ne.966 = pred[128]{0} compare(%sign.963, %ne.965), direction=NE, metadata={op_name="ne" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  %rem.967 = s32[128]{0} broadcast(%Arg_1.956), dimensions={}, metadata={op_name="rem" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  %rem.968 = s32[128]{0} remainder(%Arg_0.955, %rem.967), metadata={op_name="rem" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  %constant.959 = s32[] constant(0)
  %ne.960 = s32[128]{0} broadcast(%constant.959), dimensions={}, metadata={op_name="ne" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  %ne.969 = pred[128]{0} compare(%rem.968, %ne.960), direction=NE, metadata={op_name="ne" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  %and.970 = pred[128]{0} and(%ne.966, %ne.969), metadata={op_name="and" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  %div.961 = s32[128]{0} broadcast(%Arg_1.956), dimensions={}, metadata={op_name="div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  %div.962 = s32[128]{0} divide(%Arg_0.955, %div.961), metadata={op_name="div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  %constant.957 = s32[] constant(1)
  %sub.958 = s32[128]{0} broadcast(%constant.957), dimensions={}, metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  %sub.971 = s32[128]{0} subtract(%div.962, %sub.958), metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  ROOT %jit__where_.977 = s32[128]{0} call(%and.970, %sub.971, %div.962), to_apply=%_where_129.976, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
}

%_where_135.992 (Arg_0.987: pred[128], Arg_1.988: s32[], Arg_2.989: s32[128]) -> s32[128] {
  %Arg_0.987 = pred[128]{0} parameter(0)
  %Arg_1.988 = s32[] parameter(1)
  %broadcast_in_dim.990 = s32[128]{0} broadcast(%Arg_1.988), dimensions={}, metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=154 source_end_line=154 source_column=24 source_end_column=75}
  %Arg_2.989 = s32[128]{0} parameter(2)
  ROOT %select_n.991 = s32[128]{0} select(%Arg_0.987, %broadcast_in_dim.990, %Arg_2.989), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=154 source_end_line=154 source_column=24 source_end_column=75}
}

%_roll_static.1000 (Arg_0.996: s32[128]) -> s32[128] {
  %Arg_0.996 = s32[128]{0} parameter(0)
  %slice.997 = s32[1]{0} slice(%Arg_0.996), slice={[127:128]}, metadata={op_name="slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %slice.998 = s32[127]{0} slice(%Arg_0.996), slice={[0:127]}, metadata={op_name="slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  ROOT %concatenate.999 = s32[128]{0} concatenate(%slice.997, %slice.998), dimensions={0}, metadata={op_name="concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
}

%region_12.1004 (scatter.1002: s32[], scatter.1003: s32[]) -> s32[] {
  %scatter.1002 = s32[] parameter(0), metadata={op_name="scatter"}
  ROOT %scatter.1003 = s32[] parameter(1), metadata={op_name="scatter"}
}

%region_13.1014 (scatter-add.1011: s32[], scatter-add.1012: s32[]) -> s32[] {
  %scatter-add.1011 = s32[] parameter(0), metadata={op_name="scatter-add"}
  %scatter-add.1012 = s32[] parameter(1), metadata={op_name="scatter-add"}
  ROOT %add.1013 = s32[] add(%scatter-add.1011, %scatter-add.1012), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
}

%region_14.1041 (reduce_and.1038: pred[], reduce_and.1039: pred[]) -> pred[] {
  %reduce_and.1038 = pred[] parameter(0), metadata={op_name="reduce_and"}
  %reduce_and.1039 = pred[] parameter(1), metadata={op_name="reduce_and"}
  ROOT %reduce_and.1040 = pred[] and(%reduce_and.1038, %reduce_and.1039), metadata={op_name="reduce_and" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
}

%_take_147.1045 (Arg_0.1018: s32[128], Arg_1.1019: s32[128]) -> s32[128] {
  %Arg_1.1019 = s32[128]{0} parameter(1)
  %constant.1029 = s32[] constant(0)
  %lt.1030 = s32[128]{0} broadcast(%constant.1029), dimensions={}, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %lt.1031 = pred[128]{0} compare(%Arg_1.1019, %lt.1030), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %constant.1026 = s32[] constant(128)
  %add.1027 = s32[128]{0} broadcast(%constant.1026), dimensions={}, metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %add.1032 = s32[128]{0} add(%Arg_1.1019, %add.1027), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %jit__where_.1033 = s32[128]{0} call(%lt.1031, %add.1032, %Arg_1.1019), to_apply=%_where_129.976, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %broadcast_in_dim.1034 = s32[128,1]{1,0} reshape(%jit__where_.1033), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %constant.1024 = s32[] constant(0)
  %ge.1025 = s32[128,1]{1,0} broadcast(%constant.1024), dimensions={}, metadata={op_name="ge" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %ge.1035 = pred[128,1]{1,0} compare(%broadcast_in_dim.1034, %ge.1025), direction=GE, metadata={op_name="ge" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %constant.1022 = s32[] constant(127)
  %le.1023 = s32[128,1]{1,0} broadcast(%constant.1022), dimensions={}, metadata={op_name="le" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %le.1036 = pred[128,1]{1,0} compare(%broadcast_in_dim.1034, %le.1023), direction=LE, metadata={op_name="le" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %and.1037 = pred[128,1]{1,0} and(%ge.1035, %le.1036), metadata={op_name="and" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %constant.1028 = pred[] constant(true)
  %reduce_and.1042 = pred[128]{0} reduce(%and.1037, %constant.1028), dimensions={1}, to_apply=%region_14.1041, metadata={op_name="reduce_and" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %Arg_0.1018 = s32[128]{0} parameter(0)
  %gather.1043 = s32[128]{0} gather(%Arg_0.1018, %broadcast_in_dim.1034), offset_dims={}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1}, metadata={op_name="gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %constant.1020 = s32[] constant(-2147483648)
  %broadcast_in_dim.1021 = s32[128]{0} broadcast(%constant.1020), dimensions={}, metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  ROOT %select_n.1044 = s32[128]{0} select(%reduce_and.1042, %gather.1043, %broadcast_in_dim.1021), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
}

%_where_158.1059 (Arg_0.1055: pred[], Arg_1.1056: s32[], Arg_2.1057: s32[]) -> s32[] {
  %Arg_0.1055 = pred[] parameter(0)
  %Arg_1.1056 = s32[] parameter(1)
  %Arg_2.1057 = s32[] parameter(2)
  ROOT %select_n.1058 = s32[] select(%Arg_0.1055, %Arg_1.1056, %Arg_2.1057), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
}

%remainder.1072 (Arg_0.1048: s32[128], Arg_1.1049: s32[]) -> s32[128] {
  %Arg_0.1048 = s32[128]{0} parameter(0)
  %Arg_1.1049 = s32[] parameter(1)
  %constant.1053 = s32[] constant(0)
  %eq.1054 = pred[] compare(%Arg_1.1049, %constant.1053), direction=EQ, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
  %constant.1052 = s32[] constant(1)
  %jit__where_.1060 = s32[] call(%eq.1054, %constant.1052, %Arg_1.1049), to_apply=%_where_158.1059, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
  %rem.1061 = s32[128]{0} broadcast(%jit__where_.1060), dimensions={}, metadata={op_name="rem" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
  %rem.1062 = s32[128]{0} remainder(%Arg_0.1048, %rem.1061), metadata={op_name="rem" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
  %constant.1050 = s32[] constant(0)
  %broadcast.1051 = s32[128]{0} broadcast(%constant.1050), dimensions={}
  %lt.1064 = pred[128]{0} compare(%rem.1062, %broadcast.1051), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
  %lt.1065 = pred[] compare(%jit__where_.1060, %constant.1053), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
  %ne.1066 = pred[128]{0} broadcast(%lt.1065), dimensions={}, metadata={op_name="ne" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
  %ne.1067 = pred[128]{0} compare(%lt.1064, %ne.1066), direction=NE, metadata={op_name="ne" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
  %ne.1063 = pred[128]{0} compare(%rem.1062, %broadcast.1051), direction=NE, metadata={op_name="ne" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
  %and.1068 = pred[128]{0} and(%ne.1067, %ne.1063), metadata={op_name="and" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
  %add.1069 = s32[128]{0} broadcast(%jit__where_.1060), dimensions={}, metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
  %add.1070 = s32[128]{0} add(%rem.1062, %add.1069), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
  ROOT %select_n.1071 = s32[128]{0} select(%and.1068, %add.1070, %rem.1062), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
}

%region_15.1087 (reduce_max.1084: f32[], reduce_max.1085: f32[]) -> f32[] {
  %reduce_max.1084 = f32[] parameter(0), metadata={op_name="reduce_max"}
  %reduce_max.1085 = f32[] parameter(1), metadata={op_name="reduce_max"}
  ROOT %reduce_max.1086 = f32[] maximum(%reduce_max.1084, %reduce_max.1085), metadata={op_name="reduce_max" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
}

%region_16.1092 (reduce_min.1089: f32[], reduce_min.1090: f32[]) -> f32[] {
  %reduce_min.1089 = f32[] parameter(0), metadata={op_name="reduce_min"}
  %reduce_min.1090 = f32[] parameter(1), metadata={op_name="reduce_min"}
  ROOT %reduce_min.1091 = f32[] minimum(%reduce_min.1089, %reduce_min.1090), metadata={op_name="reduce_min" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
}

%_ptp.1095 (Arg_0.1081: f32[2]) -> f32[] {
  %Arg_0.1081 = f32[2]{0} parameter(0)
  %constant.1083 = f32[] constant(-inf)
  %reduce_max.1088 = f32[] reduce(%Arg_0.1081, %constant.1083), dimensions={0}, to_apply=%region_15.1087, metadata={op_name="reduce_max" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.1082 = f32[] constant(inf)
  %reduce_min.1093 = f32[] reduce(%Arg_0.1081, %constant.1082), dimensions={0}, to_apply=%region_16.1092, metadata={op_name="reduce_min" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  ROOT %sub.1094 = f32[] subtract(%reduce_max.1088, %reduce_min.1093), metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
}

%_where_171.1102 (Arg_0.1098: pred[], Arg_1.1099: f32[], Arg_2.1100: f32[]) -> f32[] {
  %Arg_0.1098 = pred[] parameter(0)
  %Arg_1.1099 = f32[] parameter(1)
  %Arg_2.1100 = f32[] parameter(2)
  ROOT %select_n.1101 = f32[] select(%Arg_0.1098, %Arg_1.1099, %Arg_2.1100), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
}

%_linspace.1116 (Arg_0.1107: f32[], Arg_1.1108: f32[]) -> f32[2] {
  %Arg_0.1107 = f32[] parameter(0)
  %reshape.1110 = f32[1]{0} reshape(%Arg_0.1107), metadata={op_name="reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %Arg_1.1108 = f32[] parameter(1)
  %reshape.1111 = f32[1]{0} reshape(%Arg_1.1108), metadata={op_name="reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.1109 = f32[1]{0} constant({0})
  %mul.1112 = f32[1]{0} multiply(%reshape.1111, %constant.1109), metadata={op_name="mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %add.1113 = f32[1]{0} add(%reshape.1110, %mul.1112), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %broadcast_in_dim.1114 = f32[1]{0} reshape(%Arg_1.1108), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  ROOT %concatenate.1115 = f32[2]{0} concatenate(%add.1113, %broadcast_in_dim.1114), dimensions={0}, metadata={op_name="concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
}

%_where_196.1170 (Arg_0.1166: pred[128], Arg_1.1167: s32[128], Arg_2.1168: s32[128]) -> s32[128] {
  %Arg_0.1166 = pred[128]{0} parameter(0)
  %Arg_1.1167 = s32[128]{0} parameter(1)
  %Arg_2.1168 = s32[128]{0} parameter(2)
  ROOT %select_n.1169 = s32[128]{0} select(%Arg_0.1166, %Arg_1.1167, %Arg_2.1168), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
}

%_where_198.1176 (Arg_0.1172: pred[128], Arg_1.1173: s32[128], Arg_2.1174: s32[128]) -> s32[128] {
  %Arg_0.1172 = pred[128]{0} parameter(0)
  %Arg_1.1173 = s32[128]{0} parameter(1)
  %Arg_2.1174 = s32[128]{0} parameter(2)
  ROOT %select_n.1175 = s32[128]{0} select(%Arg_0.1172, %Arg_1.1173, %Arg_2.1174), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
}

%closed_call.1179 (Arg_0.1132: f32[2], Arg_1.1133: f32[128], Arg_2.1134: s32[128], Arg_3.1135: s32[128]) -> (s32[128], s32[128]) {
  %Arg_1.1133 = f32[128]{0} parameter(1)
  %ne.1159 = pred[128]{0} compare(%Arg_1.1133, %Arg_1.1133), direction=NE, metadata={op_name="ne" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.1136 = f32[] constant(nan)
  %broadcast.1137 = f32[128]{0} broadcast(%constant.1136), dimensions={}
  %constant.1138 = f32[] constant(0)
  %broadcast.1139 = f32[128]{0} broadcast(%constant.1138), dimensions={}
  %eq.1157 = pred[128]{0} compare(%Arg_1.1133, %broadcast.1139), direction=EQ, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %select_n.1158 = f32[128]{0} select(%eq.1157, %broadcast.1139, %Arg_1.1133), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %select_n.1160 = f32[128]{0} select(%ne.1159, %broadcast.1137, %select_n.1158), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %Arg_0.1132 = f32[2]{0} parameter(0)
  %Arg_2.1134 = s32[128]{0} parameter(2)
  %convert_element_type.1146 = u32[128]{0} convert(%Arg_2.1134), metadata={op_name="convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %Arg_3.1135 = s32[128]{0} parameter(3)
  %convert_element_type.1147 = u32[128]{0} convert(%Arg_3.1135), metadata={op_name="convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %add.1148 = u32[128]{0} add(%convert_element_type.1146, %convert_element_type.1147), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.1144 = u32[] constant(2)
  %div.1145 = u32[128]{0} broadcast(%constant.1144), dimensions={}, metadata={op_name="div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %div.1149 = u32[128]{0} divide(%add.1148, %div.1145), metadata={op_name="div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %convert_element_type.1150 = s32[128]{0} convert(%div.1149), metadata={op_name="convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.1142 = s32[] constant(0)
  %lt.1143 = s32[128]{0} broadcast(%constant.1142), dimensions={}, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %lt.1151 = pred[128]{0} compare(%convert_element_type.1150, %lt.1143), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.1140 = s32[] constant(2)
  %add.1141 = s32[128]{0} broadcast(%constant.1140), dimensions={}, metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %add.1152 = s32[128]{0} add(%convert_element_type.1150, %add.1141), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %select_n.1153 = s32[128]{0} select(%lt.1151, %add.1152, %convert_element_type.1150), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %broadcast_in_dim.1154 = s32[128,1]{1,0} reshape(%select_n.1153), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %gather.1155 = f32[128,1]{1,0} gather(%Arg_0.1132, %broadcast_in_dim.1154), offset_dims={1}, collapsed_slice_dims={}, start_index_map={0}, index_vector_dim=1, slice_sizes={1}, metadata={op_name="gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %squeeze.1156 = f32[128]{0} reshape(%gather.1155), metadata={op_name="squeeze" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %ne.1163 = pred[128]{0} compare(%squeeze.1156, %squeeze.1156), direction=NE, metadata={op_name="ne" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %eq.1161 = pred[128]{0} compare(%squeeze.1156, %broadcast.1139), direction=EQ, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %select_n.1162 = f32[128]{0} select(%eq.1161, %broadcast.1139, %squeeze.1156), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %select_n.1164 = f32[128]{0} select(%ne.1163, %broadcast.1137, %select_n.1162), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %lt_to.1165 = pred[128]{0} compare(%select_n.1160, %select_n.1164), direction=LT, type=TOTALORDER, metadata={op_name="lt_to" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %jit__where_.1171 = s32[128]{0} call(%lt_to.1165, %Arg_2.1134, %convert_element_type.1150), to_apply=%_where_196.1170, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %jit__where_.1177 = s32[128]{0} call(%lt_to.1165, %convert_element_type.1150, %Arg_3.1135), to_apply=%_where_198.1176, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  ROOT %tuple.1178 = (s32[128]{0}, s32[128]{0}) tuple(%jit__where_.1171, %jit__where_.1177)
}

%region_17.1185 (arg_tuple.1125: (s32[], s32[128], s32[128], f32[2], f32[128])) -> (s32[], s32[128], s32[128], f32[2], f32[128]) {
  %arg_tuple.1125 = (s32[], s32[128]{0}, s32[128]{0}, f32[2]{0}, f32[128]{0}) parameter(0)
  %get-tuple-element.1126 = s32[] get-tuple-element(%arg_tuple.1125), index=0
  %constant.1131 = s32[] constant(1)
  %add.1183 = s32[] add(%get-tuple-element.1126, %constant.1131), metadata={op_name="vmap()/while/body/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %get-tuple-element.1129 = f32[2]{0} get-tuple-element(%arg_tuple.1125), index=3
  %get-tuple-element.1130 = f32[128]{0} get-tuple-element(%arg_tuple.1125), index=4
  %get-tuple-element.1127 = s32[128]{0} get-tuple-element(%arg_tuple.1125), index=1
  %get-tuple-element.1128 = s32[128]{0} get-tuple-element(%arg_tuple.1125), index=2
  %closed_call.1180 = (s32[128]{0}, s32[128]{0}) call(%get-tuple-element.1129, %get-tuple-element.1130, %get-tuple-element.1127, %get-tuple-element.1128), to_apply=%closed_call.1179, metadata={op_name="vmap()/while/body/closed_call" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %closed_call.1181 = s32[128]{0} get-tuple-element(%closed_call.1180), index=0, metadata={op_name="vmap()/while/body/closed_call" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %closed_call.1182 = s32[128]{0} get-tuple-element(%closed_call.1180), index=1, metadata={op_name="vmap()/while/body/closed_call" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  ROOT %tuple.1184 = (s32[], s32[128]{0}, s32[128]{0}, f32[2]{0}, f32[128]{0}) tuple(%add.1183, %closed_call.1181, %closed_call.1182, %get-tuple-element.1129, %get-tuple-element.1130)
}

%region_18.1194 (arg_tuple.1186: (s32[], s32[128], s32[128], f32[2], f32[128])) -> pred[] {
  %arg_tuple.1186 = (s32[], s32[128]{0}, s32[128]{0}, f32[2]{0}, f32[128]{0}) parameter(0)
  %get-tuple-element.1188 = s32[128]{0} get-tuple-element(%arg_tuple.1186), index=1
  %get-tuple-element.1189 = s32[128]{0} get-tuple-element(%arg_tuple.1186), index=2
  %get-tuple-element.1190 = f32[2]{0} get-tuple-element(%arg_tuple.1186), index=3
  %get-tuple-element.1191 = f32[128]{0} get-tuple-element(%arg_tuple.1186), index=4
  %get-tuple-element.1187 = s32[] get-tuple-element(%arg_tuple.1186), index=0
  %constant.1192 = s32[] constant(2)
  ROOT %lt.1193 = pred[] compare(%get-tuple-element.1187, %constant.1192), direction=LT, metadata={op_name="vmap()/while/cond/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
}

%searchsorted.1200 (Arg_0.1118: f32[2], Arg_1.1119: f32[128]) -> s32[128] {
  %constant.1120 = s32[] constant(0)
  %constant.1121 = s32[] constant(0)
  %broadcast_in_dim.1122 = s32[128]{0} broadcast(%constant.1121), dimensions={}, metadata={op_name="vmap()/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.1123 = s32[] constant(2)
  %broadcast_in_dim.1124 = s32[128]{0} broadcast(%constant.1123), dimensions={}, metadata={op_name="vmap()/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %Arg_0.1118 = f32[2]{0} parameter(0)
  %Arg_1.1119 = f32[128]{0} parameter(1)
  %while.1195 = (s32[], s32[128]{0}, s32[128]{0}, f32[2]{0}, f32[128]{0}) tuple(%constant.1120, %broadcast_in_dim.1122, %broadcast_in_dim.1124, %Arg_0.1118, %Arg_1.1119), metadata={op_name="vmap()/while" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %while.1196 = (s32[], s32[128]{0}, s32[128]{0}, f32[2]{0}, f32[128]{0}) while(%while.1195), condition=%region_18.1194, body=%region_17.1185, metadata={op_name="vmap()/while" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %while.1197 = s32[] get-tuple-element(%while.1196), index=0, metadata={op_name="vmap()/while" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %while.1198 = s32[128]{0} get-tuple-element(%while.1196), index=1, metadata={op_name="vmap()/while" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  ROOT %while.1199 = s32[128]{0} get-tuple-element(%while.1196), index=2, metadata={op_name="vmap()/while" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
}

%region_19.1214 (scatter-add.1211: f32[], scatter-add.1212: f32[]) -> f32[] {
  %scatter-add.1211 = f32[] parameter(0), metadata={op_name="scatter-add"}
  %scatter-add.1212 = f32[] parameter(1), metadata={op_name="scatter-add"}
  ROOT %add.1213 = f32[] add(%scatter-add.1211, %scatter-add.1212), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
}

%_roll_static_208.1220 (Arg_0.1219: s32[1]) -> s32[1] {
  ROOT %Arg_0.1219 = s32[1]{0} parameter(0)
}

%region_20.1224 (scatter.1222: s32[], scatter.1223: s32[]) -> s32[] {
  %scatter.1222 = s32[] parameter(0), metadata={op_name="scatter"}
  ROOT %scatter.1223 = s32[] parameter(1), metadata={op_name="scatter"}
}

%cumsum_214.1228 (make_group_metadata.1227: s32[1]) -> s32[1] {
  ROOT %make_group_metadata.1227 = s32[1]{0} parameter(0), metadata={op_name="make_group_metadata"}
}

%cumsum_213.1230 (Arg_0.1226: s32[1]) -> s32[1] {
  %Arg_0.1226 = s32[1]{0} parameter(0)
  ROOT %make_group_metadata.1229 = s32[1]{0} call(%Arg_0.1226), to_apply=%cumsum_214.1228, metadata={op_name="make_group_metadata" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
}

%region_21.1239 (scatter-add.1236: s32[], scatter-add.1237: s32[]) -> s32[] {
  %scatter-add.1236 = s32[] parameter(0), metadata={op_name="scatter-add"}
  %scatter-add.1237 = s32[] parameter(1), metadata={op_name="scatter-add"}
  ROOT %add.1238 = s32[] add(%scatter-add.1236, %scatter-add.1237), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
}

%region_22.1264 (reduce_and.1261: pred[], reduce_and.1262: pred[]) -> pred[] {
  %reduce_and.1261 = pred[] parameter(0), metadata={op_name="reduce_and"}
  %reduce_and.1262 = pred[] parameter(1), metadata={op_name="reduce_and"}
  ROOT %reduce_and.1263 = pred[] and(%reduce_and.1261, %reduce_and.1262), metadata={op_name="reduce_and" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
}

%_take_221.1268 (Arg_0.1243: s32[1], Arg_1.1244: s32[128]) -> s32[128] {
  %Arg_1.1244 = s32[128]{0} parameter(1)
  %constant.1252 = s32[] constant(0)
  %lt.1253 = s32[128]{0} broadcast(%constant.1252), dimensions={}, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %lt.1254 = pred[128]{0} compare(%Arg_1.1244, %lt.1253), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %constant.1249 = s32[] constant(1)
  %add.1250 = s32[128]{0} broadcast(%constant.1249), dimensions={}, metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %add.1255 = s32[128]{0} add(%Arg_1.1244, %add.1250), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %jit__where_.1256 = s32[128]{0} call(%lt.1254, %add.1255, %Arg_1.1244), to_apply=%_where_129.976, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %broadcast_in_dim.1257 = s32[128,1]{1,0} reshape(%jit__where_.1256), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %constant.1247 = s32[] constant(0)
  %broadcast.1248 = s32[128,1]{1,0} broadcast(%constant.1247), dimensions={}
  %ge.1258 = pred[128,1]{1,0} compare(%broadcast_in_dim.1257, %broadcast.1248), direction=GE, metadata={op_name="ge" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %le.1259 = pred[128,1]{1,0} compare(%broadcast_in_dim.1257, %broadcast.1248), direction=LE, metadata={op_name="le" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %and.1260 = pred[128,1]{1,0} and(%ge.1258, %le.1259), metadata={op_name="and" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %constant.1251 = pred[] constant(true)
  %reduce_and.1265 = pred[128]{0} reduce(%and.1260, %constant.1251), dimensions={1}, to_apply=%region_22.1264, metadata={op_name="reduce_and" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %Arg_0.1243 = s32[1]{0} parameter(0)
  %gather.1266 = s32[128]{0} gather(%Arg_0.1243, %broadcast_in_dim.1257), offset_dims={}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1}, metadata={op_name="gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %constant.1245 = s32[] constant(-2147483648)
  %broadcast_in_dim.1246 = s32[128]{0} broadcast(%constant.1245), dimensions={}, metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  ROOT %select_n.1267 = s32[128]{0} select(%reduce_and.1265, %gather.1266, %broadcast_in_dim.1246), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
}

%region_23.1276 (reduce_sum.1273: s32[], reduce_sum.1274: s32[]) -> s32[] {
  %reduce_sum.1273 = s32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1274 = s32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1275 = s32[] add(%reduce_sum.1273, %reduce_sum.1274), metadata={op_name="reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=244 source_end_line=244 source_column=24 source_end_column=55}
}

%remainder_230.1298 (Arg_0.1284: s32[], Arg_1.1285: s32[]) -> s32[] {
  %Arg_0.1284 = s32[] parameter(0)
  %Arg_1.1285 = s32[] parameter(1)
  %constant.1287 = s32[] constant(0)
  %eq.1288 = pred[] compare(%Arg_1.1285, %constant.1287), direction=EQ, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  %constant.1286 = s32[] constant(1)
  %jit__where_.1289 = s32[] call(%eq.1288, %constant.1286, %Arg_1.1285), to_apply=%_where_158.1059, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  %rem.1290 = s32[] remainder(%Arg_0.1284, %jit__where_.1289), metadata={op_name="rem" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  %lt.1292 = pred[] compare(%rem.1290, %constant.1287), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  %lt.1293 = pred[] compare(%jit__where_.1289, %constant.1287), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  %ne.1294 = pred[] compare(%lt.1292, %lt.1293), direction=NE, metadata={op_name="ne" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  %ne.1291 = pred[] compare(%rem.1290, %constant.1287), direction=NE, metadata={op_name="ne" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  %and.1295 = pred[] and(%ne.1294, %ne.1291), metadata={op_name="and" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  %add.1296 = s32[] add(%rem.1290, %jit__where_.1289), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  ROOT %select_n.1297 = s32[] select(%and.1295, %add.1296, %rem.1290), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
}

%_roll_dynamic.1306 (Arg_0.1279: s32[128], Arg_1.1280: s32[]) -> s32[128] {
  %Arg_0.1279 = s32[128]{0} parameter(0)
  %concatenate.1300 = s32[256]{0} concatenate(%Arg_0.1279, %Arg_0.1279), dimensions={0}, metadata={op_name="concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  %constant.1283 = s32[] constant(128)
  %Arg_1.1280 = s32[] parameter(1)
  %jit_remainder_.1299 = s32[] call(%Arg_1.1280, %constant.1283), to_apply=%remainder_230.1298, metadata={op_name="jit(remainder)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  %sub.1301 = s32[] subtract(%constant.1283, %jit_remainder_.1299), metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  %constant.1282 = s32[] constant(0)
  %lt.1302 = pred[] compare(%sub.1301, %constant.1282), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  %constant.1281 = s32[] constant(256)
  %add.1303 = s32[] add(%sub.1301, %constant.1281), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  %select_n.1304 = s32[] select(%lt.1302, %add.1303, %sub.1301), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  ROOT %dynamic_slice.1305 = s32[128]{0} dynamic-slice(%concatenate.1300, %select_n.1304), dynamic_slice_sizes={128}, metadata={op_name="dynamic_slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
}

%_where_242.1321 (Arg_0.1316: pred[128], Arg_1.1317: s32[128], Arg_2.1318: s32[]) -> s32[128] {
  %Arg_0.1316 = pred[128]{0} parameter(0)
  %Arg_1.1317 = s32[128]{0} parameter(1)
  %Arg_2.1318 = s32[] parameter(2)
  %broadcast_in_dim.1319 = s32[128]{0} broadcast(%Arg_2.1318), dimensions={}, metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=253 source_end_line=253 source_column=16 source_end_column=60}
  ROOT %select_n.1320 = s32[128]{0} select(%Arg_0.1316, %Arg_1.1317, %broadcast_in_dim.1319), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=253 source_end_line=253 source_column=16 source_end_column=60}
}

%region_24.1326 (reduce_sum.1323: s32[], reduce_sum.1324: s32[]) -> s32[] {
  %reduce_sum.1323 = s32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1324 = s32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1325 = s32[] add(%reduce_sum.1323, %reduce_sum.1324), metadata={op_name="reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=254 source_end_line=254 source_column=14 source_end_column=31}
}

%gmm.1329 (Arg_0.911: bf16[128,2048], Arg_1.912: bf16[128,384,2048], Arg_2.913: s32[128], Arg_3.914: s32[]) -> bf16[128,384] {
  %iota.1310 = s32[128]{0} iota(), iota_dimension=0, metadata={op_name="iota" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=251 source_end_line=251 source_column=9 source_end_column=48}
  %Arg_3.914 = s32[] parameter(3)
  %constant.934 = s32[] constant(128)
  %add.938 = s32[] add(%Arg_3.914, %constant.934), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=116 source_end_line=116 source_column=14 source_end_column=46}
  %constant.933 = s32[] constant(1)
  %sub.939 = s32[] subtract(%add.938, %constant.933), metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=116 source_end_line=116 source_column=14 source_end_column=46}
  %le.1311 = s32[128]{0} broadcast(%sub.939), dimensions={}, metadata={op_name="le" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=252 source_end_line=252 source_column=38 source_end_column=55}
  %le.1312 = pred[128]{0} compare(%iota.1310, %le.1311), direction=LE, metadata={op_name="le" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=252 source_end_line=252 source_column=38 source_end_column=55}
  %ge.1313 = s32[128]{0} broadcast(%Arg_3.914), dimensions={}, metadata={op_name="ge" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=252 source_end_line=252 source_column=57 source_end_column=76}
  %ge.1314 = pred[128]{0} compare(%iota.1310, %ge.1313), direction=GE, metadata={op_name="ge" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=252 source_end_line=252 source_column=57 source_end_column=76}
  %and.1315 = pred[128]{0} and(%le.1312, %ge.1314), metadata={op_name="and" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=252 source_end_line=252 source_column=22 source_end_column=77}
  %Arg_2.913 = s32[128]{0} parameter(2)
  %constant.924 = s32[] constant(0)
  %broadcast.925 = s32[128]{0} broadcast(%constant.924), dimensions={}
  %eq.986 = pred[128]{0} compare(%Arg_2.913, %broadcast.925), direction=EQ, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=154 source_end_line=154 source_column=34 source_end_column=50}
  %constant.932 = s32[] constant(0)
  %jit_cumsum_.951 = s32[128]{0} call(%Arg_2.913), to_apply=%cumsum.950, metadata={op_name="jit(cumsum)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=126 source_end_line=126 source_column=15 source_end_column=38}
  %constant.928 = s32[] constant(128)
  %broadcast.929 = s32[128]{0} broadcast(%constant.928), dimensions={}
  %add.953 = s32[128]{0} add(%jit_cumsum_.951, %broadcast.929), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=25 source_end_column=40}
  %constant.926 = s32[] constant(1)
  %broadcast.927 = s32[128]{0} broadcast(%constant.926), dimensions={}
  %sub.954 = s32[128]{0} subtract(%add.953, %broadcast.927), metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=25 source_end_column=40}
  %jit_floor_divide_.979 = s32[128]{0} call(%sub.954, %constant.934), to_apply=%floor_divide.978, metadata={op_name="jit(floor_divide)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  %mul.980 = s32[128]{0} multiply(%jit_floor_divide_.979, %broadcast.929), metadata={op_name="mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  %constant.930 = s32[1]{0} constant({0})
  %slice.981 = s32[127]{0} slice(%jit_cumsum_.951), slice={[0:127]}, metadata={op_name="slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=144 source_end_line=144 source_column=38 source_end_column=53}
  %concatenate.982 = s32[128]{0} concatenate(%constant.930, %slice.981), dimensions={0}, metadata={op_name="concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=143 source_end_line=145 source_column=17 source_end_column=3}
  %jit_floor_divide_.983 = s32[128]{0} call(%concatenate.982, %constant.934), to_apply=%floor_divide.978, metadata={op_name="jit(floor_divide)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=146 source_end_line=146 source_column=25 source_end_column=43}
  %mul.984 = s32[128]{0} multiply(%jit_floor_divide_.983, %broadcast.929), metadata={op_name="mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=146 source_end_line=146 source_column=25 source_end_column=43}
  %sub.985 = s32[128]{0} subtract(%mul.980, %mul.984), metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=153 source_end_line=153 source_column=24 source_end_column=65}
  %jit__where_.993 = s32[128]{0} call(%eq.986, %constant.932, %sub.985), to_apply=%_where_135.992, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=154 source_end_line=154 source_column=24 source_end_column=75}
  %jit_floor_divide_.994 = s32[128]{0} call(%jit__where_.993, %constant.934), to_apply=%floor_divide.978, metadata={op_name="jit(floor_divide)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=174 source_end_line=174 source_column=16 source_end_column=41}
  %jit__where_.1322 = s32[128]{0} call(%and.1315, %jit_floor_divide_.994, %constant.932), to_apply=%_where_242.1321, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=253 source_end_line=253 source_column=16 source_end_column=60}
  %reduce_sum.1327 = s32[] reduce(%jit__where_.1322, %constant.932), dimensions={0}, to_apply=%region_24.1326, metadata={op_name="reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=254 source_end_line=254 source_column=14 source_end_column=31}
  %concatenate.952 = s32[129]{0} concatenate(%constant.930, %jit_cumsum_.951), dimensions={0}, metadata={op_name="concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=127 source_end_line=127 source_column=18 source_end_column=78}
  %iota.995 = s32[128]{0} iota(), iota_dimension=0, metadata={op_name="iota" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=188 source_end_line=188 source_column=6 source_end_column=45}
  %jit__roll_static_.1001 = s32[128]{0} call(%jit_floor_divide_.994), to_apply=%_roll_static.1000, metadata={op_name="jit(_roll_static)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %scatter.1005 = s32[128]{0} scatter(%jit__roll_static_.1001, %constant.930, %constant.932), update_window_dims={}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=0, indices_are_sorted=true, unique_indices=true, to_apply=%region_12.1004, metadata={op_name="scatter" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %jit_cumsum_.1006 = s32[128]{0} call(%scatter.1005), to_apply=%cumsum.950, metadata={op_name="jit(cumsum)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %lt.1007 = pred[128]{0} compare(%jit_cumsum_.1006, %broadcast.925), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %add.1008 = s32[128]{0} add(%jit_cumsum_.1006, %broadcast.929), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %select_n.1009 = s32[128]{0} select(%lt.1007, %add.1008, %jit_cumsum_.1006), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %broadcast_in_dim.1010 = s32[128,1]{1,0} reshape(%select_n.1009), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %scatter-add.1015 = s32[128]{0} scatter(%broadcast.925, %broadcast_in_dim.1010, %broadcast.927), update_window_dims={}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=1, to_apply=%region_13.1014, metadata={op_name="scatter-add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %jit_cumsum_.1016 = s32[128]{0} call(%scatter-add.1015), to_apply=%cumsum.950, metadata={op_name="jit(cumsum)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %sub.1017 = s32[128]{0} subtract(%jit_cumsum_.1016, %broadcast.927), metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %jit__take_.1046 = s32[128]{0} call(%iota.995, %sub.1017), to_apply=%_take_147.1045, metadata={op_name="jit(_take)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %lt.1270 = s32[128]{0} broadcast(%Arg_3.914), dimensions={}, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=244 source_end_line=244 source_column=25 source_end_column=48}
  %lt.1271 = pred[128]{0} compare(%jit__take_.1046, %lt.1270), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=244 source_end_line=244 source_column=25 source_end_column=48}
  %convert_element_type.1272 = s32[128]{0} convert(%lt.1271), metadata={op_name="convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=244 source_end_line=244 source_column=24 source_end_column=55}
  %reduce_sum.1277 = s32[] reduce(%convert_element_type.1272, %constant.932), dimensions={0}, to_apply=%region_23.1276, metadata={op_name="reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=244 source_end_line=244 source_column=24 source_end_column=55}
  %neg.1278 = s32[] negate(%reduce_sum.1277), metadata={op_name="neg" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=40 source_end_column=60}
  %jit__roll_dynamic_.1307 = s32[128]{0} call(%jit__take_.1046, %neg.1278), to_apply=%_roll_dynamic.1306, metadata={op_name="jit(_roll_dynamic)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  %constant.935 = f32[] constant(0)
  %broadcast.936 = f32[2]{0} broadcast(%constant.935), dimensions={}
  %slice.1047 = s32[128]{0} slice(%concatenate.952), slice={[0:128]}, metadata={op_name="slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
  %jit_remainder_.1073 = s32[128]{0} call(%slice.1047, %constant.934), to_apply=%remainder.1072, metadata={op_name="jit(remainder)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
  %eq.1074 = pred[128]{0} compare(%jit_remainder_.1073, %broadcast.925), direction=EQ, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=6 source_end_column=36}
  %eq.1075 = pred[128]{0} compare(%Arg_2.913, %broadcast.925), direction=EQ, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=38 source_end_column=54}
  %or.1076 = pred[128]{0} or(%eq.1074, %eq.1075), metadata={op_name="or" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=212 source_end_line=214 source_column=22 source_end_column=3}
  %slice.1077 = s32[128]{0} slice(%concatenate.952), slice={[0:128]}, metadata={op_name="slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=222 source_end_line=222 source_column=34 source_end_column=52}
  %jit_floor_divide_.1078 = s32[128]{0} call(%slice.1077, %constant.934), to_apply=%floor_divide.978, metadata={op_name="jit(floor_divide)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=222 source_end_line=222 source_column=34 source_end_column=52}
  %jit__where_.1079 = s32[128]{0} call(%or.1076, %constant.933, %jit_floor_divide_.1078), to_apply=%_where_135.992, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=221 source_end_line=223 source_column=21 source_end_column=3}
  %convert_element_type.1080 = f32[128]{0} convert(%jit__where_.1079), metadata={op_name="convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %jit__ptp_.1096 = f32[] call(%broadcast.936), to_apply=%_ptp.1095, metadata={op_name="jit(_ptp)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.931 = f32[] constant(0)
  %eq.1097 = pred[] compare(%jit__ptp_.1096, %constant.931), direction=EQ, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.921 = f32[] constant(-0.5)
  %jit__where_.1103 = f32[] call(%eq.1097, %constant.921, %constant.931), to_apply=%_where_171.1102, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %jit__ptp_.1104 = f32[] call(%broadcast.936), to_apply=%_ptp.1095, metadata={op_name="jit(_ptp)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %eq.1105 = pred[] compare(%jit__ptp_.1104, %constant.931), direction=EQ, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.920 = f32[] constant(0.5)
  %jit__where_.1106 = f32[] call(%eq.1105, %constant.920, %constant.931), to_apply=%_where_171.1102, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %jit__linspace_.1117 = f32[2]{0} call(%jit__where_.1103, %jit__where_.1106), to_apply=%_linspace.1116, metadata={op_name="jit(_linspace)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %dynamic_slice.1202 = f32[1]{0} slice(%jit__linspace_.1117), slice={[1:2]}, metadata={op_name="dynamic_slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %squeeze.1203 = f32[] reshape(%dynamic_slice.1202), metadata={op_name="squeeze" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %eq.1204 = f32[128]{0} broadcast(%squeeze.1203), dimensions={}, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %eq.1205 = pred[128]{0} compare(%convert_element_type.1080, %eq.1204), direction=EQ, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %jit_searchsorted_.1201 = s32[128]{0} call(%jit__linspace_.1117, %convert_element_type.1080), to_apply=%searchsorted.1200, metadata={op_name="jit(searchsorted)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %jit__where_.1206 = s32[128]{0} call(%eq.1205, %constant.933, %jit_searchsorted_.1201), to_apply=%_where_135.992, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %lt.1207 = pred[128]{0} compare(%jit__where_.1206, %broadcast.925), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.918 = s32[] constant(2)
  %add.919 = s32[128]{0} broadcast(%constant.918), dimensions={}, metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %add.1208 = s32[128]{0} add(%jit__where_.1206, %add.919), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %select_n.1209 = s32[128]{0} select(%lt.1207, %add.1208, %jit__where_.1206), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %broadcast_in_dim.1210 = s32[128,1]{1,0} reshape(%select_n.1209), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.922 = f32[] constant(1)
  %broadcast_in_dim.923 = f32[128]{0} broadcast(%constant.922), dimensions={}, metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %scatter-add.1215 = f32[2]{0} scatter(%broadcast.936, %broadcast_in_dim.1210, %broadcast_in_dim.923), update_window_dims={}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=1, to_apply=%region_19.1214, metadata={op_name="scatter-add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %slice.1216 = f32[1]{0} slice(%scatter-add.1215), slice={[1:2]}, metadata={op_name="slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.917 = f32[1]{0} constant({1})
  %add.1217 = f32[1]{0} add(%slice.1216, %constant.917), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %convert_element_type.1218 = s32[1]{0} convert(%add.1217), metadata={op_name="convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=234 source_end_line=234 source_column=6 source_end_column=35}
  %jit__roll_static_.1221 = s32[1]{0} call(%convert_element_type.1218), to_apply=%_roll_static_208.1220, metadata={op_name="jit(_roll_static)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %scatter.1225 = s32[1]{0} scatter(%jit__roll_static_.1221, %constant.930, %constant.932), update_window_dims={}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=0, indices_are_sorted=true, unique_indices=true, to_apply=%region_20.1224, metadata={op_name="scatter" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %jit_cumsum_.1231 = s32[1]{0} call(%scatter.1225), to_apply=%cumsum_213.1230, metadata={op_name="jit(cumsum)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %lt.1232 = pred[1]{0} compare(%jit_cumsum_.1231, %constant.930), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %constant.916 = s32[1]{0} constant({128})
  %add.1233 = s32[1]{0} add(%jit_cumsum_.1231, %constant.916), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %select_n.1234 = s32[1]{0} select(%lt.1232, %add.1233, %jit_cumsum_.1231), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %broadcast_in_dim.1235 = s32[1,1]{1,0} reshape(%select_n.1234), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %constant.915 = s32[1]{0} constant({1})
  %scatter-add.1240 = s32[128]{0} scatter(%broadcast.925, %broadcast_in_dim.1235, %constant.915), update_window_dims={}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=1, to_apply=%region_21.1239, metadata={op_name="scatter-add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %jit_cumsum_.1241 = s32[128]{0} call(%scatter-add.1240), to_apply=%cumsum.950, metadata={op_name="jit(cumsum)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %sub.1242 = s32[128]{0} subtract(%jit_cumsum_.1241, %broadcast.927), metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %jit__take_.1269 = s32[128]{0} call(%constant.930, %sub.1242), to_apply=%_take_221.1268, metadata={op_name="jit(_take)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %neg.1308 = s32[] negate(%reduce_sum.1277), metadata={op_name="neg" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=246 source_end_line=246 source_column=42 source_end_column=62}
  %jit__roll_dynamic_.1309 = s32[128]{0} call(%jit__take_.1269, %neg.1308), to_apply=%_roll_dynamic.1306, metadata={op_name="jit(_roll_dynamic)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=246 source_end_line=246 source_column=15 source_end_column=71}
  %broadcast_in_dim.937 = s32[1]{0} reshape(%Arg_3.914), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=358 source_end_line=358 source_column=19 source_end_column=37}
  %Arg_0.911 = bf16[128,2048]{1,0} parameter(0)
  %Arg_1.912 = bf16[128,384,2048]{2,1,0} parameter(1)
  ROOT %pallas_call.1328 = bf16[128,384]{1,0} custom-call(%reduce_sum.1327, %concatenate.952, %jit__roll_dynamic_.1307, %jit__roll_dynamic_.1309, %broadcast_in_dim.937, /*index=5*/%Arg_0.911, %Arg_1.912), custom_call_target="tpu_custom_call", operand_layout_constraints={s32[], s32[129]{0}, s32[128]{0}, s32[128]{0}, s32[1]{0}, bf16[128,2048]{1,0}, bf16[128,384,2048]{2,1,0}}, metadata={op_name="pallas_call" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=547 source_end_line=553 source_column=8 source_end_column=3}, backend_config={"custom_call_config": {"body": "TUzvUgFNTElSMjIuMC4wZ2l0AAFDCQEDBQcBAwkDLwsNDxETFRcZGx0fISMlJykrLS8xMzU3A04GtgUvAfkHCxcLCxMLFxMTExcLCwsTExMTCxMTDwsXFxcXFxcbCwsLCxMXCzNlhQsLCxcLDwsLCxMTDwsLCwsTCxcLExMTEwsLFw8TCwsTEw8TExczGxMTExMTExMXExcXFwsPGwsPC0MLFwulC3MLDwsLCxcbC1MbC3MbC1MbGwsbBQthYZGNKgIBqgMTExcLHwsnEwsfEwsnEwsnEwsrCxMLJxMLHxMLGxcLGw8TExMfDxMTEx8LFwsXCxMTHxMTFwsfExMTHw8TDx8PExMTHxMPJw8TExMfExMTExMPExMTHw8THx8LFwsTEycLCwsLExMTJw8LUwsTExMTHxMnEx8TExMTEw8TExMfFw8TExMfExMTHxMTEx8XEwsXCxMTHxsLIxcLFwsTEx8TExMfCxcLExMfFw8LFwsTEx8XDxcLFwsTEx8TExMfExMTExMTDxMTEx8TExMTHxcLFwsTEycTExMTHxMTEx8XDwsXCxMTHxMTEx8HBVlZAS8PBx8fDx8bBwsfHwcfHycrJycjHzszNwIqIB8FOQMDG5oCBTsFPR1hpgMFPxXKA9IDHQdOAxUxIgIdByYDAwMbhgIFQQVDBUUdB14DFaX+BB1hbgUdYZ4FBUcdjQIDHY0iAxVHlwVJHRoCHgIdJgIqAh0yAjYCHT4CQgIdSgJOAh1aAl4CAwOuAq4FBUsFTQVPBVEdPx4DHW4DcgMFUwMHS12qA64DsgO2A2FmZmluZV9tYXA8KGQwKSAtPiAoZDApPgBhZmZpbmVfbWFwPChkMCwgZDEpIC0+IChkMCwgZDEpPgAFVQVXBVkdZgJqAgVbEREABV0FXwVhHQfuBB0HGgURCQUFYwVlBWcNKx0HBgIFaR1yAnYCBWsdB4oCHQeeAh0HzgIdg+ICBW0FbwMDQfICFYsTHT/+AgVxBXMDA0FpHYMGAxVHExUxNgMVYgMtAwMbagMDB4YDAgKKA12OA10DA5IDsgUdX5YDHQe6Ax0d1gMdB/IDHV8KBB0HGgQdByoEHUIERgQdX4IEHZIElgQdsgS2BB2GBYoFBXUVi5cDBb/BJ8MFdxEJIQV5Aw/HyS/Lz9HT1ddpJ9nb3QV7AQf//f0NKWFmZmluZV9tYXA8KGQwLCBkMSwgZDIpIC0+IChkMCwgZDEsIGQyKT4ABX0jCQcxAQAAAAAAAAAAAAAAAAAAgAEAAAAAAAAABX8RCREFgQWDBYUBB9/l6wMFU+FV4wlrIwkFIYAAAAAAAAAAAAgAAAAAAAADBVPnVekJbSMJBzEBAAAAAAAAAAAGAAAAAAAAAAgAAAAAAAADBVPtVe8JbyMJBSGAAAAAAAAAAAAGAAAAAAAAAwUvcSdrAwUv9SdtDS0DBS9xJ28jdHB1Lm1lbW9yeV9zcGFjZTx2bWVtPgAjdHB1Lm1lbW9yeV9zcGFjZTxzbWVtPgAjdHB1LmRpbWVuc2lvbl9zZW1hbnRpY3M8YXJiaXRyYXJ5PgAjdHB1LmRpbWVuc2lvbl9zZW1hbnRpY3M8cGFyYWxsZWw+ACN0cHUuZG90X2RpbWVuc2lvbl9udW1iZXJzPFsxXSwgWzFdLCBbMF0sIFswXSwgWzAsIDAsIDEsIDBdLCBbXSwgW10+AB0JCgIVDgITHRICFgIFhy0DB84HFz0FiS0DCY4IEaYIBxUzLgIFiy1XCcEjzTkVNToCBY0tVwk6BSNSBWEVN0YCBY8tVwk2Bh8+Bn8VOVYCBZEtUgIJAgQjFgQTBZMVO2ICBZUtdQn+IkVSIxsVWW4CBZctdQeeHz+dFXd6AgWZLXkHmR9nHX4CggIFmy15B10faREBAR0JjgIVkgITHVuWAi0DB7YHFzsRAwEdCaICFaYCEx1bqgItAwe2B0FfBZ0dtgK6AgWfHb4CwgIFoRXGAhMdW8oCLQMHtgcXXx0J0gIV1gITHdoC3gIFoy0DB4IHFz0dheYCFeoCEx0/7gItAwdiBhsrEQkBHUP6Ah1FiS0DB2IGCy0dj4kdhQoDFQ4DEx0/EgMtAwdeBxE1HUMaAx1FlS0DCVoHCWoHCx2PlR0JKgMVLgMtHR0yAy0DByoHJzcVMzoDFTU+AxU3QgMVOUYDFTtKAxVZdx0JUgMVVgMtHR1aAy0DBy4HJzcdCZkdHWYDLQMHMgcNLSUFCQAAAAAFpR12A3oDBacVfgMtHR2CAy0DCTIHNUYHDwWpBasFrQWvHUuaAxWeAy0dHaIDLQMJMgcNRgcPHWOZBbEjAQkhAQAAAAEAAAACAAAAAAAAAAWzIwEBAR0JvgMVwgMPHQ3GAy0DB1oEGz8dGc4DLQMJygYb3gYPFaXaAy0DB1IHES0VR94DFTHiAxUz5gMVNeoDFTfuAxU5Ox0J9gMV+gMPHQ3+Ay0DB14EIU8DAxsGBBEBBR1LDgQVEgQPHQ0WBC0DB2IEOVEdCR4EFSIEDx0NJgQtAwdiBB1THQkuBBUyBA8dDTYELQMHZgQTOQMDGz4EEQECBAW1HUoETgQFtxVSBA8dDVYELQMHZgQTQwMDXgRiBAW5IwEDCQAAAAAdagRuBAW7HXIEdgQFvRV6BA8dDX4ELQMHagQTcx1LhgQVigQPHQ2OBC0DB2oEE4EFvx2aBJ4EBcEVogQPHQ2mBC0DB24EM1kDA0GuBBEJFQXDHboEvgQFxRXCBA8dDcYELQMHbgRdfQMDQc4EEQkJHdYE2gQFxx3eBOIEBckV5gQPHQ3qBC0DB24EE38dCfIEFfYEIR0Z+gQtAwfiBiNDFUcCBRUxBgUVMwoFFTUOBRU3EgUVORYFFTtZHQkeBRUiBSEdGSYFLQMH6gY/Tx1DLgUdRTIFFTYFIR0ZOgUtAwfqBj93HUIFRgUFyx1KBU4FBc0VUgUhHRlWBS0DCeYGI+4GDx1DXgUdRWIFFWYFIR0ZagUtAwfuBhFNHWNyBRV2BSEdGXoFLQMH5gYNHQMDG4IFExcBBc8djgWSBQXRFZYFux25mgUtAwdqBjNpHWOiBRWmBbsduaoFLQMHagYNLSNhcml0aC5vdmVyZmxvdzxub25lPgAjYXJpdGguZmFzdG1hdGg8bm9uZT4AAQICAycFAgQCMBcX+wMCBAFPAQIEF/sDCgQBTxf7AwUBTwcBCScFAgQCMAEnBQIEAjAPCycFAgQCQA8nBQIEAjARF/kFAgQCQA9RF/kHBQIwAkAPzRf5BQIEAjAPURf5BQIEAjAXUScHBQIwAkAPJwUCMAJADwUXAQEBCwcHDR0fISMBBQ8BAQELBwcNBQEBBQ8BAQELBwcNBwEBAQQWDwUBEQG9BwMBEQ8RAcUHAys3FwEBAQEBAQsBBwEHAQ0BHQEfASEBIwEDA4EXAwENB4GHAxEFBRcZBvYCAwEDGQMDKRcDAQ0HKZEDEQUbHRsUKQMfCQMPJQMDt34FAxcXBrcDBQMrAwMlBQMDAwMlBQMDBQYlAwUHFS8xBwYlAwUDMwcGJQMFAy0TBSVNCTcVLzEVACkDAQUVACkDA5MXAwENB5OHAxEFBSEZBhYDAwEDIwMDKxcDAQ0HK5EDEQUlJxsUKwMpCQNt5QMDFQUDAwMDFQUDAwUGFQMZBw8rLQcGFQMZAy8DAxEFAwMDAxEFAwMDAxEFAwMFBhEDJQkRMzU3BwYRAycDOQMDHwUDAwMDHwUDAwUGHwMFBxU9PwMDSZsDBR0HSZ0DBQcxO0MfB6GfAwUFQUUDAwsFAwMDAwsFAwMFBgsDBQcVSUsHBgsDBQNNBwYLAwUDRxMFC00JURVJSwsGowMDAwMJBqMDAQUJUwsGpwMDA1UJBqcDAQUHVwMDqQIEAwEhB6k9AwEFVVsLBqsDAwNdCQarAwEFB18LBq0DAwMDCQatAwEFC2MDA686BAMBJQevPQMBBWVnJwNmBFoEAxMXBrEDEwNpIQexPQMTBWttFwazAxMDWQ0Hs6oEAxsFb3EXBrUDEwNhDQe1ygQDGwVvdSkG0gQDGwVzdwMDZQUDAwMDZQUDAwUGZQMFBxV7fQMDZwUDAwMDZwUDAwUGZwMVBxOBgysGKgUDBQOFLQY+BQMFB3l/hy8GWgUDFQOJAwMjBQMDAwMjBQMDBQYjAxUHE42PBwYjAxUDkQcGIwMVA4sTBSNNCZUTjY8VACsDKVkDAxUFAwMDAxUFAwMFBhUDGQcPKy0HBhUDGQMvAwMRBQMDAwMRBQMDAwMRBQMDBQYRAyUJETM1NwcGEQMnAzkDAx8FAwMDAx8FAwMFBh8DBQcVPT8DA0mbAwUdB0mdAwUHMTtDHwehnwMFBUFFAwMLBQMDAwMLBQMDBQYLAwUHFUlLBwYLAwUDTQcGCwMFA0cTBQtNCVEVSUsVACsRAAEPEQHxBwMVEw8BAQEBAQELAQcBBwENAQsGfwMDAwMJBn8DAQULDwMDARcDAREEAQURBQ8RAfMHAxsfDwEBAQEBAQsBBwEHAQ0BCwZ7AwMDAwkGewMBBQkPAwN9BQMDCQZ9AwEFDRMjB7ICPQMBBREVAwMBFwMBEQQBBxcBBQ8RAfcHAxUTDwEBAQEBAQsBBwEHAQ0BCwZzAwMDAwkGcwMBBQsPAwMBFwMBEQQBBREBBgMBBQEA+h/TIyUTFQkLBwkHCQsNFwkLESkTHR0lGRtHCQsdIysxLQYCSTUnVQlHHQsjISMpDy1PCw0HCdnzGRkZCw0LR+UdJQkrLRUpHRNJDVUhCQv3GxsXFxMXFxcXFw8ZIxUjGRUXIxklGR8PDQkdEWJ1aWx0aW4Ac3RhYmxlX21vc2FpYwB0cHUAYXJpdGgAbW9kdWxlAGFyaXRoLmNvbnN0YW50AHZlY3Rvci5sb2FkAHZlY3Rvci5zaGFwZV9jYXN0AG1lbXJlZi5sb2FkAGFyaXRoLmluZGV4X2Nhc3QAYXJpdGguY21waQBmdW5jLmZ1bmMAZnVuYy5yZXR1cm4AdHB1LnZlY3Rvcl9zdG9yZQBzY2YueWllbGQAdmVjdG9yLmJyb2FkY2FzdABhcml0aC5leHR1aQBzY2YuaWYAdHB1Lm1hdG11bABhcml0aC5hZGRmAGFyaXRoLmFkZGkAYXJpdGguc3ViaQBhcml0aC5tdWxpAHRwdS5pb3RhAGFyaXRoLmFuZGkAYXJpdGguZXh0ZgBhcml0aC5zZWxlY3QAYXJpdGgudHJ1bmNmAC9ob21lL2Vwb3JhdC9iZW5jaG1hcmtpbmdfcXdlbl9vbW5pX3RwdS8udmVudi9saWIvcHl0aG9uMy4xMS9zaXRlLXBhY2thZ2VzL2pheC9leHBlcmltZW50YWwvcGFsbGFzL29wcy90cHUvbWVnYWJsb3gvZ21tLnB5AGdldDoAZ2V0AF9nZXRfc3RvcmVfbWFzawBnbW0uPGxvY2Fscz4ua2VybmVsLjxsb2NhbHM+Ll9zdG9yZV9hY2N1bQB2YWx1ZQBnbW0uPGxvY2Fscz4ua2VybmVsLjxsb2NhbHM+Ll9hY2N1bQBzeW1fbmFtZQBmdW5jdGlvbl90eXBlAGdtbS48bG9jYWxzPi5rZXJuZWwAcHJlZGljYXRlAGNvbnZlcnRfZWxlbWVudF90eXBlOgBjb252ZXJ0X2VsZW1lbnRfdHlwZQBhZGQAdHJhbnNmb3JtX2luZGljZXMAd2luZG93X2JvdW5kcwAvaG9tZS9lcG9yYXQvYmVuY2htYXJraW5nX3F3ZW5fb21uaV90cHUvLnZlbnYvbGliL3B5dGhvbjMuMTEvc2l0ZS1wYWNrYWdlcy90cHVfaW5mZXJlbmNlL2xheWVycy92bGxtL2Z1c2VkX21vZS5weQBnbW0uPGxvY2Fscz4ucmhzX3RyYW5zZm9ybV9pbmRpY2VzAGFkZDoAc3dhcDoAc3dhcAB0cmFuc2Zvcm1fMAB0cmFuc2Zvcm1fMQB0cmFuc2Zvcm1fMgAvaG9tZS9lcG9yYXQvYmVuY2htYXJraW5nX3F3ZW5fb21uaV90cHUvLnZlbnYvbGliL3B5dGhvbjMuMTEvc2l0ZS1wYWNrYWdlcy92bGxtL21vZGVsX2V4ZWN1dG9yL2xheWVycy9mdXNlZF9tb2UvbGF5ZXIucHkAL2hvbWUvZXBvcmF0L2JlbmNobWFya2luZ19xd2VuX29tbmlfdHB1Ly52ZW52L2xpYi9weXRob24zLjExL3NpdGUtcGFja2FnZXMvdmxsbS9tb2RlbF9leGVjdXRvci9jdXN0b21fb3AucHkAZXE6AGVxAGNvbmQ6AGNvbmQAZ21tLjxsb2NhbHM+Lmtlcm5lbC48bG9jYWxzPi5femVyb19hY2MAc3RhYmxlX21vc2FpYy52ZXJzaW9uAGtlcm5lbABkaW1lbnNpb25fc2VtYW50aWNzAGl0ZXJhdGlvbl9ib3VuZHMAc2NhbGFyX3ByZWZldGNoAHNjcmF0Y2hfb3BlcmFuZHMAbWFpbgB3aW5kb3dfcGFyYW1zAGdtbS48bG9jYWxzPi5vdXRfdHJhbnNmb3JtX2luZGljZXMAZ21tAHRlbnNvcl9zaGFyZGVkX2dtbV9tZXJnZWRfY29sdW1uX3BhcmFsbGVsAGpheF9mdXNlZF9tb2VfZnVuYwBqYXhfZnVzZWRfbW9lX2Z1bmNfcGFkZGVkAFZsbG1VbnF1YW50aXplZEZ1c2VkTW9FTWV0aG9kLmFwcGx5AC9ob21lL2Vwb3JhdC9iZW5jaG1hcmtpbmdfcXdlbl9vbW5pX3RwdS8udmVudi9saWIvcHl0aG9uMy4xMS9zaXRlLXBhY2thZ2VzL3RwdV9pbmZlcmVuY2UvbGF5ZXJzL3ZsbG0vcXVhbnRpemF0aW9uL3VucXVhbnRpemVkLnB5AEZ1c2VkTW9FLmZvcndhcmRfaW1wbABGdXNlZE1vRS5mb3J3YXJkX25hdGl2ZQBDdXN0b21PcC5mb3J3YXJkX3RwdQBDdXN0b21PcC5mb3J3YXJkAG92ZXJmbG93RmxhZ3MAc3ViOgBzdWIAZ21tLjxsb2NhbHM+Lmxoc190cmFuc2Zvcm1faW5kaWNlcwBkb3RfZ2VuZXJhbDoAZG90X2dlbmVyYWwAZGltZW5zaW9uX251bWJlcnMAdHJhbnNwb3NlX2xocwB0cmFuc3Bvc2VfcmhzAGZhc3RtYXRoAG9wZXJhbmRTZWdtZW50U2l6ZXMAc3RyaWRlcwBtdWw6AG11bABkaW1lbnNpb25zAGlvdGE6AGlvdGEAZ2U6AGdlAGx0OgBsdABhbmQ6AGFuZABzZWxlY3RfbjoAc2VsZWN0X24AYnJvYWRjYXN0X2luX2RpbToAYnJvYWRjYXN0X2luX2RpbQA=", "cost_estimate": {"bytes_accessed": 201949184, "flops": 201326592, "transcendentals": 0}, "serialization_format": 1, "needs_layout_passes": true}}
}

%xla.sdy.manual_computation_body_0.1331 (shard_map.907: s32[], shard_map.908: bf16[128,2048], shard_map.909: bf16[128,384,2048], shard_map.910: s32[128]) -> bf16[128,384] {
  %shard_map.908 = bf16[128,2048]{1,0} parameter(1), metadata={op_name="shard_map"}
  %shard_map.909 = bf16[128,384,2048]{2,1,0} parameter(2), metadata={op_name="shard_map"}
  %shard_map.910 = s32[128]{0} parameter(3), metadata={op_name="shard_map"}
  %shard_map.907 = s32[] parameter(0), metadata={op_name="shard_map"}
  ROOT %jit_gmm_.1330 = bf16[128,384]{1,0} call(%shard_map.908, %shard_map.909, %shard_map.910, %shard_map.907), to_apply=%gmm.1329, metadata={op_name="jit(gmm)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=96 source_end_line=102 source_column=17 source_end_column=28}
}

%silu.1347 (Arg_0.1339: bf16[128,768]) -> bf16[128,768] {
  %Arg_0.1339 = bf16[128,768]{1,0} parameter(0)
  %constant.1340 = bf16[] constant(1)
  %broadcast.1341 = bf16[128,768]{1,0} broadcast(%constant.1340), dimensions={}
  %neg.1342 = bf16[128,768]{1,0} negate(%Arg_0.1339), metadata={op_name="neg" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=342 source_end_line=342 source_column=8 source_end_column=23}
  %exp.1343 = bf16[128,768]{1,0} exponential(%neg.1342), metadata={op_name="exp" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=342 source_end_line=342 source_column=8 source_end_column=23}
  %add.1344 = bf16[128,768]{1,0} add(%exp.1343, %broadcast.1341), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=342 source_end_line=342 source_column=8 source_end_column=23}
  %div.1345 = bf16[128,768]{1,0} divide(%broadcast.1341, %add.1344), metadata={op_name="div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=342 source_end_line=342 source_column=8 source_end_column=23}
  ROOT %mul.1346 = bf16[128,768]{1,0} multiply(%Arg_0.1339, %div.1345), metadata={op_name="mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=342 source_end_line=342 source_column=8 source_end_column=23}
}

%region_25.1407 (scatter.1405: s32[], scatter.1406: s32[]) -> s32[] {
  %scatter.1405 = s32[] parameter(0), metadata={op_name="scatter"}
  ROOT %scatter.1406 = s32[] parameter(1), metadata={op_name="scatter"}
}

%region_26.1417 (scatter-add.1414: s32[], scatter-add.1415: s32[]) -> s32[] {
  %scatter-add.1414 = s32[] parameter(0), metadata={op_name="scatter-add"}
  %scatter-add.1415 = s32[] parameter(1), metadata={op_name="scatter-add"}
  ROOT %add.1416 = s32[] add(%scatter-add.1414, %scatter-add.1415), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
}

%region_27.1451 (scatter-add.1448: f32[], scatter-add.1449: f32[]) -> f32[] {
  %scatter-add.1448 = f32[] parameter(0), metadata={op_name="scatter-add"}
  %scatter-add.1449 = f32[] parameter(1), metadata={op_name="scatter-add"}
  ROOT %add.1450 = f32[] add(%scatter-add.1448, %scatter-add.1449), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
}

%region_28.1459 (scatter.1457: s32[], scatter.1458: s32[]) -> s32[] {
  %scatter.1457 = s32[] parameter(0), metadata={op_name="scatter"}
  ROOT %scatter.1458 = s32[] parameter(1), metadata={op_name="scatter"}
}

%region_29.1469 (scatter-add.1466: s32[], scatter-add.1467: s32[]) -> s32[] {
  %scatter-add.1466 = s32[] parameter(0), metadata={op_name="scatter-add"}
  %scatter-add.1467 = s32[] parameter(1), metadata={op_name="scatter-add"}
  ROOT %add.1468 = s32[] add(%scatter-add.1466, %scatter-add.1467), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
}

%region_30.1480 (reduce_sum.1477: s32[], reduce_sum.1478: s32[]) -> s32[] {
  %reduce_sum.1477 = s32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1478 = s32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1479 = s32[] add(%reduce_sum.1477, %reduce_sum.1478), metadata={op_name="reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=244 source_end_line=244 source_column=24 source_end_column=55}
}

%region_31.1496 (reduce_sum.1493: s32[], reduce_sum.1494: s32[]) -> s32[] {
  %reduce_sum.1493 = s32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1494 = s32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1495 = s32[] add(%reduce_sum.1493, %reduce_sum.1494), metadata={op_name="reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=254 source_end_line=254 source_column=14 source_end_column=31}
}

%gmm_254.1499 (Arg_0.1360: bf16[128,192], Arg_1.1361: bf16[128,2048,192], Arg_2.1362: s32[128], Arg_3.1363: s32[]) -> bf16[128,2048] {
  %iota.1486 = s32[128]{0} iota(), iota_dimension=0, metadata={op_name="iota" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=251 source_end_line=251 source_column=9 source_end_column=48}
  %Arg_3.1363 = s32[] parameter(3)
  %constant.1383 = s32[] constant(128)
  %add.1387 = s32[] add(%Arg_3.1363, %constant.1383), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=116 source_end_line=116 source_column=14 source_end_column=46}
  %constant.1382 = s32[] constant(1)
  %sub.1388 = s32[] subtract(%add.1387, %constant.1382), metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=116 source_end_line=116 source_column=14 source_end_column=46}
  %le.1487 = s32[128]{0} broadcast(%sub.1388), dimensions={}, metadata={op_name="le" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=252 source_end_line=252 source_column=38 source_end_column=55}
  %le.1488 = pred[128]{0} compare(%iota.1486, %le.1487), direction=LE, metadata={op_name="le" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=252 source_end_line=252 source_column=38 source_end_column=55}
  %ge.1489 = s32[128]{0} broadcast(%Arg_3.1363), dimensions={}, metadata={op_name="ge" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=252 source_end_line=252 source_column=57 source_end_column=76}
  %ge.1490 = pred[128]{0} compare(%iota.1486, %ge.1489), direction=GE, metadata={op_name="ge" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=252 source_end_line=252 source_column=57 source_end_column=76}
  %and.1491 = pred[128]{0} and(%le.1488, %ge.1490), metadata={op_name="and" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=252 source_end_line=252 source_column=22 source_end_column=77}
  %Arg_2.1362 = s32[128]{0} parameter(2)
  %constant.1373 = s32[] constant(0)
  %broadcast.1374 = s32[128]{0} broadcast(%constant.1373), dimensions={}
  %eq.1400 = pred[128]{0} compare(%Arg_2.1362, %broadcast.1374), direction=EQ, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=154 source_end_line=154 source_column=34 source_end_column=50}
  %constant.1381 = s32[] constant(0)
  %jit_cumsum_.1389 = s32[128]{0} call(%Arg_2.1362), to_apply=%cumsum.950, metadata={op_name="jit(cumsum)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=126 source_end_line=126 source_column=15 source_end_column=38}
  %constant.1377 = s32[] constant(128)
  %broadcast.1378 = s32[128]{0} broadcast(%constant.1377), dimensions={}
  %add.1391 = s32[128]{0} add(%jit_cumsum_.1389, %broadcast.1378), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=25 source_end_column=40}
  %constant.1375 = s32[] constant(1)
  %broadcast.1376 = s32[128]{0} broadcast(%constant.1375), dimensions={}
  %sub.1392 = s32[128]{0} subtract(%add.1391, %broadcast.1376), metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=25 source_end_column=40}
  %jit_floor_divide_.1393 = s32[128]{0} call(%sub.1392, %constant.1383), to_apply=%floor_divide.978, metadata={op_name="jit(floor_divide)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  %mul.1394 = s32[128]{0} multiply(%jit_floor_divide_.1393, %broadcast.1378), metadata={op_name="mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  %constant.1379 = s32[1]{0} constant({0})
  %slice.1395 = s32[127]{0} slice(%jit_cumsum_.1389), slice={[0:127]}, metadata={op_name="slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=144 source_end_line=144 source_column=38 source_end_column=53}
  %concatenate.1396 = s32[128]{0} concatenate(%constant.1379, %slice.1395), dimensions={0}, metadata={op_name="concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=143 source_end_line=145 source_column=17 source_end_column=3}
  %jit_floor_divide_.1397 = s32[128]{0} call(%concatenate.1396, %constant.1383), to_apply=%floor_divide.978, metadata={op_name="jit(floor_divide)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=146 source_end_line=146 source_column=25 source_end_column=43}
  %mul.1398 = s32[128]{0} multiply(%jit_floor_divide_.1397, %broadcast.1378), metadata={op_name="mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=146 source_end_line=146 source_column=25 source_end_column=43}
  %sub.1399 = s32[128]{0} subtract(%mul.1394, %mul.1398), metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=153 source_end_line=153 source_column=24 source_end_column=65}
  %jit__where_.1401 = s32[128]{0} call(%eq.1400, %constant.1381, %sub.1399), to_apply=%_where_135.992, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=154 source_end_line=154 source_column=24 source_end_column=75}
  %jit_floor_divide_.1402 = s32[128]{0} call(%jit__where_.1401, %constant.1383), to_apply=%floor_divide.978, metadata={op_name="jit(floor_divide)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=174 source_end_line=174 source_column=16 source_end_column=41}
  %jit__where_.1492 = s32[128]{0} call(%and.1491, %jit_floor_divide_.1402, %constant.1381), to_apply=%_where_242.1321, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=253 source_end_line=253 source_column=16 source_end_column=60}
  %reduce_sum.1497 = s32[] reduce(%jit__where_.1492, %constant.1381), dimensions={0}, to_apply=%region_31.1496, metadata={op_name="reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=254 source_end_line=254 source_column=14 source_end_column=31}
  %concatenate.1390 = s32[129]{0} concatenate(%constant.1379, %jit_cumsum_.1389), dimensions={0}, metadata={op_name="concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=127 source_end_line=127 source_column=18 source_end_column=78}
  %iota.1403 = s32[128]{0} iota(), iota_dimension=0, metadata={op_name="iota" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=188 source_end_line=188 source_column=6 source_end_column=45}
  %jit__roll_static_.1404 = s32[128]{0} call(%jit_floor_divide_.1402), to_apply=%_roll_static.1000, metadata={op_name="jit(_roll_static)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %scatter.1408 = s32[128]{0} scatter(%jit__roll_static_.1404, %constant.1379, %constant.1381), update_window_dims={}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=0, indices_are_sorted=true, unique_indices=true, to_apply=%region_25.1407, metadata={op_name="scatter" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %jit_cumsum_.1409 = s32[128]{0} call(%scatter.1408), to_apply=%cumsum.950, metadata={op_name="jit(cumsum)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %lt.1410 = pred[128]{0} compare(%jit_cumsum_.1409, %broadcast.1374), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %add.1411 = s32[128]{0} add(%jit_cumsum_.1409, %broadcast.1378), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %select_n.1412 = s32[128]{0} select(%lt.1410, %add.1411, %jit_cumsum_.1409), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %broadcast_in_dim.1413 = s32[128,1]{1,0} reshape(%select_n.1412), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %scatter-add.1418 = s32[128]{0} scatter(%broadcast.1374, %broadcast_in_dim.1413, %broadcast.1376), update_window_dims={}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=1, to_apply=%region_26.1417, metadata={op_name="scatter-add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %jit_cumsum_.1419 = s32[128]{0} call(%scatter-add.1418), to_apply=%cumsum.950, metadata={op_name="jit(cumsum)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %sub.1420 = s32[128]{0} subtract(%jit_cumsum_.1419, %broadcast.1376), metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %jit__take_.1421 = s32[128]{0} call(%iota.1403, %sub.1420), to_apply=%_take_147.1045, metadata={op_name="jit(_take)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %lt.1474 = s32[128]{0} broadcast(%Arg_3.1363), dimensions={}, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=244 source_end_line=244 source_column=25 source_end_column=48}
  %lt.1475 = pred[128]{0} compare(%jit__take_.1421, %lt.1474), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=244 source_end_line=244 source_column=25 source_end_column=48}
  %convert_element_type.1476 = s32[128]{0} convert(%lt.1475), metadata={op_name="convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=244 source_end_line=244 source_column=24 source_end_column=55}
  %reduce_sum.1481 = s32[] reduce(%convert_element_type.1476, %constant.1381), dimensions={0}, to_apply=%region_30.1480, metadata={op_name="reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=244 source_end_line=244 source_column=24 source_end_column=55}
  %neg.1482 = s32[] negate(%reduce_sum.1481), metadata={op_name="neg" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=40 source_end_column=60}
  %jit__roll_dynamic_.1483 = s32[128]{0} call(%jit__take_.1421, %neg.1482), to_apply=%_roll_dynamic.1306, metadata={op_name="jit(_roll_dynamic)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  %constant.1384 = f32[] constant(0)
  %broadcast.1385 = f32[2]{0} broadcast(%constant.1384), dimensions={}
  %slice.1422 = s32[128]{0} slice(%concatenate.1390), slice={[0:128]}, metadata={op_name="slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
  %jit_remainder_.1423 = s32[128]{0} call(%slice.1422, %constant.1383), to_apply=%remainder.1072, metadata={op_name="jit(remainder)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
  %eq.1424 = pred[128]{0} compare(%jit_remainder_.1423, %broadcast.1374), direction=EQ, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=6 source_end_column=36}
  %eq.1425 = pred[128]{0} compare(%Arg_2.1362, %broadcast.1374), direction=EQ, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=38 source_end_column=54}
  %or.1426 = pred[128]{0} or(%eq.1424, %eq.1425), metadata={op_name="or" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=212 source_end_line=214 source_column=22 source_end_column=3}
  %slice.1427 = s32[128]{0} slice(%concatenate.1390), slice={[0:128]}, metadata={op_name="slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=222 source_end_line=222 source_column=34 source_end_column=52}
  %jit_floor_divide_.1428 = s32[128]{0} call(%slice.1427, %constant.1383), to_apply=%floor_divide.978, metadata={op_name="jit(floor_divide)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=222 source_end_line=222 source_column=34 source_end_column=52}
  %jit__where_.1429 = s32[128]{0} call(%or.1426, %constant.1382, %jit_floor_divide_.1428), to_apply=%_where_135.992, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=221 source_end_line=223 source_column=21 source_end_column=3}
  %convert_element_type.1430 = f32[128]{0} convert(%jit__where_.1429), metadata={op_name="convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %jit__ptp_.1431 = f32[] call(%broadcast.1385), to_apply=%_ptp.1095, metadata={op_name="jit(_ptp)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.1380 = f32[] constant(0)
  %eq.1432 = pred[] compare(%jit__ptp_.1431, %constant.1380), direction=EQ, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.1370 = f32[] constant(-0.5)
  %jit__where_.1433 = f32[] call(%eq.1432, %constant.1370, %constant.1380), to_apply=%_where_171.1102, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %jit__ptp_.1434 = f32[] call(%broadcast.1385), to_apply=%_ptp.1095, metadata={op_name="jit(_ptp)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %eq.1435 = pred[] compare(%jit__ptp_.1434, %constant.1380), direction=EQ, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.1369 = f32[] constant(0.5)
  %jit__where_.1436 = f32[] call(%eq.1435, %constant.1369, %constant.1380), to_apply=%_where_171.1102, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %jit__linspace_.1437 = f32[2]{0} call(%jit__where_.1433, %jit__where_.1436), to_apply=%_linspace.1116, metadata={op_name="jit(_linspace)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %dynamic_slice.1439 = f32[1]{0} slice(%jit__linspace_.1437), slice={[1:2]}, metadata={op_name="dynamic_slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %squeeze.1440 = f32[] reshape(%dynamic_slice.1439), metadata={op_name="squeeze" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %eq.1441 = f32[128]{0} broadcast(%squeeze.1440), dimensions={}, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %eq.1442 = pred[128]{0} compare(%convert_element_type.1430, %eq.1441), direction=EQ, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %jit_searchsorted_.1438 = s32[128]{0} call(%jit__linspace_.1437, %convert_element_type.1430), to_apply=%searchsorted.1200, metadata={op_name="jit(searchsorted)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %jit__where_.1443 = s32[128]{0} call(%eq.1442, %constant.1382, %jit_searchsorted_.1438), to_apply=%_where_135.992, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %lt.1444 = pred[128]{0} compare(%jit__where_.1443, %broadcast.1374), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.1367 = s32[] constant(2)
  %add.1368 = s32[128]{0} broadcast(%constant.1367), dimensions={}, metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %add.1445 = s32[128]{0} add(%jit__where_.1443, %add.1368), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %select_n.1446 = s32[128]{0} select(%lt.1444, %add.1445, %jit__where_.1443), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %broadcast_in_dim.1447 = s32[128,1]{1,0} reshape(%select_n.1446), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.1371 = f32[] constant(1)
  %broadcast_in_dim.1372 = f32[128]{0} broadcast(%constant.1371), dimensions={}, metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %scatter-add.1452 = f32[2]{0} scatter(%broadcast.1385, %broadcast_in_dim.1447, %broadcast_in_dim.1372), update_window_dims={}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=1, to_apply=%region_27.1451, metadata={op_name="scatter-add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %slice.1453 = f32[1]{0} slice(%scatter-add.1452), slice={[1:2]}, metadata={op_name="slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.1366 = f32[1]{0} constant({1})
  %add.1454 = f32[1]{0} add(%slice.1453, %constant.1366), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %convert_element_type.1455 = s32[1]{0} convert(%add.1454), metadata={op_name="convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=234 source_end_line=234 source_column=6 source_end_column=35}
  %jit__roll_static_.1456 = s32[1]{0} call(%convert_element_type.1455), to_apply=%_roll_static_208.1220, metadata={op_name="jit(_roll_static)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %scatter.1460 = s32[1]{0} scatter(%jit__roll_static_.1456, %constant.1379, %constant.1381), update_window_dims={}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=0, indices_are_sorted=true, unique_indices=true, to_apply=%region_28.1459, metadata={op_name="scatter" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %jit_cumsum_.1461 = s32[1]{0} call(%scatter.1460), to_apply=%cumsum_213.1230, metadata={op_name="jit(cumsum)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %lt.1462 = pred[1]{0} compare(%jit_cumsum_.1461, %constant.1379), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %constant.1365 = s32[1]{0} constant({128})
  %add.1463 = s32[1]{0} add(%jit_cumsum_.1461, %constant.1365), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %select_n.1464 = s32[1]{0} select(%lt.1462, %add.1463, %jit_cumsum_.1461), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %broadcast_in_dim.1465 = s32[1,1]{1,0} reshape(%select_n.1464), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %constant.1364 = s32[1]{0} constant({1})
  %scatter-add.1470 = s32[128]{0} scatter(%broadcast.1374, %broadcast_in_dim.1465, %constant.1364), update_window_dims={}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=1, to_apply=%region_29.1469, metadata={op_name="scatter-add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %jit_cumsum_.1471 = s32[128]{0} call(%scatter-add.1470), to_apply=%cumsum.950, metadata={op_name="jit(cumsum)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %sub.1472 = s32[128]{0} subtract(%jit_cumsum_.1471, %broadcast.1376), metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %jit__take_.1473 = s32[128]{0} call(%constant.1379, %sub.1472), to_apply=%_take_221.1268, metadata={op_name="jit(_take)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %neg.1484 = s32[] negate(%reduce_sum.1481), metadata={op_name="neg" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=246 source_end_line=246 source_column=42 source_end_column=62}
  %jit__roll_dynamic_.1485 = s32[128]{0} call(%jit__take_.1473, %neg.1484), to_apply=%_roll_dynamic.1306, metadata={op_name="jit(_roll_dynamic)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=246 source_end_line=246 source_column=15 source_end_column=71}
  %broadcast_in_dim.1386 = s32[1]{0} reshape(%Arg_3.1363), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=358 source_end_line=358 source_column=19 source_end_column=37}
  %Arg_0.1360 = bf16[128,192]{1,0} parameter(0)
  %Arg_1.1361 = bf16[128,2048,192]{2,1,0} parameter(1)
  ROOT %pallas_call.1498 = bf16[128,2048]{1,0} custom-call(%reduce_sum.1497, %concatenate.1390, %jit__roll_dynamic_.1483, %jit__roll_dynamic_.1485, %broadcast_in_dim.1386, /*index=5*/%Arg_0.1360, %Arg_1.1361), custom_call_target="tpu_custom_call", operand_layout_constraints={s32[], s32[129]{0}, s32[128]{0}, s32[128]{0}, s32[1]{0}, bf16[128,192]{1,0}, bf16[128,2048,192]{2,1,0}}, metadata={op_name="pallas_call" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=547 source_end_line=553 source_column=8 source_end_column=3}, backend_config={"custom_call_config": {"body": "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", "cost_estimate": {"bytes_accessed": 101236736, "flops": 100663296, "transcendentals": 0}, "serialization_format": 1, "needs_layout_passes": true}}
}

%region_32.1504 (psum.1501: bf16[], psum.1502: bf16[]) -> bf16[] {
  %psum.1501 = bf16[] parameter(0), metadata={op_name="psum"}
  %psum.1502 = bf16[] parameter(1), metadata={op_name="psum"}
  ROOT %add.1503 = bf16[] add(%psum.1501, %psum.1502), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=133 source_end_line=133 source_column=15 source_end_column=49}
}

%xla.sdy.manual_computation_body_1.1506 (shard_map.1356: s32[], shard_map.1357: bf16[128,192], shard_map.1358: bf16[128,2048,192], shard_map.1359: s32[128]) -> bf16[128,2048] {
  %shard_map.1357 = bf16[128,192]{1,0} parameter(1), metadata={op_name="shard_map"}
  %shard_map.1358 = bf16[128,2048,192]{2,1,0} parameter(2), metadata={op_name="shard_map"}
  %shard_map.1359 = s32[128]{0} parameter(3), metadata={op_name="shard_map"}
  %shard_map.1356 = s32[] parameter(0), metadata={op_name="shard_map"}
  %jit_gmm_.1500 = bf16[128,2048]{1,0} call(%shard_map.1357, %shard_map.1358, %shard_map.1359, %shard_map.1356), to_apply=%gmm_254.1499, metadata={op_name="jit(gmm)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=132 source_end_line=132 source_column=12 source_end_column=39}
  ROOT %psum.1505 = bf16[128,2048]{1,0} all-reduce(%jit_gmm_.1500), channel_id=1, replica_groups={{0,1,2,3}}, use_global_device_ids=true, to_apply=%region_32.1504, metadata={op_name="psum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=133 source_end_line=133 source_column=15 source_end_column=49}
}

%region_33.1524 (reduce_sum.1521: f32[], reduce_sum.1522: f32[]) -> f32[] {
  %reduce_sum.1521 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1522 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1523 = f32[] add(%reduce_sum.1521, %reduce_sum.1522), metadata={op_name="reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=363 source_end_line=363 source_column=8 source_end_column=22}
}

%jax_fused_moe_func_padded.1528 (Arg_0.793: bf16[16,2048], Arg_1.794: bf16[128,1536,2048], Arg_2.795: bf16[128,2048,768], Arg_3.796: bf16[16,128]) -> bf16[16,2048] {
  %constant.807 = s32[] constant(0)
  %Arg_0.793 = bf16[16,2048]{1,0} parameter(0)
  %iota.874 = s32[16]{0} iota(), iota_dimension=0, metadata={op_name="iota" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=318 source_end_line=318 source_column=20 source_end_column=59}
  %broadcast_in_dim.875 = s32[16,8]{1,0} broadcast(%iota.874), dimensions={0}, metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=318 source_end_line=318 source_column=20 source_end_column=59}
  %reshape.876 = s32[128]{0} reshape(%broadcast_in_dim.875), metadata={op_name="reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=318 source_end_line=318 source_column=20 source_end_column=59}
  %Arg_3.796 = bf16[16,128]{1,0} parameter(3)
  %convert_element_type.810 = f32[16,128]{1,0} convert(%Arg_3.796), metadata={op_name="convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=34 source_end_column=67}
  %constant.809 = f32[] constant(-inf)
  %reduce_max.815 = f32[16]{0} reduce(%convert_element_type.810, %constant.809), dimensions={1}, to_apply=%region_5.814, metadata={op_name="reduce_max" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
  %constant.805 = f32[] constant(-inf)
  %broadcast.806 = f32[16]{0} broadcast(%constant.805), dimensions={}
  %max.816 = f32[16]{0} maximum(%reduce_max.815, %broadcast.806), metadata={op_name="max" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
  %broadcast_in_dim.817 = f32[16,1]{1,0} reshape(%max.816), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
  %sub.818 = f32[16,1]{1,0} broadcast(%broadcast_in_dim.817), dimensions={0,1}, metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
  %sub.819 = f32[16]{0} reshape(%sub.818), metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
  %sub.820 = f32[16,128]{1,0} broadcast(%sub.819), dimensions={0}, metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
  %sub.821 = f32[16,128]{1,0} subtract(%convert_element_type.810, %sub.820), metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
  %exp.822 = f32[16,128]{1,0} exponential(%sub.821), metadata={op_name="exp" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
  %constant.808 = f32[] constant(0)
  %reduce_sum.827 = f32[16]{0} reduce(%exp.822, %constant.808), dimensions={1}, to_apply=%region_6.826, metadata={op_name="reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
  %broadcast_in_dim.828 = f32[16,1]{1,0} reshape(%reduce_sum.827), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
  %div.829 = f32[16,1]{1,0} broadcast(%broadcast_in_dim.828), dimensions={0,1}, metadata={op_name="div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
  %div.830 = f32[16]{0} reshape(%div.829), metadata={op_name="div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
  %div.831 = f32[16,128]{1,0} broadcast(%div.830), dimensions={0}, metadata={op_name="div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
  %div.832 = f32[16,128]{1,0} divide(%exp.822, %div.831), metadata={op_name="div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
  %top_k.833 = (f32[16,8]{1,0}, s32[16,8]{1,0}) topk(%div.832), k=8, largest=true, metadata={op_name="top_k" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=310 source_end_line=310 source_column=33 source_end_column=68}
  %top_k.835 = s32[16,8]{1,0} get-tuple-element(%top_k.833), index=1, metadata={op_name="top_k" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=310 source_end_line=310 source_column=33 source_end_column=68}
  %reshape.847 = s32[128]{0} reshape(%top_k.835), metadata={op_name="reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=315 source_end_line=315 source_column=24 source_end_column=46}
  %jit_argsort_.860 = s32[128]{0} call(%reshape.847), to_apply=%argsort.859, metadata={op_name="jit(argsort)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=316 source_end_line=316 source_column=27 source_end_column=57}
  %constant.803 = s32[] constant(0)
  %broadcast.804 = s32[128]{0} broadcast(%constant.803), dimensions={}
  %lt.877 = pred[128]{0} compare(%jit_argsort_.860, %broadcast.804), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=319 source_end_line=319 source_column=27 source_end_column=62}
  %constant.801 = s32[] constant(128)
  %broadcast.802 = s32[128]{0} broadcast(%constant.801), dimensions={}
  %add.878 = s32[128]{0} add(%jit_argsort_.860, %broadcast.802), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=319 source_end_line=319 source_column=27 source_end_column=62}
  %select_n.879 = s32[128]{0} select(%lt.877, %add.878, %jit_argsort_.860), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=319 source_end_line=319 source_column=27 source_end_column=62}
  %broadcast_in_dim.880 = s32[128,1]{1,0} reshape(%select_n.879), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=319 source_end_line=319 source_column=27 source_end_column=62}
  %gather.881 = s32[128]{0} gather(%reshape.876, %broadcast_in_dim.880), offset_dims={}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1}, metadata={op_name="gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=319 source_end_line=319 source_column=27 source_end_column=62}
  %lt.897 = pred[128]{0} compare(%gather.881, %broadcast.804), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=322 source_end_line=322 source_column=8 source_end_column=43}
  %constant.797 = s32[] constant(16)
  %add.798 = s32[128]{0} broadcast(%constant.797), dimensions={}, metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=322 source_end_line=322 source_column=8 source_end_column=43}
  %add.898 = s32[128]{0} add(%gather.881, %add.798), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=322 source_end_line=322 source_column=8 source_end_column=43}
  %select_n.899 = s32[128]{0} select(%lt.897, %add.898, %gather.881), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=322 source_end_line=322 source_column=8 source_end_column=43}
  %broadcast_in_dim.900 = s32[128,1]{1,0} reshape(%select_n.899), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=322 source_end_line=322 source_column=8 source_end_column=43}
  %gather.901 = bf16[128,2048]{1,0} gather(%Arg_0.793, %broadcast_in_dim.900), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,2048}, metadata={op_name="gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=322 source_end_line=322 source_column=8 source_end_column=43}
  %Arg_1.794 = bf16[128,1536,2048]{2,1,0} parameter(1)
  %jit_clip_.887 = s32[128]{0} call(%reshape.847, %constant.807), to_apply=%clip.886, metadata={op_name="jit(clip)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=320 source_end_line=320 source_column=18 source_end_column=76}
  %lt.888 = pred[128]{0} compare(%jit_clip_.887, %broadcast.804), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=320 source_end_line=320 source_column=18 source_end_column=76}
  %add.889 = s32[128]{0} add(%jit_clip_.887, %broadcast.802), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=320 source_end_line=320 source_column=18 source_end_column=76}
  %select_n.890 = s32[128]{0} select(%lt.888, %add.889, %jit_clip_.887), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=320 source_end_line=320 source_column=18 source_end_column=76}
  %broadcast_in_dim.891 = s32[128,1]{1,0} reshape(%select_n.890), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=320 source_end_line=320 source_column=18 source_end_column=76}
  %constant.799 = s32[] constant(1)
  %broadcast_in_dim.800 = s32[128]{0} broadcast(%constant.799), dimensions={}, metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=320 source_end_line=320 source_column=18 source_end_column=76}
  %scatter-add.896 = s32[128]{0} scatter(%broadcast.804, %broadcast_in_dim.891, %broadcast_in_dim.800), update_window_dims={}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=1, to_apply=%region_10.895, metadata={op_name="scatter-add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=320 source_end_line=320 source_column=18 source_end_column=76}
  %shard_map.902 = (s32[], bf16[128,2048]{1,0}, bf16[128,384,2048]{2,1,0}, s32[128]{0}) custom-call(%constant.807, %gather.901, %Arg_1.794, %scatter-add.896), custom_call_target="xla.sdy.GlobalToLocalShape", custom_call_has_side_effect=true, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, []>, <@mesh, [{}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=96 source_end_line=102 source_column=17 source_end_column=28}
  %shard_map.903 = s32[] get-tuple-element(%shard_map.902), index=0, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, []>, <@mesh, [{}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=96 source_end_line=102 source_column=17 source_end_column=28}
  %shard_map.904 = bf16[128,2048]{1,0} get-tuple-element(%shard_map.902), index=1, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, []>, <@mesh, [{}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=96 source_end_line=102 source_column=17 source_end_column=28}
  %shard_map.905 = bf16[128,384,2048]{2,1,0} get-tuple-element(%shard_map.902), index=2, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, []>, <@mesh, [{}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=96 source_end_line=102 source_column=17 source_end_column=28}
  %shard_map.906 = s32[128]{0} get-tuple-element(%shard_map.902), index=3, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, []>, <@mesh, [{}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=96 source_end_line=102 source_column=17 source_end_column=28}
  %shard_map.1332 = bf16[128,384]{1,0} call(%shard_map.903, %shard_map.904, %shard_map.905, %shard_map.906), to_apply=%xla.sdy.manual_computation_body_0.1331, frontend_attributes={inlineable="false"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=96 source_end_line=102 source_column=17 source_end_column=28}
  %shard_map.1333 = bf16[128,1536]{1,0} custom-call(%shard_map.1332), custom_call_target="xla.sdy.LocalToGlobalShape", custom_call_has_side_effect=true, frontend_attributes={xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>",xla.sdy.out_shardings="#sdy.sharding_per_value<[<@mesh, [{}, {\"model\"}]>]>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=96 source_end_line=102 source_column=17 source_end_column=28}
  %reshape.1334 = bf16[128,4,384]{2,1,0} reshape(%shard_map.1333), metadata={op_name="reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.1335 = bf16[128,4,192]{2,1,0} slice(%reshape.1334), slice={[0:128], [0:4], [0:192]}, metadata={op_name="slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.1336 = bf16[128,768]{1,0} reshape(%slice.1335), metadata={op_name="reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit_silu_.1348 = bf16[128,768]{1,0} call(%reshape.1336), to_apply=%silu.1347, metadata={op_name="jit(silu)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=342 source_end_line=342 source_column=8 source_end_column=23}
  %slice.1337 = bf16[128,4,192]{2,1,0} slice(%reshape.1334), slice={[0:128], [0:4], [192:384]}, metadata={op_name="slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.1338 = bf16[128,768]{1,0} reshape(%slice.1337), metadata={op_name="reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %mul.1349 = bf16[128,768]{1,0} multiply(%jit_silu_.1348, %reshape.1338), metadata={op_name="mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=342 source_end_line=342 source_column=8 source_end_column=23}
  %sharding_constraint.1350 = bf16[128,768]{1,0} custom-call(%mul.1349), custom_call_target="Sharding", sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding_per_value<[<@mesh, [{}, {\"model\"}]>]>"}, metadata={op_name="sharding_constraint" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=353 source_end_line=354 source_column=12 source_end_column=53}
  %Arg_2.795 = bf16[128,2048,768]{2,1,0} parameter(2)
  %shard_map.1351 = (s32[], bf16[128,192]{1,0}, bf16[128,2048,192]{2,1,0}, s32[128]{0}) custom-call(%constant.807, %sharding_constraint.1350, %Arg_2.795, %scatter-add.896), custom_call_target="xla.sdy.GlobalToLocalShape", custom_call_has_side_effect=true, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, []>, <@mesh, [{}, {\"model\"}]>, <@mesh, [{}, {}, {\"model\"}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=135 source_end_line=141 source_column=11 source_end_column=28}
  %shard_map.1352 = s32[] get-tuple-element(%shard_map.1351), index=0, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, []>, <@mesh, [{}, {\"model\"}]>, <@mesh, [{}, {}, {\"model\"}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=135 source_end_line=141 source_column=11 source_end_column=28}
  %shard_map.1353 = bf16[128,192]{1,0} get-tuple-element(%shard_map.1351), index=1, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, []>, <@mesh, [{}, {\"model\"}]>, <@mesh, [{}, {}, {\"model\"}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=135 source_end_line=141 source_column=11 source_end_column=28}
  %shard_map.1354 = bf16[128,2048,192]{2,1,0} get-tuple-element(%shard_map.1351), index=2, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, []>, <@mesh, [{}, {\"model\"}]>, <@mesh, [{}, {}, {\"model\"}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=135 source_end_line=141 source_column=11 source_end_column=28}
  %shard_map.1355 = s32[128]{0} get-tuple-element(%shard_map.1351), index=3, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, []>, <@mesh, [{}, {\"model\"}]>, <@mesh, [{}, {}, {\"model\"}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=135 source_end_line=141 source_column=11 source_end_column=28}
  %shard_map.1507 = bf16[128,2048]{1,0} call(%shard_map.1352, %shard_map.1353, %shard_map.1354, %shard_map.1355), to_apply=%xla.sdy.manual_computation_body_1.1506, frontend_attributes={inlineable="false"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=135 source_end_line=141 source_column=11 source_end_column=28}
  %shard_map.1508 = bf16[128,2048]{1,0} custom-call(%shard_map.1507), custom_call_target="xla.sdy.LocalToGlobalShape", custom_call_has_side_effect=true, frontend_attributes={xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>",xla.sdy.out_shardings="#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=135 source_end_line=141 source_column=11 source_end_column=28}
  %jit_argsort_.873 = s32[128]{0} call(%jit_argsort_.860), to_apply=%argsort_93.872, metadata={op_name="jit(argsort)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=317 source_end_line=317 source_column=34 source_end_column=67}
  %lt.1509 = pred[128]{0} compare(%jit_argsort_.873, %broadcast.804), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=361 source_end_line=361 source_column=8 source_end_column=38}
  %add.1510 = s32[128]{0} add(%jit_argsort_.873, %broadcast.802), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=361 source_end_line=361 source_column=8 source_end_column=38}
  %select_n.1511 = s32[128]{0} select(%lt.1509, %add.1510, %jit_argsort_.873), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=361 source_end_line=361 source_column=8 source_end_column=38}
  %broadcast_in_dim.1512 = s32[128,1]{1,0} reshape(%select_n.1511), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=361 source_end_line=361 source_column=8 source_end_column=38}
  %gather.1513 = bf16[128,2048]{1,0} gather(%shard_map.1508, %broadcast_in_dim.1512), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,2048}, metadata={op_name="gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=361 source_end_line=361 source_column=8 source_end_column=38}
  %reshape.1514 = bf16[16,8,2048]{2,1,0} reshape(%gather.1513), metadata={op_name="reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=361 source_end_line=361 source_column=8 source_end_column=38}
  %top_k.834 = f32[16,8]{1,0} get-tuple-element(%top_k.833), index=0, metadata={op_name="top_k" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=310 source_end_line=310 source_column=33 source_end_column=68}
  %reduce_sum.840 = f32[16]{0} reduce(%top_k.834, %constant.808), dimensions={1}, to_apply=%region_7.839, metadata={op_name="reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=312 source_end_line=312 source_column=38 source_end_column=78}
  %broadcast_in_dim.841 = f32[16,1]{1,0} reshape(%reduce_sum.840), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=312 source_end_line=312 source_column=38 source_end_column=78}
  %div.842 = f32[16,1]{1,0} broadcast(%broadcast_in_dim.841), dimensions={0,1}, metadata={op_name="div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=312 source_end_line=312 source_column=23 source_end_column=78}
  %div.843 = f32[16]{0} reshape(%div.842), metadata={op_name="div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=312 source_end_line=312 source_column=23 source_end_column=78}
  %div.844 = f32[16,8]{1,0} broadcast(%div.843), dimensions={0}, metadata={op_name="div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=312 source_end_line=312 source_column=23 source_end_column=78}
  %div.845 = f32[16,8]{1,0} divide(%top_k.834, %div.844), metadata={op_name="div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=312 source_end_line=312 source_column=23 source_end_column=78}
  %convert_element_type.846 = bf16[16,8]{1,0} convert(%div.845), metadata={op_name="convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=313 source_end_line=313 source_column=19 source_end_column=45}
  %broadcast_in_dim.1515 = bf16[16,8,1]{2,1,0} reshape(%convert_element_type.846), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=362 source_end_line=362 source_column=12 source_end_column=50}
  %mul.1516 = bf16[16,8,1]{2,1,0} broadcast(%broadcast_in_dim.1515), dimensions={0,1,2}, metadata={op_name="mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=362 source_end_line=362 source_column=8 source_end_column=50}
  %mul.1517 = bf16[16,8]{1,0} reshape(%mul.1516), metadata={op_name="mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=362 source_end_line=362 source_column=8 source_end_column=50}
  %mul.1518 = bf16[16,8,2048]{2,1,0} broadcast(%mul.1517), dimensions={0,1}, metadata={op_name="mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=362 source_end_line=362 source_column=8 source_end_column=50}
  %mul.1519 = bf16[16,8,2048]{2,1,0} multiply(%reshape.1514, %mul.1518), metadata={op_name="mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=362 source_end_line=362 source_column=8 source_end_column=50}
  %convert_element_type.1520 = f32[16,8,2048]{2,1,0} convert(%mul.1519), metadata={op_name="convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=363 source_end_line=363 source_column=8 source_end_column=22}
  %reduce_sum.1525 = f32[16,2048]{1,0} reduce(%convert_element_type.1520, %constant.808), dimensions={1}, to_apply=%region_33.1524, metadata={op_name="reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=363 source_end_line=363 source_column=8 source_end_column=22}
  %convert_element_type.1526 = bf16[16,2048]{1,0} convert(%reduce_sum.1525), metadata={op_name="convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=363 source_end_line=363 source_column=8 source_end_column=22}
  ROOT %sharding_constraint.1527 = bf16[16,2048]{1,0} custom-call(%convert_element_type.1526), custom_call_target="Sharding", sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, metadata={op_name="sharding_constraint" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=367 source_end_line=367 source_column=12 source_end_column=73}
}

%region_34.1538 (reduce_sum.1535: f32[], reduce_sum.1536: f32[]) -> f32[] {
  %reduce_sum.1535 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1536 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1537 = f32[] add(%reduce_sum.1535, %reduce_sum.1536), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_35.1566 (reduce_sum.1563: f32[], reduce_sum.1564: f32[]) -> f32[] {
  %reduce_sum.1563 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1564 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1565 = f32[] add(%reduce_sum.1563, %reduce_sum.1564), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_36.1587 (reduce_sum.1584: f32[], reduce_sum.1585: f32[]) -> f32[] {
  %reduce_sum.1584 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1585 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1586 = f32[] add(%reduce_sum.1584, %reduce_sum.1585), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_37.1670 (reduce_sum.1667: f32[], reduce_sum.1668: f32[]) -> f32[] {
  %reduce_sum.1667 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1668 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1669 = f32[] add(%reduce_sum.1667, %reduce_sum.1668), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_38.1696 (reduce_sum.1693: f32[], reduce_sum.1694: f32[]) -> f32[] {
  %reduce_sum.1693 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1694 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1695 = f32[] add(%reduce_sum.1693, %reduce_sum.1694), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_39.1724 (reduce_sum.1721: f32[], reduce_sum.1722: f32[]) -> f32[] {
  %reduce_sum.1721 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1722 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1723 = f32[] add(%reduce_sum.1721, %reduce_sum.1722), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_40.1745 (reduce_sum.1742: f32[], reduce_sum.1743: f32[]) -> f32[] {
  %reduce_sum.1742 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1743 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1744 = f32[] add(%reduce_sum.1742, %reduce_sum.1743), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_41.1828 (reduce_sum.1825: f32[], reduce_sum.1826: f32[]) -> f32[] {
  %reduce_sum.1825 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1826 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1827 = f32[] add(%reduce_sum.1825, %reduce_sum.1826), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_42.1854 (reduce_sum.1851: f32[], reduce_sum.1852: f32[]) -> f32[] {
  %reduce_sum.1851 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1852 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1853 = f32[] add(%reduce_sum.1851, %reduce_sum.1852), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_43.1882 (reduce_sum.1879: f32[], reduce_sum.1880: f32[]) -> f32[] {
  %reduce_sum.1879 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1880 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1881 = f32[] add(%reduce_sum.1879, %reduce_sum.1880), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_44.1903 (reduce_sum.1900: f32[], reduce_sum.1901: f32[]) -> f32[] {
  %reduce_sum.1900 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1901 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1902 = f32[] add(%reduce_sum.1900, %reduce_sum.1901), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_45.1986 (reduce_sum.1983: f32[], reduce_sum.1984: f32[]) -> f32[] {
  %reduce_sum.1983 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1984 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1985 = f32[] add(%reduce_sum.1983, %reduce_sum.1984), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_46.2012 (reduce_sum.2009: f32[], reduce_sum.2010: f32[]) -> f32[] {
  %reduce_sum.2009 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2010 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2011 = f32[] add(%reduce_sum.2009, %reduce_sum.2010), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_47.2040 (reduce_sum.2037: f32[], reduce_sum.2038: f32[]) -> f32[] {
  %reduce_sum.2037 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2038 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2039 = f32[] add(%reduce_sum.2037, %reduce_sum.2038), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_48.2061 (reduce_sum.2058: f32[], reduce_sum.2059: f32[]) -> f32[] {
  %reduce_sum.2058 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2059 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2060 = f32[] add(%reduce_sum.2058, %reduce_sum.2059), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_49.2144 (reduce_sum.2141: f32[], reduce_sum.2142: f32[]) -> f32[] {
  %reduce_sum.2141 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2142 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2143 = f32[] add(%reduce_sum.2141, %reduce_sum.2142), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_50.2170 (reduce_sum.2167: f32[], reduce_sum.2168: f32[]) -> f32[] {
  %reduce_sum.2167 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2168 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2169 = f32[] add(%reduce_sum.2167, %reduce_sum.2168), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_51.2198 (reduce_sum.2195: f32[], reduce_sum.2196: f32[]) -> f32[] {
  %reduce_sum.2195 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2196 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2197 = f32[] add(%reduce_sum.2195, %reduce_sum.2196), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_52.2219 (reduce_sum.2216: f32[], reduce_sum.2217: f32[]) -> f32[] {
  %reduce_sum.2216 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2217 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2218 = f32[] add(%reduce_sum.2216, %reduce_sum.2217), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_53.2302 (reduce_sum.2299: f32[], reduce_sum.2300: f32[]) -> f32[] {
  %reduce_sum.2299 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2300 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2301 = f32[] add(%reduce_sum.2299, %reduce_sum.2300), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_54.2328 (reduce_sum.2325: f32[], reduce_sum.2326: f32[]) -> f32[] {
  %reduce_sum.2325 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2326 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2327 = f32[] add(%reduce_sum.2325, %reduce_sum.2326), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_55.2356 (reduce_sum.2353: f32[], reduce_sum.2354: f32[]) -> f32[] {
  %reduce_sum.2353 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2354 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2355 = f32[] add(%reduce_sum.2353, %reduce_sum.2354), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_56.2377 (reduce_sum.2374: f32[], reduce_sum.2375: f32[]) -> f32[] {
  %reduce_sum.2374 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2375 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2376 = f32[] add(%reduce_sum.2374, %reduce_sum.2375), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_57.2460 (reduce_sum.2457: f32[], reduce_sum.2458: f32[]) -> f32[] {
  %reduce_sum.2457 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2458 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2459 = f32[] add(%reduce_sum.2457, %reduce_sum.2458), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_58.2486 (reduce_sum.2483: f32[], reduce_sum.2484: f32[]) -> f32[] {
  %reduce_sum.2483 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2484 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2485 = f32[] add(%reduce_sum.2483, %reduce_sum.2484), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_59.2514 (reduce_sum.2511: f32[], reduce_sum.2512: f32[]) -> f32[] {
  %reduce_sum.2511 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2512 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2513 = f32[] add(%reduce_sum.2511, %reduce_sum.2512), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_60.2535 (reduce_sum.2532: f32[], reduce_sum.2533: f32[]) -> f32[] {
  %reduce_sum.2532 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2533 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2534 = f32[] add(%reduce_sum.2532, %reduce_sum.2533), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_61.2618 (reduce_sum.2615: f32[], reduce_sum.2616: f32[]) -> f32[] {
  %reduce_sum.2615 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2616 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2617 = f32[] add(%reduce_sum.2615, %reduce_sum.2616), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_62.2644 (reduce_sum.2641: f32[], reduce_sum.2642: f32[]) -> f32[] {
  %reduce_sum.2641 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2642 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2643 = f32[] add(%reduce_sum.2641, %reduce_sum.2642), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_63.2672 (reduce_sum.2669: f32[], reduce_sum.2670: f32[]) -> f32[] {
  %reduce_sum.2669 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2670 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2671 = f32[] add(%reduce_sum.2669, %reduce_sum.2670), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_64.2693 (reduce_sum.2690: f32[], reduce_sum.2691: f32[]) -> f32[] {
  %reduce_sum.2690 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2691 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2692 = f32[] add(%reduce_sum.2690, %reduce_sum.2691), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_65.2776 (reduce_sum.2773: f32[], reduce_sum.2774: f32[]) -> f32[] {
  %reduce_sum.2773 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2774 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2775 = f32[] add(%reduce_sum.2773, %reduce_sum.2774), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_66.2802 (reduce_sum.2799: f32[], reduce_sum.2800: f32[]) -> f32[] {
  %reduce_sum.2799 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2800 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2801 = f32[] add(%reduce_sum.2799, %reduce_sum.2800), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_67.2830 (reduce_sum.2827: f32[], reduce_sum.2828: f32[]) -> f32[] {
  %reduce_sum.2827 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2828 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2829 = f32[] add(%reduce_sum.2827, %reduce_sum.2828), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_68.2851 (reduce_sum.2848: f32[], reduce_sum.2849: f32[]) -> f32[] {
  %reduce_sum.2848 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2849 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2850 = f32[] add(%reduce_sum.2848, %reduce_sum.2849), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_69.2934 (reduce_sum.2931: f32[], reduce_sum.2932: f32[]) -> f32[] {
  %reduce_sum.2931 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2932 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2933 = f32[] add(%reduce_sum.2931, %reduce_sum.2932), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_70.2960 (reduce_sum.2957: f32[], reduce_sum.2958: f32[]) -> f32[] {
  %reduce_sum.2957 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2958 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2959 = f32[] add(%reduce_sum.2957, %reduce_sum.2958), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_71.2988 (reduce_sum.2985: f32[], reduce_sum.2986: f32[]) -> f32[] {
  %reduce_sum.2985 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2986 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2987 = f32[] add(%reduce_sum.2985, %reduce_sum.2986), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_72.3009 (reduce_sum.3006: f32[], reduce_sum.3007: f32[]) -> f32[] {
  %reduce_sum.3006 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3007 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3008 = f32[] add(%reduce_sum.3006, %reduce_sum.3007), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_73.3092 (reduce_sum.3089: f32[], reduce_sum.3090: f32[]) -> f32[] {
  %reduce_sum.3089 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3090 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3091 = f32[] add(%reduce_sum.3089, %reduce_sum.3090), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_74.3118 (reduce_sum.3115: f32[], reduce_sum.3116: f32[]) -> f32[] {
  %reduce_sum.3115 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3116 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3117 = f32[] add(%reduce_sum.3115, %reduce_sum.3116), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_75.3146 (reduce_sum.3143: f32[], reduce_sum.3144: f32[]) -> f32[] {
  %reduce_sum.3143 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3144 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3145 = f32[] add(%reduce_sum.3143, %reduce_sum.3144), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_76.3167 (reduce_sum.3164: f32[], reduce_sum.3165: f32[]) -> f32[] {
  %reduce_sum.3164 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3165 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3166 = f32[] add(%reduce_sum.3164, %reduce_sum.3165), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_77.3250 (reduce_sum.3247: f32[], reduce_sum.3248: f32[]) -> f32[] {
  %reduce_sum.3247 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3248 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3249 = f32[] add(%reduce_sum.3247, %reduce_sum.3248), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_78.3276 (reduce_sum.3273: f32[], reduce_sum.3274: f32[]) -> f32[] {
  %reduce_sum.3273 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3274 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3275 = f32[] add(%reduce_sum.3273, %reduce_sum.3274), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_79.3304 (reduce_sum.3301: f32[], reduce_sum.3302: f32[]) -> f32[] {
  %reduce_sum.3301 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3302 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3303 = f32[] add(%reduce_sum.3301, %reduce_sum.3302), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_80.3325 (reduce_sum.3322: f32[], reduce_sum.3323: f32[]) -> f32[] {
  %reduce_sum.3322 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3323 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3324 = f32[] add(%reduce_sum.3322, %reduce_sum.3323), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_81.3408 (reduce_sum.3405: f32[], reduce_sum.3406: f32[]) -> f32[] {
  %reduce_sum.3405 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3406 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3407 = f32[] add(%reduce_sum.3405, %reduce_sum.3406), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_82.3434 (reduce_sum.3431: f32[], reduce_sum.3432: f32[]) -> f32[] {
  %reduce_sum.3431 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3432 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3433 = f32[] add(%reduce_sum.3431, %reduce_sum.3432), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_83.3462 (reduce_sum.3459: f32[], reduce_sum.3460: f32[]) -> f32[] {
  %reduce_sum.3459 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3460 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3461 = f32[] add(%reduce_sum.3459, %reduce_sum.3460), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_84.3483 (reduce_sum.3480: f32[], reduce_sum.3481: f32[]) -> f32[] {
  %reduce_sum.3480 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3481 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3482 = f32[] add(%reduce_sum.3480, %reduce_sum.3481), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_85.3566 (reduce_sum.3563: f32[], reduce_sum.3564: f32[]) -> f32[] {
  %reduce_sum.3563 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3564 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3565 = f32[] add(%reduce_sum.3563, %reduce_sum.3564), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_86.3592 (reduce_sum.3589: f32[], reduce_sum.3590: f32[]) -> f32[] {
  %reduce_sum.3589 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3590 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3591 = f32[] add(%reduce_sum.3589, %reduce_sum.3590), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_87.3620 (reduce_sum.3617: f32[], reduce_sum.3618: f32[]) -> f32[] {
  %reduce_sum.3617 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3618 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3619 = f32[] add(%reduce_sum.3617, %reduce_sum.3618), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_88.3641 (reduce_sum.3638: f32[], reduce_sum.3639: f32[]) -> f32[] {
  %reduce_sum.3638 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3639 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3640 = f32[] add(%reduce_sum.3638, %reduce_sum.3639), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_89.3724 (reduce_sum.3721: f32[], reduce_sum.3722: f32[]) -> f32[] {
  %reduce_sum.3721 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3722 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3723 = f32[] add(%reduce_sum.3721, %reduce_sum.3722), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_90.3750 (reduce_sum.3747: f32[], reduce_sum.3748: f32[]) -> f32[] {
  %reduce_sum.3747 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3748 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3749 = f32[] add(%reduce_sum.3747, %reduce_sum.3748), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_91.3778 (reduce_sum.3775: f32[], reduce_sum.3776: f32[]) -> f32[] {
  %reduce_sum.3775 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3776 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3777 = f32[] add(%reduce_sum.3775, %reduce_sum.3776), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_92.3799 (reduce_sum.3796: f32[], reduce_sum.3797: f32[]) -> f32[] {
  %reduce_sum.3796 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3797 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3798 = f32[] add(%reduce_sum.3796, %reduce_sum.3797), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_93.3882 (reduce_sum.3879: f32[], reduce_sum.3880: f32[]) -> f32[] {
  %reduce_sum.3879 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3880 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3881 = f32[] add(%reduce_sum.3879, %reduce_sum.3880), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_94.3908 (reduce_sum.3905: f32[], reduce_sum.3906: f32[]) -> f32[] {
  %reduce_sum.3905 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3906 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3907 = f32[] add(%reduce_sum.3905, %reduce_sum.3906), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_95.3936 (reduce_sum.3933: f32[], reduce_sum.3934: f32[]) -> f32[] {
  %reduce_sum.3933 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3934 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3935 = f32[] add(%reduce_sum.3933, %reduce_sum.3934), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_96.3957 (reduce_sum.3954: f32[], reduce_sum.3955: f32[]) -> f32[] {
  %reduce_sum.3954 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3955 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3956 = f32[] add(%reduce_sum.3954, %reduce_sum.3955), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_97.4040 (reduce_sum.4037: f32[], reduce_sum.4038: f32[]) -> f32[] {
  %reduce_sum.4037 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4038 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4039 = f32[] add(%reduce_sum.4037, %reduce_sum.4038), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_98.4066 (reduce_sum.4063: f32[], reduce_sum.4064: f32[]) -> f32[] {
  %reduce_sum.4063 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4064 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4065 = f32[] add(%reduce_sum.4063, %reduce_sum.4064), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_99.4094 (reduce_sum.4091: f32[], reduce_sum.4092: f32[]) -> f32[] {
  %reduce_sum.4091 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4092 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4093 = f32[] add(%reduce_sum.4091, %reduce_sum.4092), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_100.4115 (reduce_sum.4112: f32[], reduce_sum.4113: f32[]) -> f32[] {
  %reduce_sum.4112 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4113 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4114 = f32[] add(%reduce_sum.4112, %reduce_sum.4113), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_101.4198 (reduce_sum.4195: f32[], reduce_sum.4196: f32[]) -> f32[] {
  %reduce_sum.4195 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4196 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4197 = f32[] add(%reduce_sum.4195, %reduce_sum.4196), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_102.4224 (reduce_sum.4221: f32[], reduce_sum.4222: f32[]) -> f32[] {
  %reduce_sum.4221 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4222 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4223 = f32[] add(%reduce_sum.4221, %reduce_sum.4222), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_103.4252 (reduce_sum.4249: f32[], reduce_sum.4250: f32[]) -> f32[] {
  %reduce_sum.4249 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4250 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4251 = f32[] add(%reduce_sum.4249, %reduce_sum.4250), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_104.4273 (reduce_sum.4270: f32[], reduce_sum.4271: f32[]) -> f32[] {
  %reduce_sum.4270 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4271 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4272 = f32[] add(%reduce_sum.4270, %reduce_sum.4271), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_105.4356 (reduce_sum.4353: f32[], reduce_sum.4354: f32[]) -> f32[] {
  %reduce_sum.4353 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4354 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4355 = f32[] add(%reduce_sum.4353, %reduce_sum.4354), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_106.4382 (reduce_sum.4379: f32[], reduce_sum.4380: f32[]) -> f32[] {
  %reduce_sum.4379 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4380 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4381 = f32[] add(%reduce_sum.4379, %reduce_sum.4380), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_107.4410 (reduce_sum.4407: f32[], reduce_sum.4408: f32[]) -> f32[] {
  %reduce_sum.4407 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4408 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4409 = f32[] add(%reduce_sum.4407, %reduce_sum.4408), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_108.4431 (reduce_sum.4428: f32[], reduce_sum.4429: f32[]) -> f32[] {
  %reduce_sum.4428 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4429 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4430 = f32[] add(%reduce_sum.4428, %reduce_sum.4429), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_109.4514 (reduce_sum.4511: f32[], reduce_sum.4512: f32[]) -> f32[] {
  %reduce_sum.4511 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4512 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4513 = f32[] add(%reduce_sum.4511, %reduce_sum.4512), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_110.4540 (reduce_sum.4537: f32[], reduce_sum.4538: f32[]) -> f32[] {
  %reduce_sum.4537 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4538 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4539 = f32[] add(%reduce_sum.4537, %reduce_sum.4538), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_111.4568 (reduce_sum.4565: f32[], reduce_sum.4566: f32[]) -> f32[] {
  %reduce_sum.4565 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4566 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4567 = f32[] add(%reduce_sum.4565, %reduce_sum.4566), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_112.4589 (reduce_sum.4586: f32[], reduce_sum.4587: f32[]) -> f32[] {
  %reduce_sum.4586 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4587 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4588 = f32[] add(%reduce_sum.4586, %reduce_sum.4587), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_113.4672 (reduce_sum.4669: f32[], reduce_sum.4670: f32[]) -> f32[] {
  %reduce_sum.4669 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4670 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4671 = f32[] add(%reduce_sum.4669, %reduce_sum.4670), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_114.4698 (reduce_sum.4695: f32[], reduce_sum.4696: f32[]) -> f32[] {
  %reduce_sum.4695 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4696 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4697 = f32[] add(%reduce_sum.4695, %reduce_sum.4696), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_115.4726 (reduce_sum.4723: f32[], reduce_sum.4724: f32[]) -> f32[] {
  %reduce_sum.4723 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4724 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4725 = f32[] add(%reduce_sum.4723, %reduce_sum.4724), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_116.4747 (reduce_sum.4744: f32[], reduce_sum.4745: f32[]) -> f32[] {
  %reduce_sum.4744 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4745 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4746 = f32[] add(%reduce_sum.4744, %reduce_sum.4745), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_117.4830 (reduce_sum.4827: f32[], reduce_sum.4828: f32[]) -> f32[] {
  %reduce_sum.4827 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4828 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4829 = f32[] add(%reduce_sum.4827, %reduce_sum.4828), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_118.4856 (reduce_sum.4853: f32[], reduce_sum.4854: f32[]) -> f32[] {
  %reduce_sum.4853 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4854 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4855 = f32[] add(%reduce_sum.4853, %reduce_sum.4854), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_119.4884 (reduce_sum.4881: f32[], reduce_sum.4882: f32[]) -> f32[] {
  %reduce_sum.4881 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4882 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4883 = f32[] add(%reduce_sum.4881, %reduce_sum.4882), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_120.4905 (reduce_sum.4902: f32[], reduce_sum.4903: f32[]) -> f32[] {
  %reduce_sum.4902 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4903 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4904 = f32[] add(%reduce_sum.4902, %reduce_sum.4903), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_121.4988 (reduce_sum.4985: f32[], reduce_sum.4986: f32[]) -> f32[] {
  %reduce_sum.4985 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4986 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4987 = f32[] add(%reduce_sum.4985, %reduce_sum.4986), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_122.5014 (reduce_sum.5011: f32[], reduce_sum.5012: f32[]) -> f32[] {
  %reduce_sum.5011 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5012 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5013 = f32[] add(%reduce_sum.5011, %reduce_sum.5012), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_123.5042 (reduce_sum.5039: f32[], reduce_sum.5040: f32[]) -> f32[] {
  %reduce_sum.5039 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5040 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5041 = f32[] add(%reduce_sum.5039, %reduce_sum.5040), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_124.5063 (reduce_sum.5060: f32[], reduce_sum.5061: f32[]) -> f32[] {
  %reduce_sum.5060 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5061 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5062 = f32[] add(%reduce_sum.5060, %reduce_sum.5061), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_125.5146 (reduce_sum.5143: f32[], reduce_sum.5144: f32[]) -> f32[] {
  %reduce_sum.5143 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5144 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5145 = f32[] add(%reduce_sum.5143, %reduce_sum.5144), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_126.5172 (reduce_sum.5169: f32[], reduce_sum.5170: f32[]) -> f32[] {
  %reduce_sum.5169 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5170 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5171 = f32[] add(%reduce_sum.5169, %reduce_sum.5170), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_127.5200 (reduce_sum.5197: f32[], reduce_sum.5198: f32[]) -> f32[] {
  %reduce_sum.5197 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5198 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5199 = f32[] add(%reduce_sum.5197, %reduce_sum.5198), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_128.5221 (reduce_sum.5218: f32[], reduce_sum.5219: f32[]) -> f32[] {
  %reduce_sum.5218 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5219 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5220 = f32[] add(%reduce_sum.5218, %reduce_sum.5219), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_129.5304 (reduce_sum.5301: f32[], reduce_sum.5302: f32[]) -> f32[] {
  %reduce_sum.5301 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5302 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5303 = f32[] add(%reduce_sum.5301, %reduce_sum.5302), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_130.5330 (reduce_sum.5327: f32[], reduce_sum.5328: f32[]) -> f32[] {
  %reduce_sum.5327 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5328 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5329 = f32[] add(%reduce_sum.5327, %reduce_sum.5328), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_131.5358 (reduce_sum.5355: f32[], reduce_sum.5356: f32[]) -> f32[] {
  %reduce_sum.5355 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5356 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5357 = f32[] add(%reduce_sum.5355, %reduce_sum.5356), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_132.5379 (reduce_sum.5376: f32[], reduce_sum.5377: f32[]) -> f32[] {
  %reduce_sum.5376 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5377 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5378 = f32[] add(%reduce_sum.5376, %reduce_sum.5377), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_133.5462 (reduce_sum.5459: f32[], reduce_sum.5460: f32[]) -> f32[] {
  %reduce_sum.5459 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5460 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5461 = f32[] add(%reduce_sum.5459, %reduce_sum.5460), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_134.5488 (reduce_sum.5485: f32[], reduce_sum.5486: f32[]) -> f32[] {
  %reduce_sum.5485 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5486 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5487 = f32[] add(%reduce_sum.5485, %reduce_sum.5486), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_135.5516 (reduce_sum.5513: f32[], reduce_sum.5514: f32[]) -> f32[] {
  %reduce_sum.5513 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5514 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5515 = f32[] add(%reduce_sum.5513, %reduce_sum.5514), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_136.5537 (reduce_sum.5534: f32[], reduce_sum.5535: f32[]) -> f32[] {
  %reduce_sum.5534 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5535 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5536 = f32[] add(%reduce_sum.5534, %reduce_sum.5535), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_137.5620 (reduce_sum.5617: f32[], reduce_sum.5618: f32[]) -> f32[] {
  %reduce_sum.5617 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5618 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5619 = f32[] add(%reduce_sum.5617, %reduce_sum.5618), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_138.5646 (reduce_sum.5643: f32[], reduce_sum.5644: f32[]) -> f32[] {
  %reduce_sum.5643 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5644 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5645 = f32[] add(%reduce_sum.5643, %reduce_sum.5644), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_139.5674 (reduce_sum.5671: f32[], reduce_sum.5672: f32[]) -> f32[] {
  %reduce_sum.5671 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5672 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5673 = f32[] add(%reduce_sum.5671, %reduce_sum.5672), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_140.5695 (reduce_sum.5692: f32[], reduce_sum.5693: f32[]) -> f32[] {
  %reduce_sum.5692 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5693 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5694 = f32[] add(%reduce_sum.5692, %reduce_sum.5693), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_141.5778 (reduce_sum.5775: f32[], reduce_sum.5776: f32[]) -> f32[] {
  %reduce_sum.5775 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5776 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5777 = f32[] add(%reduce_sum.5775, %reduce_sum.5776), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_142.5804 (reduce_sum.5801: f32[], reduce_sum.5802: f32[]) -> f32[] {
  %reduce_sum.5801 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5802 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5803 = f32[] add(%reduce_sum.5801, %reduce_sum.5802), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_143.5832 (reduce_sum.5829: f32[], reduce_sum.5830: f32[]) -> f32[] {
  %reduce_sum.5829 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5830 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5831 = f32[] add(%reduce_sum.5829, %reduce_sum.5830), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_144.5853 (reduce_sum.5850: f32[], reduce_sum.5851: f32[]) -> f32[] {
  %reduce_sum.5850 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5851 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5852 = f32[] add(%reduce_sum.5850, %reduce_sum.5851), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_145.5936 (reduce_sum.5933: f32[], reduce_sum.5934: f32[]) -> f32[] {
  %reduce_sum.5933 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5934 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5935 = f32[] add(%reduce_sum.5933, %reduce_sum.5934), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_146.5962 (reduce_sum.5959: f32[], reduce_sum.5960: f32[]) -> f32[] {
  %reduce_sum.5959 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5960 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5961 = f32[] add(%reduce_sum.5959, %reduce_sum.5960), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_147.5990 (reduce_sum.5987: f32[], reduce_sum.5988: f32[]) -> f32[] {
  %reduce_sum.5987 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5988 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5989 = f32[] add(%reduce_sum.5987, %reduce_sum.5988), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_148.6011 (reduce_sum.6008: f32[], reduce_sum.6009: f32[]) -> f32[] {
  %reduce_sum.6008 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6009 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6010 = f32[] add(%reduce_sum.6008, %reduce_sum.6009), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_149.6094 (reduce_sum.6091: f32[], reduce_sum.6092: f32[]) -> f32[] {
  %reduce_sum.6091 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6092 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6093 = f32[] add(%reduce_sum.6091, %reduce_sum.6092), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_150.6120 (reduce_sum.6117: f32[], reduce_sum.6118: f32[]) -> f32[] {
  %reduce_sum.6117 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6118 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6119 = f32[] add(%reduce_sum.6117, %reduce_sum.6118), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_151.6148 (reduce_sum.6145: f32[], reduce_sum.6146: f32[]) -> f32[] {
  %reduce_sum.6145 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6146 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6147 = f32[] add(%reduce_sum.6145, %reduce_sum.6146), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_152.6169 (reduce_sum.6166: f32[], reduce_sum.6167: f32[]) -> f32[] {
  %reduce_sum.6166 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6167 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6168 = f32[] add(%reduce_sum.6166, %reduce_sum.6167), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_153.6252 (reduce_sum.6249: f32[], reduce_sum.6250: f32[]) -> f32[] {
  %reduce_sum.6249 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6250 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6251 = f32[] add(%reduce_sum.6249, %reduce_sum.6250), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_154.6278 (reduce_sum.6275: f32[], reduce_sum.6276: f32[]) -> f32[] {
  %reduce_sum.6275 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6276 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6277 = f32[] add(%reduce_sum.6275, %reduce_sum.6276), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_155.6306 (reduce_sum.6303: f32[], reduce_sum.6304: f32[]) -> f32[] {
  %reduce_sum.6303 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6304 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6305 = f32[] add(%reduce_sum.6303, %reduce_sum.6304), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_156.6327 (reduce_sum.6324: f32[], reduce_sum.6325: f32[]) -> f32[] {
  %reduce_sum.6324 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6325 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6326 = f32[] add(%reduce_sum.6324, %reduce_sum.6325), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_157.6410 (reduce_sum.6407: f32[], reduce_sum.6408: f32[]) -> f32[] {
  %reduce_sum.6407 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6408 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6409 = f32[] add(%reduce_sum.6407, %reduce_sum.6408), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_158.6436 (reduce_sum.6433: f32[], reduce_sum.6434: f32[]) -> f32[] {
  %reduce_sum.6433 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6434 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6435 = f32[] add(%reduce_sum.6433, %reduce_sum.6434), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_159.6464 (reduce_sum.6461: f32[], reduce_sum.6462: f32[]) -> f32[] {
  %reduce_sum.6461 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6462 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6463 = f32[] add(%reduce_sum.6461, %reduce_sum.6462), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_160.6485 (reduce_sum.6482: f32[], reduce_sum.6483: f32[]) -> f32[] {
  %reduce_sum.6482 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6483 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6484 = f32[] add(%reduce_sum.6482, %reduce_sum.6483), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_161.6568 (reduce_sum.6565: f32[], reduce_sum.6566: f32[]) -> f32[] {
  %reduce_sum.6565 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6566 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6567 = f32[] add(%reduce_sum.6565, %reduce_sum.6566), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_162.6594 (reduce_sum.6591: f32[], reduce_sum.6592: f32[]) -> f32[] {
  %reduce_sum.6591 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6592 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6593 = f32[] add(%reduce_sum.6591, %reduce_sum.6592), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_163.6622 (reduce_sum.6619: f32[], reduce_sum.6620: f32[]) -> f32[] {
  %reduce_sum.6619 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6620 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6621 = f32[] add(%reduce_sum.6619, %reduce_sum.6620), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_164.6643 (reduce_sum.6640: f32[], reduce_sum.6641: f32[]) -> f32[] {
  %reduce_sum.6640 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6641 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6642 = f32[] add(%reduce_sum.6640, %reduce_sum.6641), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_165.6726 (reduce_sum.6723: f32[], reduce_sum.6724: f32[]) -> f32[] {
  %reduce_sum.6723 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6724 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6725 = f32[] add(%reduce_sum.6723, %reduce_sum.6724), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_166.6752 (reduce_sum.6749: f32[], reduce_sum.6750: f32[]) -> f32[] {
  %reduce_sum.6749 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6750 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6751 = f32[] add(%reduce_sum.6749, %reduce_sum.6750), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_167.6780 (reduce_sum.6777: f32[], reduce_sum.6778: f32[]) -> f32[] {
  %reduce_sum.6777 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6778 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6779 = f32[] add(%reduce_sum.6777, %reduce_sum.6778), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_168.6801 (reduce_sum.6798: f32[], reduce_sum.6799: f32[]) -> f32[] {
  %reduce_sum.6798 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6799 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6800 = f32[] add(%reduce_sum.6798, %reduce_sum.6799), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_169.6884 (reduce_sum.6881: f32[], reduce_sum.6882: f32[]) -> f32[] {
  %reduce_sum.6881 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6882 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6883 = f32[] add(%reduce_sum.6881, %reduce_sum.6882), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_170.6910 (reduce_sum.6907: f32[], reduce_sum.6908: f32[]) -> f32[] {
  %reduce_sum.6907 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6908 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6909 = f32[] add(%reduce_sum.6907, %reduce_sum.6908), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_171.6938 (reduce_sum.6935: f32[], reduce_sum.6936: f32[]) -> f32[] {
  %reduce_sum.6935 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6936 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6937 = f32[] add(%reduce_sum.6935, %reduce_sum.6936), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_172.6959 (reduce_sum.6956: f32[], reduce_sum.6957: f32[]) -> f32[] {
  %reduce_sum.6956 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6957 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6958 = f32[] add(%reduce_sum.6956, %reduce_sum.6957), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_173.7042 (reduce_sum.7039: f32[], reduce_sum.7040: f32[]) -> f32[] {
  %reduce_sum.7039 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7040 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7041 = f32[] add(%reduce_sum.7039, %reduce_sum.7040), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_174.7068 (reduce_sum.7065: f32[], reduce_sum.7066: f32[]) -> f32[] {
  %reduce_sum.7065 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7066 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7067 = f32[] add(%reduce_sum.7065, %reduce_sum.7066), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_175.7096 (reduce_sum.7093: f32[], reduce_sum.7094: f32[]) -> f32[] {
  %reduce_sum.7093 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7094 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7095 = f32[] add(%reduce_sum.7093, %reduce_sum.7094), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_176.7117 (reduce_sum.7114: f32[], reduce_sum.7115: f32[]) -> f32[] {
  %reduce_sum.7114 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7115 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7116 = f32[] add(%reduce_sum.7114, %reduce_sum.7115), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_177.7200 (reduce_sum.7197: f32[], reduce_sum.7198: f32[]) -> f32[] {
  %reduce_sum.7197 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7198 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7199 = f32[] add(%reduce_sum.7197, %reduce_sum.7198), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_178.7226 (reduce_sum.7223: f32[], reduce_sum.7224: f32[]) -> f32[] {
  %reduce_sum.7223 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7224 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7225 = f32[] add(%reduce_sum.7223, %reduce_sum.7224), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_179.7254 (reduce_sum.7251: f32[], reduce_sum.7252: f32[]) -> f32[] {
  %reduce_sum.7251 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7252 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7253 = f32[] add(%reduce_sum.7251, %reduce_sum.7252), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_180.7275 (reduce_sum.7272: f32[], reduce_sum.7273: f32[]) -> f32[] {
  %reduce_sum.7272 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7273 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7274 = f32[] add(%reduce_sum.7272, %reduce_sum.7273), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_181.7358 (reduce_sum.7355: f32[], reduce_sum.7356: f32[]) -> f32[] {
  %reduce_sum.7355 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7356 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7357 = f32[] add(%reduce_sum.7355, %reduce_sum.7356), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_182.7384 (reduce_sum.7381: f32[], reduce_sum.7382: f32[]) -> f32[] {
  %reduce_sum.7381 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7382 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7383 = f32[] add(%reduce_sum.7381, %reduce_sum.7382), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_183.7412 (reduce_sum.7409: f32[], reduce_sum.7410: f32[]) -> f32[] {
  %reduce_sum.7409 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7410 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7411 = f32[] add(%reduce_sum.7409, %reduce_sum.7410), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_184.7433 (reduce_sum.7430: f32[], reduce_sum.7431: f32[]) -> f32[] {
  %reduce_sum.7430 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7431 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7432 = f32[] add(%reduce_sum.7430, %reduce_sum.7431), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_185.7516 (reduce_sum.7513: f32[], reduce_sum.7514: f32[]) -> f32[] {
  %reduce_sum.7513 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7514 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7515 = f32[] add(%reduce_sum.7513, %reduce_sum.7514), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_186.7542 (reduce_sum.7539: f32[], reduce_sum.7540: f32[]) -> f32[] {
  %reduce_sum.7539 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7540 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7541 = f32[] add(%reduce_sum.7539, %reduce_sum.7540), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_187.7570 (reduce_sum.7567: f32[], reduce_sum.7568: f32[]) -> f32[] {
  %reduce_sum.7567 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7568 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7569 = f32[] add(%reduce_sum.7567, %reduce_sum.7568), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_188.7591 (reduce_sum.7588: f32[], reduce_sum.7589: f32[]) -> f32[] {
  %reduce_sum.7588 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7589 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7590 = f32[] add(%reduce_sum.7588, %reduce_sum.7589), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_189.7674 (reduce_sum.7671: f32[], reduce_sum.7672: f32[]) -> f32[] {
  %reduce_sum.7671 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7672 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7673 = f32[] add(%reduce_sum.7671, %reduce_sum.7672), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_190.7700 (reduce_sum.7697: f32[], reduce_sum.7698: f32[]) -> f32[] {
  %reduce_sum.7697 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7698 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7699 = f32[] add(%reduce_sum.7697, %reduce_sum.7698), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_191.7728 (reduce_sum.7725: f32[], reduce_sum.7726: f32[]) -> f32[] {
  %reduce_sum.7725 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7726 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7727 = f32[] add(%reduce_sum.7725, %reduce_sum.7726), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_192.7749 (reduce_sum.7746: f32[], reduce_sum.7747: f32[]) -> f32[] {
  %reduce_sum.7746 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7747 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7748 = f32[] add(%reduce_sum.7746, %reduce_sum.7747), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_193.7832 (reduce_sum.7829: f32[], reduce_sum.7830: f32[]) -> f32[] {
  %reduce_sum.7829 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7830 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7831 = f32[] add(%reduce_sum.7829, %reduce_sum.7830), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_194.7858 (reduce_sum.7855: f32[], reduce_sum.7856: f32[]) -> f32[] {
  %reduce_sum.7855 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7856 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7857 = f32[] add(%reduce_sum.7855, %reduce_sum.7856), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_195.7886 (reduce_sum.7883: f32[], reduce_sum.7884: f32[]) -> f32[] {
  %reduce_sum.7883 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7884 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7885 = f32[] add(%reduce_sum.7883, %reduce_sum.7884), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_196.7907 (reduce_sum.7904: f32[], reduce_sum.7905: f32[]) -> f32[] {
  %reduce_sum.7904 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7905 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7906 = f32[] add(%reduce_sum.7904, %reduce_sum.7905), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_197.7990 (reduce_sum.7987: f32[], reduce_sum.7988: f32[]) -> f32[] {
  %reduce_sum.7987 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7988 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7989 = f32[] add(%reduce_sum.7987, %reduce_sum.7988), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_198.8016 (reduce_sum.8013: f32[], reduce_sum.8014: f32[]) -> f32[] {
  %reduce_sum.8013 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8014 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8015 = f32[] add(%reduce_sum.8013, %reduce_sum.8014), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_199.8044 (reduce_sum.8041: f32[], reduce_sum.8042: f32[]) -> f32[] {
  %reduce_sum.8041 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8042 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8043 = f32[] add(%reduce_sum.8041, %reduce_sum.8042), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_200.8065 (reduce_sum.8062: f32[], reduce_sum.8063: f32[]) -> f32[] {
  %reduce_sum.8062 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8063 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8064 = f32[] add(%reduce_sum.8062, %reduce_sum.8063), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_201.8148 (reduce_sum.8145: f32[], reduce_sum.8146: f32[]) -> f32[] {
  %reduce_sum.8145 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8146 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8147 = f32[] add(%reduce_sum.8145, %reduce_sum.8146), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_202.8174 (reduce_sum.8171: f32[], reduce_sum.8172: f32[]) -> f32[] {
  %reduce_sum.8171 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8172 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8173 = f32[] add(%reduce_sum.8171, %reduce_sum.8172), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_203.8202 (reduce_sum.8199: f32[], reduce_sum.8200: f32[]) -> f32[] {
  %reduce_sum.8199 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8200 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8201 = f32[] add(%reduce_sum.8199, %reduce_sum.8200), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_204.8223 (reduce_sum.8220: f32[], reduce_sum.8221: f32[]) -> f32[] {
  %reduce_sum.8220 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8221 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8222 = f32[] add(%reduce_sum.8220, %reduce_sum.8221), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_205.8306 (reduce_sum.8303: f32[], reduce_sum.8304: f32[]) -> f32[] {
  %reduce_sum.8303 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8304 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8305 = f32[] add(%reduce_sum.8303, %reduce_sum.8304), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_206.8332 (reduce_sum.8329: f32[], reduce_sum.8330: f32[]) -> f32[] {
  %reduce_sum.8329 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8330 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8331 = f32[] add(%reduce_sum.8329, %reduce_sum.8330), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_207.8360 (reduce_sum.8357: f32[], reduce_sum.8358: f32[]) -> f32[] {
  %reduce_sum.8357 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8358 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8359 = f32[] add(%reduce_sum.8357, %reduce_sum.8358), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_208.8381 (reduce_sum.8378: f32[], reduce_sum.8379: f32[]) -> f32[] {
  %reduce_sum.8378 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8379 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8380 = f32[] add(%reduce_sum.8378, %reduce_sum.8379), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_209.8464 (reduce_sum.8461: f32[], reduce_sum.8462: f32[]) -> f32[] {
  %reduce_sum.8461 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8462 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8463 = f32[] add(%reduce_sum.8461, %reduce_sum.8462), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_210.8490 (reduce_sum.8487: f32[], reduce_sum.8488: f32[]) -> f32[] {
  %reduce_sum.8487 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8488 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8489 = f32[] add(%reduce_sum.8487, %reduce_sum.8488), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_211.8518 (reduce_sum.8515: f32[], reduce_sum.8516: f32[]) -> f32[] {
  %reduce_sum.8515 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8516 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8517 = f32[] add(%reduce_sum.8515, %reduce_sum.8516), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_212.8539 (reduce_sum.8536: f32[], reduce_sum.8537: f32[]) -> f32[] {
  %reduce_sum.8536 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8537 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8538 = f32[] add(%reduce_sum.8536, %reduce_sum.8537), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_213.8622 (reduce_sum.8619: f32[], reduce_sum.8620: f32[]) -> f32[] {
  %reduce_sum.8619 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8620 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8621 = f32[] add(%reduce_sum.8619, %reduce_sum.8620), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_214.8648 (reduce_sum.8645: f32[], reduce_sum.8646: f32[]) -> f32[] {
  %reduce_sum.8645 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8646 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8647 = f32[] add(%reduce_sum.8645, %reduce_sum.8646), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_215.8676 (reduce_sum.8673: f32[], reduce_sum.8674: f32[]) -> f32[] {
  %reduce_sum.8673 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8674 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8675 = f32[] add(%reduce_sum.8673, %reduce_sum.8674), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_216.8697 (reduce_sum.8694: f32[], reduce_sum.8695: f32[]) -> f32[] {
  %reduce_sum.8694 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8695 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8696 = f32[] add(%reduce_sum.8694, %reduce_sum.8695), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_217.8780 (reduce_sum.8777: f32[], reduce_sum.8778: f32[]) -> f32[] {
  %reduce_sum.8777 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8778 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8779 = f32[] add(%reduce_sum.8777, %reduce_sum.8778), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_218.8806 (reduce_sum.8803: f32[], reduce_sum.8804: f32[]) -> f32[] {
  %reduce_sum.8803 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8804 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8805 = f32[] add(%reduce_sum.8803, %reduce_sum.8804), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_219.8834 (reduce_sum.8831: f32[], reduce_sum.8832: f32[]) -> f32[] {
  %reduce_sum.8831 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8832 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8833 = f32[] add(%reduce_sum.8831, %reduce_sum.8832), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_220.8855 (reduce_sum.8852: f32[], reduce_sum.8853: f32[]) -> f32[] {
  %reduce_sum.8852 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8853 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8854 = f32[] add(%reduce_sum.8852, %reduce_sum.8853), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_221.8938 (reduce_sum.8935: f32[], reduce_sum.8936: f32[]) -> f32[] {
  %reduce_sum.8935 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8936 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8937 = f32[] add(%reduce_sum.8935, %reduce_sum.8936), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_222.8963 (reduce_sum.8960: f32[], reduce_sum.8961: f32[]) -> f32[] {
  %reduce_sum.8960 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8961 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8962 = f32[] add(%reduce_sum.8960, %reduce_sum.8961), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

ENTRY %main.8980 (params_and_buffers__vllm_model_language_model_model_embed_tokens_weight__.1: bf16[152064,2048], params_and_buffers__vllm_model_language_model_model_layers_0_input_layernorm_weight__.2: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_0_mlp_experts_w13_weight__.3: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_0_mlp_experts_w2_weight__.4: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_0_mlp_gate_weight__.5: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_0_post_attention_layernorm_weight__.6: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_k_norm_weight__.7: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_o_proj_weight__.8: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_q_norm_weight__.9: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_qkv_proj_weight__.10: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11: bf16[262144,128], params_and_buffers__vllm_model_language_model_model_layers_1_input_layernorm_weight__.12: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_1_mlp_experts_w13_weight__.13: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_1_mlp_experts_w2_weight__.14: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_1_mlp_gate_weight__.15: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_1_post_attention_layernorm_weight__.16: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_1_self_attn_k_norm_weight__.17: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_1_self_attn_o_proj_weight__.18: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_1_self_attn_q_norm_weight__.19: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_1_self_attn_qkv_proj_weight__.20: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_10_input_layernorm_weight__.21: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_10_mlp_experts_w13_weight__.22: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_10_mlp_experts_w2_weight__.23: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_10_mlp_gate_weight__.24: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_10_post_attention_layernorm_weight__.25: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_10_self_attn_k_norm_weight__.26: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_10_self_attn_o_proj_weight__.27: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_10_self_attn_q_norm_weight__.28: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_10_self_attn_qkv_proj_weight__.29: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_11_input_layernorm_weight__.30: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_11_mlp_experts_w13_weight__.31: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_11_mlp_experts_w2_weight__.32: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_11_mlp_gate_weight__.33: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_11_post_attention_layernorm_weight__.34: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_11_self_attn_k_norm_weight__.35: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_11_self_attn_o_proj_weight__.36: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_11_self_attn_q_norm_weight__.37: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_11_self_attn_qkv_proj_weight__.38: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_12_input_layernorm_weight__.39: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_12_mlp_experts_w13_weight__.40: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_12_mlp_experts_w2_weight__.41: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_12_mlp_gate_weight__.42: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_12_post_attention_layernorm_weight__.43: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_12_self_attn_k_norm_weight__.44: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_12_self_attn_o_proj_weight__.45: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_12_self_attn_q_norm_weight__.46: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_12_self_attn_qkv_proj_weight__.47: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_13_input_layernorm_weight__.48: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_13_mlp_experts_w13_weight__.49: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_13_mlp_experts_w2_weight__.50: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_13_mlp_gate_weight__.51: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_13_post_attention_layernorm_weight__.52: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_13_self_attn_k_norm_weight__.53: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_13_self_attn_o_proj_weight__.54: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_13_self_attn_q_norm_weight__.55: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_13_self_attn_qkv_proj_weight__.56: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_14_input_layernorm_weight__.57: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_14_mlp_experts_w13_weight__.58: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_14_mlp_experts_w2_weight__.59: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_14_mlp_gate_weight__.60: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_14_post_attention_layernorm_weight__.61: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_14_self_attn_k_norm_weight__.62: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_14_self_attn_o_proj_weight__.63: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_14_self_attn_q_norm_weight__.64: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_14_self_attn_qkv_proj_weight__.65: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_15_input_layernorm_weight__.66: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_15_mlp_experts_w13_weight__.67: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_15_mlp_experts_w2_weight__.68: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_15_mlp_gate_weight__.69: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_15_post_attention_layernorm_weight__.70: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_15_self_attn_k_norm_weight__.71: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_15_self_attn_o_proj_weight__.72: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_15_self_attn_q_norm_weight__.73: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_15_self_attn_qkv_proj_weight__.74: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_16_input_layernorm_weight__.75: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_16_mlp_experts_w13_weight__.76: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_16_mlp_experts_w2_weight__.77: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_16_mlp_gate_weight__.78: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_16_post_attention_layernorm_weight__.79: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_16_self_attn_k_norm_weight__.80: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_16_self_attn_o_proj_weight__.81: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_16_self_attn_q_norm_weight__.82: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_16_self_attn_qkv_proj_weight__.83: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_17_input_layernorm_weight__.84: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_17_mlp_experts_w13_weight__.85: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_17_mlp_experts_w2_weight__.86: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_17_mlp_gate_weight__.87: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_17_post_attention_layernorm_weight__.88: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_17_self_attn_k_norm_weight__.89: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_17_self_attn_o_proj_weight__.90: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_17_self_attn_q_norm_weight__.91: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_17_self_attn_qkv_proj_weight__.92: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_18_input_layernorm_weight__.93: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_18_mlp_experts_w13_weight__.94: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_18_mlp_experts_w2_weight__.95: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_18_mlp_gate_weight__.96: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_18_post_attention_layernorm_weight__.97: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_18_self_attn_k_norm_weight__.98: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_18_self_attn_o_proj_weight__.99: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_18_self_attn_q_norm_weight__.100: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_18_self_attn_qkv_proj_weight__.101: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_19_input_layernorm_weight__.102: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_19_mlp_experts_w13_weight__.103: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_19_mlp_experts_w2_weight__.104: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_19_mlp_gate_weight__.105: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_19_post_attention_layernorm_weight__.106: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_19_self_attn_k_norm_weight__.107: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_19_self_attn_o_proj_weight__.108: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_19_self_attn_q_norm_weight__.109: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_19_self_attn_qkv_proj_weight__.110: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_2_input_layernorm_weight__.111: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_2_mlp_experts_w13_weight__.112: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_2_mlp_experts_w2_weight__.113: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_2_mlp_gate_weight__.114: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_2_post_attention_layernorm_weight__.115: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_2_self_attn_k_norm_weight__.116: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_2_self_attn_o_proj_weight__.117: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_2_self_attn_q_norm_weight__.118: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_2_self_attn_qkv_proj_weight__.119: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_20_input_layernorm_weight__.120: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_20_mlp_experts_w13_weight__.121: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_20_mlp_experts_w2_weight__.122: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_20_mlp_gate_weight__.123: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_20_post_attention_layernorm_weight__.124: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_20_self_attn_k_norm_weight__.125: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_20_self_attn_o_proj_weight__.126: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_20_self_attn_q_norm_weight__.127: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_20_self_attn_qkv_proj_weight__.128: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_21_input_layernorm_weight__.129: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_21_mlp_experts_w13_weight__.130: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_21_mlp_experts_w2_weight__.131: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_21_mlp_gate_weight__.132: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_21_post_attention_layernorm_weight__.133: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_21_self_attn_k_norm_weight__.134: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_21_self_attn_o_proj_weight__.135: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_21_self_attn_q_norm_weight__.136: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_21_self_attn_qkv_proj_weight__.137: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_22_input_layernorm_weight__.138: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_22_mlp_experts_w13_weight__.139: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_22_mlp_experts_w2_weight__.140: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_22_mlp_gate_weight__.141: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_22_post_attention_layernorm_weight__.142: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_22_self_attn_k_norm_weight__.143: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_22_self_attn_o_proj_weight__.144: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_22_self_attn_q_norm_weight__.145: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_22_self_attn_qkv_proj_weight__.146: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_23_input_layernorm_weight__.147: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_23_mlp_experts_w13_weight__.148: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_23_mlp_experts_w2_weight__.149: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_23_mlp_gate_weight__.150: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_23_post_attention_layernorm_weight__.151: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_23_self_attn_k_norm_weight__.152: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_23_self_attn_o_proj_weight__.153: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_23_self_attn_q_norm_weight__.154: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_23_self_attn_qkv_proj_weight__.155: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_24_input_layernorm_weight__.156: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_24_mlp_experts_w13_weight__.157: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_24_mlp_experts_w2_weight__.158: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_24_mlp_gate_weight__.159: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_24_post_attention_layernorm_weight__.160: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_24_self_attn_k_norm_weight__.161: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_24_self_attn_o_proj_weight__.162: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_24_self_attn_q_norm_weight__.163: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_24_self_attn_qkv_proj_weight__.164: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_25_input_layernorm_weight__.165: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_25_mlp_experts_w13_weight__.166: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_25_mlp_experts_w2_weight__.167: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_25_mlp_gate_weight__.168: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_25_post_attention_layernorm_weight__.169: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_25_self_attn_k_norm_weight__.170: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_25_self_attn_o_proj_weight__.171: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_25_self_attn_q_norm_weight__.172: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_25_self_attn_qkv_proj_weight__.173: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_26_input_layernorm_weight__.174: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_26_mlp_experts_w13_weight__.175: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_26_mlp_experts_w2_weight__.176: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_26_mlp_gate_weight__.177: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_26_post_attention_layernorm_weight__.178: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_26_self_attn_k_norm_weight__.179: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_26_self_attn_o_proj_weight__.180: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_26_self_attn_q_norm_weight__.181: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_26_self_attn_qkv_proj_weight__.182: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_27_input_layernorm_weight__.183: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_27_mlp_experts_w13_weight__.184: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_27_mlp_experts_w2_weight__.185: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_27_mlp_gate_weight__.186: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_27_post_attention_layernorm_weight__.187: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_27_self_attn_k_norm_weight__.188: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_27_self_attn_o_proj_weight__.189: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_27_self_attn_q_norm_weight__.190: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_27_self_attn_qkv_proj_weight__.191: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_28_input_layernorm_weight__.192: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_28_mlp_experts_w13_weight__.193: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_28_mlp_experts_w2_weight__.194: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_28_mlp_gate_weight__.195: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_28_post_attention_layernorm_weight__.196: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_28_self_attn_k_norm_weight__.197: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_28_self_attn_o_proj_weight__.198: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_28_self_attn_q_norm_weight__.199: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_28_self_attn_qkv_proj_weight__.200: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_29_input_layernorm_weight__.201: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_29_mlp_experts_w13_weight__.202: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_29_mlp_experts_w2_weight__.203: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_29_mlp_gate_weight__.204: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_29_post_attention_layernorm_weight__.205: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_29_self_attn_k_norm_weight__.206: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_29_self_attn_o_proj_weight__.207: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_29_self_attn_q_norm_weight__.208: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_29_self_attn_qkv_proj_weight__.209: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_3_input_layernorm_weight__.210: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_3_mlp_experts_w13_weight__.211: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_3_mlp_experts_w2_weight__.212: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_3_mlp_gate_weight__.213: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_3_post_attention_layernorm_weight__.214: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_3_self_attn_k_norm_weight__.215: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_3_self_attn_o_proj_weight__.216: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_3_self_attn_q_norm_weight__.217: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_3_self_attn_qkv_proj_weight__.218: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_30_input_layernorm_weight__.219: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_30_mlp_experts_w13_weight__.220: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_30_mlp_experts_w2_weight__.221: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_30_mlp_gate_weight__.222: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_30_post_attention_layernorm_weight__.223: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_30_self_attn_k_norm_weight__.224: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_30_self_attn_o_proj_weight__.225: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_30_self_attn_q_norm_weight__.226: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_30_self_attn_qkv_proj_weight__.227: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_31_input_layernorm_weight__.228: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_31_mlp_experts_w13_weight__.229: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_31_mlp_experts_w2_weight__.230: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_31_mlp_gate_weight__.231: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_31_post_attention_layernorm_weight__.232: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_31_self_attn_k_norm_weight__.233: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_31_self_attn_o_proj_weight__.234: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_31_self_attn_q_norm_weight__.235: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_31_self_attn_qkv_proj_weight__.236: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_32_input_layernorm_weight__.237: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_32_mlp_experts_w13_weight__.238: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_32_mlp_experts_w2_weight__.239: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_32_mlp_gate_weight__.240: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_32_post_attention_layernorm_weight__.241: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_32_self_attn_k_norm_weight__.242: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_32_self_attn_o_proj_weight__.243: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_32_self_attn_q_norm_weight__.244: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_32_self_attn_qkv_proj_weight__.245: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_33_input_layernorm_weight__.246: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_33_mlp_experts_w13_weight__.247: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_33_mlp_experts_w2_weight__.248: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_33_mlp_gate_weight__.249: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_33_post_attention_layernorm_weight__.250: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_33_self_attn_k_norm_weight__.251: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_33_self_attn_o_proj_weight__.252: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_33_self_attn_q_norm_weight__.253: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_33_self_attn_qkv_proj_weight__.254: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_34_input_layernorm_weight__.255: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_34_mlp_experts_w13_weight__.256: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_34_mlp_experts_w2_weight__.257: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_34_mlp_gate_weight__.258: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_34_post_attention_layernorm_weight__.259: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_34_self_attn_k_norm_weight__.260: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_34_self_attn_o_proj_weight__.261: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_34_self_attn_q_norm_weight__.262: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_34_self_attn_qkv_proj_weight__.263: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_35_input_layernorm_weight__.264: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_35_mlp_experts_w13_weight__.265: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_35_mlp_experts_w2_weight__.266: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_35_mlp_gate_weight__.267: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_35_post_attention_layernorm_weight__.268: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_35_self_attn_k_norm_weight__.269: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_35_self_attn_o_proj_weight__.270: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_35_self_attn_q_norm_weight__.271: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_35_self_attn_qkv_proj_weight__.272: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_36_input_layernorm_weight__.273: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_36_mlp_experts_w13_weight__.274: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_36_mlp_experts_w2_weight__.275: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_36_mlp_gate_weight__.276: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_36_post_attention_layernorm_weight__.277: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_36_self_attn_k_norm_weight__.278: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_36_self_attn_o_proj_weight__.279: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_36_self_attn_q_norm_weight__.280: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_36_self_attn_qkv_proj_weight__.281: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_37_input_layernorm_weight__.282: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_37_mlp_experts_w13_weight__.283: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_37_mlp_experts_w2_weight__.284: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_37_mlp_gate_weight__.285: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_37_post_attention_layernorm_weight__.286: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_37_self_attn_k_norm_weight__.287: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_37_self_attn_o_proj_weight__.288: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_37_self_attn_q_norm_weight__.289: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_37_self_attn_qkv_proj_weight__.290: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_38_input_layernorm_weight__.291: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_38_mlp_experts_w13_weight__.292: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_38_mlp_experts_w2_weight__.293: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_38_mlp_gate_weight__.294: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_38_post_attention_layernorm_weight__.295: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_38_self_attn_k_norm_weight__.296: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_38_self_attn_o_proj_weight__.297: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_38_self_attn_q_norm_weight__.298: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_38_self_attn_qkv_proj_weight__.299: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_39_input_layernorm_weight__.300: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_39_mlp_experts_w13_weight__.301: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_39_mlp_experts_w2_weight__.302: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_39_mlp_gate_weight__.303: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_39_post_attention_layernorm_weight__.304: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_39_self_attn_k_norm_weight__.305: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_39_self_attn_o_proj_weight__.306: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_39_self_attn_q_norm_weight__.307: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_39_self_attn_qkv_proj_weight__.308: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_4_input_layernorm_weight__.309: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_4_mlp_experts_w13_weight__.310: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_4_mlp_experts_w2_weight__.311: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_4_mlp_gate_weight__.312: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_4_post_attention_layernorm_weight__.313: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_4_self_attn_k_norm_weight__.314: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_4_self_attn_o_proj_weight__.315: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_4_self_attn_q_norm_weight__.316: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_4_self_attn_qkv_proj_weight__.317: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_40_input_layernorm_weight__.318: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_40_mlp_experts_w13_weight__.319: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_40_mlp_experts_w2_weight__.320: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_40_mlp_gate_weight__.321: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_40_post_attention_layernorm_weight__.322: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_40_self_attn_k_norm_weight__.323: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_40_self_attn_o_proj_weight__.324: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_40_self_attn_q_norm_weight__.325: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_40_self_attn_qkv_proj_weight__.326: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_41_input_layernorm_weight__.327: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_41_mlp_experts_w13_weight__.328: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_41_mlp_experts_w2_weight__.329: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_41_mlp_gate_weight__.330: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_41_post_attention_layernorm_weight__.331: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_41_self_attn_k_norm_weight__.332: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_41_self_attn_o_proj_weight__.333: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_41_self_attn_q_norm_weight__.334: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_41_self_attn_qkv_proj_weight__.335: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_42_input_layernorm_weight__.336: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_42_mlp_experts_w13_weight__.337: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_42_mlp_experts_w2_weight__.338: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_42_mlp_gate_weight__.339: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_42_post_attention_layernorm_weight__.340: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_42_self_attn_k_norm_weight__.341: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_42_self_attn_o_proj_weight__.342: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_42_self_attn_q_norm_weight__.343: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_42_self_attn_qkv_proj_weight__.344: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_43_input_layernorm_weight__.345: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_43_mlp_experts_w13_weight__.346: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_43_mlp_experts_w2_weight__.347: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_43_mlp_gate_weight__.348: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_43_post_attention_layernorm_weight__.349: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_43_self_attn_k_norm_weight__.350: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_43_self_attn_o_proj_weight__.351: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_43_self_attn_q_norm_weight__.352: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_43_self_attn_qkv_proj_weight__.353: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_44_input_layernorm_weight__.354: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_44_mlp_experts_w13_weight__.355: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_44_mlp_experts_w2_weight__.356: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_44_mlp_gate_weight__.357: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_44_post_attention_layernorm_weight__.358: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_44_self_attn_k_norm_weight__.359: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_44_self_attn_o_proj_weight__.360: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_44_self_attn_q_norm_weight__.361: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_44_self_attn_qkv_proj_weight__.362: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_45_input_layernorm_weight__.363: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_45_mlp_experts_w13_weight__.364: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_45_mlp_experts_w2_weight__.365: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_45_mlp_gate_weight__.366: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_45_post_attention_layernorm_weight__.367: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_45_self_attn_k_norm_weight__.368: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_45_self_attn_o_proj_weight__.369: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_45_self_attn_q_norm_weight__.370: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_45_self_attn_qkv_proj_weight__.371: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_46_input_layernorm_weight__.372: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_46_mlp_experts_w13_weight__.373: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_46_mlp_experts_w2_weight__.374: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_46_mlp_gate_weight__.375: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_46_post_attention_layernorm_weight__.376: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_46_self_attn_k_norm_weight__.377: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_46_self_attn_o_proj_weight__.378: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_46_self_attn_q_norm_weight__.379: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_46_self_attn_qkv_proj_weight__.380: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_47_input_layernorm_weight__.381: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_47_mlp_experts_w13_weight__.382: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_47_mlp_experts_w2_weight__.383: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_47_mlp_gate_weight__.384: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_47_post_attention_layernorm_weight__.385: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_47_self_attn_k_norm_weight__.386: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_47_self_attn_o_proj_weight__.387: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_47_self_attn_q_norm_weight__.388: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_47_self_attn_qkv_proj_weight__.389: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_5_input_layernorm_weight__.390: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_5_mlp_experts_w13_weight__.391: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_5_mlp_experts_w2_weight__.392: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_5_mlp_gate_weight__.393: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_5_post_attention_layernorm_weight__.394: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_5_self_attn_k_norm_weight__.395: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_5_self_attn_o_proj_weight__.396: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_5_self_attn_q_norm_weight__.397: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_5_self_attn_qkv_proj_weight__.398: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_6_input_layernorm_weight__.399: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_6_mlp_experts_w13_weight__.400: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_6_mlp_experts_w2_weight__.401: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_6_mlp_gate_weight__.402: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_6_post_attention_layernorm_weight__.403: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_6_self_attn_k_norm_weight__.404: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_6_self_attn_o_proj_weight__.405: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_6_self_attn_q_norm_weight__.406: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_6_self_attn_qkv_proj_weight__.407: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_7_input_layernorm_weight__.408: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_7_mlp_experts_w13_weight__.409: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_7_mlp_experts_w2_weight__.410: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_7_mlp_gate_weight__.411: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_7_post_attention_layernorm_weight__.412: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_7_self_attn_k_norm_weight__.413: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_7_self_attn_o_proj_weight__.414: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_7_self_attn_q_norm_weight__.415: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_7_self_attn_qkv_proj_weight__.416: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_8_input_layernorm_weight__.417: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_8_mlp_experts_w13_weight__.418: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_8_mlp_experts_w2_weight__.419: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_8_mlp_gate_weight__.420: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_8_post_attention_layernorm_weight__.421: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_8_self_attn_k_norm_weight__.422: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_8_self_attn_o_proj_weight__.423: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_8_self_attn_q_norm_weight__.424: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_8_self_attn_qkv_proj_weight__.425: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_9_input_layernorm_weight__.426: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_9_mlp_experts_w13_weight__.427: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_9_mlp_experts_w2_weight__.428: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_9_mlp_gate_weight__.429: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_9_post_attention_layernorm_weight__.430: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_9_self_attn_k_norm_weight__.431: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_9_self_attn_o_proj_weight__.432: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_9_self_attn_q_norm_weight__.433: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_9_self_attn_qkv_proj_weight__.434: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_norm_weight__.435: bf16[2048], kv_caches_0_.436: bf16[14813,32,4,2,128], kv_caches_1_.437: bf16[14813,32,4,2,128], kv_caches_2_.438: bf16[14813,32,4,2,128], kv_caches_3_.439: bf16[14813,32,4,2,128], kv_caches_4_.440: bf16[14813,32,4,2,128], kv_caches_5_.441: bf16[14813,32,4,2,128], kv_caches_6_.442: bf16[14813,32,4,2,128], kv_caches_7_.443: bf16[14813,32,4,2,128], kv_caches_8_.444: bf16[14813,32,4,2,128], kv_caches_9_.445: bf16[14813,32,4,2,128], kv_caches_10_.446: bf16[14813,32,4,2,128], kv_caches_11_.447: bf16[14813,32,4,2,128], kv_caches_12_.448: bf16[14813,32,4,2,128], kv_caches_13_.449: bf16[14813,32,4,2,128], kv_caches_14_.450: bf16[14813,32,4,2,128], kv_caches_15_.451: bf16[14813,32,4,2,128], kv_caches_16_.452: bf16[14813,32,4,2,128], kv_caches_17_.453: bf16[14813,32,4,2,128], kv_caches_18_.454: bf16[14813,32,4,2,128], kv_caches_19_.455: bf16[14813,32,4,2,128], kv_caches_20_.456: bf16[14813,32,4,2,128], kv_caches_21_.457: bf16[14813,32,4,2,128], kv_caches_22_.458: bf16[14813,32,4,2,128], kv_caches_23_.459: bf16[14813,32,4,2,128], kv_caches_24_.460: bf16[14813,32,4,2,128], kv_caches_25_.461: bf16[14813,32,4,2,128], kv_caches_26_.462: bf16[14813,32,4,2,128], kv_caches_27_.463: bf16[14813,32,4,2,128], kv_caches_28_.464: bf16[14813,32,4,2,128], kv_caches_29_.465: bf16[14813,32,4,2,128], kv_caches_30_.466: bf16[14813,32,4,2,128], kv_caches_31_.467: bf16[14813,32,4,2,128], kv_caches_32_.468: bf16[14813,32,4,2,128], kv_caches_33_.469: bf16[14813,32,4,2,128], kv_caches_34_.470: bf16[14813,32,4,2,128], kv_caches_35_.471: bf16[14813,32,4,2,128], kv_caches_36_.472: bf16[14813,32,4,2,128], kv_caches_37_.473: bf16[14813,32,4,2,128], kv_caches_38_.474: bf16[14813,32,4,2,128], kv_caches_39_.475: bf16[14813,32,4,2,128], kv_caches_40_.476: bf16[14813,32,4,2,128], kv_caches_41_.477: bf16[14813,32,4,2,128], kv_caches_42_.478: bf16[14813,32,4,2,128], kv_caches_43_.479: bf16[14813,32,4,2,128], kv_caches_44_.480: bf16[14813,32,4,2,128], kv_caches_45_.481: bf16[14813,32,4,2,128], kv_caches_46_.482: bf16[14813,32,4,2,128], kv_caches_47_.483: bf16[14813,32,4,2,128], input_ids.484: s32[16], attn_metadata_input_positions.485: s32[16], attn_metadata_block_tables.486: s32[131072], attn_metadata_seq_lens.487: s32[256], attn_metadata_query_start_loc.488: s32[257], attn_metadata_request_distribution.489: s32[3]) -> (bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], /*index=5*/bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], /*index=10*/bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], /*index=15*/bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], /*index=20*/bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], /*index=25*/bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], /*index=30*/bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], /*index=35*/bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], /*index=40*/bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], /*index=45*/bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[16,2048]) {
  %kv_caches_0_.436 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(435), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[0]"}
  %params_and_buffers__vllm_model_language_model_model_embed_tokens_weight__.1 = bf16[152064,2048]{1,0} parameter(0), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.embed_tokens.weight\']"}
  %input_ids.484 = s32[16]{0} parameter(483), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="input_ids"}
  %jit__take_.547 = bf16[16,2048]{1,0} call(%params_and_buffers__vllm_model_language_model_model_embed_tokens_weight__.1, %input_ids.484), to_apply=%_take.546, metadata={op_name="jit(step_fun)/aten::embedding/jit(_take)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
  %convert_element_type.548 = f32[16,2048]{1,0} convert(%jit__take_.547), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %constant.510 = f32[] constant(2)
  %broadcast.511 = f32[16,2048]{1,0} broadcast(%constant.510), dimensions={}
  %pow.549 = f32[16,2048]{1,0} power(%convert_element_type.548, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %constant.512 = f32[] constant(0)
  %reduce_sum.554 = f32[16]{0} reduce(%pow.549, %constant.512), dimensions={1}, to_apply=%region_1.553, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.555 = f32[16,1]{1,0} reshape(%reduce_sum.554), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %constant.508 = f32[] constant(2048)
  %broadcast.509 = f32[16,1]{1,0} broadcast(%constant.508), dimensions={}
  %div.556 = f32[16,1]{1,0} divide(%broadcast_in_dim.555, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %constant.506 = f32[] constant(1e-06)
  %broadcast.507 = f32[16,1]{1,0} broadcast(%constant.506), dimensions={}
  %add.557 = f32[16,1]{1,0} add(%div.556, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.558 = f32[16,1]{1,0} rsqrt(%add.557), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.559 = f32[16,1]{1,0} broadcast(%rsqrt.558), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.560 = f32[16]{0} reshape(%mul.559), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.561 = f32[16,2048]{1,0} broadcast(%mul.560), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.562 = f32[16,2048]{1,0} multiply(%convert_element_type.548, %mul.561), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.563 = bf16[16,2048]{1,0} convert(%mul.562), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_0_input_layernorm_weight__.2 = bf16[2048]{0} parameter(1), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.0.input_layernorm.weight\']"}
  %broadcast_in_dim.564 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_0_input_layernorm_weight__.2), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.565 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.564), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.566 = bf16[2048]{0} reshape(%mul.565), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.567 = bf16[16,2048]{1,0} broadcast(%mul.566), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.568 = bf16[16,2048]{1,0} multiply(%convert_element_type.563, %mul.567), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_qkv_proj_weight__.10 = bf16[5120,2048]{1,0} parameter(9), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.0.self_attn.qkv_proj.weight\']"}
  %dot_general.569 = bf16[16,5120]{1,0} dot(%mul.568, %params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_qkv_proj_weight__.10), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.570 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.569), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.571 = bf16[16,4,1024]{2,1,0} slice(%reshape.570), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.575 = bf16[16,32,128]{2,1,0} reshape(%slice.571), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.576 = f32[16,32,128]{2,1,0} convert(%reshape.575), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %constant.504 = f32[] constant(2)
  %broadcast.505 = f32[16,32,128]{2,1,0} broadcast(%constant.504), dimensions={}
  %pow.577 = f32[16,32,128]{2,1,0} power(%convert_element_type.576, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.582 = f32[16,32]{1,0} reduce(%pow.577, %constant.512), dimensions={2}, to_apply=%region_2.581, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.583 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.582), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %constant.502 = f32[] constant(128)
  %broadcast.503 = f32[16,32,1]{2,1,0} broadcast(%constant.502), dimensions={}
  %div.584 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.583, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %constant.500 = f32[] constant(1e-06)
  %broadcast.501 = f32[16,32,1]{2,1,0} broadcast(%constant.500), dimensions={}
  %add.585 = f32[16,32,1]{2,1,0} add(%div.584, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.586 = f32[16,32,1]{2,1,0} rsqrt(%add.585), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.587 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.586), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.588 = f32[16,32]{1,0} reshape(%mul.587), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.589 = f32[16,32,128]{2,1,0} broadcast(%mul.588), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.590 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.576, %mul.589), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.591 = bf16[16,32,128]{2,1,0} convert(%mul.590), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_q_norm_weight__.9 = bf16[128]{0} parameter(8), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.0.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.592 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_q_norm_weight__.9), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.593 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.592), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.594 = bf16[128]{0} reshape(%mul.593), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.595 = bf16[16,32,128]{2,1,0} broadcast(%mul.594), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.596 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.591, %mul.595), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.627 = bf16[16,32,64]{2,1,0} slice(%mul.596), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11 = bf16[262144,128]{1,0} parameter(10), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.0.self_attn.rotary_emb.cos_sin_cache\']"}
  %attn_metadata_input_positions.485 = s32[16]{0} parameter(484), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="attn_metadata.input_positions"}
  %constant.492 = s32[] constant(0)
  %broadcast.493 = s32[16]{0} broadcast(%constant.492), dimensions={}
  %lt.618 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %constant.490 = s32[] constant(262144)
  %broadcast.491 = s32[16]{0} broadcast(%constant.490), dimensions={}
  %add.619 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.620 = s32[16]{0} select(%lt.618, %add.619, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.621 = s32[16,1]{1,0} reshape(%select_n.620), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.622 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.621), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.623 = bf16[16,64]{1,0} slice(%gather.622), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.625 = bf16[16,1,64]{2,1,0} reshape(%slice.623), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.629 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.625), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.630 = bf16[16,64]{1,0} reshape(%mul.629), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.631 = bf16[16,32,64]{2,1,0} broadcast(%mul.630), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.632 = bf16[16,32,64]{2,1,0} multiply(%slice.627, %mul.631), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.628 = bf16[16,32,64]{2,1,0} slice(%mul.596), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.624 = bf16[16,64]{1,0} slice(%gather.622), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.626 = bf16[16,1,64]{2,1,0} reshape(%slice.624), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.633 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.626), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.634 = bf16[16,64]{1,0} reshape(%mul.633), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.635 = bf16[16,32,64]{2,1,0} broadcast(%mul.634), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.636 = bf16[16,32,64]{2,1,0} multiply(%slice.628, %mul.635), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.637 = bf16[16,32,64]{2,1,0} subtract(%mul.632, %mul.636), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.638 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.625), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.639 = bf16[16,64]{1,0} reshape(%mul.638), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.640 = bf16[16,32,64]{2,1,0} broadcast(%mul.639), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.641 = bf16[16,32,64]{2,1,0} multiply(%slice.628, %mul.640), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.642 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.626), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.643 = bf16[16,64]{1,0} reshape(%mul.642), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.644 = bf16[16,32,64]{2,1,0} broadcast(%mul.643), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.645 = bf16[16,32,64]{2,1,0} multiply(%slice.627, %mul.644), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.646 = bf16[16,32,64]{2,1,0} add(%mul.641, %mul.645), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.647 = bf16[16,32,128]{2,1,0} concatenate(%sub.637, %add.646), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.648 = bf16[16,4096]{1,0} reshape(%concatenate.647), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.572 = bf16[16,4,128]{2,1,0} slice(%reshape.570), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.597 = f32[16,4,128]{2,1,0} convert(%slice.572), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %constant.498 = f32[] constant(2)
  %broadcast.499 = f32[16,4,128]{2,1,0} broadcast(%constant.498), dimensions={}
  %pow.598 = f32[16,4,128]{2,1,0} power(%convert_element_type.597, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.603 = f32[16,4]{1,0} reduce(%pow.598, %constant.512), dimensions={2}, to_apply=%region_3.602, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.604 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.603), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %constant.496 = f32[] constant(128)
  %broadcast.497 = f32[16,4,1]{2,1,0} broadcast(%constant.496), dimensions={}
  %div.605 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.604, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %constant.494 = f32[] constant(1e-06)
  %broadcast.495 = f32[16,4,1]{2,1,0} broadcast(%constant.494), dimensions={}
  %add.606 = f32[16,4,1]{2,1,0} add(%div.605, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.607 = f32[16,4,1]{2,1,0} rsqrt(%add.606), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.608 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.607), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.609 = f32[16,4]{1,0} reshape(%mul.608), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.610 = f32[16,4,128]{2,1,0} broadcast(%mul.609), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.611 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.597, %mul.610), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.612 = bf16[16,4,128]{2,1,0} convert(%mul.611), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_k_norm_weight__.7 = bf16[128]{0} parameter(6), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.0.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.613 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_k_norm_weight__.7), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.614 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.613), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.615 = bf16[128]{0} reshape(%mul.614), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.616 = bf16[16,4,128]{2,1,0} broadcast(%mul.615), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.617 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.612, %mul.616), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.651 = bf16[16,4,64]{2,1,0} slice(%mul.617), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.649 = bf16[16,1,64]{2,1,0} reshape(%slice.623), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.653 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.649), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.654 = bf16[16,64]{1,0} reshape(%mul.653), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.655 = bf16[16,4,64]{2,1,0} broadcast(%mul.654), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.656 = bf16[16,4,64]{2,1,0} multiply(%slice.651, %mul.655), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.652 = bf16[16,4,64]{2,1,0} slice(%mul.617), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.650 = bf16[16,1,64]{2,1,0} reshape(%slice.624), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.657 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.650), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.658 = bf16[16,64]{1,0} reshape(%mul.657), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.659 = bf16[16,4,64]{2,1,0} broadcast(%mul.658), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.660 = bf16[16,4,64]{2,1,0} multiply(%slice.652, %mul.659), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.661 = bf16[16,4,64]{2,1,0} subtract(%mul.656, %mul.660), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.662 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.649), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.663 = bf16[16,64]{1,0} reshape(%mul.662), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.664 = bf16[16,4,64]{2,1,0} broadcast(%mul.663), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.665 = bf16[16,4,64]{2,1,0} multiply(%slice.652, %mul.664), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.666 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.650), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.667 = bf16[16,64]{1,0} reshape(%mul.666), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.668 = bf16[16,4,64]{2,1,0} broadcast(%mul.667), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.669 = bf16[16,4,64]{2,1,0} multiply(%slice.651, %mul.668), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.670 = bf16[16,4,64]{2,1,0} add(%mul.665, %mul.669), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.671 = bf16[16,4,128]{2,1,0} concatenate(%sub.661, %add.670), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.672 = bf16[16,512]{1,0} reshape(%concatenate.671), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.573 = bf16[16,4,128]{2,1,0} slice(%reshape.570), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.574 = bf16[16,512]{1,0} reshape(%slice.573), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %attn_metadata_block_tables.486 = s32[131072]{0} parameter(485), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="attn_metadata.block_tables"}
  %attn_metadata_seq_lens.487 = s32[256]{0} parameter(486), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="attn_metadata.seq_lens"}
  %attn_metadata_query_start_loc.488 = s32[257]{0} parameter(487), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="attn_metadata.query_start_loc"}
  %attn_metadata_request_distribution.489 = s32[3]{0} parameter(488), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="attn_metadata.request_distribution"}
  %jit__jax_attn_func_.764 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_0_.436, %reshape.648, %reshape.672, %reshape.574, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.765 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.764), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_1_.437 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(436), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[1]"}
  %jit__jax_attn_func_.766 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.764), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_o_proj_weight__.8 = bf16[2048,4096]{1,0} parameter(7), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.0.self_attn.o_proj.weight\']"}
  %dot_general.767 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.766, %params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_o_proj_weight__.8), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.768 = f32[16,2048]{1,0} convert(%dot_general.767), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.769 = f32[16,2048]{1,0} convert(%jit__take_.547), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.770 = f32[16,2048]{1,0} add(%convert_element_type.768, %convert_element_type.769), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.772 = f32[16,2048]{1,0} power(%add.770, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.777 = f32[16]{0} reduce(%pow.772, %constant.512), dimensions={1}, to_apply=%region_4.776, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.778 = f32[16,1]{1,0} reshape(%reduce_sum.777), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.779 = f32[16,1]{1,0} divide(%broadcast_in_dim.778, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.780 = f32[16,1]{1,0} add(%div.779, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.781 = f32[16,1]{1,0} rsqrt(%add.780), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.782 = f32[16,1]{1,0} broadcast(%rsqrt.781), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.783 = f32[16]{0} reshape(%mul.782), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.784 = f32[16,2048]{1,0} broadcast(%mul.783), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.785 = f32[16,2048]{1,0} multiply(%add.770, %mul.784), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.786 = bf16[16,2048]{1,0} convert(%mul.785), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_0_post_attention_layernorm_weight__.6 = bf16[2048]{0} parameter(5), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.0.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.787 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_0_post_attention_layernorm_weight__.6), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.788 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.787), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.789 = bf16[2048]{0} reshape(%mul.788), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.790 = bf16[16,2048]{1,0} broadcast(%mul.789), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.791 = bf16[16,2048]{1,0} multiply(%convert_element_type.786, %mul.790), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_0_mlp_experts_w13_weight__.3 = bf16[128,1536,2048]{2,1,0} parameter(2), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.0.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_0_mlp_experts_w2_weight__.4 = bf16[128,2048,768]{2,1,0} parameter(3), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.0.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_0_mlp_gate_weight__.5 = bf16[128,2048]{1,0} parameter(4), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.0.mlp.gate.weight\']"}
  %dot_general.792 = bf16[16,128]{1,0} dot(%mul.791, %params_and_buffers__vllm_model_language_model_model_layers_0_mlp_gate_weight__.5), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.1529 = bf16[16,2048]{1,0} call(%mul.791, %params_and_buffers__vllm_model_language_model_model_layers_0_mlp_experts_w13_weight__.3, %params_and_buffers__vllm_model_language_model_model_layers_0_mlp_experts_w2_weight__.4, %dot_general.792), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.1530 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.1529), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.771 = bf16[16,2048]{1,0} convert(%add.770), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.1531 = f32[16,2048]{1,0} convert(%convert_element_type.771), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.1532 = f32[16,2048]{1,0} add(%convert_element_type.1530, %convert_element_type.1531), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.1534 = f32[16,2048]{1,0} power(%add.1532, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.1539 = f32[16]{0} reduce(%pow.1534, %constant.512), dimensions={1}, to_apply=%region_34.1538, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.1540 = f32[16,1]{1,0} reshape(%reduce_sum.1539), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.1541 = f32[16,1]{1,0} divide(%broadcast_in_dim.1540, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.1542 = f32[16,1]{1,0} add(%div.1541, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.1543 = f32[16,1]{1,0} rsqrt(%add.1542), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.1544 = f32[16,1]{1,0} broadcast(%rsqrt.1543), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1545 = f32[16]{0} reshape(%mul.1544), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1546 = f32[16,2048]{1,0} broadcast(%mul.1545), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1547 = f32[16,2048]{1,0} multiply(%add.1532, %mul.1546), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.1548 = bf16[16,2048]{1,0} convert(%mul.1547), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_1_input_layernorm_weight__.12 = bf16[2048]{0} parameter(11), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.1.input_layernorm.weight\']"}
  %broadcast_in_dim.1549 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_1_input_layernorm_weight__.12), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1550 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.1549), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1551 = bf16[2048]{0} reshape(%mul.1550), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1552 = bf16[16,2048]{1,0} broadcast(%mul.1551), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1553 = bf16[16,2048]{1,0} multiply(%convert_element_type.1548, %mul.1552), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_1_self_attn_qkv_proj_weight__.20 = bf16[5120,2048]{1,0} parameter(19), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.1.self_attn.qkv_proj.weight\']"}
  %dot_general.1554 = bf16[16,5120]{1,0} dot(%mul.1553, %params_and_buffers__vllm_model_language_model_model_layers_1_self_attn_qkv_proj_weight__.20), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.1555 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.1554), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.1556 = bf16[16,4,1024]{2,1,0} slice(%reshape.1555), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.1560 = bf16[16,32,128]{2,1,0} reshape(%slice.1556), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.1561 = f32[16,32,128]{2,1,0} convert(%reshape.1560), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.1562 = f32[16,32,128]{2,1,0} power(%convert_element_type.1561, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.1567 = f32[16,32]{1,0} reduce(%pow.1562, %constant.512), dimensions={2}, to_apply=%region_35.1566, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.1568 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.1567), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.1569 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.1568, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.1570 = f32[16,32,1]{2,1,0} add(%div.1569, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.1571 = f32[16,32,1]{2,1,0} rsqrt(%add.1570), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.1572 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.1571), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1573 = f32[16,32]{1,0} reshape(%mul.1572), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1574 = f32[16,32,128]{2,1,0} broadcast(%mul.1573), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1575 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.1561, %mul.1574), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.1576 = bf16[16,32,128]{2,1,0} convert(%mul.1575), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_1_self_attn_q_norm_weight__.19 = bf16[128]{0} parameter(18), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.1.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.1577 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_1_self_attn_q_norm_weight__.19), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1578 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.1577), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1579 = bf16[128]{0} reshape(%mul.1578), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1580 = bf16[16,32,128]{2,1,0} broadcast(%mul.1579), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1581 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.1576, %mul.1580), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.1612 = bf16[16,32,64]{2,1,0} slice(%mul.1581), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.1603 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.1604 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.1605 = s32[16]{0} select(%lt.1603, %add.1604, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.1606 = s32[16,1]{1,0} reshape(%select_n.1605), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.1607 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.1606), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.1608 = bf16[16,64]{1,0} slice(%gather.1607), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.1610 = bf16[16,1,64]{2,1,0} reshape(%slice.1608), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.1614 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.1610), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1615 = bf16[16,64]{1,0} reshape(%mul.1614), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1616 = bf16[16,32,64]{2,1,0} broadcast(%mul.1615), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1617 = bf16[16,32,64]{2,1,0} multiply(%slice.1612, %mul.1616), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.1613 = bf16[16,32,64]{2,1,0} slice(%mul.1581), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.1609 = bf16[16,64]{1,0} slice(%gather.1607), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.1611 = bf16[16,1,64]{2,1,0} reshape(%slice.1609), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.1618 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.1611), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1619 = bf16[16,64]{1,0} reshape(%mul.1618), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1620 = bf16[16,32,64]{2,1,0} broadcast(%mul.1619), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1621 = bf16[16,32,64]{2,1,0} multiply(%slice.1613, %mul.1620), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.1622 = bf16[16,32,64]{2,1,0} subtract(%mul.1617, %mul.1621), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.1623 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.1610), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1624 = bf16[16,64]{1,0} reshape(%mul.1623), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1625 = bf16[16,32,64]{2,1,0} broadcast(%mul.1624), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1626 = bf16[16,32,64]{2,1,0} multiply(%slice.1613, %mul.1625), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1627 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.1611), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1628 = bf16[16,64]{1,0} reshape(%mul.1627), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1629 = bf16[16,32,64]{2,1,0} broadcast(%mul.1628), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1630 = bf16[16,32,64]{2,1,0} multiply(%slice.1612, %mul.1629), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.1631 = bf16[16,32,64]{2,1,0} add(%mul.1626, %mul.1630), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.1632 = bf16[16,32,128]{2,1,0} concatenate(%sub.1622, %add.1631), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.1633 = bf16[16,4096]{1,0} reshape(%concatenate.1632), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.1557 = bf16[16,4,128]{2,1,0} slice(%reshape.1555), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.1582 = f32[16,4,128]{2,1,0} convert(%slice.1557), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.1583 = f32[16,4,128]{2,1,0} power(%convert_element_type.1582, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.1588 = f32[16,4]{1,0} reduce(%pow.1583, %constant.512), dimensions={2}, to_apply=%region_36.1587, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.1589 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.1588), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.1590 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.1589, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.1591 = f32[16,4,1]{2,1,0} add(%div.1590, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.1592 = f32[16,4,1]{2,1,0} rsqrt(%add.1591), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.1593 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.1592), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1594 = f32[16,4]{1,0} reshape(%mul.1593), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1595 = f32[16,4,128]{2,1,0} broadcast(%mul.1594), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1596 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.1582, %mul.1595), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.1597 = bf16[16,4,128]{2,1,0} convert(%mul.1596), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_1_self_attn_k_norm_weight__.17 = bf16[128]{0} parameter(16), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.1.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.1598 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_1_self_attn_k_norm_weight__.17), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1599 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.1598), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1600 = bf16[128]{0} reshape(%mul.1599), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1601 = bf16[16,4,128]{2,1,0} broadcast(%mul.1600), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1602 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.1597, %mul.1601), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.1636 = bf16[16,4,64]{2,1,0} slice(%mul.1602), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.1634 = bf16[16,1,64]{2,1,0} reshape(%slice.1608), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.1638 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.1634), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1639 = bf16[16,64]{1,0} reshape(%mul.1638), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1640 = bf16[16,4,64]{2,1,0} broadcast(%mul.1639), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1641 = bf16[16,4,64]{2,1,0} multiply(%slice.1636, %mul.1640), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.1637 = bf16[16,4,64]{2,1,0} slice(%mul.1602), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.1635 = bf16[16,1,64]{2,1,0} reshape(%slice.1609), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.1642 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.1635), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1643 = bf16[16,64]{1,0} reshape(%mul.1642), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1644 = bf16[16,4,64]{2,1,0} broadcast(%mul.1643), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1645 = bf16[16,4,64]{2,1,0} multiply(%slice.1637, %mul.1644), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.1646 = bf16[16,4,64]{2,1,0} subtract(%mul.1641, %mul.1645), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.1647 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.1634), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1648 = bf16[16,64]{1,0} reshape(%mul.1647), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1649 = bf16[16,4,64]{2,1,0} broadcast(%mul.1648), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1650 = bf16[16,4,64]{2,1,0} multiply(%slice.1637, %mul.1649), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1651 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.1635), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1652 = bf16[16,64]{1,0} reshape(%mul.1651), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1653 = bf16[16,4,64]{2,1,0} broadcast(%mul.1652), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1654 = bf16[16,4,64]{2,1,0} multiply(%slice.1636, %mul.1653), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.1655 = bf16[16,4,64]{2,1,0} add(%mul.1650, %mul.1654), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.1656 = bf16[16,4,128]{2,1,0} concatenate(%sub.1646, %add.1655), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.1657 = bf16[16,512]{1,0} reshape(%concatenate.1656), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.1558 = bf16[16,4,128]{2,1,0} slice(%reshape.1555), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.1559 = bf16[16,512]{1,0} reshape(%slice.1558), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.1658 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_1_.437, %reshape.1633, %reshape.1657, %reshape.1559, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.1659 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.1658), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_2_.438 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(437), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[2]"}
  %jit__jax_attn_func_.1660 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.1658), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_1_self_attn_o_proj_weight__.18 = bf16[2048,4096]{1,0} parameter(17), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.1.self_attn.o_proj.weight\']"}
  %dot_general.1661 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.1660, %params_and_buffers__vllm_model_language_model_model_layers_1_self_attn_o_proj_weight__.18), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.1662 = f32[16,2048]{1,0} convert(%dot_general.1661), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.1533 = bf16[16,2048]{1,0} convert(%add.1532), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.1663 = f32[16,2048]{1,0} convert(%convert_element_type.1533), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.1664 = f32[16,2048]{1,0} add(%convert_element_type.1662, %convert_element_type.1663), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.1666 = f32[16,2048]{1,0} power(%add.1664, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.1671 = f32[16]{0} reduce(%pow.1666, %constant.512), dimensions={1}, to_apply=%region_37.1670, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.1672 = f32[16,1]{1,0} reshape(%reduce_sum.1671), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.1673 = f32[16,1]{1,0} divide(%broadcast_in_dim.1672, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.1674 = f32[16,1]{1,0} add(%div.1673, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.1675 = f32[16,1]{1,0} rsqrt(%add.1674), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.1676 = f32[16,1]{1,0} broadcast(%rsqrt.1675), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1677 = f32[16]{0} reshape(%mul.1676), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1678 = f32[16,2048]{1,0} broadcast(%mul.1677), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1679 = f32[16,2048]{1,0} multiply(%add.1664, %mul.1678), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.1680 = bf16[16,2048]{1,0} convert(%mul.1679), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_1_post_attention_layernorm_weight__.16 = bf16[2048]{0} parameter(15), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.1.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.1681 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_1_post_attention_layernorm_weight__.16), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1682 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.1681), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1683 = bf16[2048]{0} reshape(%mul.1682), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1684 = bf16[16,2048]{1,0} broadcast(%mul.1683), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1685 = bf16[16,2048]{1,0} multiply(%convert_element_type.1680, %mul.1684), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_1_mlp_experts_w13_weight__.13 = bf16[128,1536,2048]{2,1,0} parameter(12), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.1.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_1_mlp_experts_w2_weight__.14 = bf16[128,2048,768]{2,1,0} parameter(13), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.1.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_1_mlp_gate_weight__.15 = bf16[128,2048]{1,0} parameter(14), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.1.mlp.gate.weight\']"}
  %dot_general.1686 = bf16[16,128]{1,0} dot(%mul.1685, %params_and_buffers__vllm_model_language_model_model_layers_1_mlp_gate_weight__.15), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.1687 = bf16[16,2048]{1,0} call(%mul.1685, %params_and_buffers__vllm_model_language_model_model_layers_1_mlp_experts_w13_weight__.13, %params_and_buffers__vllm_model_language_model_model_layers_1_mlp_experts_w2_weight__.14, %dot_general.1686), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.1688 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.1687), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.1665 = bf16[16,2048]{1,0} convert(%add.1664), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.1689 = f32[16,2048]{1,0} convert(%convert_element_type.1665), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.1690 = f32[16,2048]{1,0} add(%convert_element_type.1688, %convert_element_type.1689), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.1692 = f32[16,2048]{1,0} power(%add.1690, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.1697 = f32[16]{0} reduce(%pow.1692, %constant.512), dimensions={1}, to_apply=%region_38.1696, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.1698 = f32[16,1]{1,0} reshape(%reduce_sum.1697), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.1699 = f32[16,1]{1,0} divide(%broadcast_in_dim.1698, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.1700 = f32[16,1]{1,0} add(%div.1699, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.1701 = f32[16,1]{1,0} rsqrt(%add.1700), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.1702 = f32[16,1]{1,0} broadcast(%rsqrt.1701), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1703 = f32[16]{0} reshape(%mul.1702), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1704 = f32[16,2048]{1,0} broadcast(%mul.1703), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1705 = f32[16,2048]{1,0} multiply(%add.1690, %mul.1704), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.1706 = bf16[16,2048]{1,0} convert(%mul.1705), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_2_input_layernorm_weight__.111 = bf16[2048]{0} parameter(110), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.2.input_layernorm.weight\']"}
  %broadcast_in_dim.1707 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_2_input_layernorm_weight__.111), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1708 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.1707), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1709 = bf16[2048]{0} reshape(%mul.1708), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1710 = bf16[16,2048]{1,0} broadcast(%mul.1709), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1711 = bf16[16,2048]{1,0} multiply(%convert_element_type.1706, %mul.1710), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_2_self_attn_qkv_proj_weight__.119 = bf16[5120,2048]{1,0} parameter(118), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.2.self_attn.qkv_proj.weight\']"}
  %dot_general.1712 = bf16[16,5120]{1,0} dot(%mul.1711, %params_and_buffers__vllm_model_language_model_model_layers_2_self_attn_qkv_proj_weight__.119), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.1713 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.1712), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.1714 = bf16[16,4,1024]{2,1,0} slice(%reshape.1713), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.1718 = bf16[16,32,128]{2,1,0} reshape(%slice.1714), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.1719 = f32[16,32,128]{2,1,0} convert(%reshape.1718), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.1720 = f32[16,32,128]{2,1,0} power(%convert_element_type.1719, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.1725 = f32[16,32]{1,0} reduce(%pow.1720, %constant.512), dimensions={2}, to_apply=%region_39.1724, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.1726 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.1725), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.1727 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.1726, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.1728 = f32[16,32,1]{2,1,0} add(%div.1727, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.1729 = f32[16,32,1]{2,1,0} rsqrt(%add.1728), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.1730 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.1729), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1731 = f32[16,32]{1,0} reshape(%mul.1730), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1732 = f32[16,32,128]{2,1,0} broadcast(%mul.1731), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1733 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.1719, %mul.1732), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.1734 = bf16[16,32,128]{2,1,0} convert(%mul.1733), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_2_self_attn_q_norm_weight__.118 = bf16[128]{0} parameter(117), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.2.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.1735 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_2_self_attn_q_norm_weight__.118), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1736 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.1735), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1737 = bf16[128]{0} reshape(%mul.1736), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1738 = bf16[16,32,128]{2,1,0} broadcast(%mul.1737), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1739 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.1734, %mul.1738), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.1770 = bf16[16,32,64]{2,1,0} slice(%mul.1739), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.1761 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.1762 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.1763 = s32[16]{0} select(%lt.1761, %add.1762, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.1764 = s32[16,1]{1,0} reshape(%select_n.1763), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.1765 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.1764), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.1766 = bf16[16,64]{1,0} slice(%gather.1765), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.1768 = bf16[16,1,64]{2,1,0} reshape(%slice.1766), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.1772 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.1768), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1773 = bf16[16,64]{1,0} reshape(%mul.1772), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1774 = bf16[16,32,64]{2,1,0} broadcast(%mul.1773), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1775 = bf16[16,32,64]{2,1,0} multiply(%slice.1770, %mul.1774), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.1771 = bf16[16,32,64]{2,1,0} slice(%mul.1739), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.1767 = bf16[16,64]{1,0} slice(%gather.1765), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.1769 = bf16[16,1,64]{2,1,0} reshape(%slice.1767), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.1776 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.1769), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1777 = bf16[16,64]{1,0} reshape(%mul.1776), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1778 = bf16[16,32,64]{2,1,0} broadcast(%mul.1777), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1779 = bf16[16,32,64]{2,1,0} multiply(%slice.1771, %mul.1778), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.1780 = bf16[16,32,64]{2,1,0} subtract(%mul.1775, %mul.1779), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.1781 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.1768), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1782 = bf16[16,64]{1,0} reshape(%mul.1781), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1783 = bf16[16,32,64]{2,1,0} broadcast(%mul.1782), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1784 = bf16[16,32,64]{2,1,0} multiply(%slice.1771, %mul.1783), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1785 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.1769), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1786 = bf16[16,64]{1,0} reshape(%mul.1785), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1787 = bf16[16,32,64]{2,1,0} broadcast(%mul.1786), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1788 = bf16[16,32,64]{2,1,0} multiply(%slice.1770, %mul.1787), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.1789 = bf16[16,32,64]{2,1,0} add(%mul.1784, %mul.1788), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.1790 = bf16[16,32,128]{2,1,0} concatenate(%sub.1780, %add.1789), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.1791 = bf16[16,4096]{1,0} reshape(%concatenate.1790), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.1715 = bf16[16,4,128]{2,1,0} slice(%reshape.1713), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.1740 = f32[16,4,128]{2,1,0} convert(%slice.1715), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.1741 = f32[16,4,128]{2,1,0} power(%convert_element_type.1740, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.1746 = f32[16,4]{1,0} reduce(%pow.1741, %constant.512), dimensions={2}, to_apply=%region_40.1745, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.1747 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.1746), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.1748 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.1747, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.1749 = f32[16,4,1]{2,1,0} add(%div.1748, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.1750 = f32[16,4,1]{2,1,0} rsqrt(%add.1749), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.1751 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.1750), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1752 = f32[16,4]{1,0} reshape(%mul.1751), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1753 = f32[16,4,128]{2,1,0} broadcast(%mul.1752), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1754 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.1740, %mul.1753), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.1755 = bf16[16,4,128]{2,1,0} convert(%mul.1754), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_2_self_attn_k_norm_weight__.116 = bf16[128]{0} parameter(115), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.2.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.1756 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_2_self_attn_k_norm_weight__.116), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1757 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.1756), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1758 = bf16[128]{0} reshape(%mul.1757), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1759 = bf16[16,4,128]{2,1,0} broadcast(%mul.1758), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1760 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.1755, %mul.1759), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.1794 = bf16[16,4,64]{2,1,0} slice(%mul.1760), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.1792 = bf16[16,1,64]{2,1,0} reshape(%slice.1766), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.1796 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.1792), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1797 = bf16[16,64]{1,0} reshape(%mul.1796), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1798 = bf16[16,4,64]{2,1,0} broadcast(%mul.1797), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1799 = bf16[16,4,64]{2,1,0} multiply(%slice.1794, %mul.1798), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.1795 = bf16[16,4,64]{2,1,0} slice(%mul.1760), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.1793 = bf16[16,1,64]{2,1,0} reshape(%slice.1767), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.1800 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.1793), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1801 = bf16[16,64]{1,0} reshape(%mul.1800), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1802 = bf16[16,4,64]{2,1,0} broadcast(%mul.1801), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1803 = bf16[16,4,64]{2,1,0} multiply(%slice.1795, %mul.1802), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.1804 = bf16[16,4,64]{2,1,0} subtract(%mul.1799, %mul.1803), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.1805 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.1792), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1806 = bf16[16,64]{1,0} reshape(%mul.1805), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1807 = bf16[16,4,64]{2,1,0} broadcast(%mul.1806), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1808 = bf16[16,4,64]{2,1,0} multiply(%slice.1795, %mul.1807), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1809 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.1793), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1810 = bf16[16,64]{1,0} reshape(%mul.1809), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1811 = bf16[16,4,64]{2,1,0} broadcast(%mul.1810), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1812 = bf16[16,4,64]{2,1,0} multiply(%slice.1794, %mul.1811), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.1813 = bf16[16,4,64]{2,1,0} add(%mul.1808, %mul.1812), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.1814 = bf16[16,4,128]{2,1,0} concatenate(%sub.1804, %add.1813), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.1815 = bf16[16,512]{1,0} reshape(%concatenate.1814), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.1716 = bf16[16,4,128]{2,1,0} slice(%reshape.1713), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.1717 = bf16[16,512]{1,0} reshape(%slice.1716), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.1816 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_2_.438, %reshape.1791, %reshape.1815, %reshape.1717, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.1817 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.1816), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_3_.439 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(438), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[3]"}
  %jit__jax_attn_func_.1818 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.1816), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_2_self_attn_o_proj_weight__.117 = bf16[2048,4096]{1,0} parameter(116), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.2.self_attn.o_proj.weight\']"}
  %dot_general.1819 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.1818, %params_and_buffers__vllm_model_language_model_model_layers_2_self_attn_o_proj_weight__.117), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.1820 = f32[16,2048]{1,0} convert(%dot_general.1819), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.1691 = bf16[16,2048]{1,0} convert(%add.1690), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.1821 = f32[16,2048]{1,0} convert(%convert_element_type.1691), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.1822 = f32[16,2048]{1,0} add(%convert_element_type.1820, %convert_element_type.1821), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.1824 = f32[16,2048]{1,0} power(%add.1822, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.1829 = f32[16]{0} reduce(%pow.1824, %constant.512), dimensions={1}, to_apply=%region_41.1828, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.1830 = f32[16,1]{1,0} reshape(%reduce_sum.1829), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.1831 = f32[16,1]{1,0} divide(%broadcast_in_dim.1830, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.1832 = f32[16,1]{1,0} add(%div.1831, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.1833 = f32[16,1]{1,0} rsqrt(%add.1832), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.1834 = f32[16,1]{1,0} broadcast(%rsqrt.1833), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1835 = f32[16]{0} reshape(%mul.1834), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1836 = f32[16,2048]{1,0} broadcast(%mul.1835), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1837 = f32[16,2048]{1,0} multiply(%add.1822, %mul.1836), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.1838 = bf16[16,2048]{1,0} convert(%mul.1837), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_2_post_attention_layernorm_weight__.115 = bf16[2048]{0} parameter(114), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.2.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.1839 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_2_post_attention_layernorm_weight__.115), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1840 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.1839), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1841 = bf16[2048]{0} reshape(%mul.1840), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1842 = bf16[16,2048]{1,0} broadcast(%mul.1841), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1843 = bf16[16,2048]{1,0} multiply(%convert_element_type.1838, %mul.1842), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_2_mlp_experts_w13_weight__.112 = bf16[128,1536,2048]{2,1,0} parameter(111), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.2.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_2_mlp_experts_w2_weight__.113 = bf16[128,2048,768]{2,1,0} parameter(112), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.2.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_2_mlp_gate_weight__.114 = bf16[128,2048]{1,0} parameter(113), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.2.mlp.gate.weight\']"}
  %dot_general.1844 = bf16[16,128]{1,0} dot(%mul.1843, %params_and_buffers__vllm_model_language_model_model_layers_2_mlp_gate_weight__.114), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.1845 = bf16[16,2048]{1,0} call(%mul.1843, %params_and_buffers__vllm_model_language_model_model_layers_2_mlp_experts_w13_weight__.112, %params_and_buffers__vllm_model_language_model_model_layers_2_mlp_experts_w2_weight__.113, %dot_general.1844), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.1846 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.1845), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.1823 = bf16[16,2048]{1,0} convert(%add.1822), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.1847 = f32[16,2048]{1,0} convert(%convert_element_type.1823), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.1848 = f32[16,2048]{1,0} add(%convert_element_type.1846, %convert_element_type.1847), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.1850 = f32[16,2048]{1,0} power(%add.1848, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.1855 = f32[16]{0} reduce(%pow.1850, %constant.512), dimensions={1}, to_apply=%region_42.1854, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.1856 = f32[16,1]{1,0} reshape(%reduce_sum.1855), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.1857 = f32[16,1]{1,0} divide(%broadcast_in_dim.1856, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.1858 = f32[16,1]{1,0} add(%div.1857, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.1859 = f32[16,1]{1,0} rsqrt(%add.1858), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.1860 = f32[16,1]{1,0} broadcast(%rsqrt.1859), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1861 = f32[16]{0} reshape(%mul.1860), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1862 = f32[16,2048]{1,0} broadcast(%mul.1861), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1863 = f32[16,2048]{1,0} multiply(%add.1848, %mul.1862), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.1864 = bf16[16,2048]{1,0} convert(%mul.1863), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_3_input_layernorm_weight__.210 = bf16[2048]{0} parameter(209), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.3.input_layernorm.weight\']"}
  %broadcast_in_dim.1865 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_3_input_layernorm_weight__.210), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1866 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.1865), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1867 = bf16[2048]{0} reshape(%mul.1866), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1868 = bf16[16,2048]{1,0} broadcast(%mul.1867), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1869 = bf16[16,2048]{1,0} multiply(%convert_element_type.1864, %mul.1868), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_3_self_attn_qkv_proj_weight__.218 = bf16[5120,2048]{1,0} parameter(217), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.3.self_attn.qkv_proj.weight\']"}
  %dot_general.1870 = bf16[16,5120]{1,0} dot(%mul.1869, %params_and_buffers__vllm_model_language_model_model_layers_3_self_attn_qkv_proj_weight__.218), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.1871 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.1870), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.1872 = bf16[16,4,1024]{2,1,0} slice(%reshape.1871), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.1876 = bf16[16,32,128]{2,1,0} reshape(%slice.1872), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.1877 = f32[16,32,128]{2,1,0} convert(%reshape.1876), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.1878 = f32[16,32,128]{2,1,0} power(%convert_element_type.1877, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.1883 = f32[16,32]{1,0} reduce(%pow.1878, %constant.512), dimensions={2}, to_apply=%region_43.1882, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.1884 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.1883), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.1885 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.1884, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.1886 = f32[16,32,1]{2,1,0} add(%div.1885, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.1887 = f32[16,32,1]{2,1,0} rsqrt(%add.1886), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.1888 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.1887), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1889 = f32[16,32]{1,0} reshape(%mul.1888), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1890 = f32[16,32,128]{2,1,0} broadcast(%mul.1889), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1891 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.1877, %mul.1890), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.1892 = bf16[16,32,128]{2,1,0} convert(%mul.1891), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_3_self_attn_q_norm_weight__.217 = bf16[128]{0} parameter(216), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.3.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.1893 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_3_self_attn_q_norm_weight__.217), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1894 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.1893), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1895 = bf16[128]{0} reshape(%mul.1894), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1896 = bf16[16,32,128]{2,1,0} broadcast(%mul.1895), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1897 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.1892, %mul.1896), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.1928 = bf16[16,32,64]{2,1,0} slice(%mul.1897), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.1919 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.1920 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.1921 = s32[16]{0} select(%lt.1919, %add.1920, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.1922 = s32[16,1]{1,0} reshape(%select_n.1921), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.1923 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.1922), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.1924 = bf16[16,64]{1,0} slice(%gather.1923), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.1926 = bf16[16,1,64]{2,1,0} reshape(%slice.1924), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.1930 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.1926), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1931 = bf16[16,64]{1,0} reshape(%mul.1930), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1932 = bf16[16,32,64]{2,1,0} broadcast(%mul.1931), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1933 = bf16[16,32,64]{2,1,0} multiply(%slice.1928, %mul.1932), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.1929 = bf16[16,32,64]{2,1,0} slice(%mul.1897), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.1925 = bf16[16,64]{1,0} slice(%gather.1923), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.1927 = bf16[16,1,64]{2,1,0} reshape(%slice.1925), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.1934 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.1927), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1935 = bf16[16,64]{1,0} reshape(%mul.1934), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1936 = bf16[16,32,64]{2,1,0} broadcast(%mul.1935), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1937 = bf16[16,32,64]{2,1,0} multiply(%slice.1929, %mul.1936), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.1938 = bf16[16,32,64]{2,1,0} subtract(%mul.1933, %mul.1937), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.1939 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.1926), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1940 = bf16[16,64]{1,0} reshape(%mul.1939), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1941 = bf16[16,32,64]{2,1,0} broadcast(%mul.1940), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1942 = bf16[16,32,64]{2,1,0} multiply(%slice.1929, %mul.1941), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1943 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.1927), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1944 = bf16[16,64]{1,0} reshape(%mul.1943), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1945 = bf16[16,32,64]{2,1,0} broadcast(%mul.1944), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1946 = bf16[16,32,64]{2,1,0} multiply(%slice.1928, %mul.1945), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.1947 = bf16[16,32,64]{2,1,0} add(%mul.1942, %mul.1946), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.1948 = bf16[16,32,128]{2,1,0} concatenate(%sub.1938, %add.1947), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.1949 = bf16[16,4096]{1,0} reshape(%concatenate.1948), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.1873 = bf16[16,4,128]{2,1,0} slice(%reshape.1871), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.1898 = f32[16,4,128]{2,1,0} convert(%slice.1873), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.1899 = f32[16,4,128]{2,1,0} power(%convert_element_type.1898, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.1904 = f32[16,4]{1,0} reduce(%pow.1899, %constant.512), dimensions={2}, to_apply=%region_44.1903, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.1905 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.1904), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.1906 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.1905, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.1907 = f32[16,4,1]{2,1,0} add(%div.1906, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.1908 = f32[16,4,1]{2,1,0} rsqrt(%add.1907), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.1909 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.1908), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1910 = f32[16,4]{1,0} reshape(%mul.1909), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1911 = f32[16,4,128]{2,1,0} broadcast(%mul.1910), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1912 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.1898, %mul.1911), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.1913 = bf16[16,4,128]{2,1,0} convert(%mul.1912), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_3_self_attn_k_norm_weight__.215 = bf16[128]{0} parameter(214), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.3.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.1914 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_3_self_attn_k_norm_weight__.215), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1915 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.1914), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1916 = bf16[128]{0} reshape(%mul.1915), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1917 = bf16[16,4,128]{2,1,0} broadcast(%mul.1916), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1918 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.1913, %mul.1917), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.1952 = bf16[16,4,64]{2,1,0} slice(%mul.1918), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.1950 = bf16[16,1,64]{2,1,0} reshape(%slice.1924), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.1954 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.1950), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1955 = bf16[16,64]{1,0} reshape(%mul.1954), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1956 = bf16[16,4,64]{2,1,0} broadcast(%mul.1955), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1957 = bf16[16,4,64]{2,1,0} multiply(%slice.1952, %mul.1956), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.1953 = bf16[16,4,64]{2,1,0} slice(%mul.1918), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.1951 = bf16[16,1,64]{2,1,0} reshape(%slice.1925), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.1958 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.1951), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1959 = bf16[16,64]{1,0} reshape(%mul.1958), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1960 = bf16[16,4,64]{2,1,0} broadcast(%mul.1959), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1961 = bf16[16,4,64]{2,1,0} multiply(%slice.1953, %mul.1960), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.1962 = bf16[16,4,64]{2,1,0} subtract(%mul.1957, %mul.1961), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.1963 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.1950), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1964 = bf16[16,64]{1,0} reshape(%mul.1963), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1965 = bf16[16,4,64]{2,1,0} broadcast(%mul.1964), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1966 = bf16[16,4,64]{2,1,0} multiply(%slice.1953, %mul.1965), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1967 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.1951), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1968 = bf16[16,64]{1,0} reshape(%mul.1967), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1969 = bf16[16,4,64]{2,1,0} broadcast(%mul.1968), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1970 = bf16[16,4,64]{2,1,0} multiply(%slice.1952, %mul.1969), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.1971 = bf16[16,4,64]{2,1,0} add(%mul.1966, %mul.1970), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.1972 = bf16[16,4,128]{2,1,0} concatenate(%sub.1962, %add.1971), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.1973 = bf16[16,512]{1,0} reshape(%concatenate.1972), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.1874 = bf16[16,4,128]{2,1,0} slice(%reshape.1871), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.1875 = bf16[16,512]{1,0} reshape(%slice.1874), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.1974 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_3_.439, %reshape.1949, %reshape.1973, %reshape.1875, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.1975 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.1974), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_4_.440 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(439), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[4]"}
  %jit__jax_attn_func_.1976 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.1974), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_3_self_attn_o_proj_weight__.216 = bf16[2048,4096]{1,0} parameter(215), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.3.self_attn.o_proj.weight\']"}
  %dot_general.1977 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.1976, %params_and_buffers__vllm_model_language_model_model_layers_3_self_attn_o_proj_weight__.216), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.1978 = f32[16,2048]{1,0} convert(%dot_general.1977), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.1849 = bf16[16,2048]{1,0} convert(%add.1848), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.1979 = f32[16,2048]{1,0} convert(%convert_element_type.1849), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.1980 = f32[16,2048]{1,0} add(%convert_element_type.1978, %convert_element_type.1979), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.1982 = f32[16,2048]{1,0} power(%add.1980, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.1987 = f32[16]{0} reduce(%pow.1982, %constant.512), dimensions={1}, to_apply=%region_45.1986, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.1988 = f32[16,1]{1,0} reshape(%reduce_sum.1987), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.1989 = f32[16,1]{1,0} divide(%broadcast_in_dim.1988, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.1990 = f32[16,1]{1,0} add(%div.1989, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.1991 = f32[16,1]{1,0} rsqrt(%add.1990), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.1992 = f32[16,1]{1,0} broadcast(%rsqrt.1991), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1993 = f32[16]{0} reshape(%mul.1992), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1994 = f32[16,2048]{1,0} broadcast(%mul.1993), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1995 = f32[16,2048]{1,0} multiply(%add.1980, %mul.1994), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.1996 = bf16[16,2048]{1,0} convert(%mul.1995), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_3_post_attention_layernorm_weight__.214 = bf16[2048]{0} parameter(213), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.3.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.1997 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_3_post_attention_layernorm_weight__.214), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1998 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.1997), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1999 = bf16[2048]{0} reshape(%mul.1998), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2000 = bf16[16,2048]{1,0} broadcast(%mul.1999), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2001 = bf16[16,2048]{1,0} multiply(%convert_element_type.1996, %mul.2000), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_3_mlp_experts_w13_weight__.211 = bf16[128,1536,2048]{2,1,0} parameter(210), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.3.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_3_mlp_experts_w2_weight__.212 = bf16[128,2048,768]{2,1,0} parameter(211), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.3.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_3_mlp_gate_weight__.213 = bf16[128,2048]{1,0} parameter(212), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.3.mlp.gate.weight\']"}
  %dot_general.2002 = bf16[16,128]{1,0} dot(%mul.2001, %params_and_buffers__vllm_model_language_model_model_layers_3_mlp_gate_weight__.213), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.2003 = bf16[16,2048]{1,0} call(%mul.2001, %params_and_buffers__vllm_model_language_model_model_layers_3_mlp_experts_w13_weight__.211, %params_and_buffers__vllm_model_language_model_model_layers_3_mlp_experts_w2_weight__.212, %dot_general.2002), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.2004 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.2003), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.1981 = bf16[16,2048]{1,0} convert(%add.1980), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2005 = f32[16,2048]{1,0} convert(%convert_element_type.1981), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.2006 = f32[16,2048]{1,0} add(%convert_element_type.2004, %convert_element_type.2005), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.2008 = f32[16,2048]{1,0} power(%add.2006, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2013 = f32[16]{0} reduce(%pow.2008, %constant.512), dimensions={1}, to_apply=%region_46.2012, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2014 = f32[16,1]{1,0} reshape(%reduce_sum.2013), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2015 = f32[16,1]{1,0} divide(%broadcast_in_dim.2014, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2016 = f32[16,1]{1,0} add(%div.2015, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2017 = f32[16,1]{1,0} rsqrt(%add.2016), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2018 = f32[16,1]{1,0} broadcast(%rsqrt.2017), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2019 = f32[16]{0} reshape(%mul.2018), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2020 = f32[16,2048]{1,0} broadcast(%mul.2019), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2021 = f32[16,2048]{1,0} multiply(%add.2006, %mul.2020), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2022 = bf16[16,2048]{1,0} convert(%mul.2021), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_4_input_layernorm_weight__.309 = bf16[2048]{0} parameter(308), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.4.input_layernorm.weight\']"}
  %broadcast_in_dim.2023 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_4_input_layernorm_weight__.309), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2024 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.2023), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2025 = bf16[2048]{0} reshape(%mul.2024), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2026 = bf16[16,2048]{1,0} broadcast(%mul.2025), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2027 = bf16[16,2048]{1,0} multiply(%convert_element_type.2022, %mul.2026), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_4_self_attn_qkv_proj_weight__.317 = bf16[5120,2048]{1,0} parameter(316), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.4.self_attn.qkv_proj.weight\']"}
  %dot_general.2028 = bf16[16,5120]{1,0} dot(%mul.2027, %params_and_buffers__vllm_model_language_model_model_layers_4_self_attn_qkv_proj_weight__.317), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.2029 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.2028), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.2030 = bf16[16,4,1024]{2,1,0} slice(%reshape.2029), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.2034 = bf16[16,32,128]{2,1,0} reshape(%slice.2030), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.2035 = f32[16,32,128]{2,1,0} convert(%reshape.2034), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.2036 = f32[16,32,128]{2,1,0} power(%convert_element_type.2035, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2041 = f32[16,32]{1,0} reduce(%pow.2036, %constant.512), dimensions={2}, to_apply=%region_47.2040, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2042 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.2041), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2043 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.2042, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2044 = f32[16,32,1]{2,1,0} add(%div.2043, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2045 = f32[16,32,1]{2,1,0} rsqrt(%add.2044), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2046 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.2045), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2047 = f32[16,32]{1,0} reshape(%mul.2046), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2048 = f32[16,32,128]{2,1,0} broadcast(%mul.2047), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2049 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.2035, %mul.2048), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2050 = bf16[16,32,128]{2,1,0} convert(%mul.2049), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_4_self_attn_q_norm_weight__.316 = bf16[128]{0} parameter(315), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.4.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.2051 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_4_self_attn_q_norm_weight__.316), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2052 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.2051), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2053 = bf16[128]{0} reshape(%mul.2052), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2054 = bf16[16,32,128]{2,1,0} broadcast(%mul.2053), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2055 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.2050, %mul.2054), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2086 = bf16[16,32,64]{2,1,0} slice(%mul.2055), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.2077 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.2078 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.2079 = s32[16]{0} select(%lt.2077, %add.2078, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.2080 = s32[16,1]{1,0} reshape(%select_n.2079), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.2081 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.2080), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.2082 = bf16[16,64]{1,0} slice(%gather.2081), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2084 = bf16[16,1,64]{2,1,0} reshape(%slice.2082), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2088 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2084), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2089 = bf16[16,64]{1,0} reshape(%mul.2088), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2090 = bf16[16,32,64]{2,1,0} broadcast(%mul.2089), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2091 = bf16[16,32,64]{2,1,0} multiply(%slice.2086, %mul.2090), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2087 = bf16[16,32,64]{2,1,0} slice(%mul.2055), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.2083 = bf16[16,64]{1,0} slice(%gather.2081), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2085 = bf16[16,1,64]{2,1,0} reshape(%slice.2083), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2092 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2085), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2093 = bf16[16,64]{1,0} reshape(%mul.2092), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2094 = bf16[16,32,64]{2,1,0} broadcast(%mul.2093), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2095 = bf16[16,32,64]{2,1,0} multiply(%slice.2087, %mul.2094), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.2096 = bf16[16,32,64]{2,1,0} subtract(%mul.2091, %mul.2095), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.2097 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2084), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2098 = bf16[16,64]{1,0} reshape(%mul.2097), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2099 = bf16[16,32,64]{2,1,0} broadcast(%mul.2098), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2100 = bf16[16,32,64]{2,1,0} multiply(%slice.2087, %mul.2099), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2101 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2085), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2102 = bf16[16,64]{1,0} reshape(%mul.2101), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2103 = bf16[16,32,64]{2,1,0} broadcast(%mul.2102), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2104 = bf16[16,32,64]{2,1,0} multiply(%slice.2086, %mul.2103), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.2105 = bf16[16,32,64]{2,1,0} add(%mul.2100, %mul.2104), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.2106 = bf16[16,32,128]{2,1,0} concatenate(%sub.2096, %add.2105), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.2107 = bf16[16,4096]{1,0} reshape(%concatenate.2106), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.2031 = bf16[16,4,128]{2,1,0} slice(%reshape.2029), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.2056 = f32[16,4,128]{2,1,0} convert(%slice.2031), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.2057 = f32[16,4,128]{2,1,0} power(%convert_element_type.2056, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2062 = f32[16,4]{1,0} reduce(%pow.2057, %constant.512), dimensions={2}, to_apply=%region_48.2061, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2063 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.2062), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2064 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.2063, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2065 = f32[16,4,1]{2,1,0} add(%div.2064, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2066 = f32[16,4,1]{2,1,0} rsqrt(%add.2065), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2067 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.2066), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2068 = f32[16,4]{1,0} reshape(%mul.2067), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2069 = f32[16,4,128]{2,1,0} broadcast(%mul.2068), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2070 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.2056, %mul.2069), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2071 = bf16[16,4,128]{2,1,0} convert(%mul.2070), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_4_self_attn_k_norm_weight__.314 = bf16[128]{0} parameter(313), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.4.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.2072 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_4_self_attn_k_norm_weight__.314), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2073 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.2072), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2074 = bf16[128]{0} reshape(%mul.2073), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2075 = bf16[16,4,128]{2,1,0} broadcast(%mul.2074), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2076 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.2071, %mul.2075), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2110 = bf16[16,4,64]{2,1,0} slice(%mul.2076), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2108 = bf16[16,1,64]{2,1,0} reshape(%slice.2082), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2112 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2108), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2113 = bf16[16,64]{1,0} reshape(%mul.2112), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2114 = bf16[16,4,64]{2,1,0} broadcast(%mul.2113), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2115 = bf16[16,4,64]{2,1,0} multiply(%slice.2110, %mul.2114), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2111 = bf16[16,4,64]{2,1,0} slice(%mul.2076), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2109 = bf16[16,1,64]{2,1,0} reshape(%slice.2083), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2116 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2109), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2117 = bf16[16,64]{1,0} reshape(%mul.2116), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2118 = bf16[16,4,64]{2,1,0} broadcast(%mul.2117), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2119 = bf16[16,4,64]{2,1,0} multiply(%slice.2111, %mul.2118), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.2120 = bf16[16,4,64]{2,1,0} subtract(%mul.2115, %mul.2119), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.2121 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2108), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2122 = bf16[16,64]{1,0} reshape(%mul.2121), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2123 = bf16[16,4,64]{2,1,0} broadcast(%mul.2122), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2124 = bf16[16,4,64]{2,1,0} multiply(%slice.2111, %mul.2123), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2125 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2109), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2126 = bf16[16,64]{1,0} reshape(%mul.2125), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2127 = bf16[16,4,64]{2,1,0} broadcast(%mul.2126), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2128 = bf16[16,4,64]{2,1,0} multiply(%slice.2110, %mul.2127), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.2129 = bf16[16,4,64]{2,1,0} add(%mul.2124, %mul.2128), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.2130 = bf16[16,4,128]{2,1,0} concatenate(%sub.2120, %add.2129), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.2131 = bf16[16,512]{1,0} reshape(%concatenate.2130), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.2032 = bf16[16,4,128]{2,1,0} slice(%reshape.2029), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.2033 = bf16[16,512]{1,0} reshape(%slice.2032), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.2132 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_4_.440, %reshape.2107, %reshape.2131, %reshape.2033, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.2133 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.2132), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_5_.441 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(440), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[5]"}
  %jit__jax_attn_func_.2134 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.2132), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_4_self_attn_o_proj_weight__.315 = bf16[2048,4096]{1,0} parameter(314), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.4.self_attn.o_proj.weight\']"}
  %dot_general.2135 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.2134, %params_and_buffers__vllm_model_language_model_model_layers_4_self_attn_o_proj_weight__.315), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.2136 = f32[16,2048]{1,0} convert(%dot_general.2135), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2007 = bf16[16,2048]{1,0} convert(%add.2006), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2137 = f32[16,2048]{1,0} convert(%convert_element_type.2007), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.2138 = f32[16,2048]{1,0} add(%convert_element_type.2136, %convert_element_type.2137), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.2140 = f32[16,2048]{1,0} power(%add.2138, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2145 = f32[16]{0} reduce(%pow.2140, %constant.512), dimensions={1}, to_apply=%region_49.2144, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2146 = f32[16,1]{1,0} reshape(%reduce_sum.2145), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2147 = f32[16,1]{1,0} divide(%broadcast_in_dim.2146, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2148 = f32[16,1]{1,0} add(%div.2147, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2149 = f32[16,1]{1,0} rsqrt(%add.2148), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2150 = f32[16,1]{1,0} broadcast(%rsqrt.2149), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2151 = f32[16]{0} reshape(%mul.2150), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2152 = f32[16,2048]{1,0} broadcast(%mul.2151), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2153 = f32[16,2048]{1,0} multiply(%add.2138, %mul.2152), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2154 = bf16[16,2048]{1,0} convert(%mul.2153), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_4_post_attention_layernorm_weight__.313 = bf16[2048]{0} parameter(312), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.4.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.2155 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_4_post_attention_layernorm_weight__.313), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2156 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.2155), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2157 = bf16[2048]{0} reshape(%mul.2156), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2158 = bf16[16,2048]{1,0} broadcast(%mul.2157), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2159 = bf16[16,2048]{1,0} multiply(%convert_element_type.2154, %mul.2158), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_4_mlp_experts_w13_weight__.310 = bf16[128,1536,2048]{2,1,0} parameter(309), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.4.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_4_mlp_experts_w2_weight__.311 = bf16[128,2048,768]{2,1,0} parameter(310), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.4.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_4_mlp_gate_weight__.312 = bf16[128,2048]{1,0} parameter(311), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.4.mlp.gate.weight\']"}
  %dot_general.2160 = bf16[16,128]{1,0} dot(%mul.2159, %params_and_buffers__vllm_model_language_model_model_layers_4_mlp_gate_weight__.312), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.2161 = bf16[16,2048]{1,0} call(%mul.2159, %params_and_buffers__vllm_model_language_model_model_layers_4_mlp_experts_w13_weight__.310, %params_and_buffers__vllm_model_language_model_model_layers_4_mlp_experts_w2_weight__.311, %dot_general.2160), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.2162 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.2161), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2139 = bf16[16,2048]{1,0} convert(%add.2138), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2163 = f32[16,2048]{1,0} convert(%convert_element_type.2139), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.2164 = f32[16,2048]{1,0} add(%convert_element_type.2162, %convert_element_type.2163), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.2166 = f32[16,2048]{1,0} power(%add.2164, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2171 = f32[16]{0} reduce(%pow.2166, %constant.512), dimensions={1}, to_apply=%region_50.2170, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2172 = f32[16,1]{1,0} reshape(%reduce_sum.2171), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2173 = f32[16,1]{1,0} divide(%broadcast_in_dim.2172, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2174 = f32[16,1]{1,0} add(%div.2173, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2175 = f32[16,1]{1,0} rsqrt(%add.2174), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2176 = f32[16,1]{1,0} broadcast(%rsqrt.2175), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2177 = f32[16]{0} reshape(%mul.2176), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2178 = f32[16,2048]{1,0} broadcast(%mul.2177), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2179 = f32[16,2048]{1,0} multiply(%add.2164, %mul.2178), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2180 = bf16[16,2048]{1,0} convert(%mul.2179), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_5_input_layernorm_weight__.390 = bf16[2048]{0} parameter(389), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.5.input_layernorm.weight\']"}
  %broadcast_in_dim.2181 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_5_input_layernorm_weight__.390), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2182 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.2181), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2183 = bf16[2048]{0} reshape(%mul.2182), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2184 = bf16[16,2048]{1,0} broadcast(%mul.2183), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2185 = bf16[16,2048]{1,0} multiply(%convert_element_type.2180, %mul.2184), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_5_self_attn_qkv_proj_weight__.398 = bf16[5120,2048]{1,0} parameter(397), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.5.self_attn.qkv_proj.weight\']"}
  %dot_general.2186 = bf16[16,5120]{1,0} dot(%mul.2185, %params_and_buffers__vllm_model_language_model_model_layers_5_self_attn_qkv_proj_weight__.398), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.2187 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.2186), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.2188 = bf16[16,4,1024]{2,1,0} slice(%reshape.2187), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.2192 = bf16[16,32,128]{2,1,0} reshape(%slice.2188), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.2193 = f32[16,32,128]{2,1,0} convert(%reshape.2192), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.2194 = f32[16,32,128]{2,1,0} power(%convert_element_type.2193, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2199 = f32[16,32]{1,0} reduce(%pow.2194, %constant.512), dimensions={2}, to_apply=%region_51.2198, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2200 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.2199), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2201 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.2200, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2202 = f32[16,32,1]{2,1,0} add(%div.2201, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2203 = f32[16,32,1]{2,1,0} rsqrt(%add.2202), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2204 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.2203), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2205 = f32[16,32]{1,0} reshape(%mul.2204), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2206 = f32[16,32,128]{2,1,0} broadcast(%mul.2205), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2207 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.2193, %mul.2206), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2208 = bf16[16,32,128]{2,1,0} convert(%mul.2207), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_5_self_attn_q_norm_weight__.397 = bf16[128]{0} parameter(396), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.5.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.2209 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_5_self_attn_q_norm_weight__.397), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2210 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.2209), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2211 = bf16[128]{0} reshape(%mul.2210), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2212 = bf16[16,32,128]{2,1,0} broadcast(%mul.2211), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2213 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.2208, %mul.2212), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2244 = bf16[16,32,64]{2,1,0} slice(%mul.2213), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.2235 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.2236 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.2237 = s32[16]{0} select(%lt.2235, %add.2236, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.2238 = s32[16,1]{1,0} reshape(%select_n.2237), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.2239 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.2238), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.2240 = bf16[16,64]{1,0} slice(%gather.2239), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2242 = bf16[16,1,64]{2,1,0} reshape(%slice.2240), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2246 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2242), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2247 = bf16[16,64]{1,0} reshape(%mul.2246), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2248 = bf16[16,32,64]{2,1,0} broadcast(%mul.2247), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2249 = bf16[16,32,64]{2,1,0} multiply(%slice.2244, %mul.2248), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2245 = bf16[16,32,64]{2,1,0} slice(%mul.2213), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.2241 = bf16[16,64]{1,0} slice(%gather.2239), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2243 = bf16[16,1,64]{2,1,0} reshape(%slice.2241), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2250 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2243), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2251 = bf16[16,64]{1,0} reshape(%mul.2250), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2252 = bf16[16,32,64]{2,1,0} broadcast(%mul.2251), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2253 = bf16[16,32,64]{2,1,0} multiply(%slice.2245, %mul.2252), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.2254 = bf16[16,32,64]{2,1,0} subtract(%mul.2249, %mul.2253), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.2255 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2242), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2256 = bf16[16,64]{1,0} reshape(%mul.2255), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2257 = bf16[16,32,64]{2,1,0} broadcast(%mul.2256), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2258 = bf16[16,32,64]{2,1,0} multiply(%slice.2245, %mul.2257), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2259 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2243), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2260 = bf16[16,64]{1,0} reshape(%mul.2259), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2261 = bf16[16,32,64]{2,1,0} broadcast(%mul.2260), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2262 = bf16[16,32,64]{2,1,0} multiply(%slice.2244, %mul.2261), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.2263 = bf16[16,32,64]{2,1,0} add(%mul.2258, %mul.2262), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.2264 = bf16[16,32,128]{2,1,0} concatenate(%sub.2254, %add.2263), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.2265 = bf16[16,4096]{1,0} reshape(%concatenate.2264), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.2189 = bf16[16,4,128]{2,1,0} slice(%reshape.2187), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.2214 = f32[16,4,128]{2,1,0} convert(%slice.2189), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.2215 = f32[16,4,128]{2,1,0} power(%convert_element_type.2214, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2220 = f32[16,4]{1,0} reduce(%pow.2215, %constant.512), dimensions={2}, to_apply=%region_52.2219, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2221 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.2220), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2222 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.2221, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2223 = f32[16,4,1]{2,1,0} add(%div.2222, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2224 = f32[16,4,1]{2,1,0} rsqrt(%add.2223), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2225 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.2224), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2226 = f32[16,4]{1,0} reshape(%mul.2225), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2227 = f32[16,4,128]{2,1,0} broadcast(%mul.2226), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2228 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.2214, %mul.2227), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2229 = bf16[16,4,128]{2,1,0} convert(%mul.2228), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_5_self_attn_k_norm_weight__.395 = bf16[128]{0} parameter(394), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.5.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.2230 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_5_self_attn_k_norm_weight__.395), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2231 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.2230), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2232 = bf16[128]{0} reshape(%mul.2231), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2233 = bf16[16,4,128]{2,1,0} broadcast(%mul.2232), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2234 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.2229, %mul.2233), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2268 = bf16[16,4,64]{2,1,0} slice(%mul.2234), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2266 = bf16[16,1,64]{2,1,0} reshape(%slice.2240), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2270 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2266), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2271 = bf16[16,64]{1,0} reshape(%mul.2270), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2272 = bf16[16,4,64]{2,1,0} broadcast(%mul.2271), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2273 = bf16[16,4,64]{2,1,0} multiply(%slice.2268, %mul.2272), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2269 = bf16[16,4,64]{2,1,0} slice(%mul.2234), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2267 = bf16[16,1,64]{2,1,0} reshape(%slice.2241), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2274 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2267), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2275 = bf16[16,64]{1,0} reshape(%mul.2274), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2276 = bf16[16,4,64]{2,1,0} broadcast(%mul.2275), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2277 = bf16[16,4,64]{2,1,0} multiply(%slice.2269, %mul.2276), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.2278 = bf16[16,4,64]{2,1,0} subtract(%mul.2273, %mul.2277), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.2279 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2266), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2280 = bf16[16,64]{1,0} reshape(%mul.2279), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2281 = bf16[16,4,64]{2,1,0} broadcast(%mul.2280), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2282 = bf16[16,4,64]{2,1,0} multiply(%slice.2269, %mul.2281), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2283 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2267), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2284 = bf16[16,64]{1,0} reshape(%mul.2283), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2285 = bf16[16,4,64]{2,1,0} broadcast(%mul.2284), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2286 = bf16[16,4,64]{2,1,0} multiply(%slice.2268, %mul.2285), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.2287 = bf16[16,4,64]{2,1,0} add(%mul.2282, %mul.2286), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.2288 = bf16[16,4,128]{2,1,0} concatenate(%sub.2278, %add.2287), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.2289 = bf16[16,512]{1,0} reshape(%concatenate.2288), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.2190 = bf16[16,4,128]{2,1,0} slice(%reshape.2187), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.2191 = bf16[16,512]{1,0} reshape(%slice.2190), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.2290 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_5_.441, %reshape.2265, %reshape.2289, %reshape.2191, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.2291 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.2290), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_6_.442 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(441), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[6]"}
  %jit__jax_attn_func_.2292 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.2290), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_5_self_attn_o_proj_weight__.396 = bf16[2048,4096]{1,0} parameter(395), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.5.self_attn.o_proj.weight\']"}
  %dot_general.2293 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.2292, %params_and_buffers__vllm_model_language_model_model_layers_5_self_attn_o_proj_weight__.396), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.2294 = f32[16,2048]{1,0} convert(%dot_general.2293), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2165 = bf16[16,2048]{1,0} convert(%add.2164), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2295 = f32[16,2048]{1,0} convert(%convert_element_type.2165), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.2296 = f32[16,2048]{1,0} add(%convert_element_type.2294, %convert_element_type.2295), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.2298 = f32[16,2048]{1,0} power(%add.2296, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2303 = f32[16]{0} reduce(%pow.2298, %constant.512), dimensions={1}, to_apply=%region_53.2302, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2304 = f32[16,1]{1,0} reshape(%reduce_sum.2303), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2305 = f32[16,1]{1,0} divide(%broadcast_in_dim.2304, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2306 = f32[16,1]{1,0} add(%div.2305, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2307 = f32[16,1]{1,0} rsqrt(%add.2306), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2308 = f32[16,1]{1,0} broadcast(%rsqrt.2307), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2309 = f32[16]{0} reshape(%mul.2308), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2310 = f32[16,2048]{1,0} broadcast(%mul.2309), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2311 = f32[16,2048]{1,0} multiply(%add.2296, %mul.2310), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2312 = bf16[16,2048]{1,0} convert(%mul.2311), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_5_post_attention_layernorm_weight__.394 = bf16[2048]{0} parameter(393), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.5.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.2313 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_5_post_attention_layernorm_weight__.394), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2314 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.2313), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2315 = bf16[2048]{0} reshape(%mul.2314), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2316 = bf16[16,2048]{1,0} broadcast(%mul.2315), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2317 = bf16[16,2048]{1,0} multiply(%convert_element_type.2312, %mul.2316), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_5_mlp_experts_w13_weight__.391 = bf16[128,1536,2048]{2,1,0} parameter(390), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.5.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_5_mlp_experts_w2_weight__.392 = bf16[128,2048,768]{2,1,0} parameter(391), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.5.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_5_mlp_gate_weight__.393 = bf16[128,2048]{1,0} parameter(392), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.5.mlp.gate.weight\']"}
  %dot_general.2318 = bf16[16,128]{1,0} dot(%mul.2317, %params_and_buffers__vllm_model_language_model_model_layers_5_mlp_gate_weight__.393), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.2319 = bf16[16,2048]{1,0} call(%mul.2317, %params_and_buffers__vllm_model_language_model_model_layers_5_mlp_experts_w13_weight__.391, %params_and_buffers__vllm_model_language_model_model_layers_5_mlp_experts_w2_weight__.392, %dot_general.2318), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.2320 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.2319), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2297 = bf16[16,2048]{1,0} convert(%add.2296), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2321 = f32[16,2048]{1,0} convert(%convert_element_type.2297), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.2322 = f32[16,2048]{1,0} add(%convert_element_type.2320, %convert_element_type.2321), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.2324 = f32[16,2048]{1,0} power(%add.2322, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2329 = f32[16]{0} reduce(%pow.2324, %constant.512), dimensions={1}, to_apply=%region_54.2328, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2330 = f32[16,1]{1,0} reshape(%reduce_sum.2329), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2331 = f32[16,1]{1,0} divide(%broadcast_in_dim.2330, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2332 = f32[16,1]{1,0} add(%div.2331, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2333 = f32[16,1]{1,0} rsqrt(%add.2332), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2334 = f32[16,1]{1,0} broadcast(%rsqrt.2333), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2335 = f32[16]{0} reshape(%mul.2334), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2336 = f32[16,2048]{1,0} broadcast(%mul.2335), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2337 = f32[16,2048]{1,0} multiply(%add.2322, %mul.2336), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2338 = bf16[16,2048]{1,0} convert(%mul.2337), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_6_input_layernorm_weight__.399 = bf16[2048]{0} parameter(398), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.6.input_layernorm.weight\']"}
  %broadcast_in_dim.2339 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_6_input_layernorm_weight__.399), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2340 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.2339), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2341 = bf16[2048]{0} reshape(%mul.2340), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2342 = bf16[16,2048]{1,0} broadcast(%mul.2341), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2343 = bf16[16,2048]{1,0} multiply(%convert_element_type.2338, %mul.2342), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_6_self_attn_qkv_proj_weight__.407 = bf16[5120,2048]{1,0} parameter(406), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.6.self_attn.qkv_proj.weight\']"}
  %dot_general.2344 = bf16[16,5120]{1,0} dot(%mul.2343, %params_and_buffers__vllm_model_language_model_model_layers_6_self_attn_qkv_proj_weight__.407), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.2345 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.2344), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.2346 = bf16[16,4,1024]{2,1,0} slice(%reshape.2345), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.2350 = bf16[16,32,128]{2,1,0} reshape(%slice.2346), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.2351 = f32[16,32,128]{2,1,0} convert(%reshape.2350), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.2352 = f32[16,32,128]{2,1,0} power(%convert_element_type.2351, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2357 = f32[16,32]{1,0} reduce(%pow.2352, %constant.512), dimensions={2}, to_apply=%region_55.2356, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2358 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.2357), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2359 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.2358, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2360 = f32[16,32,1]{2,1,0} add(%div.2359, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2361 = f32[16,32,1]{2,1,0} rsqrt(%add.2360), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2362 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.2361), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2363 = f32[16,32]{1,0} reshape(%mul.2362), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2364 = f32[16,32,128]{2,1,0} broadcast(%mul.2363), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2365 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.2351, %mul.2364), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2366 = bf16[16,32,128]{2,1,0} convert(%mul.2365), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_6_self_attn_q_norm_weight__.406 = bf16[128]{0} parameter(405), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.6.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.2367 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_6_self_attn_q_norm_weight__.406), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2368 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.2367), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2369 = bf16[128]{0} reshape(%mul.2368), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2370 = bf16[16,32,128]{2,1,0} broadcast(%mul.2369), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2371 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.2366, %mul.2370), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2402 = bf16[16,32,64]{2,1,0} slice(%mul.2371), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.2393 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.2394 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.2395 = s32[16]{0} select(%lt.2393, %add.2394, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.2396 = s32[16,1]{1,0} reshape(%select_n.2395), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.2397 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.2396), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.2398 = bf16[16,64]{1,0} slice(%gather.2397), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2400 = bf16[16,1,64]{2,1,0} reshape(%slice.2398), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2404 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2400), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2405 = bf16[16,64]{1,0} reshape(%mul.2404), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2406 = bf16[16,32,64]{2,1,0} broadcast(%mul.2405), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2407 = bf16[16,32,64]{2,1,0} multiply(%slice.2402, %mul.2406), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2403 = bf16[16,32,64]{2,1,0} slice(%mul.2371), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.2399 = bf16[16,64]{1,0} slice(%gather.2397), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2401 = bf16[16,1,64]{2,1,0} reshape(%slice.2399), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2408 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2401), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2409 = bf16[16,64]{1,0} reshape(%mul.2408), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2410 = bf16[16,32,64]{2,1,0} broadcast(%mul.2409), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2411 = bf16[16,32,64]{2,1,0} multiply(%slice.2403, %mul.2410), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.2412 = bf16[16,32,64]{2,1,0} subtract(%mul.2407, %mul.2411), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.2413 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2400), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2414 = bf16[16,64]{1,0} reshape(%mul.2413), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2415 = bf16[16,32,64]{2,1,0} broadcast(%mul.2414), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2416 = bf16[16,32,64]{2,1,0} multiply(%slice.2403, %mul.2415), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2417 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2401), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2418 = bf16[16,64]{1,0} reshape(%mul.2417), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2419 = bf16[16,32,64]{2,1,0} broadcast(%mul.2418), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2420 = bf16[16,32,64]{2,1,0} multiply(%slice.2402, %mul.2419), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.2421 = bf16[16,32,64]{2,1,0} add(%mul.2416, %mul.2420), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.2422 = bf16[16,32,128]{2,1,0} concatenate(%sub.2412, %add.2421), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.2423 = bf16[16,4096]{1,0} reshape(%concatenate.2422), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.2347 = bf16[16,4,128]{2,1,0} slice(%reshape.2345), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.2372 = f32[16,4,128]{2,1,0} convert(%slice.2347), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.2373 = f32[16,4,128]{2,1,0} power(%convert_element_type.2372, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2378 = f32[16,4]{1,0} reduce(%pow.2373, %constant.512), dimensions={2}, to_apply=%region_56.2377, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2379 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.2378), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2380 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.2379, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2381 = f32[16,4,1]{2,1,0} add(%div.2380, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2382 = f32[16,4,1]{2,1,0} rsqrt(%add.2381), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2383 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.2382), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2384 = f32[16,4]{1,0} reshape(%mul.2383), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2385 = f32[16,4,128]{2,1,0} broadcast(%mul.2384), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2386 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.2372, %mul.2385), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2387 = bf16[16,4,128]{2,1,0} convert(%mul.2386), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_6_self_attn_k_norm_weight__.404 = bf16[128]{0} parameter(403), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.6.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.2388 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_6_self_attn_k_norm_weight__.404), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2389 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.2388), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2390 = bf16[128]{0} reshape(%mul.2389), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2391 = bf16[16,4,128]{2,1,0} broadcast(%mul.2390), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2392 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.2387, %mul.2391), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2426 = bf16[16,4,64]{2,1,0} slice(%mul.2392), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2424 = bf16[16,1,64]{2,1,0} reshape(%slice.2398), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2428 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2424), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2429 = bf16[16,64]{1,0} reshape(%mul.2428), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2430 = bf16[16,4,64]{2,1,0} broadcast(%mul.2429), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2431 = bf16[16,4,64]{2,1,0} multiply(%slice.2426, %mul.2430), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2427 = bf16[16,4,64]{2,1,0} slice(%mul.2392), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2425 = bf16[16,1,64]{2,1,0} reshape(%slice.2399), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2432 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2425), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2433 = bf16[16,64]{1,0} reshape(%mul.2432), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2434 = bf16[16,4,64]{2,1,0} broadcast(%mul.2433), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2435 = bf16[16,4,64]{2,1,0} multiply(%slice.2427, %mul.2434), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.2436 = bf16[16,4,64]{2,1,0} subtract(%mul.2431, %mul.2435), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.2437 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2424), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2438 = bf16[16,64]{1,0} reshape(%mul.2437), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2439 = bf16[16,4,64]{2,1,0} broadcast(%mul.2438), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2440 = bf16[16,4,64]{2,1,0} multiply(%slice.2427, %mul.2439), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2441 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2425), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2442 = bf16[16,64]{1,0} reshape(%mul.2441), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2443 = bf16[16,4,64]{2,1,0} broadcast(%mul.2442), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2444 = bf16[16,4,64]{2,1,0} multiply(%slice.2426, %mul.2443), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.2445 = bf16[16,4,64]{2,1,0} add(%mul.2440, %mul.2444), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.2446 = bf16[16,4,128]{2,1,0} concatenate(%sub.2436, %add.2445), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.2447 = bf16[16,512]{1,0} reshape(%concatenate.2446), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.2348 = bf16[16,4,128]{2,1,0} slice(%reshape.2345), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.2349 = bf16[16,512]{1,0} reshape(%slice.2348), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.2448 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_6_.442, %reshape.2423, %reshape.2447, %reshape.2349, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.2449 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.2448), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_7_.443 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(442), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[7]"}
  %jit__jax_attn_func_.2450 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.2448), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_6_self_attn_o_proj_weight__.405 = bf16[2048,4096]{1,0} parameter(404), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.6.self_attn.o_proj.weight\']"}
  %dot_general.2451 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.2450, %params_and_buffers__vllm_model_language_model_model_layers_6_self_attn_o_proj_weight__.405), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.2452 = f32[16,2048]{1,0} convert(%dot_general.2451), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2323 = bf16[16,2048]{1,0} convert(%add.2322), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2453 = f32[16,2048]{1,0} convert(%convert_element_type.2323), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.2454 = f32[16,2048]{1,0} add(%convert_element_type.2452, %convert_element_type.2453), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.2456 = f32[16,2048]{1,0} power(%add.2454, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2461 = f32[16]{0} reduce(%pow.2456, %constant.512), dimensions={1}, to_apply=%region_57.2460, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2462 = f32[16,1]{1,0} reshape(%reduce_sum.2461), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2463 = f32[16,1]{1,0} divide(%broadcast_in_dim.2462, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2464 = f32[16,1]{1,0} add(%div.2463, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2465 = f32[16,1]{1,0} rsqrt(%add.2464), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2466 = f32[16,1]{1,0} broadcast(%rsqrt.2465), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2467 = f32[16]{0} reshape(%mul.2466), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2468 = f32[16,2048]{1,0} broadcast(%mul.2467), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2469 = f32[16,2048]{1,0} multiply(%add.2454, %mul.2468), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2470 = bf16[16,2048]{1,0} convert(%mul.2469), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_6_post_attention_layernorm_weight__.403 = bf16[2048]{0} parameter(402), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.6.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.2471 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_6_post_attention_layernorm_weight__.403), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2472 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.2471), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2473 = bf16[2048]{0} reshape(%mul.2472), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2474 = bf16[16,2048]{1,0} broadcast(%mul.2473), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2475 = bf16[16,2048]{1,0} multiply(%convert_element_type.2470, %mul.2474), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_6_mlp_experts_w13_weight__.400 = bf16[128,1536,2048]{2,1,0} parameter(399), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.6.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_6_mlp_experts_w2_weight__.401 = bf16[128,2048,768]{2,1,0} parameter(400), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.6.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_6_mlp_gate_weight__.402 = bf16[128,2048]{1,0} parameter(401), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.6.mlp.gate.weight\']"}
  %dot_general.2476 = bf16[16,128]{1,0} dot(%mul.2475, %params_and_buffers__vllm_model_language_model_model_layers_6_mlp_gate_weight__.402), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.2477 = bf16[16,2048]{1,0} call(%mul.2475, %params_and_buffers__vllm_model_language_model_model_layers_6_mlp_experts_w13_weight__.400, %params_and_buffers__vllm_model_language_model_model_layers_6_mlp_experts_w2_weight__.401, %dot_general.2476), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.2478 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.2477), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2455 = bf16[16,2048]{1,0} convert(%add.2454), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2479 = f32[16,2048]{1,0} convert(%convert_element_type.2455), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.2480 = f32[16,2048]{1,0} add(%convert_element_type.2478, %convert_element_type.2479), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.2482 = f32[16,2048]{1,0} power(%add.2480, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2487 = f32[16]{0} reduce(%pow.2482, %constant.512), dimensions={1}, to_apply=%region_58.2486, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2488 = f32[16,1]{1,0} reshape(%reduce_sum.2487), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2489 = f32[16,1]{1,0} divide(%broadcast_in_dim.2488, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2490 = f32[16,1]{1,0} add(%div.2489, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2491 = f32[16,1]{1,0} rsqrt(%add.2490), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2492 = f32[16,1]{1,0} broadcast(%rsqrt.2491), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2493 = f32[16]{0} reshape(%mul.2492), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2494 = f32[16,2048]{1,0} broadcast(%mul.2493), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2495 = f32[16,2048]{1,0} multiply(%add.2480, %mul.2494), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2496 = bf16[16,2048]{1,0} convert(%mul.2495), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_7_input_layernorm_weight__.408 = bf16[2048]{0} parameter(407), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.7.input_layernorm.weight\']"}
  %broadcast_in_dim.2497 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_7_input_layernorm_weight__.408), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2498 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.2497), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2499 = bf16[2048]{0} reshape(%mul.2498), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2500 = bf16[16,2048]{1,0} broadcast(%mul.2499), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2501 = bf16[16,2048]{1,0} multiply(%convert_element_type.2496, %mul.2500), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_7_self_attn_qkv_proj_weight__.416 = bf16[5120,2048]{1,0} parameter(415), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.7.self_attn.qkv_proj.weight\']"}
  %dot_general.2502 = bf16[16,5120]{1,0} dot(%mul.2501, %params_and_buffers__vllm_model_language_model_model_layers_7_self_attn_qkv_proj_weight__.416), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.2503 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.2502), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.2504 = bf16[16,4,1024]{2,1,0} slice(%reshape.2503), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.2508 = bf16[16,32,128]{2,1,0} reshape(%slice.2504), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.2509 = f32[16,32,128]{2,1,0} convert(%reshape.2508), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.2510 = f32[16,32,128]{2,1,0} power(%convert_element_type.2509, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2515 = f32[16,32]{1,0} reduce(%pow.2510, %constant.512), dimensions={2}, to_apply=%region_59.2514, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2516 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.2515), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2517 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.2516, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2518 = f32[16,32,1]{2,1,0} add(%div.2517, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2519 = f32[16,32,1]{2,1,0} rsqrt(%add.2518), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2520 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.2519), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2521 = f32[16,32]{1,0} reshape(%mul.2520), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2522 = f32[16,32,128]{2,1,0} broadcast(%mul.2521), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2523 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.2509, %mul.2522), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2524 = bf16[16,32,128]{2,1,0} convert(%mul.2523), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_7_self_attn_q_norm_weight__.415 = bf16[128]{0} parameter(414), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.7.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.2525 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_7_self_attn_q_norm_weight__.415), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2526 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.2525), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2527 = bf16[128]{0} reshape(%mul.2526), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2528 = bf16[16,32,128]{2,1,0} broadcast(%mul.2527), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2529 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.2524, %mul.2528), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2560 = bf16[16,32,64]{2,1,0} slice(%mul.2529), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.2551 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.2552 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.2553 = s32[16]{0} select(%lt.2551, %add.2552, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.2554 = s32[16,1]{1,0} reshape(%select_n.2553), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.2555 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.2554), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.2556 = bf16[16,64]{1,0} slice(%gather.2555), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2558 = bf16[16,1,64]{2,1,0} reshape(%slice.2556), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2562 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2558), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2563 = bf16[16,64]{1,0} reshape(%mul.2562), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2564 = bf16[16,32,64]{2,1,0} broadcast(%mul.2563), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2565 = bf16[16,32,64]{2,1,0} multiply(%slice.2560, %mul.2564), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2561 = bf16[16,32,64]{2,1,0} slice(%mul.2529), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.2557 = bf16[16,64]{1,0} slice(%gather.2555), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2559 = bf16[16,1,64]{2,1,0} reshape(%slice.2557), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2566 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2559), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2567 = bf16[16,64]{1,0} reshape(%mul.2566), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2568 = bf16[16,32,64]{2,1,0} broadcast(%mul.2567), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2569 = bf16[16,32,64]{2,1,0} multiply(%slice.2561, %mul.2568), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.2570 = bf16[16,32,64]{2,1,0} subtract(%mul.2565, %mul.2569), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.2571 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2558), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2572 = bf16[16,64]{1,0} reshape(%mul.2571), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2573 = bf16[16,32,64]{2,1,0} broadcast(%mul.2572), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2574 = bf16[16,32,64]{2,1,0} multiply(%slice.2561, %mul.2573), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2575 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2559), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2576 = bf16[16,64]{1,0} reshape(%mul.2575), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2577 = bf16[16,32,64]{2,1,0} broadcast(%mul.2576), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2578 = bf16[16,32,64]{2,1,0} multiply(%slice.2560, %mul.2577), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.2579 = bf16[16,32,64]{2,1,0} add(%mul.2574, %mul.2578), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.2580 = bf16[16,32,128]{2,1,0} concatenate(%sub.2570, %add.2579), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.2581 = bf16[16,4096]{1,0} reshape(%concatenate.2580), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.2505 = bf16[16,4,128]{2,1,0} slice(%reshape.2503), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.2530 = f32[16,4,128]{2,1,0} convert(%slice.2505), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.2531 = f32[16,4,128]{2,1,0} power(%convert_element_type.2530, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2536 = f32[16,4]{1,0} reduce(%pow.2531, %constant.512), dimensions={2}, to_apply=%region_60.2535, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2537 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.2536), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2538 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.2537, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2539 = f32[16,4,1]{2,1,0} add(%div.2538, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2540 = f32[16,4,1]{2,1,0} rsqrt(%add.2539), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2541 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.2540), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2542 = f32[16,4]{1,0} reshape(%mul.2541), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2543 = f32[16,4,128]{2,1,0} broadcast(%mul.2542), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2544 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.2530, %mul.2543), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2545 = bf16[16,4,128]{2,1,0} convert(%mul.2544), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_7_self_attn_k_norm_weight__.413 = bf16[128]{0} parameter(412), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.7.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.2546 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_7_self_attn_k_norm_weight__.413), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2547 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.2546), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2548 = bf16[128]{0} reshape(%mul.2547), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2549 = bf16[16,4,128]{2,1,0} broadcast(%mul.2548), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2550 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.2545, %mul.2549), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2584 = bf16[16,4,64]{2,1,0} slice(%mul.2550), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2582 = bf16[16,1,64]{2,1,0} reshape(%slice.2556), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2586 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2582), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2587 = bf16[16,64]{1,0} reshape(%mul.2586), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2588 = bf16[16,4,64]{2,1,0} broadcast(%mul.2587), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2589 = bf16[16,4,64]{2,1,0} multiply(%slice.2584, %mul.2588), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2585 = bf16[16,4,64]{2,1,0} slice(%mul.2550), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2583 = bf16[16,1,64]{2,1,0} reshape(%slice.2557), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2590 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2583), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2591 = bf16[16,64]{1,0} reshape(%mul.2590), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2592 = bf16[16,4,64]{2,1,0} broadcast(%mul.2591), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2593 = bf16[16,4,64]{2,1,0} multiply(%slice.2585, %mul.2592), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.2594 = bf16[16,4,64]{2,1,0} subtract(%mul.2589, %mul.2593), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.2595 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2582), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2596 = bf16[16,64]{1,0} reshape(%mul.2595), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2597 = bf16[16,4,64]{2,1,0} broadcast(%mul.2596), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2598 = bf16[16,4,64]{2,1,0} multiply(%slice.2585, %mul.2597), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2599 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2583), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2600 = bf16[16,64]{1,0} reshape(%mul.2599), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2601 = bf16[16,4,64]{2,1,0} broadcast(%mul.2600), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2602 = bf16[16,4,64]{2,1,0} multiply(%slice.2584, %mul.2601), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.2603 = bf16[16,4,64]{2,1,0} add(%mul.2598, %mul.2602), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.2604 = bf16[16,4,128]{2,1,0} concatenate(%sub.2594, %add.2603), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.2605 = bf16[16,512]{1,0} reshape(%concatenate.2604), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.2506 = bf16[16,4,128]{2,1,0} slice(%reshape.2503), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.2507 = bf16[16,512]{1,0} reshape(%slice.2506), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.2606 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_7_.443, %reshape.2581, %reshape.2605, %reshape.2507, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.2607 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.2606), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_8_.444 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(443), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[8]"}
  %jit__jax_attn_func_.2608 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.2606), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_7_self_attn_o_proj_weight__.414 = bf16[2048,4096]{1,0} parameter(413), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.7.self_attn.o_proj.weight\']"}
  %dot_general.2609 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.2608, %params_and_buffers__vllm_model_language_model_model_layers_7_self_attn_o_proj_weight__.414), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.2610 = f32[16,2048]{1,0} convert(%dot_general.2609), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2481 = bf16[16,2048]{1,0} convert(%add.2480), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2611 = f32[16,2048]{1,0} convert(%convert_element_type.2481), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.2612 = f32[16,2048]{1,0} add(%convert_element_type.2610, %convert_element_type.2611), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.2614 = f32[16,2048]{1,0} power(%add.2612, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2619 = f32[16]{0} reduce(%pow.2614, %constant.512), dimensions={1}, to_apply=%region_61.2618, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2620 = f32[16,1]{1,0} reshape(%reduce_sum.2619), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2621 = f32[16,1]{1,0} divide(%broadcast_in_dim.2620, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2622 = f32[16,1]{1,0} add(%div.2621, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2623 = f32[16,1]{1,0} rsqrt(%add.2622), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2624 = f32[16,1]{1,0} broadcast(%rsqrt.2623), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2625 = f32[16]{0} reshape(%mul.2624), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2626 = f32[16,2048]{1,0} broadcast(%mul.2625), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2627 = f32[16,2048]{1,0} multiply(%add.2612, %mul.2626), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2628 = bf16[16,2048]{1,0} convert(%mul.2627), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_7_post_attention_layernorm_weight__.412 = bf16[2048]{0} parameter(411), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.7.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.2629 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_7_post_attention_layernorm_weight__.412), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2630 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.2629), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2631 = bf16[2048]{0} reshape(%mul.2630), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2632 = bf16[16,2048]{1,0} broadcast(%mul.2631), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2633 = bf16[16,2048]{1,0} multiply(%convert_element_type.2628, %mul.2632), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_7_mlp_experts_w13_weight__.409 = bf16[128,1536,2048]{2,1,0} parameter(408), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.7.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_7_mlp_experts_w2_weight__.410 = bf16[128,2048,768]{2,1,0} parameter(409), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.7.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_7_mlp_gate_weight__.411 = bf16[128,2048]{1,0} parameter(410), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.7.mlp.gate.weight\']"}
  %dot_general.2634 = bf16[16,128]{1,0} dot(%mul.2633, %params_and_buffers__vllm_model_language_model_model_layers_7_mlp_gate_weight__.411), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.2635 = bf16[16,2048]{1,0} call(%mul.2633, %params_and_buffers__vllm_model_language_model_model_layers_7_mlp_experts_w13_weight__.409, %params_and_buffers__vllm_model_language_model_model_layers_7_mlp_experts_w2_weight__.410, %dot_general.2634), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.2636 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.2635), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2613 = bf16[16,2048]{1,0} convert(%add.2612), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2637 = f32[16,2048]{1,0} convert(%convert_element_type.2613), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.2638 = f32[16,2048]{1,0} add(%convert_element_type.2636, %convert_element_type.2637), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.2640 = f32[16,2048]{1,0} power(%add.2638, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2645 = f32[16]{0} reduce(%pow.2640, %constant.512), dimensions={1}, to_apply=%region_62.2644, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2646 = f32[16,1]{1,0} reshape(%reduce_sum.2645), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2647 = f32[16,1]{1,0} divide(%broadcast_in_dim.2646, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2648 = f32[16,1]{1,0} add(%div.2647, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2649 = f32[16,1]{1,0} rsqrt(%add.2648), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2650 = f32[16,1]{1,0} broadcast(%rsqrt.2649), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2651 = f32[16]{0} reshape(%mul.2650), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2652 = f32[16,2048]{1,0} broadcast(%mul.2651), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2653 = f32[16,2048]{1,0} multiply(%add.2638, %mul.2652), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2654 = bf16[16,2048]{1,0} convert(%mul.2653), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_8_input_layernorm_weight__.417 = bf16[2048]{0} parameter(416), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.8.input_layernorm.weight\']"}
  %broadcast_in_dim.2655 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_8_input_layernorm_weight__.417), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2656 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.2655), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2657 = bf16[2048]{0} reshape(%mul.2656), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2658 = bf16[16,2048]{1,0} broadcast(%mul.2657), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2659 = bf16[16,2048]{1,0} multiply(%convert_element_type.2654, %mul.2658), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_8_self_attn_qkv_proj_weight__.425 = bf16[5120,2048]{1,0} parameter(424), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.8.self_attn.qkv_proj.weight\']"}
  %dot_general.2660 = bf16[16,5120]{1,0} dot(%mul.2659, %params_and_buffers__vllm_model_language_model_model_layers_8_self_attn_qkv_proj_weight__.425), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.2661 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.2660), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.2662 = bf16[16,4,1024]{2,1,0} slice(%reshape.2661), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.2666 = bf16[16,32,128]{2,1,0} reshape(%slice.2662), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.2667 = f32[16,32,128]{2,1,0} convert(%reshape.2666), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.2668 = f32[16,32,128]{2,1,0} power(%convert_element_type.2667, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2673 = f32[16,32]{1,0} reduce(%pow.2668, %constant.512), dimensions={2}, to_apply=%region_63.2672, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2674 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.2673), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2675 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.2674, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2676 = f32[16,32,1]{2,1,0} add(%div.2675, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2677 = f32[16,32,1]{2,1,0} rsqrt(%add.2676), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2678 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.2677), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2679 = f32[16,32]{1,0} reshape(%mul.2678), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2680 = f32[16,32,128]{2,1,0} broadcast(%mul.2679), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2681 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.2667, %mul.2680), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2682 = bf16[16,32,128]{2,1,0} convert(%mul.2681), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_8_self_attn_q_norm_weight__.424 = bf16[128]{0} parameter(423), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.8.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.2683 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_8_self_attn_q_norm_weight__.424), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2684 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.2683), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2685 = bf16[128]{0} reshape(%mul.2684), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2686 = bf16[16,32,128]{2,1,0} broadcast(%mul.2685), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2687 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.2682, %mul.2686), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2718 = bf16[16,32,64]{2,1,0} slice(%mul.2687), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.2709 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.2710 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.2711 = s32[16]{0} select(%lt.2709, %add.2710, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.2712 = s32[16,1]{1,0} reshape(%select_n.2711), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.2713 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.2712), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.2714 = bf16[16,64]{1,0} slice(%gather.2713), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2716 = bf16[16,1,64]{2,1,0} reshape(%slice.2714), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2720 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2716), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2721 = bf16[16,64]{1,0} reshape(%mul.2720), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2722 = bf16[16,32,64]{2,1,0} broadcast(%mul.2721), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2723 = bf16[16,32,64]{2,1,0} multiply(%slice.2718, %mul.2722), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2719 = bf16[16,32,64]{2,1,0} slice(%mul.2687), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.2715 = bf16[16,64]{1,0} slice(%gather.2713), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2717 = bf16[16,1,64]{2,1,0} reshape(%slice.2715), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2724 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2717), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2725 = bf16[16,64]{1,0} reshape(%mul.2724), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2726 = bf16[16,32,64]{2,1,0} broadcast(%mul.2725), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2727 = bf16[16,32,64]{2,1,0} multiply(%slice.2719, %mul.2726), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.2728 = bf16[16,32,64]{2,1,0} subtract(%mul.2723, %mul.2727), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.2729 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2716), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2730 = bf16[16,64]{1,0} reshape(%mul.2729), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2731 = bf16[16,32,64]{2,1,0} broadcast(%mul.2730), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2732 = bf16[16,32,64]{2,1,0} multiply(%slice.2719, %mul.2731), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2733 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2717), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2734 = bf16[16,64]{1,0} reshape(%mul.2733), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2735 = bf16[16,32,64]{2,1,0} broadcast(%mul.2734), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2736 = bf16[16,32,64]{2,1,0} multiply(%slice.2718, %mul.2735), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.2737 = bf16[16,32,64]{2,1,0} add(%mul.2732, %mul.2736), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.2738 = bf16[16,32,128]{2,1,0} concatenate(%sub.2728, %add.2737), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.2739 = bf16[16,4096]{1,0} reshape(%concatenate.2738), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.2663 = bf16[16,4,128]{2,1,0} slice(%reshape.2661), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.2688 = f32[16,4,128]{2,1,0} convert(%slice.2663), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.2689 = f32[16,4,128]{2,1,0} power(%convert_element_type.2688, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2694 = f32[16,4]{1,0} reduce(%pow.2689, %constant.512), dimensions={2}, to_apply=%region_64.2693, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2695 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.2694), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2696 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.2695, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2697 = f32[16,4,1]{2,1,0} add(%div.2696, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2698 = f32[16,4,1]{2,1,0} rsqrt(%add.2697), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2699 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.2698), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2700 = f32[16,4]{1,0} reshape(%mul.2699), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2701 = f32[16,4,128]{2,1,0} broadcast(%mul.2700), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2702 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.2688, %mul.2701), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2703 = bf16[16,4,128]{2,1,0} convert(%mul.2702), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_8_self_attn_k_norm_weight__.422 = bf16[128]{0} parameter(421), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.8.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.2704 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_8_self_attn_k_norm_weight__.422), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2705 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.2704), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2706 = bf16[128]{0} reshape(%mul.2705), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2707 = bf16[16,4,128]{2,1,0} broadcast(%mul.2706), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2708 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.2703, %mul.2707), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2742 = bf16[16,4,64]{2,1,0} slice(%mul.2708), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2740 = bf16[16,1,64]{2,1,0} reshape(%slice.2714), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2744 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2740), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2745 = bf16[16,64]{1,0} reshape(%mul.2744), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2746 = bf16[16,4,64]{2,1,0} broadcast(%mul.2745), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2747 = bf16[16,4,64]{2,1,0} multiply(%slice.2742, %mul.2746), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2743 = bf16[16,4,64]{2,1,0} slice(%mul.2708), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2741 = bf16[16,1,64]{2,1,0} reshape(%slice.2715), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2748 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2741), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2749 = bf16[16,64]{1,0} reshape(%mul.2748), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2750 = bf16[16,4,64]{2,1,0} broadcast(%mul.2749), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2751 = bf16[16,4,64]{2,1,0} multiply(%slice.2743, %mul.2750), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.2752 = bf16[16,4,64]{2,1,0} subtract(%mul.2747, %mul.2751), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.2753 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2740), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2754 = bf16[16,64]{1,0} reshape(%mul.2753), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2755 = bf16[16,4,64]{2,1,0} broadcast(%mul.2754), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2756 = bf16[16,4,64]{2,1,0} multiply(%slice.2743, %mul.2755), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2757 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2741), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2758 = bf16[16,64]{1,0} reshape(%mul.2757), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2759 = bf16[16,4,64]{2,1,0} broadcast(%mul.2758), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2760 = bf16[16,4,64]{2,1,0} multiply(%slice.2742, %mul.2759), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.2761 = bf16[16,4,64]{2,1,0} add(%mul.2756, %mul.2760), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.2762 = bf16[16,4,128]{2,1,0} concatenate(%sub.2752, %add.2761), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.2763 = bf16[16,512]{1,0} reshape(%concatenate.2762), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.2664 = bf16[16,4,128]{2,1,0} slice(%reshape.2661), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.2665 = bf16[16,512]{1,0} reshape(%slice.2664), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.2764 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_8_.444, %reshape.2739, %reshape.2763, %reshape.2665, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.2765 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.2764), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_9_.445 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(444), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[9]"}
  %jit__jax_attn_func_.2766 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.2764), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_8_self_attn_o_proj_weight__.423 = bf16[2048,4096]{1,0} parameter(422), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.8.self_attn.o_proj.weight\']"}
  %dot_general.2767 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.2766, %params_and_buffers__vllm_model_language_model_model_layers_8_self_attn_o_proj_weight__.423), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.2768 = f32[16,2048]{1,0} convert(%dot_general.2767), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2639 = bf16[16,2048]{1,0} convert(%add.2638), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2769 = f32[16,2048]{1,0} convert(%convert_element_type.2639), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.2770 = f32[16,2048]{1,0} add(%convert_element_type.2768, %convert_element_type.2769), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.2772 = f32[16,2048]{1,0} power(%add.2770, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2777 = f32[16]{0} reduce(%pow.2772, %constant.512), dimensions={1}, to_apply=%region_65.2776, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2778 = f32[16,1]{1,0} reshape(%reduce_sum.2777), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2779 = f32[16,1]{1,0} divide(%broadcast_in_dim.2778, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2780 = f32[16,1]{1,0} add(%div.2779, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2781 = f32[16,1]{1,0} rsqrt(%add.2780), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2782 = f32[16,1]{1,0} broadcast(%rsqrt.2781), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2783 = f32[16]{0} reshape(%mul.2782), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2784 = f32[16,2048]{1,0} broadcast(%mul.2783), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2785 = f32[16,2048]{1,0} multiply(%add.2770, %mul.2784), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2786 = bf16[16,2048]{1,0} convert(%mul.2785), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_8_post_attention_layernorm_weight__.421 = bf16[2048]{0} parameter(420), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.8.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.2787 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_8_post_attention_layernorm_weight__.421), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2788 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.2787), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2789 = bf16[2048]{0} reshape(%mul.2788), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2790 = bf16[16,2048]{1,0} broadcast(%mul.2789), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2791 = bf16[16,2048]{1,0} multiply(%convert_element_type.2786, %mul.2790), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_8_mlp_experts_w13_weight__.418 = bf16[128,1536,2048]{2,1,0} parameter(417), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.8.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_8_mlp_experts_w2_weight__.419 = bf16[128,2048,768]{2,1,0} parameter(418), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.8.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_8_mlp_gate_weight__.420 = bf16[128,2048]{1,0} parameter(419), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.8.mlp.gate.weight\']"}
  %dot_general.2792 = bf16[16,128]{1,0} dot(%mul.2791, %params_and_buffers__vllm_model_language_model_model_layers_8_mlp_gate_weight__.420), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.2793 = bf16[16,2048]{1,0} call(%mul.2791, %params_and_buffers__vllm_model_language_model_model_layers_8_mlp_experts_w13_weight__.418, %params_and_buffers__vllm_model_language_model_model_layers_8_mlp_experts_w2_weight__.419, %dot_general.2792), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.2794 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.2793), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2771 = bf16[16,2048]{1,0} convert(%add.2770), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2795 = f32[16,2048]{1,0} convert(%convert_element_type.2771), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.2796 = f32[16,2048]{1,0} add(%convert_element_type.2794, %convert_element_type.2795), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.2798 = f32[16,2048]{1,0} power(%add.2796, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2803 = f32[16]{0} reduce(%pow.2798, %constant.512), dimensions={1}, to_apply=%region_66.2802, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2804 = f32[16,1]{1,0} reshape(%reduce_sum.2803), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2805 = f32[16,1]{1,0} divide(%broadcast_in_dim.2804, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2806 = f32[16,1]{1,0} add(%div.2805, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2807 = f32[16,1]{1,0} rsqrt(%add.2806), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2808 = f32[16,1]{1,0} broadcast(%rsqrt.2807), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2809 = f32[16]{0} reshape(%mul.2808), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2810 = f32[16,2048]{1,0} broadcast(%mul.2809), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2811 = f32[16,2048]{1,0} multiply(%add.2796, %mul.2810), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2812 = bf16[16,2048]{1,0} convert(%mul.2811), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_9_input_layernorm_weight__.426 = bf16[2048]{0} parameter(425), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.9.input_layernorm.weight\']"}
  %broadcast_in_dim.2813 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_9_input_layernorm_weight__.426), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2814 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.2813), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2815 = bf16[2048]{0} reshape(%mul.2814), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2816 = bf16[16,2048]{1,0} broadcast(%mul.2815), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2817 = bf16[16,2048]{1,0} multiply(%convert_element_type.2812, %mul.2816), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_9_self_attn_qkv_proj_weight__.434 = bf16[5120,2048]{1,0} parameter(433), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.9.self_attn.qkv_proj.weight\']"}
  %dot_general.2818 = bf16[16,5120]{1,0} dot(%mul.2817, %params_and_buffers__vllm_model_language_model_model_layers_9_self_attn_qkv_proj_weight__.434), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.2819 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.2818), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.2820 = bf16[16,4,1024]{2,1,0} slice(%reshape.2819), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.2824 = bf16[16,32,128]{2,1,0} reshape(%slice.2820), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.2825 = f32[16,32,128]{2,1,0} convert(%reshape.2824), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.2826 = f32[16,32,128]{2,1,0} power(%convert_element_type.2825, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2831 = f32[16,32]{1,0} reduce(%pow.2826, %constant.512), dimensions={2}, to_apply=%region_67.2830, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2832 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.2831), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2833 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.2832, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2834 = f32[16,32,1]{2,1,0} add(%div.2833, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2835 = f32[16,32,1]{2,1,0} rsqrt(%add.2834), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2836 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.2835), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2837 = f32[16,32]{1,0} reshape(%mul.2836), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2838 = f32[16,32,128]{2,1,0} broadcast(%mul.2837), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2839 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.2825, %mul.2838), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2840 = bf16[16,32,128]{2,1,0} convert(%mul.2839), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_9_self_attn_q_norm_weight__.433 = bf16[128]{0} parameter(432), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.9.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.2841 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_9_self_attn_q_norm_weight__.433), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2842 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.2841), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2843 = bf16[128]{0} reshape(%mul.2842), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2844 = bf16[16,32,128]{2,1,0} broadcast(%mul.2843), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2845 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.2840, %mul.2844), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2876 = bf16[16,32,64]{2,1,0} slice(%mul.2845), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.2867 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.2868 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.2869 = s32[16]{0} select(%lt.2867, %add.2868, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.2870 = s32[16,1]{1,0} reshape(%select_n.2869), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.2871 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.2870), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.2872 = bf16[16,64]{1,0} slice(%gather.2871), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2874 = bf16[16,1,64]{2,1,0} reshape(%slice.2872), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2878 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2874), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2879 = bf16[16,64]{1,0} reshape(%mul.2878), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2880 = bf16[16,32,64]{2,1,0} broadcast(%mul.2879), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2881 = bf16[16,32,64]{2,1,0} multiply(%slice.2876, %mul.2880), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2877 = bf16[16,32,64]{2,1,0} slice(%mul.2845), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.2873 = bf16[16,64]{1,0} slice(%gather.2871), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2875 = bf16[16,1,64]{2,1,0} reshape(%slice.2873), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2882 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2875), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2883 = bf16[16,64]{1,0} reshape(%mul.2882), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2884 = bf16[16,32,64]{2,1,0} broadcast(%mul.2883), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2885 = bf16[16,32,64]{2,1,0} multiply(%slice.2877, %mul.2884), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.2886 = bf16[16,32,64]{2,1,0} subtract(%mul.2881, %mul.2885), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.2887 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2874), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2888 = bf16[16,64]{1,0} reshape(%mul.2887), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2889 = bf16[16,32,64]{2,1,0} broadcast(%mul.2888), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2890 = bf16[16,32,64]{2,1,0} multiply(%slice.2877, %mul.2889), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2891 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2875), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2892 = bf16[16,64]{1,0} reshape(%mul.2891), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2893 = bf16[16,32,64]{2,1,0} broadcast(%mul.2892), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2894 = bf16[16,32,64]{2,1,0} multiply(%slice.2876, %mul.2893), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.2895 = bf16[16,32,64]{2,1,0} add(%mul.2890, %mul.2894), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.2896 = bf16[16,32,128]{2,1,0} concatenate(%sub.2886, %add.2895), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.2897 = bf16[16,4096]{1,0} reshape(%concatenate.2896), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.2821 = bf16[16,4,128]{2,1,0} slice(%reshape.2819), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.2846 = f32[16,4,128]{2,1,0} convert(%slice.2821), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.2847 = f32[16,4,128]{2,1,0} power(%convert_element_type.2846, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2852 = f32[16,4]{1,0} reduce(%pow.2847, %constant.512), dimensions={2}, to_apply=%region_68.2851, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2853 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.2852), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2854 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.2853, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2855 = f32[16,4,1]{2,1,0} add(%div.2854, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2856 = f32[16,4,1]{2,1,0} rsqrt(%add.2855), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2857 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.2856), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2858 = f32[16,4]{1,0} reshape(%mul.2857), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2859 = f32[16,4,128]{2,1,0} broadcast(%mul.2858), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2860 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.2846, %mul.2859), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2861 = bf16[16,4,128]{2,1,0} convert(%mul.2860), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_9_self_attn_k_norm_weight__.431 = bf16[128]{0} parameter(430), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.9.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.2862 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_9_self_attn_k_norm_weight__.431), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2863 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.2862), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2864 = bf16[128]{0} reshape(%mul.2863), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2865 = bf16[16,4,128]{2,1,0} broadcast(%mul.2864), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2866 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.2861, %mul.2865), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2900 = bf16[16,4,64]{2,1,0} slice(%mul.2866), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2898 = bf16[16,1,64]{2,1,0} reshape(%slice.2872), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2902 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2898), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2903 = bf16[16,64]{1,0} reshape(%mul.2902), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2904 = bf16[16,4,64]{2,1,0} broadcast(%mul.2903), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2905 = bf16[16,4,64]{2,1,0} multiply(%slice.2900, %mul.2904), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2901 = bf16[16,4,64]{2,1,0} slice(%mul.2866), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2899 = bf16[16,1,64]{2,1,0} reshape(%slice.2873), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2906 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2899), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2907 = bf16[16,64]{1,0} reshape(%mul.2906), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2908 = bf16[16,4,64]{2,1,0} broadcast(%mul.2907), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2909 = bf16[16,4,64]{2,1,0} multiply(%slice.2901, %mul.2908), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.2910 = bf16[16,4,64]{2,1,0} subtract(%mul.2905, %mul.2909), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.2911 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2898), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2912 = bf16[16,64]{1,0} reshape(%mul.2911), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2913 = bf16[16,4,64]{2,1,0} broadcast(%mul.2912), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2914 = bf16[16,4,64]{2,1,0} multiply(%slice.2901, %mul.2913), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2915 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.2899), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2916 = bf16[16,64]{1,0} reshape(%mul.2915), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2917 = bf16[16,4,64]{2,1,0} broadcast(%mul.2916), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2918 = bf16[16,4,64]{2,1,0} multiply(%slice.2900, %mul.2917), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.2919 = bf16[16,4,64]{2,1,0} add(%mul.2914, %mul.2918), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.2920 = bf16[16,4,128]{2,1,0} concatenate(%sub.2910, %add.2919), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.2921 = bf16[16,512]{1,0} reshape(%concatenate.2920), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.2822 = bf16[16,4,128]{2,1,0} slice(%reshape.2819), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.2823 = bf16[16,512]{1,0} reshape(%slice.2822), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.2922 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_9_.445, %reshape.2897, %reshape.2921, %reshape.2823, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.2923 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.2922), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_10_.446 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(445), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[10]"}
  %jit__jax_attn_func_.2924 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.2922), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_9_self_attn_o_proj_weight__.432 = bf16[2048,4096]{1,0} parameter(431), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.9.self_attn.o_proj.weight\']"}
  %dot_general.2925 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.2924, %params_and_buffers__vllm_model_language_model_model_layers_9_self_attn_o_proj_weight__.432), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.2926 = f32[16,2048]{1,0} convert(%dot_general.2925), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2797 = bf16[16,2048]{1,0} convert(%add.2796), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2927 = f32[16,2048]{1,0} convert(%convert_element_type.2797), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.2928 = f32[16,2048]{1,0} add(%convert_element_type.2926, %convert_element_type.2927), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.2930 = f32[16,2048]{1,0} power(%add.2928, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2935 = f32[16]{0} reduce(%pow.2930, %constant.512), dimensions={1}, to_apply=%region_69.2934, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2936 = f32[16,1]{1,0} reshape(%reduce_sum.2935), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2937 = f32[16,1]{1,0} divide(%broadcast_in_dim.2936, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2938 = f32[16,1]{1,0} add(%div.2937, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2939 = f32[16,1]{1,0} rsqrt(%add.2938), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2940 = f32[16,1]{1,0} broadcast(%rsqrt.2939), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2941 = f32[16]{0} reshape(%mul.2940), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2942 = f32[16,2048]{1,0} broadcast(%mul.2941), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2943 = f32[16,2048]{1,0} multiply(%add.2928, %mul.2942), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2944 = bf16[16,2048]{1,0} convert(%mul.2943), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_9_post_attention_layernorm_weight__.430 = bf16[2048]{0} parameter(429), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.9.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.2945 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_9_post_attention_layernorm_weight__.430), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2946 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.2945), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2947 = bf16[2048]{0} reshape(%mul.2946), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2948 = bf16[16,2048]{1,0} broadcast(%mul.2947), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2949 = bf16[16,2048]{1,0} multiply(%convert_element_type.2944, %mul.2948), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_9_mlp_experts_w13_weight__.427 = bf16[128,1536,2048]{2,1,0} parameter(426), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.9.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_9_mlp_experts_w2_weight__.428 = bf16[128,2048,768]{2,1,0} parameter(427), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.9.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_9_mlp_gate_weight__.429 = bf16[128,2048]{1,0} parameter(428), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.9.mlp.gate.weight\']"}
  %dot_general.2950 = bf16[16,128]{1,0} dot(%mul.2949, %params_and_buffers__vllm_model_language_model_model_layers_9_mlp_gate_weight__.429), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.2951 = bf16[16,2048]{1,0} call(%mul.2949, %params_and_buffers__vllm_model_language_model_model_layers_9_mlp_experts_w13_weight__.427, %params_and_buffers__vllm_model_language_model_model_layers_9_mlp_experts_w2_weight__.428, %dot_general.2950), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.2952 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.2951), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2929 = bf16[16,2048]{1,0} convert(%add.2928), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2953 = f32[16,2048]{1,0} convert(%convert_element_type.2929), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.2954 = f32[16,2048]{1,0} add(%convert_element_type.2952, %convert_element_type.2953), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.2956 = f32[16,2048]{1,0} power(%add.2954, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2961 = f32[16]{0} reduce(%pow.2956, %constant.512), dimensions={1}, to_apply=%region_70.2960, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2962 = f32[16,1]{1,0} reshape(%reduce_sum.2961), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2963 = f32[16,1]{1,0} divide(%broadcast_in_dim.2962, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2964 = f32[16,1]{1,0} add(%div.2963, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2965 = f32[16,1]{1,0} rsqrt(%add.2964), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2966 = f32[16,1]{1,0} broadcast(%rsqrt.2965), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2967 = f32[16]{0} reshape(%mul.2966), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2968 = f32[16,2048]{1,0} broadcast(%mul.2967), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2969 = f32[16,2048]{1,0} multiply(%add.2954, %mul.2968), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2970 = bf16[16,2048]{1,0} convert(%mul.2969), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_10_input_layernorm_weight__.21 = bf16[2048]{0} parameter(20), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.10.input_layernorm.weight\']"}
  %broadcast_in_dim.2971 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_10_input_layernorm_weight__.21), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2972 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.2971), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2973 = bf16[2048]{0} reshape(%mul.2972), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2974 = bf16[16,2048]{1,0} broadcast(%mul.2973), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2975 = bf16[16,2048]{1,0} multiply(%convert_element_type.2970, %mul.2974), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_10_self_attn_qkv_proj_weight__.29 = bf16[5120,2048]{1,0} parameter(28), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.10.self_attn.qkv_proj.weight\']"}
  %dot_general.2976 = bf16[16,5120]{1,0} dot(%mul.2975, %params_and_buffers__vllm_model_language_model_model_layers_10_self_attn_qkv_proj_weight__.29), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.2977 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.2976), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.2978 = bf16[16,4,1024]{2,1,0} slice(%reshape.2977), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.2982 = bf16[16,32,128]{2,1,0} reshape(%slice.2978), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.2983 = f32[16,32,128]{2,1,0} convert(%reshape.2982), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.2984 = f32[16,32,128]{2,1,0} power(%convert_element_type.2983, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2989 = f32[16,32]{1,0} reduce(%pow.2984, %constant.512), dimensions={2}, to_apply=%region_71.2988, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2990 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.2989), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2991 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.2990, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2992 = f32[16,32,1]{2,1,0} add(%div.2991, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2993 = f32[16,32,1]{2,1,0} rsqrt(%add.2992), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2994 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.2993), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2995 = f32[16,32]{1,0} reshape(%mul.2994), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2996 = f32[16,32,128]{2,1,0} broadcast(%mul.2995), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2997 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.2983, %mul.2996), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2998 = bf16[16,32,128]{2,1,0} convert(%mul.2997), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_10_self_attn_q_norm_weight__.28 = bf16[128]{0} parameter(27), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.10.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.2999 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_10_self_attn_q_norm_weight__.28), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3000 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.2999), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3001 = bf16[128]{0} reshape(%mul.3000), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3002 = bf16[16,32,128]{2,1,0} broadcast(%mul.3001), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3003 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.2998, %mul.3002), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3034 = bf16[16,32,64]{2,1,0} slice(%mul.3003), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.3025 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.3026 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.3027 = s32[16]{0} select(%lt.3025, %add.3026, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.3028 = s32[16,1]{1,0} reshape(%select_n.3027), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.3029 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.3028), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.3030 = bf16[16,64]{1,0} slice(%gather.3029), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3032 = bf16[16,1,64]{2,1,0} reshape(%slice.3030), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3036 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3032), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3037 = bf16[16,64]{1,0} reshape(%mul.3036), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3038 = bf16[16,32,64]{2,1,0} broadcast(%mul.3037), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3039 = bf16[16,32,64]{2,1,0} multiply(%slice.3034, %mul.3038), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3035 = bf16[16,32,64]{2,1,0} slice(%mul.3003), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.3031 = bf16[16,64]{1,0} slice(%gather.3029), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3033 = bf16[16,1,64]{2,1,0} reshape(%slice.3031), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3040 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3033), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3041 = bf16[16,64]{1,0} reshape(%mul.3040), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3042 = bf16[16,32,64]{2,1,0} broadcast(%mul.3041), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3043 = bf16[16,32,64]{2,1,0} multiply(%slice.3035, %mul.3042), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.3044 = bf16[16,32,64]{2,1,0} subtract(%mul.3039, %mul.3043), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.3045 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3032), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3046 = bf16[16,64]{1,0} reshape(%mul.3045), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3047 = bf16[16,32,64]{2,1,0} broadcast(%mul.3046), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3048 = bf16[16,32,64]{2,1,0} multiply(%slice.3035, %mul.3047), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3049 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3033), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3050 = bf16[16,64]{1,0} reshape(%mul.3049), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3051 = bf16[16,32,64]{2,1,0} broadcast(%mul.3050), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3052 = bf16[16,32,64]{2,1,0} multiply(%slice.3034, %mul.3051), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.3053 = bf16[16,32,64]{2,1,0} add(%mul.3048, %mul.3052), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.3054 = bf16[16,32,128]{2,1,0} concatenate(%sub.3044, %add.3053), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.3055 = bf16[16,4096]{1,0} reshape(%concatenate.3054), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.2979 = bf16[16,4,128]{2,1,0} slice(%reshape.2977), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.3004 = f32[16,4,128]{2,1,0} convert(%slice.2979), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.3005 = f32[16,4,128]{2,1,0} power(%convert_element_type.3004, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3010 = f32[16,4]{1,0} reduce(%pow.3005, %constant.512), dimensions={2}, to_apply=%region_72.3009, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3011 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.3010), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3012 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.3011, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3013 = f32[16,4,1]{2,1,0} add(%div.3012, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3014 = f32[16,4,1]{2,1,0} rsqrt(%add.3013), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3015 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.3014), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3016 = f32[16,4]{1,0} reshape(%mul.3015), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3017 = f32[16,4,128]{2,1,0} broadcast(%mul.3016), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3018 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.3004, %mul.3017), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3019 = bf16[16,4,128]{2,1,0} convert(%mul.3018), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_10_self_attn_k_norm_weight__.26 = bf16[128]{0} parameter(25), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.10.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.3020 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_10_self_attn_k_norm_weight__.26), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3021 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.3020), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3022 = bf16[128]{0} reshape(%mul.3021), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3023 = bf16[16,4,128]{2,1,0} broadcast(%mul.3022), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3024 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.3019, %mul.3023), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3058 = bf16[16,4,64]{2,1,0} slice(%mul.3024), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3056 = bf16[16,1,64]{2,1,0} reshape(%slice.3030), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3060 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3056), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3061 = bf16[16,64]{1,0} reshape(%mul.3060), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3062 = bf16[16,4,64]{2,1,0} broadcast(%mul.3061), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3063 = bf16[16,4,64]{2,1,0} multiply(%slice.3058, %mul.3062), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3059 = bf16[16,4,64]{2,1,0} slice(%mul.3024), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3057 = bf16[16,1,64]{2,1,0} reshape(%slice.3031), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3064 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3057), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3065 = bf16[16,64]{1,0} reshape(%mul.3064), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3066 = bf16[16,4,64]{2,1,0} broadcast(%mul.3065), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3067 = bf16[16,4,64]{2,1,0} multiply(%slice.3059, %mul.3066), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.3068 = bf16[16,4,64]{2,1,0} subtract(%mul.3063, %mul.3067), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.3069 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3056), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3070 = bf16[16,64]{1,0} reshape(%mul.3069), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3071 = bf16[16,4,64]{2,1,0} broadcast(%mul.3070), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3072 = bf16[16,4,64]{2,1,0} multiply(%slice.3059, %mul.3071), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3073 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3057), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3074 = bf16[16,64]{1,0} reshape(%mul.3073), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3075 = bf16[16,4,64]{2,1,0} broadcast(%mul.3074), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3076 = bf16[16,4,64]{2,1,0} multiply(%slice.3058, %mul.3075), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.3077 = bf16[16,4,64]{2,1,0} add(%mul.3072, %mul.3076), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.3078 = bf16[16,4,128]{2,1,0} concatenate(%sub.3068, %add.3077), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.3079 = bf16[16,512]{1,0} reshape(%concatenate.3078), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.2980 = bf16[16,4,128]{2,1,0} slice(%reshape.2977), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.2981 = bf16[16,512]{1,0} reshape(%slice.2980), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.3080 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_10_.446, %reshape.3055, %reshape.3079, %reshape.2981, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.3081 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.3080), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_11_.447 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(446), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[11]"}
  %jit__jax_attn_func_.3082 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.3080), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_10_self_attn_o_proj_weight__.27 = bf16[2048,4096]{1,0} parameter(26), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.10.self_attn.o_proj.weight\']"}
  %dot_general.3083 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.3082, %params_and_buffers__vllm_model_language_model_model_layers_10_self_attn_o_proj_weight__.27), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.3084 = f32[16,2048]{1,0} convert(%dot_general.3083), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2955 = bf16[16,2048]{1,0} convert(%add.2954), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3085 = f32[16,2048]{1,0} convert(%convert_element_type.2955), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.3086 = f32[16,2048]{1,0} add(%convert_element_type.3084, %convert_element_type.3085), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.3088 = f32[16,2048]{1,0} power(%add.3086, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3093 = f32[16]{0} reduce(%pow.3088, %constant.512), dimensions={1}, to_apply=%region_73.3092, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3094 = f32[16,1]{1,0} reshape(%reduce_sum.3093), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3095 = f32[16,1]{1,0} divide(%broadcast_in_dim.3094, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3096 = f32[16,1]{1,0} add(%div.3095, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3097 = f32[16,1]{1,0} rsqrt(%add.3096), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3098 = f32[16,1]{1,0} broadcast(%rsqrt.3097), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3099 = f32[16]{0} reshape(%mul.3098), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3100 = f32[16,2048]{1,0} broadcast(%mul.3099), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3101 = f32[16,2048]{1,0} multiply(%add.3086, %mul.3100), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3102 = bf16[16,2048]{1,0} convert(%mul.3101), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_10_post_attention_layernorm_weight__.25 = bf16[2048]{0} parameter(24), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.10.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.3103 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_10_post_attention_layernorm_weight__.25), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3104 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.3103), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3105 = bf16[2048]{0} reshape(%mul.3104), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3106 = bf16[16,2048]{1,0} broadcast(%mul.3105), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3107 = bf16[16,2048]{1,0} multiply(%convert_element_type.3102, %mul.3106), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_10_mlp_experts_w13_weight__.22 = bf16[128,1536,2048]{2,1,0} parameter(21), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.10.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_10_mlp_experts_w2_weight__.23 = bf16[128,2048,768]{2,1,0} parameter(22), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.10.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_10_mlp_gate_weight__.24 = bf16[128,2048]{1,0} parameter(23), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.10.mlp.gate.weight\']"}
  %dot_general.3108 = bf16[16,128]{1,0} dot(%mul.3107, %params_and_buffers__vllm_model_language_model_model_layers_10_mlp_gate_weight__.24), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.3109 = bf16[16,2048]{1,0} call(%mul.3107, %params_and_buffers__vllm_model_language_model_model_layers_10_mlp_experts_w13_weight__.22, %params_and_buffers__vllm_model_language_model_model_layers_10_mlp_experts_w2_weight__.23, %dot_general.3108), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.3110 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.3109), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3087 = bf16[16,2048]{1,0} convert(%add.3086), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3111 = f32[16,2048]{1,0} convert(%convert_element_type.3087), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.3112 = f32[16,2048]{1,0} add(%convert_element_type.3110, %convert_element_type.3111), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.3114 = f32[16,2048]{1,0} power(%add.3112, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3119 = f32[16]{0} reduce(%pow.3114, %constant.512), dimensions={1}, to_apply=%region_74.3118, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3120 = f32[16,1]{1,0} reshape(%reduce_sum.3119), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3121 = f32[16,1]{1,0} divide(%broadcast_in_dim.3120, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3122 = f32[16,1]{1,0} add(%div.3121, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3123 = f32[16,1]{1,0} rsqrt(%add.3122), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3124 = f32[16,1]{1,0} broadcast(%rsqrt.3123), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3125 = f32[16]{0} reshape(%mul.3124), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3126 = f32[16,2048]{1,0} broadcast(%mul.3125), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3127 = f32[16,2048]{1,0} multiply(%add.3112, %mul.3126), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3128 = bf16[16,2048]{1,0} convert(%mul.3127), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_11_input_layernorm_weight__.30 = bf16[2048]{0} parameter(29), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.11.input_layernorm.weight\']"}
  %broadcast_in_dim.3129 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_11_input_layernorm_weight__.30), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3130 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.3129), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3131 = bf16[2048]{0} reshape(%mul.3130), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3132 = bf16[16,2048]{1,0} broadcast(%mul.3131), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3133 = bf16[16,2048]{1,0} multiply(%convert_element_type.3128, %mul.3132), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_11_self_attn_qkv_proj_weight__.38 = bf16[5120,2048]{1,0} parameter(37), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.11.self_attn.qkv_proj.weight\']"}
  %dot_general.3134 = bf16[16,5120]{1,0} dot(%mul.3133, %params_and_buffers__vllm_model_language_model_model_layers_11_self_attn_qkv_proj_weight__.38), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.3135 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.3134), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.3136 = bf16[16,4,1024]{2,1,0} slice(%reshape.3135), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.3140 = bf16[16,32,128]{2,1,0} reshape(%slice.3136), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.3141 = f32[16,32,128]{2,1,0} convert(%reshape.3140), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.3142 = f32[16,32,128]{2,1,0} power(%convert_element_type.3141, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3147 = f32[16,32]{1,0} reduce(%pow.3142, %constant.512), dimensions={2}, to_apply=%region_75.3146, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3148 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.3147), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3149 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.3148, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3150 = f32[16,32,1]{2,1,0} add(%div.3149, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3151 = f32[16,32,1]{2,1,0} rsqrt(%add.3150), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3152 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.3151), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3153 = f32[16,32]{1,0} reshape(%mul.3152), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3154 = f32[16,32,128]{2,1,0} broadcast(%mul.3153), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3155 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.3141, %mul.3154), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3156 = bf16[16,32,128]{2,1,0} convert(%mul.3155), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_11_self_attn_q_norm_weight__.37 = bf16[128]{0} parameter(36), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.11.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.3157 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_11_self_attn_q_norm_weight__.37), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3158 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.3157), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3159 = bf16[128]{0} reshape(%mul.3158), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3160 = bf16[16,32,128]{2,1,0} broadcast(%mul.3159), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3161 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.3156, %mul.3160), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3192 = bf16[16,32,64]{2,1,0} slice(%mul.3161), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.3183 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.3184 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.3185 = s32[16]{0} select(%lt.3183, %add.3184, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.3186 = s32[16,1]{1,0} reshape(%select_n.3185), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.3187 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.3186), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.3188 = bf16[16,64]{1,0} slice(%gather.3187), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3190 = bf16[16,1,64]{2,1,0} reshape(%slice.3188), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3194 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3190), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3195 = bf16[16,64]{1,0} reshape(%mul.3194), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3196 = bf16[16,32,64]{2,1,0} broadcast(%mul.3195), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3197 = bf16[16,32,64]{2,1,0} multiply(%slice.3192, %mul.3196), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3193 = bf16[16,32,64]{2,1,0} slice(%mul.3161), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.3189 = bf16[16,64]{1,0} slice(%gather.3187), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3191 = bf16[16,1,64]{2,1,0} reshape(%slice.3189), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3198 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3191), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3199 = bf16[16,64]{1,0} reshape(%mul.3198), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3200 = bf16[16,32,64]{2,1,0} broadcast(%mul.3199), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3201 = bf16[16,32,64]{2,1,0} multiply(%slice.3193, %mul.3200), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.3202 = bf16[16,32,64]{2,1,0} subtract(%mul.3197, %mul.3201), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.3203 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3190), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3204 = bf16[16,64]{1,0} reshape(%mul.3203), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3205 = bf16[16,32,64]{2,1,0} broadcast(%mul.3204), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3206 = bf16[16,32,64]{2,1,0} multiply(%slice.3193, %mul.3205), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3207 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3191), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3208 = bf16[16,64]{1,0} reshape(%mul.3207), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3209 = bf16[16,32,64]{2,1,0} broadcast(%mul.3208), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3210 = bf16[16,32,64]{2,1,0} multiply(%slice.3192, %mul.3209), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.3211 = bf16[16,32,64]{2,1,0} add(%mul.3206, %mul.3210), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.3212 = bf16[16,32,128]{2,1,0} concatenate(%sub.3202, %add.3211), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.3213 = bf16[16,4096]{1,0} reshape(%concatenate.3212), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.3137 = bf16[16,4,128]{2,1,0} slice(%reshape.3135), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.3162 = f32[16,4,128]{2,1,0} convert(%slice.3137), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.3163 = f32[16,4,128]{2,1,0} power(%convert_element_type.3162, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3168 = f32[16,4]{1,0} reduce(%pow.3163, %constant.512), dimensions={2}, to_apply=%region_76.3167, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3169 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.3168), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3170 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.3169, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3171 = f32[16,4,1]{2,1,0} add(%div.3170, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3172 = f32[16,4,1]{2,1,0} rsqrt(%add.3171), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3173 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.3172), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3174 = f32[16,4]{1,0} reshape(%mul.3173), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3175 = f32[16,4,128]{2,1,0} broadcast(%mul.3174), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3176 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.3162, %mul.3175), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3177 = bf16[16,4,128]{2,1,0} convert(%mul.3176), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_11_self_attn_k_norm_weight__.35 = bf16[128]{0} parameter(34), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.11.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.3178 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_11_self_attn_k_norm_weight__.35), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3179 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.3178), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3180 = bf16[128]{0} reshape(%mul.3179), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3181 = bf16[16,4,128]{2,1,0} broadcast(%mul.3180), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3182 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.3177, %mul.3181), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3216 = bf16[16,4,64]{2,1,0} slice(%mul.3182), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3214 = bf16[16,1,64]{2,1,0} reshape(%slice.3188), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3218 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3214), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3219 = bf16[16,64]{1,0} reshape(%mul.3218), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3220 = bf16[16,4,64]{2,1,0} broadcast(%mul.3219), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3221 = bf16[16,4,64]{2,1,0} multiply(%slice.3216, %mul.3220), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3217 = bf16[16,4,64]{2,1,0} slice(%mul.3182), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3215 = bf16[16,1,64]{2,1,0} reshape(%slice.3189), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3222 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3215), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3223 = bf16[16,64]{1,0} reshape(%mul.3222), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3224 = bf16[16,4,64]{2,1,0} broadcast(%mul.3223), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3225 = bf16[16,4,64]{2,1,0} multiply(%slice.3217, %mul.3224), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.3226 = bf16[16,4,64]{2,1,0} subtract(%mul.3221, %mul.3225), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.3227 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3214), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3228 = bf16[16,64]{1,0} reshape(%mul.3227), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3229 = bf16[16,4,64]{2,1,0} broadcast(%mul.3228), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3230 = bf16[16,4,64]{2,1,0} multiply(%slice.3217, %mul.3229), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3231 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3215), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3232 = bf16[16,64]{1,0} reshape(%mul.3231), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3233 = bf16[16,4,64]{2,1,0} broadcast(%mul.3232), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3234 = bf16[16,4,64]{2,1,0} multiply(%slice.3216, %mul.3233), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.3235 = bf16[16,4,64]{2,1,0} add(%mul.3230, %mul.3234), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.3236 = bf16[16,4,128]{2,1,0} concatenate(%sub.3226, %add.3235), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.3237 = bf16[16,512]{1,0} reshape(%concatenate.3236), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.3138 = bf16[16,4,128]{2,1,0} slice(%reshape.3135), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.3139 = bf16[16,512]{1,0} reshape(%slice.3138), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.3238 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_11_.447, %reshape.3213, %reshape.3237, %reshape.3139, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.3239 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.3238), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_12_.448 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(447), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[12]"}
  %jit__jax_attn_func_.3240 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.3238), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_11_self_attn_o_proj_weight__.36 = bf16[2048,4096]{1,0} parameter(35), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.11.self_attn.o_proj.weight\']"}
  %dot_general.3241 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.3240, %params_and_buffers__vllm_model_language_model_model_layers_11_self_attn_o_proj_weight__.36), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.3242 = f32[16,2048]{1,0} convert(%dot_general.3241), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3113 = bf16[16,2048]{1,0} convert(%add.3112), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3243 = f32[16,2048]{1,0} convert(%convert_element_type.3113), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.3244 = f32[16,2048]{1,0} add(%convert_element_type.3242, %convert_element_type.3243), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.3246 = f32[16,2048]{1,0} power(%add.3244, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3251 = f32[16]{0} reduce(%pow.3246, %constant.512), dimensions={1}, to_apply=%region_77.3250, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3252 = f32[16,1]{1,0} reshape(%reduce_sum.3251), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3253 = f32[16,1]{1,0} divide(%broadcast_in_dim.3252, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3254 = f32[16,1]{1,0} add(%div.3253, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3255 = f32[16,1]{1,0} rsqrt(%add.3254), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3256 = f32[16,1]{1,0} broadcast(%rsqrt.3255), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3257 = f32[16]{0} reshape(%mul.3256), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3258 = f32[16,2048]{1,0} broadcast(%mul.3257), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3259 = f32[16,2048]{1,0} multiply(%add.3244, %mul.3258), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3260 = bf16[16,2048]{1,0} convert(%mul.3259), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_11_post_attention_layernorm_weight__.34 = bf16[2048]{0} parameter(33), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.11.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.3261 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_11_post_attention_layernorm_weight__.34), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3262 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.3261), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3263 = bf16[2048]{0} reshape(%mul.3262), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3264 = bf16[16,2048]{1,0} broadcast(%mul.3263), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3265 = bf16[16,2048]{1,0} multiply(%convert_element_type.3260, %mul.3264), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_11_mlp_experts_w13_weight__.31 = bf16[128,1536,2048]{2,1,0} parameter(30), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.11.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_11_mlp_experts_w2_weight__.32 = bf16[128,2048,768]{2,1,0} parameter(31), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.11.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_11_mlp_gate_weight__.33 = bf16[128,2048]{1,0} parameter(32), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.11.mlp.gate.weight\']"}
  %dot_general.3266 = bf16[16,128]{1,0} dot(%mul.3265, %params_and_buffers__vllm_model_language_model_model_layers_11_mlp_gate_weight__.33), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.3267 = bf16[16,2048]{1,0} call(%mul.3265, %params_and_buffers__vllm_model_language_model_model_layers_11_mlp_experts_w13_weight__.31, %params_and_buffers__vllm_model_language_model_model_layers_11_mlp_experts_w2_weight__.32, %dot_general.3266), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.3268 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.3267), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3245 = bf16[16,2048]{1,0} convert(%add.3244), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3269 = f32[16,2048]{1,0} convert(%convert_element_type.3245), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.3270 = f32[16,2048]{1,0} add(%convert_element_type.3268, %convert_element_type.3269), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.3272 = f32[16,2048]{1,0} power(%add.3270, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3277 = f32[16]{0} reduce(%pow.3272, %constant.512), dimensions={1}, to_apply=%region_78.3276, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3278 = f32[16,1]{1,0} reshape(%reduce_sum.3277), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3279 = f32[16,1]{1,0} divide(%broadcast_in_dim.3278, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3280 = f32[16,1]{1,0} add(%div.3279, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3281 = f32[16,1]{1,0} rsqrt(%add.3280), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3282 = f32[16,1]{1,0} broadcast(%rsqrt.3281), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3283 = f32[16]{0} reshape(%mul.3282), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3284 = f32[16,2048]{1,0} broadcast(%mul.3283), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3285 = f32[16,2048]{1,0} multiply(%add.3270, %mul.3284), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3286 = bf16[16,2048]{1,0} convert(%mul.3285), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_12_input_layernorm_weight__.39 = bf16[2048]{0} parameter(38), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.12.input_layernorm.weight\']"}
  %broadcast_in_dim.3287 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_12_input_layernorm_weight__.39), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3288 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.3287), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3289 = bf16[2048]{0} reshape(%mul.3288), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3290 = bf16[16,2048]{1,0} broadcast(%mul.3289), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3291 = bf16[16,2048]{1,0} multiply(%convert_element_type.3286, %mul.3290), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_12_self_attn_qkv_proj_weight__.47 = bf16[5120,2048]{1,0} parameter(46), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.12.self_attn.qkv_proj.weight\']"}
  %dot_general.3292 = bf16[16,5120]{1,0} dot(%mul.3291, %params_and_buffers__vllm_model_language_model_model_layers_12_self_attn_qkv_proj_weight__.47), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.3293 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.3292), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.3294 = bf16[16,4,1024]{2,1,0} slice(%reshape.3293), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.3298 = bf16[16,32,128]{2,1,0} reshape(%slice.3294), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.3299 = f32[16,32,128]{2,1,0} convert(%reshape.3298), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.3300 = f32[16,32,128]{2,1,0} power(%convert_element_type.3299, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3305 = f32[16,32]{1,0} reduce(%pow.3300, %constant.512), dimensions={2}, to_apply=%region_79.3304, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3306 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.3305), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3307 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.3306, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3308 = f32[16,32,1]{2,1,0} add(%div.3307, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3309 = f32[16,32,1]{2,1,0} rsqrt(%add.3308), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3310 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.3309), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3311 = f32[16,32]{1,0} reshape(%mul.3310), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3312 = f32[16,32,128]{2,1,0} broadcast(%mul.3311), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3313 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.3299, %mul.3312), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3314 = bf16[16,32,128]{2,1,0} convert(%mul.3313), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_12_self_attn_q_norm_weight__.46 = bf16[128]{0} parameter(45), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.12.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.3315 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_12_self_attn_q_norm_weight__.46), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3316 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.3315), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3317 = bf16[128]{0} reshape(%mul.3316), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3318 = bf16[16,32,128]{2,1,0} broadcast(%mul.3317), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3319 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.3314, %mul.3318), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3350 = bf16[16,32,64]{2,1,0} slice(%mul.3319), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.3341 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.3342 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.3343 = s32[16]{0} select(%lt.3341, %add.3342, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.3344 = s32[16,1]{1,0} reshape(%select_n.3343), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.3345 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.3344), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.3346 = bf16[16,64]{1,0} slice(%gather.3345), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3348 = bf16[16,1,64]{2,1,0} reshape(%slice.3346), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3352 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3348), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3353 = bf16[16,64]{1,0} reshape(%mul.3352), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3354 = bf16[16,32,64]{2,1,0} broadcast(%mul.3353), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3355 = bf16[16,32,64]{2,1,0} multiply(%slice.3350, %mul.3354), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3351 = bf16[16,32,64]{2,1,0} slice(%mul.3319), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.3347 = bf16[16,64]{1,0} slice(%gather.3345), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3349 = bf16[16,1,64]{2,1,0} reshape(%slice.3347), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3356 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3349), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3357 = bf16[16,64]{1,0} reshape(%mul.3356), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3358 = bf16[16,32,64]{2,1,0} broadcast(%mul.3357), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3359 = bf16[16,32,64]{2,1,0} multiply(%slice.3351, %mul.3358), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.3360 = bf16[16,32,64]{2,1,0} subtract(%mul.3355, %mul.3359), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.3361 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3348), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3362 = bf16[16,64]{1,0} reshape(%mul.3361), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3363 = bf16[16,32,64]{2,1,0} broadcast(%mul.3362), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3364 = bf16[16,32,64]{2,1,0} multiply(%slice.3351, %mul.3363), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3365 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3349), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3366 = bf16[16,64]{1,0} reshape(%mul.3365), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3367 = bf16[16,32,64]{2,1,0} broadcast(%mul.3366), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3368 = bf16[16,32,64]{2,1,0} multiply(%slice.3350, %mul.3367), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.3369 = bf16[16,32,64]{2,1,0} add(%mul.3364, %mul.3368), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.3370 = bf16[16,32,128]{2,1,0} concatenate(%sub.3360, %add.3369), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.3371 = bf16[16,4096]{1,0} reshape(%concatenate.3370), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.3295 = bf16[16,4,128]{2,1,0} slice(%reshape.3293), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.3320 = f32[16,4,128]{2,1,0} convert(%slice.3295), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.3321 = f32[16,4,128]{2,1,0} power(%convert_element_type.3320, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3326 = f32[16,4]{1,0} reduce(%pow.3321, %constant.512), dimensions={2}, to_apply=%region_80.3325, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3327 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.3326), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3328 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.3327, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3329 = f32[16,4,1]{2,1,0} add(%div.3328, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3330 = f32[16,4,1]{2,1,0} rsqrt(%add.3329), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3331 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.3330), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3332 = f32[16,4]{1,0} reshape(%mul.3331), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3333 = f32[16,4,128]{2,1,0} broadcast(%mul.3332), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3334 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.3320, %mul.3333), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3335 = bf16[16,4,128]{2,1,0} convert(%mul.3334), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_12_self_attn_k_norm_weight__.44 = bf16[128]{0} parameter(43), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.12.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.3336 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_12_self_attn_k_norm_weight__.44), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3337 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.3336), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3338 = bf16[128]{0} reshape(%mul.3337), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3339 = bf16[16,4,128]{2,1,0} broadcast(%mul.3338), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3340 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.3335, %mul.3339), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3374 = bf16[16,4,64]{2,1,0} slice(%mul.3340), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3372 = bf16[16,1,64]{2,1,0} reshape(%slice.3346), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3376 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3372), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3377 = bf16[16,64]{1,0} reshape(%mul.3376), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3378 = bf16[16,4,64]{2,1,0} broadcast(%mul.3377), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3379 = bf16[16,4,64]{2,1,0} multiply(%slice.3374, %mul.3378), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3375 = bf16[16,4,64]{2,1,0} slice(%mul.3340), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3373 = bf16[16,1,64]{2,1,0} reshape(%slice.3347), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3380 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3373), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3381 = bf16[16,64]{1,0} reshape(%mul.3380), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3382 = bf16[16,4,64]{2,1,0} broadcast(%mul.3381), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3383 = bf16[16,4,64]{2,1,0} multiply(%slice.3375, %mul.3382), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.3384 = bf16[16,4,64]{2,1,0} subtract(%mul.3379, %mul.3383), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.3385 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3372), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3386 = bf16[16,64]{1,0} reshape(%mul.3385), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3387 = bf16[16,4,64]{2,1,0} broadcast(%mul.3386), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3388 = bf16[16,4,64]{2,1,0} multiply(%slice.3375, %mul.3387), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3389 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3373), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3390 = bf16[16,64]{1,0} reshape(%mul.3389), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3391 = bf16[16,4,64]{2,1,0} broadcast(%mul.3390), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3392 = bf16[16,4,64]{2,1,0} multiply(%slice.3374, %mul.3391), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.3393 = bf16[16,4,64]{2,1,0} add(%mul.3388, %mul.3392), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.3394 = bf16[16,4,128]{2,1,0} concatenate(%sub.3384, %add.3393), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.3395 = bf16[16,512]{1,0} reshape(%concatenate.3394), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.3296 = bf16[16,4,128]{2,1,0} slice(%reshape.3293), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.3297 = bf16[16,512]{1,0} reshape(%slice.3296), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.3396 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_12_.448, %reshape.3371, %reshape.3395, %reshape.3297, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.3397 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.3396), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_13_.449 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(448), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[13]"}
  %jit__jax_attn_func_.3398 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.3396), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_12_self_attn_o_proj_weight__.45 = bf16[2048,4096]{1,0} parameter(44), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.12.self_attn.o_proj.weight\']"}
  %dot_general.3399 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.3398, %params_and_buffers__vllm_model_language_model_model_layers_12_self_attn_o_proj_weight__.45), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.3400 = f32[16,2048]{1,0} convert(%dot_general.3399), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3271 = bf16[16,2048]{1,0} convert(%add.3270), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3401 = f32[16,2048]{1,0} convert(%convert_element_type.3271), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.3402 = f32[16,2048]{1,0} add(%convert_element_type.3400, %convert_element_type.3401), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.3404 = f32[16,2048]{1,0} power(%add.3402, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3409 = f32[16]{0} reduce(%pow.3404, %constant.512), dimensions={1}, to_apply=%region_81.3408, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3410 = f32[16,1]{1,0} reshape(%reduce_sum.3409), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3411 = f32[16,1]{1,0} divide(%broadcast_in_dim.3410, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3412 = f32[16,1]{1,0} add(%div.3411, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3413 = f32[16,1]{1,0} rsqrt(%add.3412), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3414 = f32[16,1]{1,0} broadcast(%rsqrt.3413), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3415 = f32[16]{0} reshape(%mul.3414), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3416 = f32[16,2048]{1,0} broadcast(%mul.3415), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3417 = f32[16,2048]{1,0} multiply(%add.3402, %mul.3416), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3418 = bf16[16,2048]{1,0} convert(%mul.3417), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_12_post_attention_layernorm_weight__.43 = bf16[2048]{0} parameter(42), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.12.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.3419 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_12_post_attention_layernorm_weight__.43), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3420 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.3419), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3421 = bf16[2048]{0} reshape(%mul.3420), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3422 = bf16[16,2048]{1,0} broadcast(%mul.3421), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3423 = bf16[16,2048]{1,0} multiply(%convert_element_type.3418, %mul.3422), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_12_mlp_experts_w13_weight__.40 = bf16[128,1536,2048]{2,1,0} parameter(39), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.12.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_12_mlp_experts_w2_weight__.41 = bf16[128,2048,768]{2,1,0} parameter(40), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.12.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_12_mlp_gate_weight__.42 = bf16[128,2048]{1,0} parameter(41), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.12.mlp.gate.weight\']"}
  %dot_general.3424 = bf16[16,128]{1,0} dot(%mul.3423, %params_and_buffers__vllm_model_language_model_model_layers_12_mlp_gate_weight__.42), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.3425 = bf16[16,2048]{1,0} call(%mul.3423, %params_and_buffers__vllm_model_language_model_model_layers_12_mlp_experts_w13_weight__.40, %params_and_buffers__vllm_model_language_model_model_layers_12_mlp_experts_w2_weight__.41, %dot_general.3424), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.3426 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.3425), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3403 = bf16[16,2048]{1,0} convert(%add.3402), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3427 = f32[16,2048]{1,0} convert(%convert_element_type.3403), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.3428 = f32[16,2048]{1,0} add(%convert_element_type.3426, %convert_element_type.3427), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.3430 = f32[16,2048]{1,0} power(%add.3428, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3435 = f32[16]{0} reduce(%pow.3430, %constant.512), dimensions={1}, to_apply=%region_82.3434, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3436 = f32[16,1]{1,0} reshape(%reduce_sum.3435), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3437 = f32[16,1]{1,0} divide(%broadcast_in_dim.3436, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3438 = f32[16,1]{1,0} add(%div.3437, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3439 = f32[16,1]{1,0} rsqrt(%add.3438), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3440 = f32[16,1]{1,0} broadcast(%rsqrt.3439), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3441 = f32[16]{0} reshape(%mul.3440), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3442 = f32[16,2048]{1,0} broadcast(%mul.3441), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3443 = f32[16,2048]{1,0} multiply(%add.3428, %mul.3442), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3444 = bf16[16,2048]{1,0} convert(%mul.3443), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_13_input_layernorm_weight__.48 = bf16[2048]{0} parameter(47), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.13.input_layernorm.weight\']"}
  %broadcast_in_dim.3445 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_13_input_layernorm_weight__.48), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3446 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.3445), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3447 = bf16[2048]{0} reshape(%mul.3446), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3448 = bf16[16,2048]{1,0} broadcast(%mul.3447), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3449 = bf16[16,2048]{1,0} multiply(%convert_element_type.3444, %mul.3448), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_13_self_attn_qkv_proj_weight__.56 = bf16[5120,2048]{1,0} parameter(55), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.13.self_attn.qkv_proj.weight\']"}
  %dot_general.3450 = bf16[16,5120]{1,0} dot(%mul.3449, %params_and_buffers__vllm_model_language_model_model_layers_13_self_attn_qkv_proj_weight__.56), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.3451 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.3450), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.3452 = bf16[16,4,1024]{2,1,0} slice(%reshape.3451), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.3456 = bf16[16,32,128]{2,1,0} reshape(%slice.3452), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.3457 = f32[16,32,128]{2,1,0} convert(%reshape.3456), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.3458 = f32[16,32,128]{2,1,0} power(%convert_element_type.3457, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3463 = f32[16,32]{1,0} reduce(%pow.3458, %constant.512), dimensions={2}, to_apply=%region_83.3462, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3464 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.3463), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3465 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.3464, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3466 = f32[16,32,1]{2,1,0} add(%div.3465, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3467 = f32[16,32,1]{2,1,0} rsqrt(%add.3466), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3468 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.3467), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3469 = f32[16,32]{1,0} reshape(%mul.3468), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3470 = f32[16,32,128]{2,1,0} broadcast(%mul.3469), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3471 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.3457, %mul.3470), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3472 = bf16[16,32,128]{2,1,0} convert(%mul.3471), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_13_self_attn_q_norm_weight__.55 = bf16[128]{0} parameter(54), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.13.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.3473 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_13_self_attn_q_norm_weight__.55), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3474 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.3473), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3475 = bf16[128]{0} reshape(%mul.3474), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3476 = bf16[16,32,128]{2,1,0} broadcast(%mul.3475), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3477 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.3472, %mul.3476), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3508 = bf16[16,32,64]{2,1,0} slice(%mul.3477), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.3499 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.3500 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.3501 = s32[16]{0} select(%lt.3499, %add.3500, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.3502 = s32[16,1]{1,0} reshape(%select_n.3501), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.3503 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.3502), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.3504 = bf16[16,64]{1,0} slice(%gather.3503), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3506 = bf16[16,1,64]{2,1,0} reshape(%slice.3504), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3510 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3506), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3511 = bf16[16,64]{1,0} reshape(%mul.3510), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3512 = bf16[16,32,64]{2,1,0} broadcast(%mul.3511), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3513 = bf16[16,32,64]{2,1,0} multiply(%slice.3508, %mul.3512), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3509 = bf16[16,32,64]{2,1,0} slice(%mul.3477), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.3505 = bf16[16,64]{1,0} slice(%gather.3503), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3507 = bf16[16,1,64]{2,1,0} reshape(%slice.3505), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3514 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3507), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3515 = bf16[16,64]{1,0} reshape(%mul.3514), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3516 = bf16[16,32,64]{2,1,0} broadcast(%mul.3515), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3517 = bf16[16,32,64]{2,1,0} multiply(%slice.3509, %mul.3516), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.3518 = bf16[16,32,64]{2,1,0} subtract(%mul.3513, %mul.3517), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.3519 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3506), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3520 = bf16[16,64]{1,0} reshape(%mul.3519), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3521 = bf16[16,32,64]{2,1,0} broadcast(%mul.3520), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3522 = bf16[16,32,64]{2,1,0} multiply(%slice.3509, %mul.3521), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3523 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3507), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3524 = bf16[16,64]{1,0} reshape(%mul.3523), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3525 = bf16[16,32,64]{2,1,0} broadcast(%mul.3524), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3526 = bf16[16,32,64]{2,1,0} multiply(%slice.3508, %mul.3525), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.3527 = bf16[16,32,64]{2,1,0} add(%mul.3522, %mul.3526), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.3528 = bf16[16,32,128]{2,1,0} concatenate(%sub.3518, %add.3527), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.3529 = bf16[16,4096]{1,0} reshape(%concatenate.3528), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.3453 = bf16[16,4,128]{2,1,0} slice(%reshape.3451), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.3478 = f32[16,4,128]{2,1,0} convert(%slice.3453), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.3479 = f32[16,4,128]{2,1,0} power(%convert_element_type.3478, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3484 = f32[16,4]{1,0} reduce(%pow.3479, %constant.512), dimensions={2}, to_apply=%region_84.3483, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3485 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.3484), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3486 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.3485, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3487 = f32[16,4,1]{2,1,0} add(%div.3486, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3488 = f32[16,4,1]{2,1,0} rsqrt(%add.3487), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3489 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.3488), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3490 = f32[16,4]{1,0} reshape(%mul.3489), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3491 = f32[16,4,128]{2,1,0} broadcast(%mul.3490), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3492 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.3478, %mul.3491), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3493 = bf16[16,4,128]{2,1,0} convert(%mul.3492), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_13_self_attn_k_norm_weight__.53 = bf16[128]{0} parameter(52), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.13.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.3494 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_13_self_attn_k_norm_weight__.53), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3495 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.3494), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3496 = bf16[128]{0} reshape(%mul.3495), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3497 = bf16[16,4,128]{2,1,0} broadcast(%mul.3496), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3498 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.3493, %mul.3497), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3532 = bf16[16,4,64]{2,1,0} slice(%mul.3498), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3530 = bf16[16,1,64]{2,1,0} reshape(%slice.3504), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3534 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3530), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3535 = bf16[16,64]{1,0} reshape(%mul.3534), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3536 = bf16[16,4,64]{2,1,0} broadcast(%mul.3535), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3537 = bf16[16,4,64]{2,1,0} multiply(%slice.3532, %mul.3536), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3533 = bf16[16,4,64]{2,1,0} slice(%mul.3498), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3531 = bf16[16,1,64]{2,1,0} reshape(%slice.3505), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3538 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3531), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3539 = bf16[16,64]{1,0} reshape(%mul.3538), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3540 = bf16[16,4,64]{2,1,0} broadcast(%mul.3539), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3541 = bf16[16,4,64]{2,1,0} multiply(%slice.3533, %mul.3540), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.3542 = bf16[16,4,64]{2,1,0} subtract(%mul.3537, %mul.3541), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.3543 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3530), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3544 = bf16[16,64]{1,0} reshape(%mul.3543), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3545 = bf16[16,4,64]{2,1,0} broadcast(%mul.3544), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3546 = bf16[16,4,64]{2,1,0} multiply(%slice.3533, %mul.3545), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3547 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3531), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3548 = bf16[16,64]{1,0} reshape(%mul.3547), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3549 = bf16[16,4,64]{2,1,0} broadcast(%mul.3548), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3550 = bf16[16,4,64]{2,1,0} multiply(%slice.3532, %mul.3549), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.3551 = bf16[16,4,64]{2,1,0} add(%mul.3546, %mul.3550), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.3552 = bf16[16,4,128]{2,1,0} concatenate(%sub.3542, %add.3551), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.3553 = bf16[16,512]{1,0} reshape(%concatenate.3552), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.3454 = bf16[16,4,128]{2,1,0} slice(%reshape.3451), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.3455 = bf16[16,512]{1,0} reshape(%slice.3454), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.3554 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_13_.449, %reshape.3529, %reshape.3553, %reshape.3455, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.3555 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.3554), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_14_.450 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(449), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[14]"}
  %jit__jax_attn_func_.3556 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.3554), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_13_self_attn_o_proj_weight__.54 = bf16[2048,4096]{1,0} parameter(53), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.13.self_attn.o_proj.weight\']"}
  %dot_general.3557 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.3556, %params_and_buffers__vllm_model_language_model_model_layers_13_self_attn_o_proj_weight__.54), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.3558 = f32[16,2048]{1,0} convert(%dot_general.3557), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3429 = bf16[16,2048]{1,0} convert(%add.3428), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3559 = f32[16,2048]{1,0} convert(%convert_element_type.3429), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.3560 = f32[16,2048]{1,0} add(%convert_element_type.3558, %convert_element_type.3559), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.3562 = f32[16,2048]{1,0} power(%add.3560, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3567 = f32[16]{0} reduce(%pow.3562, %constant.512), dimensions={1}, to_apply=%region_85.3566, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3568 = f32[16,1]{1,0} reshape(%reduce_sum.3567), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3569 = f32[16,1]{1,0} divide(%broadcast_in_dim.3568, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3570 = f32[16,1]{1,0} add(%div.3569, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3571 = f32[16,1]{1,0} rsqrt(%add.3570), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3572 = f32[16,1]{1,0} broadcast(%rsqrt.3571), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3573 = f32[16]{0} reshape(%mul.3572), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3574 = f32[16,2048]{1,0} broadcast(%mul.3573), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3575 = f32[16,2048]{1,0} multiply(%add.3560, %mul.3574), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3576 = bf16[16,2048]{1,0} convert(%mul.3575), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_13_post_attention_layernorm_weight__.52 = bf16[2048]{0} parameter(51), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.13.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.3577 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_13_post_attention_layernorm_weight__.52), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3578 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.3577), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3579 = bf16[2048]{0} reshape(%mul.3578), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3580 = bf16[16,2048]{1,0} broadcast(%mul.3579), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3581 = bf16[16,2048]{1,0} multiply(%convert_element_type.3576, %mul.3580), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_13_mlp_experts_w13_weight__.49 = bf16[128,1536,2048]{2,1,0} parameter(48), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.13.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_13_mlp_experts_w2_weight__.50 = bf16[128,2048,768]{2,1,0} parameter(49), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.13.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_13_mlp_gate_weight__.51 = bf16[128,2048]{1,0} parameter(50), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.13.mlp.gate.weight\']"}
  %dot_general.3582 = bf16[16,128]{1,0} dot(%mul.3581, %params_and_buffers__vllm_model_language_model_model_layers_13_mlp_gate_weight__.51), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.3583 = bf16[16,2048]{1,0} call(%mul.3581, %params_and_buffers__vllm_model_language_model_model_layers_13_mlp_experts_w13_weight__.49, %params_and_buffers__vllm_model_language_model_model_layers_13_mlp_experts_w2_weight__.50, %dot_general.3582), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.3584 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.3583), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3561 = bf16[16,2048]{1,0} convert(%add.3560), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3585 = f32[16,2048]{1,0} convert(%convert_element_type.3561), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.3586 = f32[16,2048]{1,0} add(%convert_element_type.3584, %convert_element_type.3585), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.3588 = f32[16,2048]{1,0} power(%add.3586, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3593 = f32[16]{0} reduce(%pow.3588, %constant.512), dimensions={1}, to_apply=%region_86.3592, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3594 = f32[16,1]{1,0} reshape(%reduce_sum.3593), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3595 = f32[16,1]{1,0} divide(%broadcast_in_dim.3594, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3596 = f32[16,1]{1,0} add(%div.3595, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3597 = f32[16,1]{1,0} rsqrt(%add.3596), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3598 = f32[16,1]{1,0} broadcast(%rsqrt.3597), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3599 = f32[16]{0} reshape(%mul.3598), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3600 = f32[16,2048]{1,0} broadcast(%mul.3599), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3601 = f32[16,2048]{1,0} multiply(%add.3586, %mul.3600), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3602 = bf16[16,2048]{1,0} convert(%mul.3601), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_14_input_layernorm_weight__.57 = bf16[2048]{0} parameter(56), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.14.input_layernorm.weight\']"}
  %broadcast_in_dim.3603 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_14_input_layernorm_weight__.57), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3604 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.3603), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3605 = bf16[2048]{0} reshape(%mul.3604), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3606 = bf16[16,2048]{1,0} broadcast(%mul.3605), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3607 = bf16[16,2048]{1,0} multiply(%convert_element_type.3602, %mul.3606), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_14_self_attn_qkv_proj_weight__.65 = bf16[5120,2048]{1,0} parameter(64), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.14.self_attn.qkv_proj.weight\']"}
  %dot_general.3608 = bf16[16,5120]{1,0} dot(%mul.3607, %params_and_buffers__vllm_model_language_model_model_layers_14_self_attn_qkv_proj_weight__.65), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.3609 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.3608), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.3610 = bf16[16,4,1024]{2,1,0} slice(%reshape.3609), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.3614 = bf16[16,32,128]{2,1,0} reshape(%slice.3610), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.3615 = f32[16,32,128]{2,1,0} convert(%reshape.3614), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.3616 = f32[16,32,128]{2,1,0} power(%convert_element_type.3615, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3621 = f32[16,32]{1,0} reduce(%pow.3616, %constant.512), dimensions={2}, to_apply=%region_87.3620, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3622 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.3621), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3623 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.3622, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3624 = f32[16,32,1]{2,1,0} add(%div.3623, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3625 = f32[16,32,1]{2,1,0} rsqrt(%add.3624), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3626 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.3625), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3627 = f32[16,32]{1,0} reshape(%mul.3626), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3628 = f32[16,32,128]{2,1,0} broadcast(%mul.3627), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3629 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.3615, %mul.3628), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3630 = bf16[16,32,128]{2,1,0} convert(%mul.3629), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_14_self_attn_q_norm_weight__.64 = bf16[128]{0} parameter(63), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.14.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.3631 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_14_self_attn_q_norm_weight__.64), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3632 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.3631), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3633 = bf16[128]{0} reshape(%mul.3632), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3634 = bf16[16,32,128]{2,1,0} broadcast(%mul.3633), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3635 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.3630, %mul.3634), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3666 = bf16[16,32,64]{2,1,0} slice(%mul.3635), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.3657 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.3658 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.3659 = s32[16]{0} select(%lt.3657, %add.3658, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.3660 = s32[16,1]{1,0} reshape(%select_n.3659), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.3661 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.3660), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.3662 = bf16[16,64]{1,0} slice(%gather.3661), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3664 = bf16[16,1,64]{2,1,0} reshape(%slice.3662), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3668 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3664), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3669 = bf16[16,64]{1,0} reshape(%mul.3668), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3670 = bf16[16,32,64]{2,1,0} broadcast(%mul.3669), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3671 = bf16[16,32,64]{2,1,0} multiply(%slice.3666, %mul.3670), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3667 = bf16[16,32,64]{2,1,0} slice(%mul.3635), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.3663 = bf16[16,64]{1,0} slice(%gather.3661), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3665 = bf16[16,1,64]{2,1,0} reshape(%slice.3663), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3672 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3665), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3673 = bf16[16,64]{1,0} reshape(%mul.3672), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3674 = bf16[16,32,64]{2,1,0} broadcast(%mul.3673), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3675 = bf16[16,32,64]{2,1,0} multiply(%slice.3667, %mul.3674), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.3676 = bf16[16,32,64]{2,1,0} subtract(%mul.3671, %mul.3675), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.3677 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3664), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3678 = bf16[16,64]{1,0} reshape(%mul.3677), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3679 = bf16[16,32,64]{2,1,0} broadcast(%mul.3678), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3680 = bf16[16,32,64]{2,1,0} multiply(%slice.3667, %mul.3679), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3681 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3665), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3682 = bf16[16,64]{1,0} reshape(%mul.3681), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3683 = bf16[16,32,64]{2,1,0} broadcast(%mul.3682), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3684 = bf16[16,32,64]{2,1,0} multiply(%slice.3666, %mul.3683), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.3685 = bf16[16,32,64]{2,1,0} add(%mul.3680, %mul.3684), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.3686 = bf16[16,32,128]{2,1,0} concatenate(%sub.3676, %add.3685), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.3687 = bf16[16,4096]{1,0} reshape(%concatenate.3686), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.3611 = bf16[16,4,128]{2,1,0} slice(%reshape.3609), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.3636 = f32[16,4,128]{2,1,0} convert(%slice.3611), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.3637 = f32[16,4,128]{2,1,0} power(%convert_element_type.3636, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3642 = f32[16,4]{1,0} reduce(%pow.3637, %constant.512), dimensions={2}, to_apply=%region_88.3641, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3643 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.3642), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3644 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.3643, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3645 = f32[16,4,1]{2,1,0} add(%div.3644, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3646 = f32[16,4,1]{2,1,0} rsqrt(%add.3645), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3647 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.3646), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3648 = f32[16,4]{1,0} reshape(%mul.3647), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3649 = f32[16,4,128]{2,1,0} broadcast(%mul.3648), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3650 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.3636, %mul.3649), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3651 = bf16[16,4,128]{2,1,0} convert(%mul.3650), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_14_self_attn_k_norm_weight__.62 = bf16[128]{0} parameter(61), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.14.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.3652 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_14_self_attn_k_norm_weight__.62), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3653 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.3652), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3654 = bf16[128]{0} reshape(%mul.3653), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3655 = bf16[16,4,128]{2,1,0} broadcast(%mul.3654), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3656 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.3651, %mul.3655), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3690 = bf16[16,4,64]{2,1,0} slice(%mul.3656), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3688 = bf16[16,1,64]{2,1,0} reshape(%slice.3662), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3692 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3688), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3693 = bf16[16,64]{1,0} reshape(%mul.3692), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3694 = bf16[16,4,64]{2,1,0} broadcast(%mul.3693), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3695 = bf16[16,4,64]{2,1,0} multiply(%slice.3690, %mul.3694), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3691 = bf16[16,4,64]{2,1,0} slice(%mul.3656), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3689 = bf16[16,1,64]{2,1,0} reshape(%slice.3663), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3696 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3689), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3697 = bf16[16,64]{1,0} reshape(%mul.3696), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3698 = bf16[16,4,64]{2,1,0} broadcast(%mul.3697), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3699 = bf16[16,4,64]{2,1,0} multiply(%slice.3691, %mul.3698), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.3700 = bf16[16,4,64]{2,1,0} subtract(%mul.3695, %mul.3699), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.3701 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3688), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3702 = bf16[16,64]{1,0} reshape(%mul.3701), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3703 = bf16[16,4,64]{2,1,0} broadcast(%mul.3702), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3704 = bf16[16,4,64]{2,1,0} multiply(%slice.3691, %mul.3703), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3705 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3689), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3706 = bf16[16,64]{1,0} reshape(%mul.3705), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3707 = bf16[16,4,64]{2,1,0} broadcast(%mul.3706), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3708 = bf16[16,4,64]{2,1,0} multiply(%slice.3690, %mul.3707), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.3709 = bf16[16,4,64]{2,1,0} add(%mul.3704, %mul.3708), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.3710 = bf16[16,4,128]{2,1,0} concatenate(%sub.3700, %add.3709), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.3711 = bf16[16,512]{1,0} reshape(%concatenate.3710), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.3612 = bf16[16,4,128]{2,1,0} slice(%reshape.3609), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.3613 = bf16[16,512]{1,0} reshape(%slice.3612), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.3712 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_14_.450, %reshape.3687, %reshape.3711, %reshape.3613, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.3713 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.3712), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_15_.451 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(450), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[15]"}
  %jit__jax_attn_func_.3714 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.3712), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_14_self_attn_o_proj_weight__.63 = bf16[2048,4096]{1,0} parameter(62), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.14.self_attn.o_proj.weight\']"}
  %dot_general.3715 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.3714, %params_and_buffers__vllm_model_language_model_model_layers_14_self_attn_o_proj_weight__.63), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.3716 = f32[16,2048]{1,0} convert(%dot_general.3715), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3587 = bf16[16,2048]{1,0} convert(%add.3586), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3717 = f32[16,2048]{1,0} convert(%convert_element_type.3587), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.3718 = f32[16,2048]{1,0} add(%convert_element_type.3716, %convert_element_type.3717), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.3720 = f32[16,2048]{1,0} power(%add.3718, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3725 = f32[16]{0} reduce(%pow.3720, %constant.512), dimensions={1}, to_apply=%region_89.3724, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3726 = f32[16,1]{1,0} reshape(%reduce_sum.3725), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3727 = f32[16,1]{1,0} divide(%broadcast_in_dim.3726, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3728 = f32[16,1]{1,0} add(%div.3727, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3729 = f32[16,1]{1,0} rsqrt(%add.3728), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3730 = f32[16,1]{1,0} broadcast(%rsqrt.3729), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3731 = f32[16]{0} reshape(%mul.3730), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3732 = f32[16,2048]{1,0} broadcast(%mul.3731), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3733 = f32[16,2048]{1,0} multiply(%add.3718, %mul.3732), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3734 = bf16[16,2048]{1,0} convert(%mul.3733), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_14_post_attention_layernorm_weight__.61 = bf16[2048]{0} parameter(60), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.14.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.3735 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_14_post_attention_layernorm_weight__.61), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3736 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.3735), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3737 = bf16[2048]{0} reshape(%mul.3736), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3738 = bf16[16,2048]{1,0} broadcast(%mul.3737), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3739 = bf16[16,2048]{1,0} multiply(%convert_element_type.3734, %mul.3738), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_14_mlp_experts_w13_weight__.58 = bf16[128,1536,2048]{2,1,0} parameter(57), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.14.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_14_mlp_experts_w2_weight__.59 = bf16[128,2048,768]{2,1,0} parameter(58), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.14.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_14_mlp_gate_weight__.60 = bf16[128,2048]{1,0} parameter(59), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.14.mlp.gate.weight\']"}
  %dot_general.3740 = bf16[16,128]{1,0} dot(%mul.3739, %params_and_buffers__vllm_model_language_model_model_layers_14_mlp_gate_weight__.60), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.3741 = bf16[16,2048]{1,0} call(%mul.3739, %params_and_buffers__vllm_model_language_model_model_layers_14_mlp_experts_w13_weight__.58, %params_and_buffers__vllm_model_language_model_model_layers_14_mlp_experts_w2_weight__.59, %dot_general.3740), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.3742 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.3741), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3719 = bf16[16,2048]{1,0} convert(%add.3718), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3743 = f32[16,2048]{1,0} convert(%convert_element_type.3719), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.3744 = f32[16,2048]{1,0} add(%convert_element_type.3742, %convert_element_type.3743), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.3746 = f32[16,2048]{1,0} power(%add.3744, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3751 = f32[16]{0} reduce(%pow.3746, %constant.512), dimensions={1}, to_apply=%region_90.3750, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3752 = f32[16,1]{1,0} reshape(%reduce_sum.3751), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3753 = f32[16,1]{1,0} divide(%broadcast_in_dim.3752, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3754 = f32[16,1]{1,0} add(%div.3753, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3755 = f32[16,1]{1,0} rsqrt(%add.3754), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3756 = f32[16,1]{1,0} broadcast(%rsqrt.3755), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3757 = f32[16]{0} reshape(%mul.3756), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3758 = f32[16,2048]{1,0} broadcast(%mul.3757), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3759 = f32[16,2048]{1,0} multiply(%add.3744, %mul.3758), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3760 = bf16[16,2048]{1,0} convert(%mul.3759), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_15_input_layernorm_weight__.66 = bf16[2048]{0} parameter(65), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.15.input_layernorm.weight\']"}
  %broadcast_in_dim.3761 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_15_input_layernorm_weight__.66), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3762 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.3761), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3763 = bf16[2048]{0} reshape(%mul.3762), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3764 = bf16[16,2048]{1,0} broadcast(%mul.3763), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3765 = bf16[16,2048]{1,0} multiply(%convert_element_type.3760, %mul.3764), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_15_self_attn_qkv_proj_weight__.74 = bf16[5120,2048]{1,0} parameter(73), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.15.self_attn.qkv_proj.weight\']"}
  %dot_general.3766 = bf16[16,5120]{1,0} dot(%mul.3765, %params_and_buffers__vllm_model_language_model_model_layers_15_self_attn_qkv_proj_weight__.74), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.3767 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.3766), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.3768 = bf16[16,4,1024]{2,1,0} slice(%reshape.3767), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.3772 = bf16[16,32,128]{2,1,0} reshape(%slice.3768), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.3773 = f32[16,32,128]{2,1,0} convert(%reshape.3772), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.3774 = f32[16,32,128]{2,1,0} power(%convert_element_type.3773, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3779 = f32[16,32]{1,0} reduce(%pow.3774, %constant.512), dimensions={2}, to_apply=%region_91.3778, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3780 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.3779), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3781 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.3780, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3782 = f32[16,32,1]{2,1,0} add(%div.3781, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3783 = f32[16,32,1]{2,1,0} rsqrt(%add.3782), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3784 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.3783), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3785 = f32[16,32]{1,0} reshape(%mul.3784), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3786 = f32[16,32,128]{2,1,0} broadcast(%mul.3785), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3787 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.3773, %mul.3786), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3788 = bf16[16,32,128]{2,1,0} convert(%mul.3787), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_15_self_attn_q_norm_weight__.73 = bf16[128]{0} parameter(72), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.15.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.3789 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_15_self_attn_q_norm_weight__.73), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3790 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.3789), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3791 = bf16[128]{0} reshape(%mul.3790), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3792 = bf16[16,32,128]{2,1,0} broadcast(%mul.3791), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3793 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.3788, %mul.3792), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3824 = bf16[16,32,64]{2,1,0} slice(%mul.3793), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.3815 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.3816 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.3817 = s32[16]{0} select(%lt.3815, %add.3816, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.3818 = s32[16,1]{1,0} reshape(%select_n.3817), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.3819 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.3818), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.3820 = bf16[16,64]{1,0} slice(%gather.3819), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3822 = bf16[16,1,64]{2,1,0} reshape(%slice.3820), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3826 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3822), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3827 = bf16[16,64]{1,0} reshape(%mul.3826), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3828 = bf16[16,32,64]{2,1,0} broadcast(%mul.3827), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3829 = bf16[16,32,64]{2,1,0} multiply(%slice.3824, %mul.3828), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3825 = bf16[16,32,64]{2,1,0} slice(%mul.3793), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.3821 = bf16[16,64]{1,0} slice(%gather.3819), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3823 = bf16[16,1,64]{2,1,0} reshape(%slice.3821), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3830 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3823), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3831 = bf16[16,64]{1,0} reshape(%mul.3830), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3832 = bf16[16,32,64]{2,1,0} broadcast(%mul.3831), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3833 = bf16[16,32,64]{2,1,0} multiply(%slice.3825, %mul.3832), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.3834 = bf16[16,32,64]{2,1,0} subtract(%mul.3829, %mul.3833), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.3835 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3822), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3836 = bf16[16,64]{1,0} reshape(%mul.3835), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3837 = bf16[16,32,64]{2,1,0} broadcast(%mul.3836), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3838 = bf16[16,32,64]{2,1,0} multiply(%slice.3825, %mul.3837), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3839 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3823), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3840 = bf16[16,64]{1,0} reshape(%mul.3839), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3841 = bf16[16,32,64]{2,1,0} broadcast(%mul.3840), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3842 = bf16[16,32,64]{2,1,0} multiply(%slice.3824, %mul.3841), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.3843 = bf16[16,32,64]{2,1,0} add(%mul.3838, %mul.3842), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.3844 = bf16[16,32,128]{2,1,0} concatenate(%sub.3834, %add.3843), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.3845 = bf16[16,4096]{1,0} reshape(%concatenate.3844), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.3769 = bf16[16,4,128]{2,1,0} slice(%reshape.3767), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.3794 = f32[16,4,128]{2,1,0} convert(%slice.3769), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.3795 = f32[16,4,128]{2,1,0} power(%convert_element_type.3794, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3800 = f32[16,4]{1,0} reduce(%pow.3795, %constant.512), dimensions={2}, to_apply=%region_92.3799, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3801 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.3800), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3802 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.3801, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3803 = f32[16,4,1]{2,1,0} add(%div.3802, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3804 = f32[16,4,1]{2,1,0} rsqrt(%add.3803), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3805 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.3804), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3806 = f32[16,4]{1,0} reshape(%mul.3805), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3807 = f32[16,4,128]{2,1,0} broadcast(%mul.3806), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3808 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.3794, %mul.3807), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3809 = bf16[16,4,128]{2,1,0} convert(%mul.3808), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_15_self_attn_k_norm_weight__.71 = bf16[128]{0} parameter(70), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.15.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.3810 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_15_self_attn_k_norm_weight__.71), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3811 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.3810), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3812 = bf16[128]{0} reshape(%mul.3811), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3813 = bf16[16,4,128]{2,1,0} broadcast(%mul.3812), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3814 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.3809, %mul.3813), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3848 = bf16[16,4,64]{2,1,0} slice(%mul.3814), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3846 = bf16[16,1,64]{2,1,0} reshape(%slice.3820), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3850 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3846), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3851 = bf16[16,64]{1,0} reshape(%mul.3850), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3852 = bf16[16,4,64]{2,1,0} broadcast(%mul.3851), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3853 = bf16[16,4,64]{2,1,0} multiply(%slice.3848, %mul.3852), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3849 = bf16[16,4,64]{2,1,0} slice(%mul.3814), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3847 = bf16[16,1,64]{2,1,0} reshape(%slice.3821), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3854 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3847), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3855 = bf16[16,64]{1,0} reshape(%mul.3854), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3856 = bf16[16,4,64]{2,1,0} broadcast(%mul.3855), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3857 = bf16[16,4,64]{2,1,0} multiply(%slice.3849, %mul.3856), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.3858 = bf16[16,4,64]{2,1,0} subtract(%mul.3853, %mul.3857), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.3859 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3846), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3860 = bf16[16,64]{1,0} reshape(%mul.3859), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3861 = bf16[16,4,64]{2,1,0} broadcast(%mul.3860), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3862 = bf16[16,4,64]{2,1,0} multiply(%slice.3849, %mul.3861), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3863 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3847), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3864 = bf16[16,64]{1,0} reshape(%mul.3863), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3865 = bf16[16,4,64]{2,1,0} broadcast(%mul.3864), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3866 = bf16[16,4,64]{2,1,0} multiply(%slice.3848, %mul.3865), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.3867 = bf16[16,4,64]{2,1,0} add(%mul.3862, %mul.3866), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.3868 = bf16[16,4,128]{2,1,0} concatenate(%sub.3858, %add.3867), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.3869 = bf16[16,512]{1,0} reshape(%concatenate.3868), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.3770 = bf16[16,4,128]{2,1,0} slice(%reshape.3767), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.3771 = bf16[16,512]{1,0} reshape(%slice.3770), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.3870 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_15_.451, %reshape.3845, %reshape.3869, %reshape.3771, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.3871 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.3870), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_16_.452 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(451), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[16]"}
  %jit__jax_attn_func_.3872 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.3870), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_15_self_attn_o_proj_weight__.72 = bf16[2048,4096]{1,0} parameter(71), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.15.self_attn.o_proj.weight\']"}
  %dot_general.3873 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.3872, %params_and_buffers__vllm_model_language_model_model_layers_15_self_attn_o_proj_weight__.72), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.3874 = f32[16,2048]{1,0} convert(%dot_general.3873), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3745 = bf16[16,2048]{1,0} convert(%add.3744), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3875 = f32[16,2048]{1,0} convert(%convert_element_type.3745), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.3876 = f32[16,2048]{1,0} add(%convert_element_type.3874, %convert_element_type.3875), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.3878 = f32[16,2048]{1,0} power(%add.3876, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3883 = f32[16]{0} reduce(%pow.3878, %constant.512), dimensions={1}, to_apply=%region_93.3882, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3884 = f32[16,1]{1,0} reshape(%reduce_sum.3883), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3885 = f32[16,1]{1,0} divide(%broadcast_in_dim.3884, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3886 = f32[16,1]{1,0} add(%div.3885, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3887 = f32[16,1]{1,0} rsqrt(%add.3886), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3888 = f32[16,1]{1,0} broadcast(%rsqrt.3887), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3889 = f32[16]{0} reshape(%mul.3888), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3890 = f32[16,2048]{1,0} broadcast(%mul.3889), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3891 = f32[16,2048]{1,0} multiply(%add.3876, %mul.3890), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3892 = bf16[16,2048]{1,0} convert(%mul.3891), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_15_post_attention_layernorm_weight__.70 = bf16[2048]{0} parameter(69), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.15.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.3893 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_15_post_attention_layernorm_weight__.70), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3894 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.3893), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3895 = bf16[2048]{0} reshape(%mul.3894), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3896 = bf16[16,2048]{1,0} broadcast(%mul.3895), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3897 = bf16[16,2048]{1,0} multiply(%convert_element_type.3892, %mul.3896), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_15_mlp_experts_w13_weight__.67 = bf16[128,1536,2048]{2,1,0} parameter(66), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.15.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_15_mlp_experts_w2_weight__.68 = bf16[128,2048,768]{2,1,0} parameter(67), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.15.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_15_mlp_gate_weight__.69 = bf16[128,2048]{1,0} parameter(68), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.15.mlp.gate.weight\']"}
  %dot_general.3898 = bf16[16,128]{1,0} dot(%mul.3897, %params_and_buffers__vllm_model_language_model_model_layers_15_mlp_gate_weight__.69), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.3899 = bf16[16,2048]{1,0} call(%mul.3897, %params_and_buffers__vllm_model_language_model_model_layers_15_mlp_experts_w13_weight__.67, %params_and_buffers__vllm_model_language_model_model_layers_15_mlp_experts_w2_weight__.68, %dot_general.3898), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.3900 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.3899), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3877 = bf16[16,2048]{1,0} convert(%add.3876), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3901 = f32[16,2048]{1,0} convert(%convert_element_type.3877), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.3902 = f32[16,2048]{1,0} add(%convert_element_type.3900, %convert_element_type.3901), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.3904 = f32[16,2048]{1,0} power(%add.3902, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3909 = f32[16]{0} reduce(%pow.3904, %constant.512), dimensions={1}, to_apply=%region_94.3908, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3910 = f32[16,1]{1,0} reshape(%reduce_sum.3909), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3911 = f32[16,1]{1,0} divide(%broadcast_in_dim.3910, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3912 = f32[16,1]{1,0} add(%div.3911, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3913 = f32[16,1]{1,0} rsqrt(%add.3912), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3914 = f32[16,1]{1,0} broadcast(%rsqrt.3913), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3915 = f32[16]{0} reshape(%mul.3914), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3916 = f32[16,2048]{1,0} broadcast(%mul.3915), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3917 = f32[16,2048]{1,0} multiply(%add.3902, %mul.3916), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3918 = bf16[16,2048]{1,0} convert(%mul.3917), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_16_input_layernorm_weight__.75 = bf16[2048]{0} parameter(74), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.16.input_layernorm.weight\']"}
  %broadcast_in_dim.3919 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_16_input_layernorm_weight__.75), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3920 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.3919), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3921 = bf16[2048]{0} reshape(%mul.3920), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3922 = bf16[16,2048]{1,0} broadcast(%mul.3921), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3923 = bf16[16,2048]{1,0} multiply(%convert_element_type.3918, %mul.3922), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_16_self_attn_qkv_proj_weight__.83 = bf16[5120,2048]{1,0} parameter(82), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.16.self_attn.qkv_proj.weight\']"}
  %dot_general.3924 = bf16[16,5120]{1,0} dot(%mul.3923, %params_and_buffers__vllm_model_language_model_model_layers_16_self_attn_qkv_proj_weight__.83), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.3925 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.3924), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.3926 = bf16[16,4,1024]{2,1,0} slice(%reshape.3925), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.3930 = bf16[16,32,128]{2,1,0} reshape(%slice.3926), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.3931 = f32[16,32,128]{2,1,0} convert(%reshape.3930), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.3932 = f32[16,32,128]{2,1,0} power(%convert_element_type.3931, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3937 = f32[16,32]{1,0} reduce(%pow.3932, %constant.512), dimensions={2}, to_apply=%region_95.3936, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3938 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.3937), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3939 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.3938, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3940 = f32[16,32,1]{2,1,0} add(%div.3939, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3941 = f32[16,32,1]{2,1,0} rsqrt(%add.3940), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3942 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.3941), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3943 = f32[16,32]{1,0} reshape(%mul.3942), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3944 = f32[16,32,128]{2,1,0} broadcast(%mul.3943), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3945 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.3931, %mul.3944), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3946 = bf16[16,32,128]{2,1,0} convert(%mul.3945), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_16_self_attn_q_norm_weight__.82 = bf16[128]{0} parameter(81), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.16.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.3947 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_16_self_attn_q_norm_weight__.82), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3948 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.3947), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3949 = bf16[128]{0} reshape(%mul.3948), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3950 = bf16[16,32,128]{2,1,0} broadcast(%mul.3949), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3951 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.3946, %mul.3950), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3982 = bf16[16,32,64]{2,1,0} slice(%mul.3951), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.3973 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.3974 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.3975 = s32[16]{0} select(%lt.3973, %add.3974, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.3976 = s32[16,1]{1,0} reshape(%select_n.3975), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.3977 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.3976), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.3978 = bf16[16,64]{1,0} slice(%gather.3977), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3980 = bf16[16,1,64]{2,1,0} reshape(%slice.3978), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3984 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3980), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3985 = bf16[16,64]{1,0} reshape(%mul.3984), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3986 = bf16[16,32,64]{2,1,0} broadcast(%mul.3985), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3987 = bf16[16,32,64]{2,1,0} multiply(%slice.3982, %mul.3986), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3983 = bf16[16,32,64]{2,1,0} slice(%mul.3951), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.3979 = bf16[16,64]{1,0} slice(%gather.3977), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3981 = bf16[16,1,64]{2,1,0} reshape(%slice.3979), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3988 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3981), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3989 = bf16[16,64]{1,0} reshape(%mul.3988), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3990 = bf16[16,32,64]{2,1,0} broadcast(%mul.3989), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3991 = bf16[16,32,64]{2,1,0} multiply(%slice.3983, %mul.3990), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.3992 = bf16[16,32,64]{2,1,0} subtract(%mul.3987, %mul.3991), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.3993 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3980), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3994 = bf16[16,64]{1,0} reshape(%mul.3993), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3995 = bf16[16,32,64]{2,1,0} broadcast(%mul.3994), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3996 = bf16[16,32,64]{2,1,0} multiply(%slice.3983, %mul.3995), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3997 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.3981), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3998 = bf16[16,64]{1,0} reshape(%mul.3997), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3999 = bf16[16,32,64]{2,1,0} broadcast(%mul.3998), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4000 = bf16[16,32,64]{2,1,0} multiply(%slice.3982, %mul.3999), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.4001 = bf16[16,32,64]{2,1,0} add(%mul.3996, %mul.4000), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.4002 = bf16[16,32,128]{2,1,0} concatenate(%sub.3992, %add.4001), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.4003 = bf16[16,4096]{1,0} reshape(%concatenate.4002), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.3927 = bf16[16,4,128]{2,1,0} slice(%reshape.3925), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.3952 = f32[16,4,128]{2,1,0} convert(%slice.3927), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.3953 = f32[16,4,128]{2,1,0} power(%convert_element_type.3952, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3958 = f32[16,4]{1,0} reduce(%pow.3953, %constant.512), dimensions={2}, to_apply=%region_96.3957, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3959 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.3958), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3960 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.3959, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3961 = f32[16,4,1]{2,1,0} add(%div.3960, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3962 = f32[16,4,1]{2,1,0} rsqrt(%add.3961), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3963 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.3962), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3964 = f32[16,4]{1,0} reshape(%mul.3963), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3965 = f32[16,4,128]{2,1,0} broadcast(%mul.3964), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3966 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.3952, %mul.3965), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3967 = bf16[16,4,128]{2,1,0} convert(%mul.3966), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_16_self_attn_k_norm_weight__.80 = bf16[128]{0} parameter(79), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.16.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.3968 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_16_self_attn_k_norm_weight__.80), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3969 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.3968), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3970 = bf16[128]{0} reshape(%mul.3969), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3971 = bf16[16,4,128]{2,1,0} broadcast(%mul.3970), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3972 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.3967, %mul.3971), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4006 = bf16[16,4,64]{2,1,0} slice(%mul.3972), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4004 = bf16[16,1,64]{2,1,0} reshape(%slice.3978), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4008 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4004), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4009 = bf16[16,64]{1,0} reshape(%mul.4008), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4010 = bf16[16,4,64]{2,1,0} broadcast(%mul.4009), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4011 = bf16[16,4,64]{2,1,0} multiply(%slice.4006, %mul.4010), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4007 = bf16[16,4,64]{2,1,0} slice(%mul.3972), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4005 = bf16[16,1,64]{2,1,0} reshape(%slice.3979), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4012 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4005), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4013 = bf16[16,64]{1,0} reshape(%mul.4012), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4014 = bf16[16,4,64]{2,1,0} broadcast(%mul.4013), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4015 = bf16[16,4,64]{2,1,0} multiply(%slice.4007, %mul.4014), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.4016 = bf16[16,4,64]{2,1,0} subtract(%mul.4011, %mul.4015), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.4017 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4004), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4018 = bf16[16,64]{1,0} reshape(%mul.4017), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4019 = bf16[16,4,64]{2,1,0} broadcast(%mul.4018), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4020 = bf16[16,4,64]{2,1,0} multiply(%slice.4007, %mul.4019), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4021 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4005), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4022 = bf16[16,64]{1,0} reshape(%mul.4021), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4023 = bf16[16,4,64]{2,1,0} broadcast(%mul.4022), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4024 = bf16[16,4,64]{2,1,0} multiply(%slice.4006, %mul.4023), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.4025 = bf16[16,4,64]{2,1,0} add(%mul.4020, %mul.4024), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.4026 = bf16[16,4,128]{2,1,0} concatenate(%sub.4016, %add.4025), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.4027 = bf16[16,512]{1,0} reshape(%concatenate.4026), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.3928 = bf16[16,4,128]{2,1,0} slice(%reshape.3925), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.3929 = bf16[16,512]{1,0} reshape(%slice.3928), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.4028 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_16_.452, %reshape.4003, %reshape.4027, %reshape.3929, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.4029 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.4028), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_17_.453 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(452), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[17]"}
  %jit__jax_attn_func_.4030 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.4028), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_16_self_attn_o_proj_weight__.81 = bf16[2048,4096]{1,0} parameter(80), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.16.self_attn.o_proj.weight\']"}
  %dot_general.4031 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.4030, %params_and_buffers__vllm_model_language_model_model_layers_16_self_attn_o_proj_weight__.81), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.4032 = f32[16,2048]{1,0} convert(%dot_general.4031), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3903 = bf16[16,2048]{1,0} convert(%add.3902), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4033 = f32[16,2048]{1,0} convert(%convert_element_type.3903), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.4034 = f32[16,2048]{1,0} add(%convert_element_type.4032, %convert_element_type.4033), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.4036 = f32[16,2048]{1,0} power(%add.4034, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4041 = f32[16]{0} reduce(%pow.4036, %constant.512), dimensions={1}, to_apply=%region_97.4040, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4042 = f32[16,1]{1,0} reshape(%reduce_sum.4041), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4043 = f32[16,1]{1,0} divide(%broadcast_in_dim.4042, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4044 = f32[16,1]{1,0} add(%div.4043, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4045 = f32[16,1]{1,0} rsqrt(%add.4044), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4046 = f32[16,1]{1,0} broadcast(%rsqrt.4045), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4047 = f32[16]{0} reshape(%mul.4046), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4048 = f32[16,2048]{1,0} broadcast(%mul.4047), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4049 = f32[16,2048]{1,0} multiply(%add.4034, %mul.4048), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4050 = bf16[16,2048]{1,0} convert(%mul.4049), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_16_post_attention_layernorm_weight__.79 = bf16[2048]{0} parameter(78), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.16.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.4051 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_16_post_attention_layernorm_weight__.79), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4052 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.4051), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4053 = bf16[2048]{0} reshape(%mul.4052), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4054 = bf16[16,2048]{1,0} broadcast(%mul.4053), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4055 = bf16[16,2048]{1,0} multiply(%convert_element_type.4050, %mul.4054), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_16_mlp_experts_w13_weight__.76 = bf16[128,1536,2048]{2,1,0} parameter(75), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.16.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_16_mlp_experts_w2_weight__.77 = bf16[128,2048,768]{2,1,0} parameter(76), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.16.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_16_mlp_gate_weight__.78 = bf16[128,2048]{1,0} parameter(77), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.16.mlp.gate.weight\']"}
  %dot_general.4056 = bf16[16,128]{1,0} dot(%mul.4055, %params_and_buffers__vllm_model_language_model_model_layers_16_mlp_gate_weight__.78), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.4057 = bf16[16,2048]{1,0} call(%mul.4055, %params_and_buffers__vllm_model_language_model_model_layers_16_mlp_experts_w13_weight__.76, %params_and_buffers__vllm_model_language_model_model_layers_16_mlp_experts_w2_weight__.77, %dot_general.4056), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.4058 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.4057), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4035 = bf16[16,2048]{1,0} convert(%add.4034), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4059 = f32[16,2048]{1,0} convert(%convert_element_type.4035), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.4060 = f32[16,2048]{1,0} add(%convert_element_type.4058, %convert_element_type.4059), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.4062 = f32[16,2048]{1,0} power(%add.4060, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4067 = f32[16]{0} reduce(%pow.4062, %constant.512), dimensions={1}, to_apply=%region_98.4066, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4068 = f32[16,1]{1,0} reshape(%reduce_sum.4067), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4069 = f32[16,1]{1,0} divide(%broadcast_in_dim.4068, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4070 = f32[16,1]{1,0} add(%div.4069, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4071 = f32[16,1]{1,0} rsqrt(%add.4070), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4072 = f32[16,1]{1,0} broadcast(%rsqrt.4071), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4073 = f32[16]{0} reshape(%mul.4072), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4074 = f32[16,2048]{1,0} broadcast(%mul.4073), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4075 = f32[16,2048]{1,0} multiply(%add.4060, %mul.4074), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4076 = bf16[16,2048]{1,0} convert(%mul.4075), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_17_input_layernorm_weight__.84 = bf16[2048]{0} parameter(83), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.17.input_layernorm.weight\']"}
  %broadcast_in_dim.4077 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_17_input_layernorm_weight__.84), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4078 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.4077), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4079 = bf16[2048]{0} reshape(%mul.4078), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4080 = bf16[16,2048]{1,0} broadcast(%mul.4079), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4081 = bf16[16,2048]{1,0} multiply(%convert_element_type.4076, %mul.4080), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_17_self_attn_qkv_proj_weight__.92 = bf16[5120,2048]{1,0} parameter(91), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.17.self_attn.qkv_proj.weight\']"}
  %dot_general.4082 = bf16[16,5120]{1,0} dot(%mul.4081, %params_and_buffers__vllm_model_language_model_model_layers_17_self_attn_qkv_proj_weight__.92), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.4083 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.4082), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.4084 = bf16[16,4,1024]{2,1,0} slice(%reshape.4083), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.4088 = bf16[16,32,128]{2,1,0} reshape(%slice.4084), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.4089 = f32[16,32,128]{2,1,0} convert(%reshape.4088), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.4090 = f32[16,32,128]{2,1,0} power(%convert_element_type.4089, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4095 = f32[16,32]{1,0} reduce(%pow.4090, %constant.512), dimensions={2}, to_apply=%region_99.4094, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4096 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.4095), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4097 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.4096, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4098 = f32[16,32,1]{2,1,0} add(%div.4097, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4099 = f32[16,32,1]{2,1,0} rsqrt(%add.4098), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4100 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.4099), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4101 = f32[16,32]{1,0} reshape(%mul.4100), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4102 = f32[16,32,128]{2,1,0} broadcast(%mul.4101), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4103 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.4089, %mul.4102), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4104 = bf16[16,32,128]{2,1,0} convert(%mul.4103), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_17_self_attn_q_norm_weight__.91 = bf16[128]{0} parameter(90), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.17.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.4105 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_17_self_attn_q_norm_weight__.91), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4106 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.4105), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4107 = bf16[128]{0} reshape(%mul.4106), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4108 = bf16[16,32,128]{2,1,0} broadcast(%mul.4107), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4109 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.4104, %mul.4108), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4140 = bf16[16,32,64]{2,1,0} slice(%mul.4109), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.4131 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.4132 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.4133 = s32[16]{0} select(%lt.4131, %add.4132, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.4134 = s32[16,1]{1,0} reshape(%select_n.4133), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.4135 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.4134), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.4136 = bf16[16,64]{1,0} slice(%gather.4135), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4138 = bf16[16,1,64]{2,1,0} reshape(%slice.4136), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4142 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4138), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4143 = bf16[16,64]{1,0} reshape(%mul.4142), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4144 = bf16[16,32,64]{2,1,0} broadcast(%mul.4143), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4145 = bf16[16,32,64]{2,1,0} multiply(%slice.4140, %mul.4144), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4141 = bf16[16,32,64]{2,1,0} slice(%mul.4109), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.4137 = bf16[16,64]{1,0} slice(%gather.4135), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4139 = bf16[16,1,64]{2,1,0} reshape(%slice.4137), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4146 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4139), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4147 = bf16[16,64]{1,0} reshape(%mul.4146), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4148 = bf16[16,32,64]{2,1,0} broadcast(%mul.4147), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4149 = bf16[16,32,64]{2,1,0} multiply(%slice.4141, %mul.4148), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.4150 = bf16[16,32,64]{2,1,0} subtract(%mul.4145, %mul.4149), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.4151 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4138), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4152 = bf16[16,64]{1,0} reshape(%mul.4151), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4153 = bf16[16,32,64]{2,1,0} broadcast(%mul.4152), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4154 = bf16[16,32,64]{2,1,0} multiply(%slice.4141, %mul.4153), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4155 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4139), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4156 = bf16[16,64]{1,0} reshape(%mul.4155), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4157 = bf16[16,32,64]{2,1,0} broadcast(%mul.4156), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4158 = bf16[16,32,64]{2,1,0} multiply(%slice.4140, %mul.4157), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.4159 = bf16[16,32,64]{2,1,0} add(%mul.4154, %mul.4158), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.4160 = bf16[16,32,128]{2,1,0} concatenate(%sub.4150, %add.4159), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.4161 = bf16[16,4096]{1,0} reshape(%concatenate.4160), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.4085 = bf16[16,4,128]{2,1,0} slice(%reshape.4083), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.4110 = f32[16,4,128]{2,1,0} convert(%slice.4085), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.4111 = f32[16,4,128]{2,1,0} power(%convert_element_type.4110, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4116 = f32[16,4]{1,0} reduce(%pow.4111, %constant.512), dimensions={2}, to_apply=%region_100.4115, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4117 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.4116), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4118 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.4117, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4119 = f32[16,4,1]{2,1,0} add(%div.4118, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4120 = f32[16,4,1]{2,1,0} rsqrt(%add.4119), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4121 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.4120), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4122 = f32[16,4]{1,0} reshape(%mul.4121), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4123 = f32[16,4,128]{2,1,0} broadcast(%mul.4122), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4124 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.4110, %mul.4123), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4125 = bf16[16,4,128]{2,1,0} convert(%mul.4124), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_17_self_attn_k_norm_weight__.89 = bf16[128]{0} parameter(88), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.17.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.4126 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_17_self_attn_k_norm_weight__.89), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4127 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.4126), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4128 = bf16[128]{0} reshape(%mul.4127), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4129 = bf16[16,4,128]{2,1,0} broadcast(%mul.4128), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4130 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.4125, %mul.4129), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4164 = bf16[16,4,64]{2,1,0} slice(%mul.4130), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4162 = bf16[16,1,64]{2,1,0} reshape(%slice.4136), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4166 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4162), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4167 = bf16[16,64]{1,0} reshape(%mul.4166), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4168 = bf16[16,4,64]{2,1,0} broadcast(%mul.4167), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4169 = bf16[16,4,64]{2,1,0} multiply(%slice.4164, %mul.4168), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4165 = bf16[16,4,64]{2,1,0} slice(%mul.4130), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4163 = bf16[16,1,64]{2,1,0} reshape(%slice.4137), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4170 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4163), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4171 = bf16[16,64]{1,0} reshape(%mul.4170), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4172 = bf16[16,4,64]{2,1,0} broadcast(%mul.4171), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4173 = bf16[16,4,64]{2,1,0} multiply(%slice.4165, %mul.4172), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.4174 = bf16[16,4,64]{2,1,0} subtract(%mul.4169, %mul.4173), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.4175 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4162), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4176 = bf16[16,64]{1,0} reshape(%mul.4175), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4177 = bf16[16,4,64]{2,1,0} broadcast(%mul.4176), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4178 = bf16[16,4,64]{2,1,0} multiply(%slice.4165, %mul.4177), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4179 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4163), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4180 = bf16[16,64]{1,0} reshape(%mul.4179), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4181 = bf16[16,4,64]{2,1,0} broadcast(%mul.4180), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4182 = bf16[16,4,64]{2,1,0} multiply(%slice.4164, %mul.4181), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.4183 = bf16[16,4,64]{2,1,0} add(%mul.4178, %mul.4182), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.4184 = bf16[16,4,128]{2,1,0} concatenate(%sub.4174, %add.4183), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.4185 = bf16[16,512]{1,0} reshape(%concatenate.4184), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.4086 = bf16[16,4,128]{2,1,0} slice(%reshape.4083), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.4087 = bf16[16,512]{1,0} reshape(%slice.4086), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.4186 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_17_.453, %reshape.4161, %reshape.4185, %reshape.4087, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.4187 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.4186), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_18_.454 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(453), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[18]"}
  %jit__jax_attn_func_.4188 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.4186), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_17_self_attn_o_proj_weight__.90 = bf16[2048,4096]{1,0} parameter(89), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.17.self_attn.o_proj.weight\']"}
  %dot_general.4189 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.4188, %params_and_buffers__vllm_model_language_model_model_layers_17_self_attn_o_proj_weight__.90), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.4190 = f32[16,2048]{1,0} convert(%dot_general.4189), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4061 = bf16[16,2048]{1,0} convert(%add.4060), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4191 = f32[16,2048]{1,0} convert(%convert_element_type.4061), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.4192 = f32[16,2048]{1,0} add(%convert_element_type.4190, %convert_element_type.4191), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.4194 = f32[16,2048]{1,0} power(%add.4192, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4199 = f32[16]{0} reduce(%pow.4194, %constant.512), dimensions={1}, to_apply=%region_101.4198, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4200 = f32[16,1]{1,0} reshape(%reduce_sum.4199), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4201 = f32[16,1]{1,0} divide(%broadcast_in_dim.4200, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4202 = f32[16,1]{1,0} add(%div.4201, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4203 = f32[16,1]{1,0} rsqrt(%add.4202), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4204 = f32[16,1]{1,0} broadcast(%rsqrt.4203), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4205 = f32[16]{0} reshape(%mul.4204), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4206 = f32[16,2048]{1,0} broadcast(%mul.4205), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4207 = f32[16,2048]{1,0} multiply(%add.4192, %mul.4206), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4208 = bf16[16,2048]{1,0} convert(%mul.4207), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_17_post_attention_layernorm_weight__.88 = bf16[2048]{0} parameter(87), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.17.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.4209 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_17_post_attention_layernorm_weight__.88), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4210 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.4209), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4211 = bf16[2048]{0} reshape(%mul.4210), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4212 = bf16[16,2048]{1,0} broadcast(%mul.4211), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4213 = bf16[16,2048]{1,0} multiply(%convert_element_type.4208, %mul.4212), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_17_mlp_experts_w13_weight__.85 = bf16[128,1536,2048]{2,1,0} parameter(84), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.17.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_17_mlp_experts_w2_weight__.86 = bf16[128,2048,768]{2,1,0} parameter(85), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.17.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_17_mlp_gate_weight__.87 = bf16[128,2048]{1,0} parameter(86), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.17.mlp.gate.weight\']"}
  %dot_general.4214 = bf16[16,128]{1,0} dot(%mul.4213, %params_and_buffers__vllm_model_language_model_model_layers_17_mlp_gate_weight__.87), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.4215 = bf16[16,2048]{1,0} call(%mul.4213, %params_and_buffers__vllm_model_language_model_model_layers_17_mlp_experts_w13_weight__.85, %params_and_buffers__vllm_model_language_model_model_layers_17_mlp_experts_w2_weight__.86, %dot_general.4214), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.4216 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.4215), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4193 = bf16[16,2048]{1,0} convert(%add.4192), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4217 = f32[16,2048]{1,0} convert(%convert_element_type.4193), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.4218 = f32[16,2048]{1,0} add(%convert_element_type.4216, %convert_element_type.4217), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.4220 = f32[16,2048]{1,0} power(%add.4218, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4225 = f32[16]{0} reduce(%pow.4220, %constant.512), dimensions={1}, to_apply=%region_102.4224, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4226 = f32[16,1]{1,0} reshape(%reduce_sum.4225), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4227 = f32[16,1]{1,0} divide(%broadcast_in_dim.4226, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4228 = f32[16,1]{1,0} add(%div.4227, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4229 = f32[16,1]{1,0} rsqrt(%add.4228), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4230 = f32[16,1]{1,0} broadcast(%rsqrt.4229), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4231 = f32[16]{0} reshape(%mul.4230), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4232 = f32[16,2048]{1,0} broadcast(%mul.4231), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4233 = f32[16,2048]{1,0} multiply(%add.4218, %mul.4232), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4234 = bf16[16,2048]{1,0} convert(%mul.4233), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_18_input_layernorm_weight__.93 = bf16[2048]{0} parameter(92), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.18.input_layernorm.weight\']"}
  %broadcast_in_dim.4235 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_18_input_layernorm_weight__.93), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4236 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.4235), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4237 = bf16[2048]{0} reshape(%mul.4236), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4238 = bf16[16,2048]{1,0} broadcast(%mul.4237), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4239 = bf16[16,2048]{1,0} multiply(%convert_element_type.4234, %mul.4238), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_18_self_attn_qkv_proj_weight__.101 = bf16[5120,2048]{1,0} parameter(100), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.18.self_attn.qkv_proj.weight\']"}
  %dot_general.4240 = bf16[16,5120]{1,0} dot(%mul.4239, %params_and_buffers__vllm_model_language_model_model_layers_18_self_attn_qkv_proj_weight__.101), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.4241 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.4240), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.4242 = bf16[16,4,1024]{2,1,0} slice(%reshape.4241), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.4246 = bf16[16,32,128]{2,1,0} reshape(%slice.4242), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.4247 = f32[16,32,128]{2,1,0} convert(%reshape.4246), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.4248 = f32[16,32,128]{2,1,0} power(%convert_element_type.4247, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4253 = f32[16,32]{1,0} reduce(%pow.4248, %constant.512), dimensions={2}, to_apply=%region_103.4252, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4254 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.4253), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4255 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.4254, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4256 = f32[16,32,1]{2,1,0} add(%div.4255, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4257 = f32[16,32,1]{2,1,0} rsqrt(%add.4256), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4258 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.4257), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4259 = f32[16,32]{1,0} reshape(%mul.4258), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4260 = f32[16,32,128]{2,1,0} broadcast(%mul.4259), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4261 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.4247, %mul.4260), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4262 = bf16[16,32,128]{2,1,0} convert(%mul.4261), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_18_self_attn_q_norm_weight__.100 = bf16[128]{0} parameter(99), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.18.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.4263 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_18_self_attn_q_norm_weight__.100), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4264 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.4263), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4265 = bf16[128]{0} reshape(%mul.4264), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4266 = bf16[16,32,128]{2,1,0} broadcast(%mul.4265), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4267 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.4262, %mul.4266), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4298 = bf16[16,32,64]{2,1,0} slice(%mul.4267), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.4289 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.4290 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.4291 = s32[16]{0} select(%lt.4289, %add.4290, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.4292 = s32[16,1]{1,0} reshape(%select_n.4291), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.4293 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.4292), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.4294 = bf16[16,64]{1,0} slice(%gather.4293), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4296 = bf16[16,1,64]{2,1,0} reshape(%slice.4294), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4300 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4296), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4301 = bf16[16,64]{1,0} reshape(%mul.4300), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4302 = bf16[16,32,64]{2,1,0} broadcast(%mul.4301), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4303 = bf16[16,32,64]{2,1,0} multiply(%slice.4298, %mul.4302), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4299 = bf16[16,32,64]{2,1,0} slice(%mul.4267), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.4295 = bf16[16,64]{1,0} slice(%gather.4293), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4297 = bf16[16,1,64]{2,1,0} reshape(%slice.4295), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4304 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4297), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4305 = bf16[16,64]{1,0} reshape(%mul.4304), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4306 = bf16[16,32,64]{2,1,0} broadcast(%mul.4305), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4307 = bf16[16,32,64]{2,1,0} multiply(%slice.4299, %mul.4306), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.4308 = bf16[16,32,64]{2,1,0} subtract(%mul.4303, %mul.4307), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.4309 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4296), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4310 = bf16[16,64]{1,0} reshape(%mul.4309), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4311 = bf16[16,32,64]{2,1,0} broadcast(%mul.4310), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4312 = bf16[16,32,64]{2,1,0} multiply(%slice.4299, %mul.4311), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4313 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4297), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4314 = bf16[16,64]{1,0} reshape(%mul.4313), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4315 = bf16[16,32,64]{2,1,0} broadcast(%mul.4314), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4316 = bf16[16,32,64]{2,1,0} multiply(%slice.4298, %mul.4315), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.4317 = bf16[16,32,64]{2,1,0} add(%mul.4312, %mul.4316), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.4318 = bf16[16,32,128]{2,1,0} concatenate(%sub.4308, %add.4317), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.4319 = bf16[16,4096]{1,0} reshape(%concatenate.4318), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.4243 = bf16[16,4,128]{2,1,0} slice(%reshape.4241), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.4268 = f32[16,4,128]{2,1,0} convert(%slice.4243), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.4269 = f32[16,4,128]{2,1,0} power(%convert_element_type.4268, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4274 = f32[16,4]{1,0} reduce(%pow.4269, %constant.512), dimensions={2}, to_apply=%region_104.4273, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4275 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.4274), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4276 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.4275, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4277 = f32[16,4,1]{2,1,0} add(%div.4276, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4278 = f32[16,4,1]{2,1,0} rsqrt(%add.4277), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4279 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.4278), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4280 = f32[16,4]{1,0} reshape(%mul.4279), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4281 = f32[16,4,128]{2,1,0} broadcast(%mul.4280), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4282 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.4268, %mul.4281), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4283 = bf16[16,4,128]{2,1,0} convert(%mul.4282), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_18_self_attn_k_norm_weight__.98 = bf16[128]{0} parameter(97), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.18.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.4284 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_18_self_attn_k_norm_weight__.98), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4285 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.4284), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4286 = bf16[128]{0} reshape(%mul.4285), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4287 = bf16[16,4,128]{2,1,0} broadcast(%mul.4286), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4288 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.4283, %mul.4287), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4322 = bf16[16,4,64]{2,1,0} slice(%mul.4288), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4320 = bf16[16,1,64]{2,1,0} reshape(%slice.4294), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4324 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4320), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4325 = bf16[16,64]{1,0} reshape(%mul.4324), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4326 = bf16[16,4,64]{2,1,0} broadcast(%mul.4325), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4327 = bf16[16,4,64]{2,1,0} multiply(%slice.4322, %mul.4326), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4323 = bf16[16,4,64]{2,1,0} slice(%mul.4288), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4321 = bf16[16,1,64]{2,1,0} reshape(%slice.4295), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4328 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4321), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4329 = bf16[16,64]{1,0} reshape(%mul.4328), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4330 = bf16[16,4,64]{2,1,0} broadcast(%mul.4329), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4331 = bf16[16,4,64]{2,1,0} multiply(%slice.4323, %mul.4330), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.4332 = bf16[16,4,64]{2,1,0} subtract(%mul.4327, %mul.4331), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.4333 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4320), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4334 = bf16[16,64]{1,0} reshape(%mul.4333), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4335 = bf16[16,4,64]{2,1,0} broadcast(%mul.4334), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4336 = bf16[16,4,64]{2,1,0} multiply(%slice.4323, %mul.4335), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4337 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4321), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4338 = bf16[16,64]{1,0} reshape(%mul.4337), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4339 = bf16[16,4,64]{2,1,0} broadcast(%mul.4338), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4340 = bf16[16,4,64]{2,1,0} multiply(%slice.4322, %mul.4339), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.4341 = bf16[16,4,64]{2,1,0} add(%mul.4336, %mul.4340), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.4342 = bf16[16,4,128]{2,1,0} concatenate(%sub.4332, %add.4341), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.4343 = bf16[16,512]{1,0} reshape(%concatenate.4342), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.4244 = bf16[16,4,128]{2,1,0} slice(%reshape.4241), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.4245 = bf16[16,512]{1,0} reshape(%slice.4244), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.4344 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_18_.454, %reshape.4319, %reshape.4343, %reshape.4245, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.4345 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.4344), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_19_.455 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(454), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[19]"}
  %jit__jax_attn_func_.4346 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.4344), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_18_self_attn_o_proj_weight__.99 = bf16[2048,4096]{1,0} parameter(98), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.18.self_attn.o_proj.weight\']"}
  %dot_general.4347 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.4346, %params_and_buffers__vllm_model_language_model_model_layers_18_self_attn_o_proj_weight__.99), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.4348 = f32[16,2048]{1,0} convert(%dot_general.4347), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4219 = bf16[16,2048]{1,0} convert(%add.4218), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4349 = f32[16,2048]{1,0} convert(%convert_element_type.4219), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.4350 = f32[16,2048]{1,0} add(%convert_element_type.4348, %convert_element_type.4349), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.4352 = f32[16,2048]{1,0} power(%add.4350, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4357 = f32[16]{0} reduce(%pow.4352, %constant.512), dimensions={1}, to_apply=%region_105.4356, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4358 = f32[16,1]{1,0} reshape(%reduce_sum.4357), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4359 = f32[16,1]{1,0} divide(%broadcast_in_dim.4358, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4360 = f32[16,1]{1,0} add(%div.4359, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4361 = f32[16,1]{1,0} rsqrt(%add.4360), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4362 = f32[16,1]{1,0} broadcast(%rsqrt.4361), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4363 = f32[16]{0} reshape(%mul.4362), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4364 = f32[16,2048]{1,0} broadcast(%mul.4363), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4365 = f32[16,2048]{1,0} multiply(%add.4350, %mul.4364), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4366 = bf16[16,2048]{1,0} convert(%mul.4365), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_18_post_attention_layernorm_weight__.97 = bf16[2048]{0} parameter(96), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.18.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.4367 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_18_post_attention_layernorm_weight__.97), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4368 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.4367), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4369 = bf16[2048]{0} reshape(%mul.4368), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4370 = bf16[16,2048]{1,0} broadcast(%mul.4369), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4371 = bf16[16,2048]{1,0} multiply(%convert_element_type.4366, %mul.4370), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_18_mlp_experts_w13_weight__.94 = bf16[128,1536,2048]{2,1,0} parameter(93), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.18.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_18_mlp_experts_w2_weight__.95 = bf16[128,2048,768]{2,1,0} parameter(94), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.18.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_18_mlp_gate_weight__.96 = bf16[128,2048]{1,0} parameter(95), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.18.mlp.gate.weight\']"}
  %dot_general.4372 = bf16[16,128]{1,0} dot(%mul.4371, %params_and_buffers__vllm_model_language_model_model_layers_18_mlp_gate_weight__.96), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.4373 = bf16[16,2048]{1,0} call(%mul.4371, %params_and_buffers__vllm_model_language_model_model_layers_18_mlp_experts_w13_weight__.94, %params_and_buffers__vllm_model_language_model_model_layers_18_mlp_experts_w2_weight__.95, %dot_general.4372), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.4374 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.4373), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4351 = bf16[16,2048]{1,0} convert(%add.4350), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4375 = f32[16,2048]{1,0} convert(%convert_element_type.4351), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.4376 = f32[16,2048]{1,0} add(%convert_element_type.4374, %convert_element_type.4375), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.4378 = f32[16,2048]{1,0} power(%add.4376, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4383 = f32[16]{0} reduce(%pow.4378, %constant.512), dimensions={1}, to_apply=%region_106.4382, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4384 = f32[16,1]{1,0} reshape(%reduce_sum.4383), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4385 = f32[16,1]{1,0} divide(%broadcast_in_dim.4384, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4386 = f32[16,1]{1,0} add(%div.4385, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4387 = f32[16,1]{1,0} rsqrt(%add.4386), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4388 = f32[16,1]{1,0} broadcast(%rsqrt.4387), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4389 = f32[16]{0} reshape(%mul.4388), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4390 = f32[16,2048]{1,0} broadcast(%mul.4389), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4391 = f32[16,2048]{1,0} multiply(%add.4376, %mul.4390), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4392 = bf16[16,2048]{1,0} convert(%mul.4391), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_19_input_layernorm_weight__.102 = bf16[2048]{0} parameter(101), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.19.input_layernorm.weight\']"}
  %broadcast_in_dim.4393 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_19_input_layernorm_weight__.102), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4394 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.4393), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4395 = bf16[2048]{0} reshape(%mul.4394), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4396 = bf16[16,2048]{1,0} broadcast(%mul.4395), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4397 = bf16[16,2048]{1,0} multiply(%convert_element_type.4392, %mul.4396), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_19_self_attn_qkv_proj_weight__.110 = bf16[5120,2048]{1,0} parameter(109), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.19.self_attn.qkv_proj.weight\']"}
  %dot_general.4398 = bf16[16,5120]{1,0} dot(%mul.4397, %params_and_buffers__vllm_model_language_model_model_layers_19_self_attn_qkv_proj_weight__.110), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.4399 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.4398), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.4400 = bf16[16,4,1024]{2,1,0} slice(%reshape.4399), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.4404 = bf16[16,32,128]{2,1,0} reshape(%slice.4400), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.4405 = f32[16,32,128]{2,1,0} convert(%reshape.4404), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.4406 = f32[16,32,128]{2,1,0} power(%convert_element_type.4405, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4411 = f32[16,32]{1,0} reduce(%pow.4406, %constant.512), dimensions={2}, to_apply=%region_107.4410, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4412 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.4411), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4413 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.4412, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4414 = f32[16,32,1]{2,1,0} add(%div.4413, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4415 = f32[16,32,1]{2,1,0} rsqrt(%add.4414), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4416 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.4415), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4417 = f32[16,32]{1,0} reshape(%mul.4416), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4418 = f32[16,32,128]{2,1,0} broadcast(%mul.4417), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4419 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.4405, %mul.4418), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4420 = bf16[16,32,128]{2,1,0} convert(%mul.4419), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_19_self_attn_q_norm_weight__.109 = bf16[128]{0} parameter(108), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.19.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.4421 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_19_self_attn_q_norm_weight__.109), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4422 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.4421), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4423 = bf16[128]{0} reshape(%mul.4422), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4424 = bf16[16,32,128]{2,1,0} broadcast(%mul.4423), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4425 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.4420, %mul.4424), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4456 = bf16[16,32,64]{2,1,0} slice(%mul.4425), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.4447 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.4448 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.4449 = s32[16]{0} select(%lt.4447, %add.4448, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.4450 = s32[16,1]{1,0} reshape(%select_n.4449), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.4451 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.4450), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.4452 = bf16[16,64]{1,0} slice(%gather.4451), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4454 = bf16[16,1,64]{2,1,0} reshape(%slice.4452), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4458 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4454), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4459 = bf16[16,64]{1,0} reshape(%mul.4458), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4460 = bf16[16,32,64]{2,1,0} broadcast(%mul.4459), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4461 = bf16[16,32,64]{2,1,0} multiply(%slice.4456, %mul.4460), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4457 = bf16[16,32,64]{2,1,0} slice(%mul.4425), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.4453 = bf16[16,64]{1,0} slice(%gather.4451), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4455 = bf16[16,1,64]{2,1,0} reshape(%slice.4453), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4462 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4455), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4463 = bf16[16,64]{1,0} reshape(%mul.4462), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4464 = bf16[16,32,64]{2,1,0} broadcast(%mul.4463), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4465 = bf16[16,32,64]{2,1,0} multiply(%slice.4457, %mul.4464), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.4466 = bf16[16,32,64]{2,1,0} subtract(%mul.4461, %mul.4465), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.4467 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4454), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4468 = bf16[16,64]{1,0} reshape(%mul.4467), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4469 = bf16[16,32,64]{2,1,0} broadcast(%mul.4468), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4470 = bf16[16,32,64]{2,1,0} multiply(%slice.4457, %mul.4469), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4471 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4455), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4472 = bf16[16,64]{1,0} reshape(%mul.4471), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4473 = bf16[16,32,64]{2,1,0} broadcast(%mul.4472), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4474 = bf16[16,32,64]{2,1,0} multiply(%slice.4456, %mul.4473), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.4475 = bf16[16,32,64]{2,1,0} add(%mul.4470, %mul.4474), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.4476 = bf16[16,32,128]{2,1,0} concatenate(%sub.4466, %add.4475), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.4477 = bf16[16,4096]{1,0} reshape(%concatenate.4476), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.4401 = bf16[16,4,128]{2,1,0} slice(%reshape.4399), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.4426 = f32[16,4,128]{2,1,0} convert(%slice.4401), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.4427 = f32[16,4,128]{2,1,0} power(%convert_element_type.4426, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4432 = f32[16,4]{1,0} reduce(%pow.4427, %constant.512), dimensions={2}, to_apply=%region_108.4431, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4433 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.4432), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4434 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.4433, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4435 = f32[16,4,1]{2,1,0} add(%div.4434, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4436 = f32[16,4,1]{2,1,0} rsqrt(%add.4435), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4437 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.4436), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4438 = f32[16,4]{1,0} reshape(%mul.4437), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4439 = f32[16,4,128]{2,1,0} broadcast(%mul.4438), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4440 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.4426, %mul.4439), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4441 = bf16[16,4,128]{2,1,0} convert(%mul.4440), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_19_self_attn_k_norm_weight__.107 = bf16[128]{0} parameter(106), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.19.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.4442 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_19_self_attn_k_norm_weight__.107), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4443 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.4442), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4444 = bf16[128]{0} reshape(%mul.4443), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4445 = bf16[16,4,128]{2,1,0} broadcast(%mul.4444), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4446 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.4441, %mul.4445), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4480 = bf16[16,4,64]{2,1,0} slice(%mul.4446), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4478 = bf16[16,1,64]{2,1,0} reshape(%slice.4452), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4482 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4478), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4483 = bf16[16,64]{1,0} reshape(%mul.4482), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4484 = bf16[16,4,64]{2,1,0} broadcast(%mul.4483), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4485 = bf16[16,4,64]{2,1,0} multiply(%slice.4480, %mul.4484), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4481 = bf16[16,4,64]{2,1,0} slice(%mul.4446), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4479 = bf16[16,1,64]{2,1,0} reshape(%slice.4453), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4486 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4479), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4487 = bf16[16,64]{1,0} reshape(%mul.4486), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4488 = bf16[16,4,64]{2,1,0} broadcast(%mul.4487), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4489 = bf16[16,4,64]{2,1,0} multiply(%slice.4481, %mul.4488), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.4490 = bf16[16,4,64]{2,1,0} subtract(%mul.4485, %mul.4489), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.4491 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4478), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4492 = bf16[16,64]{1,0} reshape(%mul.4491), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4493 = bf16[16,4,64]{2,1,0} broadcast(%mul.4492), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4494 = bf16[16,4,64]{2,1,0} multiply(%slice.4481, %mul.4493), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4495 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4479), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4496 = bf16[16,64]{1,0} reshape(%mul.4495), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4497 = bf16[16,4,64]{2,1,0} broadcast(%mul.4496), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4498 = bf16[16,4,64]{2,1,0} multiply(%slice.4480, %mul.4497), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.4499 = bf16[16,4,64]{2,1,0} add(%mul.4494, %mul.4498), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.4500 = bf16[16,4,128]{2,1,0} concatenate(%sub.4490, %add.4499), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.4501 = bf16[16,512]{1,0} reshape(%concatenate.4500), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.4402 = bf16[16,4,128]{2,1,0} slice(%reshape.4399), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.4403 = bf16[16,512]{1,0} reshape(%slice.4402), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.4502 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_19_.455, %reshape.4477, %reshape.4501, %reshape.4403, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.4503 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.4502), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_20_.456 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(455), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[20]"}
  %jit__jax_attn_func_.4504 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.4502), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_19_self_attn_o_proj_weight__.108 = bf16[2048,4096]{1,0} parameter(107), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.19.self_attn.o_proj.weight\']"}
  %dot_general.4505 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.4504, %params_and_buffers__vllm_model_language_model_model_layers_19_self_attn_o_proj_weight__.108), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.4506 = f32[16,2048]{1,0} convert(%dot_general.4505), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4377 = bf16[16,2048]{1,0} convert(%add.4376), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4507 = f32[16,2048]{1,0} convert(%convert_element_type.4377), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.4508 = f32[16,2048]{1,0} add(%convert_element_type.4506, %convert_element_type.4507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.4510 = f32[16,2048]{1,0} power(%add.4508, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4515 = f32[16]{0} reduce(%pow.4510, %constant.512), dimensions={1}, to_apply=%region_109.4514, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4516 = f32[16,1]{1,0} reshape(%reduce_sum.4515), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4517 = f32[16,1]{1,0} divide(%broadcast_in_dim.4516, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4518 = f32[16,1]{1,0} add(%div.4517, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4519 = f32[16,1]{1,0} rsqrt(%add.4518), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4520 = f32[16,1]{1,0} broadcast(%rsqrt.4519), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4521 = f32[16]{0} reshape(%mul.4520), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4522 = f32[16,2048]{1,0} broadcast(%mul.4521), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4523 = f32[16,2048]{1,0} multiply(%add.4508, %mul.4522), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4524 = bf16[16,2048]{1,0} convert(%mul.4523), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_19_post_attention_layernorm_weight__.106 = bf16[2048]{0} parameter(105), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.19.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.4525 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_19_post_attention_layernorm_weight__.106), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4526 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.4525), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4527 = bf16[2048]{0} reshape(%mul.4526), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4528 = bf16[16,2048]{1,0} broadcast(%mul.4527), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4529 = bf16[16,2048]{1,0} multiply(%convert_element_type.4524, %mul.4528), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_19_mlp_experts_w13_weight__.103 = bf16[128,1536,2048]{2,1,0} parameter(102), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.19.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_19_mlp_experts_w2_weight__.104 = bf16[128,2048,768]{2,1,0} parameter(103), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.19.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_19_mlp_gate_weight__.105 = bf16[128,2048]{1,0} parameter(104), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.19.mlp.gate.weight\']"}
  %dot_general.4530 = bf16[16,128]{1,0} dot(%mul.4529, %params_and_buffers__vllm_model_language_model_model_layers_19_mlp_gate_weight__.105), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.4531 = bf16[16,2048]{1,0} call(%mul.4529, %params_and_buffers__vllm_model_language_model_model_layers_19_mlp_experts_w13_weight__.103, %params_and_buffers__vllm_model_language_model_model_layers_19_mlp_experts_w2_weight__.104, %dot_general.4530), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.4532 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.4531), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4509 = bf16[16,2048]{1,0} convert(%add.4508), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4533 = f32[16,2048]{1,0} convert(%convert_element_type.4509), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.4534 = f32[16,2048]{1,0} add(%convert_element_type.4532, %convert_element_type.4533), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.4536 = f32[16,2048]{1,0} power(%add.4534, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4541 = f32[16]{0} reduce(%pow.4536, %constant.512), dimensions={1}, to_apply=%region_110.4540, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4542 = f32[16,1]{1,0} reshape(%reduce_sum.4541), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4543 = f32[16,1]{1,0} divide(%broadcast_in_dim.4542, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4544 = f32[16,1]{1,0} add(%div.4543, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4545 = f32[16,1]{1,0} rsqrt(%add.4544), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4546 = f32[16,1]{1,0} broadcast(%rsqrt.4545), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4547 = f32[16]{0} reshape(%mul.4546), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4548 = f32[16,2048]{1,0} broadcast(%mul.4547), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4549 = f32[16,2048]{1,0} multiply(%add.4534, %mul.4548), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4550 = bf16[16,2048]{1,0} convert(%mul.4549), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_20_input_layernorm_weight__.120 = bf16[2048]{0} parameter(119), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.20.input_layernorm.weight\']"}
  %broadcast_in_dim.4551 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_20_input_layernorm_weight__.120), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4552 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.4551), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4553 = bf16[2048]{0} reshape(%mul.4552), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4554 = bf16[16,2048]{1,0} broadcast(%mul.4553), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4555 = bf16[16,2048]{1,0} multiply(%convert_element_type.4550, %mul.4554), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_20_self_attn_qkv_proj_weight__.128 = bf16[5120,2048]{1,0} parameter(127), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.20.self_attn.qkv_proj.weight\']"}
  %dot_general.4556 = bf16[16,5120]{1,0} dot(%mul.4555, %params_and_buffers__vllm_model_language_model_model_layers_20_self_attn_qkv_proj_weight__.128), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.4557 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.4556), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.4558 = bf16[16,4,1024]{2,1,0} slice(%reshape.4557), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.4562 = bf16[16,32,128]{2,1,0} reshape(%slice.4558), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.4563 = f32[16,32,128]{2,1,0} convert(%reshape.4562), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.4564 = f32[16,32,128]{2,1,0} power(%convert_element_type.4563, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4569 = f32[16,32]{1,0} reduce(%pow.4564, %constant.512), dimensions={2}, to_apply=%region_111.4568, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4570 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.4569), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4571 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.4570, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4572 = f32[16,32,1]{2,1,0} add(%div.4571, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4573 = f32[16,32,1]{2,1,0} rsqrt(%add.4572), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4574 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.4573), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4575 = f32[16,32]{1,0} reshape(%mul.4574), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4576 = f32[16,32,128]{2,1,0} broadcast(%mul.4575), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4577 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.4563, %mul.4576), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4578 = bf16[16,32,128]{2,1,0} convert(%mul.4577), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_20_self_attn_q_norm_weight__.127 = bf16[128]{0} parameter(126), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.20.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.4579 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_20_self_attn_q_norm_weight__.127), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4580 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.4579), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4581 = bf16[128]{0} reshape(%mul.4580), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4582 = bf16[16,32,128]{2,1,0} broadcast(%mul.4581), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4583 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.4578, %mul.4582), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4614 = bf16[16,32,64]{2,1,0} slice(%mul.4583), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.4605 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.4606 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.4607 = s32[16]{0} select(%lt.4605, %add.4606, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.4608 = s32[16,1]{1,0} reshape(%select_n.4607), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.4609 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.4608), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.4610 = bf16[16,64]{1,0} slice(%gather.4609), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4612 = bf16[16,1,64]{2,1,0} reshape(%slice.4610), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4616 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4612), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4617 = bf16[16,64]{1,0} reshape(%mul.4616), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4618 = bf16[16,32,64]{2,1,0} broadcast(%mul.4617), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4619 = bf16[16,32,64]{2,1,0} multiply(%slice.4614, %mul.4618), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4615 = bf16[16,32,64]{2,1,0} slice(%mul.4583), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.4611 = bf16[16,64]{1,0} slice(%gather.4609), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4613 = bf16[16,1,64]{2,1,0} reshape(%slice.4611), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4620 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4613), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4621 = bf16[16,64]{1,0} reshape(%mul.4620), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4622 = bf16[16,32,64]{2,1,0} broadcast(%mul.4621), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4623 = bf16[16,32,64]{2,1,0} multiply(%slice.4615, %mul.4622), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.4624 = bf16[16,32,64]{2,1,0} subtract(%mul.4619, %mul.4623), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.4625 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4612), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4626 = bf16[16,64]{1,0} reshape(%mul.4625), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4627 = bf16[16,32,64]{2,1,0} broadcast(%mul.4626), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4628 = bf16[16,32,64]{2,1,0} multiply(%slice.4615, %mul.4627), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4629 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4613), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4630 = bf16[16,64]{1,0} reshape(%mul.4629), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4631 = bf16[16,32,64]{2,1,0} broadcast(%mul.4630), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4632 = bf16[16,32,64]{2,1,0} multiply(%slice.4614, %mul.4631), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.4633 = bf16[16,32,64]{2,1,0} add(%mul.4628, %mul.4632), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.4634 = bf16[16,32,128]{2,1,0} concatenate(%sub.4624, %add.4633), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.4635 = bf16[16,4096]{1,0} reshape(%concatenate.4634), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.4559 = bf16[16,4,128]{2,1,0} slice(%reshape.4557), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.4584 = f32[16,4,128]{2,1,0} convert(%slice.4559), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.4585 = f32[16,4,128]{2,1,0} power(%convert_element_type.4584, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4590 = f32[16,4]{1,0} reduce(%pow.4585, %constant.512), dimensions={2}, to_apply=%region_112.4589, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4591 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.4590), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4592 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.4591, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4593 = f32[16,4,1]{2,1,0} add(%div.4592, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4594 = f32[16,4,1]{2,1,0} rsqrt(%add.4593), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4595 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.4594), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4596 = f32[16,4]{1,0} reshape(%mul.4595), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4597 = f32[16,4,128]{2,1,0} broadcast(%mul.4596), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4598 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.4584, %mul.4597), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4599 = bf16[16,4,128]{2,1,0} convert(%mul.4598), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_20_self_attn_k_norm_weight__.125 = bf16[128]{0} parameter(124), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.20.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.4600 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_20_self_attn_k_norm_weight__.125), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4601 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.4600), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4602 = bf16[128]{0} reshape(%mul.4601), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4603 = bf16[16,4,128]{2,1,0} broadcast(%mul.4602), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4604 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.4599, %mul.4603), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4638 = bf16[16,4,64]{2,1,0} slice(%mul.4604), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4636 = bf16[16,1,64]{2,1,0} reshape(%slice.4610), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4640 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4636), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4641 = bf16[16,64]{1,0} reshape(%mul.4640), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4642 = bf16[16,4,64]{2,1,0} broadcast(%mul.4641), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4643 = bf16[16,4,64]{2,1,0} multiply(%slice.4638, %mul.4642), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4639 = bf16[16,4,64]{2,1,0} slice(%mul.4604), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4637 = bf16[16,1,64]{2,1,0} reshape(%slice.4611), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4644 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4637), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4645 = bf16[16,64]{1,0} reshape(%mul.4644), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4646 = bf16[16,4,64]{2,1,0} broadcast(%mul.4645), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4647 = bf16[16,4,64]{2,1,0} multiply(%slice.4639, %mul.4646), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.4648 = bf16[16,4,64]{2,1,0} subtract(%mul.4643, %mul.4647), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.4649 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4636), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4650 = bf16[16,64]{1,0} reshape(%mul.4649), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4651 = bf16[16,4,64]{2,1,0} broadcast(%mul.4650), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4652 = bf16[16,4,64]{2,1,0} multiply(%slice.4639, %mul.4651), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4653 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4637), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4654 = bf16[16,64]{1,0} reshape(%mul.4653), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4655 = bf16[16,4,64]{2,1,0} broadcast(%mul.4654), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4656 = bf16[16,4,64]{2,1,0} multiply(%slice.4638, %mul.4655), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.4657 = bf16[16,4,64]{2,1,0} add(%mul.4652, %mul.4656), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.4658 = bf16[16,4,128]{2,1,0} concatenate(%sub.4648, %add.4657), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.4659 = bf16[16,512]{1,0} reshape(%concatenate.4658), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.4560 = bf16[16,4,128]{2,1,0} slice(%reshape.4557), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.4561 = bf16[16,512]{1,0} reshape(%slice.4560), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.4660 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_20_.456, %reshape.4635, %reshape.4659, %reshape.4561, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.4661 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.4660), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_21_.457 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(456), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[21]"}
  %jit__jax_attn_func_.4662 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.4660), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_20_self_attn_o_proj_weight__.126 = bf16[2048,4096]{1,0} parameter(125), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.20.self_attn.o_proj.weight\']"}
  %dot_general.4663 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.4662, %params_and_buffers__vllm_model_language_model_model_layers_20_self_attn_o_proj_weight__.126), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.4664 = f32[16,2048]{1,0} convert(%dot_general.4663), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4535 = bf16[16,2048]{1,0} convert(%add.4534), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4665 = f32[16,2048]{1,0} convert(%convert_element_type.4535), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.4666 = f32[16,2048]{1,0} add(%convert_element_type.4664, %convert_element_type.4665), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.4668 = f32[16,2048]{1,0} power(%add.4666, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4673 = f32[16]{0} reduce(%pow.4668, %constant.512), dimensions={1}, to_apply=%region_113.4672, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4674 = f32[16,1]{1,0} reshape(%reduce_sum.4673), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4675 = f32[16,1]{1,0} divide(%broadcast_in_dim.4674, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4676 = f32[16,1]{1,0} add(%div.4675, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4677 = f32[16,1]{1,0} rsqrt(%add.4676), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4678 = f32[16,1]{1,0} broadcast(%rsqrt.4677), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4679 = f32[16]{0} reshape(%mul.4678), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4680 = f32[16,2048]{1,0} broadcast(%mul.4679), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4681 = f32[16,2048]{1,0} multiply(%add.4666, %mul.4680), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4682 = bf16[16,2048]{1,0} convert(%mul.4681), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_20_post_attention_layernorm_weight__.124 = bf16[2048]{0} parameter(123), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.20.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.4683 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_20_post_attention_layernorm_weight__.124), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4684 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.4683), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4685 = bf16[2048]{0} reshape(%mul.4684), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4686 = bf16[16,2048]{1,0} broadcast(%mul.4685), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4687 = bf16[16,2048]{1,0} multiply(%convert_element_type.4682, %mul.4686), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_20_mlp_experts_w13_weight__.121 = bf16[128,1536,2048]{2,1,0} parameter(120), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.20.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_20_mlp_experts_w2_weight__.122 = bf16[128,2048,768]{2,1,0} parameter(121), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.20.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_20_mlp_gate_weight__.123 = bf16[128,2048]{1,0} parameter(122), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.20.mlp.gate.weight\']"}
  %dot_general.4688 = bf16[16,128]{1,0} dot(%mul.4687, %params_and_buffers__vllm_model_language_model_model_layers_20_mlp_gate_weight__.123), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.4689 = bf16[16,2048]{1,0} call(%mul.4687, %params_and_buffers__vllm_model_language_model_model_layers_20_mlp_experts_w13_weight__.121, %params_and_buffers__vllm_model_language_model_model_layers_20_mlp_experts_w2_weight__.122, %dot_general.4688), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.4690 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.4689), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4667 = bf16[16,2048]{1,0} convert(%add.4666), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4691 = f32[16,2048]{1,0} convert(%convert_element_type.4667), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.4692 = f32[16,2048]{1,0} add(%convert_element_type.4690, %convert_element_type.4691), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.4694 = f32[16,2048]{1,0} power(%add.4692, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4699 = f32[16]{0} reduce(%pow.4694, %constant.512), dimensions={1}, to_apply=%region_114.4698, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4700 = f32[16,1]{1,0} reshape(%reduce_sum.4699), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4701 = f32[16,1]{1,0} divide(%broadcast_in_dim.4700, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4702 = f32[16,1]{1,0} add(%div.4701, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4703 = f32[16,1]{1,0} rsqrt(%add.4702), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4704 = f32[16,1]{1,0} broadcast(%rsqrt.4703), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4705 = f32[16]{0} reshape(%mul.4704), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4706 = f32[16,2048]{1,0} broadcast(%mul.4705), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4707 = f32[16,2048]{1,0} multiply(%add.4692, %mul.4706), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4708 = bf16[16,2048]{1,0} convert(%mul.4707), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_21_input_layernorm_weight__.129 = bf16[2048]{0} parameter(128), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.21.input_layernorm.weight\']"}
  %broadcast_in_dim.4709 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_21_input_layernorm_weight__.129), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4710 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.4709), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4711 = bf16[2048]{0} reshape(%mul.4710), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4712 = bf16[16,2048]{1,0} broadcast(%mul.4711), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4713 = bf16[16,2048]{1,0} multiply(%convert_element_type.4708, %mul.4712), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_21_self_attn_qkv_proj_weight__.137 = bf16[5120,2048]{1,0} parameter(136), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.21.self_attn.qkv_proj.weight\']"}
  %dot_general.4714 = bf16[16,5120]{1,0} dot(%mul.4713, %params_and_buffers__vllm_model_language_model_model_layers_21_self_attn_qkv_proj_weight__.137), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.4715 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.4714), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.4716 = bf16[16,4,1024]{2,1,0} slice(%reshape.4715), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.4720 = bf16[16,32,128]{2,1,0} reshape(%slice.4716), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.4721 = f32[16,32,128]{2,1,0} convert(%reshape.4720), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.4722 = f32[16,32,128]{2,1,0} power(%convert_element_type.4721, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4727 = f32[16,32]{1,0} reduce(%pow.4722, %constant.512), dimensions={2}, to_apply=%region_115.4726, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4728 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.4727), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4729 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.4728, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4730 = f32[16,32,1]{2,1,0} add(%div.4729, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4731 = f32[16,32,1]{2,1,0} rsqrt(%add.4730), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4732 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.4731), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4733 = f32[16,32]{1,0} reshape(%mul.4732), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4734 = f32[16,32,128]{2,1,0} broadcast(%mul.4733), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4735 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.4721, %mul.4734), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4736 = bf16[16,32,128]{2,1,0} convert(%mul.4735), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_21_self_attn_q_norm_weight__.136 = bf16[128]{0} parameter(135), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.21.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.4737 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_21_self_attn_q_norm_weight__.136), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4738 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.4737), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4739 = bf16[128]{0} reshape(%mul.4738), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4740 = bf16[16,32,128]{2,1,0} broadcast(%mul.4739), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4741 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.4736, %mul.4740), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4772 = bf16[16,32,64]{2,1,0} slice(%mul.4741), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.4763 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.4764 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.4765 = s32[16]{0} select(%lt.4763, %add.4764, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.4766 = s32[16,1]{1,0} reshape(%select_n.4765), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.4767 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.4766), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.4768 = bf16[16,64]{1,0} slice(%gather.4767), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4770 = bf16[16,1,64]{2,1,0} reshape(%slice.4768), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4774 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4770), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4775 = bf16[16,64]{1,0} reshape(%mul.4774), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4776 = bf16[16,32,64]{2,1,0} broadcast(%mul.4775), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4777 = bf16[16,32,64]{2,1,0} multiply(%slice.4772, %mul.4776), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4773 = bf16[16,32,64]{2,1,0} slice(%mul.4741), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.4769 = bf16[16,64]{1,0} slice(%gather.4767), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4771 = bf16[16,1,64]{2,1,0} reshape(%slice.4769), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4778 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4771), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4779 = bf16[16,64]{1,0} reshape(%mul.4778), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4780 = bf16[16,32,64]{2,1,0} broadcast(%mul.4779), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4781 = bf16[16,32,64]{2,1,0} multiply(%slice.4773, %mul.4780), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.4782 = bf16[16,32,64]{2,1,0} subtract(%mul.4777, %mul.4781), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.4783 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4770), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4784 = bf16[16,64]{1,0} reshape(%mul.4783), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4785 = bf16[16,32,64]{2,1,0} broadcast(%mul.4784), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4786 = bf16[16,32,64]{2,1,0} multiply(%slice.4773, %mul.4785), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4787 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4771), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4788 = bf16[16,64]{1,0} reshape(%mul.4787), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4789 = bf16[16,32,64]{2,1,0} broadcast(%mul.4788), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4790 = bf16[16,32,64]{2,1,0} multiply(%slice.4772, %mul.4789), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.4791 = bf16[16,32,64]{2,1,0} add(%mul.4786, %mul.4790), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.4792 = bf16[16,32,128]{2,1,0} concatenate(%sub.4782, %add.4791), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.4793 = bf16[16,4096]{1,0} reshape(%concatenate.4792), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.4717 = bf16[16,4,128]{2,1,0} slice(%reshape.4715), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.4742 = f32[16,4,128]{2,1,0} convert(%slice.4717), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.4743 = f32[16,4,128]{2,1,0} power(%convert_element_type.4742, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4748 = f32[16,4]{1,0} reduce(%pow.4743, %constant.512), dimensions={2}, to_apply=%region_116.4747, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4749 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.4748), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4750 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.4749, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4751 = f32[16,4,1]{2,1,0} add(%div.4750, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4752 = f32[16,4,1]{2,1,0} rsqrt(%add.4751), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4753 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.4752), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4754 = f32[16,4]{1,0} reshape(%mul.4753), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4755 = f32[16,4,128]{2,1,0} broadcast(%mul.4754), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4756 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.4742, %mul.4755), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4757 = bf16[16,4,128]{2,1,0} convert(%mul.4756), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_21_self_attn_k_norm_weight__.134 = bf16[128]{0} parameter(133), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.21.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.4758 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_21_self_attn_k_norm_weight__.134), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4759 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.4758), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4760 = bf16[128]{0} reshape(%mul.4759), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4761 = bf16[16,4,128]{2,1,0} broadcast(%mul.4760), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4762 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.4757, %mul.4761), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4796 = bf16[16,4,64]{2,1,0} slice(%mul.4762), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4794 = bf16[16,1,64]{2,1,0} reshape(%slice.4768), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4798 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4794), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4799 = bf16[16,64]{1,0} reshape(%mul.4798), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4800 = bf16[16,4,64]{2,1,0} broadcast(%mul.4799), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4801 = bf16[16,4,64]{2,1,0} multiply(%slice.4796, %mul.4800), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4797 = bf16[16,4,64]{2,1,0} slice(%mul.4762), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4795 = bf16[16,1,64]{2,1,0} reshape(%slice.4769), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4802 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4795), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4803 = bf16[16,64]{1,0} reshape(%mul.4802), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4804 = bf16[16,4,64]{2,1,0} broadcast(%mul.4803), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4805 = bf16[16,4,64]{2,1,0} multiply(%slice.4797, %mul.4804), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.4806 = bf16[16,4,64]{2,1,0} subtract(%mul.4801, %mul.4805), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.4807 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4794), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4808 = bf16[16,64]{1,0} reshape(%mul.4807), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4809 = bf16[16,4,64]{2,1,0} broadcast(%mul.4808), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4810 = bf16[16,4,64]{2,1,0} multiply(%slice.4797, %mul.4809), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4811 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4795), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4812 = bf16[16,64]{1,0} reshape(%mul.4811), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4813 = bf16[16,4,64]{2,1,0} broadcast(%mul.4812), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4814 = bf16[16,4,64]{2,1,0} multiply(%slice.4796, %mul.4813), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.4815 = bf16[16,4,64]{2,1,0} add(%mul.4810, %mul.4814), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.4816 = bf16[16,4,128]{2,1,0} concatenate(%sub.4806, %add.4815), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.4817 = bf16[16,512]{1,0} reshape(%concatenate.4816), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.4718 = bf16[16,4,128]{2,1,0} slice(%reshape.4715), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.4719 = bf16[16,512]{1,0} reshape(%slice.4718), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.4818 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_21_.457, %reshape.4793, %reshape.4817, %reshape.4719, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.4819 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.4818), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_22_.458 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(457), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[22]"}
  %jit__jax_attn_func_.4820 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.4818), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_21_self_attn_o_proj_weight__.135 = bf16[2048,4096]{1,0} parameter(134), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.21.self_attn.o_proj.weight\']"}
  %dot_general.4821 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.4820, %params_and_buffers__vllm_model_language_model_model_layers_21_self_attn_o_proj_weight__.135), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.4822 = f32[16,2048]{1,0} convert(%dot_general.4821), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4693 = bf16[16,2048]{1,0} convert(%add.4692), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4823 = f32[16,2048]{1,0} convert(%convert_element_type.4693), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.4824 = f32[16,2048]{1,0} add(%convert_element_type.4822, %convert_element_type.4823), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.4826 = f32[16,2048]{1,0} power(%add.4824, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4831 = f32[16]{0} reduce(%pow.4826, %constant.512), dimensions={1}, to_apply=%region_117.4830, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4832 = f32[16,1]{1,0} reshape(%reduce_sum.4831), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4833 = f32[16,1]{1,0} divide(%broadcast_in_dim.4832, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4834 = f32[16,1]{1,0} add(%div.4833, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4835 = f32[16,1]{1,0} rsqrt(%add.4834), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4836 = f32[16,1]{1,0} broadcast(%rsqrt.4835), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4837 = f32[16]{0} reshape(%mul.4836), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4838 = f32[16,2048]{1,0} broadcast(%mul.4837), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4839 = f32[16,2048]{1,0} multiply(%add.4824, %mul.4838), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4840 = bf16[16,2048]{1,0} convert(%mul.4839), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_21_post_attention_layernorm_weight__.133 = bf16[2048]{0} parameter(132), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.21.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.4841 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_21_post_attention_layernorm_weight__.133), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4842 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.4841), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4843 = bf16[2048]{0} reshape(%mul.4842), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4844 = bf16[16,2048]{1,0} broadcast(%mul.4843), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4845 = bf16[16,2048]{1,0} multiply(%convert_element_type.4840, %mul.4844), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_21_mlp_experts_w13_weight__.130 = bf16[128,1536,2048]{2,1,0} parameter(129), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.21.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_21_mlp_experts_w2_weight__.131 = bf16[128,2048,768]{2,1,0} parameter(130), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.21.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_21_mlp_gate_weight__.132 = bf16[128,2048]{1,0} parameter(131), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.21.mlp.gate.weight\']"}
  %dot_general.4846 = bf16[16,128]{1,0} dot(%mul.4845, %params_and_buffers__vllm_model_language_model_model_layers_21_mlp_gate_weight__.132), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.4847 = bf16[16,2048]{1,0} call(%mul.4845, %params_and_buffers__vllm_model_language_model_model_layers_21_mlp_experts_w13_weight__.130, %params_and_buffers__vllm_model_language_model_model_layers_21_mlp_experts_w2_weight__.131, %dot_general.4846), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.4848 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.4847), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4825 = bf16[16,2048]{1,0} convert(%add.4824), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4849 = f32[16,2048]{1,0} convert(%convert_element_type.4825), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.4850 = f32[16,2048]{1,0} add(%convert_element_type.4848, %convert_element_type.4849), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.4852 = f32[16,2048]{1,0} power(%add.4850, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4857 = f32[16]{0} reduce(%pow.4852, %constant.512), dimensions={1}, to_apply=%region_118.4856, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4858 = f32[16,1]{1,0} reshape(%reduce_sum.4857), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4859 = f32[16,1]{1,0} divide(%broadcast_in_dim.4858, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4860 = f32[16,1]{1,0} add(%div.4859, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4861 = f32[16,1]{1,0} rsqrt(%add.4860), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4862 = f32[16,1]{1,0} broadcast(%rsqrt.4861), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4863 = f32[16]{0} reshape(%mul.4862), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4864 = f32[16,2048]{1,0} broadcast(%mul.4863), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4865 = f32[16,2048]{1,0} multiply(%add.4850, %mul.4864), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4866 = bf16[16,2048]{1,0} convert(%mul.4865), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_22_input_layernorm_weight__.138 = bf16[2048]{0} parameter(137), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.22.input_layernorm.weight\']"}
  %broadcast_in_dim.4867 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_22_input_layernorm_weight__.138), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4868 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.4867), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4869 = bf16[2048]{0} reshape(%mul.4868), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4870 = bf16[16,2048]{1,0} broadcast(%mul.4869), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4871 = bf16[16,2048]{1,0} multiply(%convert_element_type.4866, %mul.4870), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_22_self_attn_qkv_proj_weight__.146 = bf16[5120,2048]{1,0} parameter(145), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.22.self_attn.qkv_proj.weight\']"}
  %dot_general.4872 = bf16[16,5120]{1,0} dot(%mul.4871, %params_and_buffers__vllm_model_language_model_model_layers_22_self_attn_qkv_proj_weight__.146), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.4873 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.4872), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.4874 = bf16[16,4,1024]{2,1,0} slice(%reshape.4873), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.4878 = bf16[16,32,128]{2,1,0} reshape(%slice.4874), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.4879 = f32[16,32,128]{2,1,0} convert(%reshape.4878), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.4880 = f32[16,32,128]{2,1,0} power(%convert_element_type.4879, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4885 = f32[16,32]{1,0} reduce(%pow.4880, %constant.512), dimensions={2}, to_apply=%region_119.4884, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4886 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.4885), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4887 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.4886, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4888 = f32[16,32,1]{2,1,0} add(%div.4887, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4889 = f32[16,32,1]{2,1,0} rsqrt(%add.4888), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4890 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.4889), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4891 = f32[16,32]{1,0} reshape(%mul.4890), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4892 = f32[16,32,128]{2,1,0} broadcast(%mul.4891), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4893 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.4879, %mul.4892), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4894 = bf16[16,32,128]{2,1,0} convert(%mul.4893), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_22_self_attn_q_norm_weight__.145 = bf16[128]{0} parameter(144), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.22.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.4895 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_22_self_attn_q_norm_weight__.145), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4896 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.4895), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4897 = bf16[128]{0} reshape(%mul.4896), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4898 = bf16[16,32,128]{2,1,0} broadcast(%mul.4897), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4899 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.4894, %mul.4898), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4930 = bf16[16,32,64]{2,1,0} slice(%mul.4899), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.4921 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.4922 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.4923 = s32[16]{0} select(%lt.4921, %add.4922, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.4924 = s32[16,1]{1,0} reshape(%select_n.4923), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.4925 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.4924), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.4926 = bf16[16,64]{1,0} slice(%gather.4925), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4928 = bf16[16,1,64]{2,1,0} reshape(%slice.4926), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4932 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4928), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4933 = bf16[16,64]{1,0} reshape(%mul.4932), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4934 = bf16[16,32,64]{2,1,0} broadcast(%mul.4933), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4935 = bf16[16,32,64]{2,1,0} multiply(%slice.4930, %mul.4934), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4931 = bf16[16,32,64]{2,1,0} slice(%mul.4899), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.4927 = bf16[16,64]{1,0} slice(%gather.4925), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4929 = bf16[16,1,64]{2,1,0} reshape(%slice.4927), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4936 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4929), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4937 = bf16[16,64]{1,0} reshape(%mul.4936), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4938 = bf16[16,32,64]{2,1,0} broadcast(%mul.4937), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4939 = bf16[16,32,64]{2,1,0} multiply(%slice.4931, %mul.4938), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.4940 = bf16[16,32,64]{2,1,0} subtract(%mul.4935, %mul.4939), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.4941 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4928), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4942 = bf16[16,64]{1,0} reshape(%mul.4941), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4943 = bf16[16,32,64]{2,1,0} broadcast(%mul.4942), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4944 = bf16[16,32,64]{2,1,0} multiply(%slice.4931, %mul.4943), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4945 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4929), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4946 = bf16[16,64]{1,0} reshape(%mul.4945), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4947 = bf16[16,32,64]{2,1,0} broadcast(%mul.4946), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4948 = bf16[16,32,64]{2,1,0} multiply(%slice.4930, %mul.4947), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.4949 = bf16[16,32,64]{2,1,0} add(%mul.4944, %mul.4948), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.4950 = bf16[16,32,128]{2,1,0} concatenate(%sub.4940, %add.4949), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.4951 = bf16[16,4096]{1,0} reshape(%concatenate.4950), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.4875 = bf16[16,4,128]{2,1,0} slice(%reshape.4873), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.4900 = f32[16,4,128]{2,1,0} convert(%slice.4875), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.4901 = f32[16,4,128]{2,1,0} power(%convert_element_type.4900, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4906 = f32[16,4]{1,0} reduce(%pow.4901, %constant.512), dimensions={2}, to_apply=%region_120.4905, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4907 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.4906), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4908 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.4907, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4909 = f32[16,4,1]{2,1,0} add(%div.4908, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4910 = f32[16,4,1]{2,1,0} rsqrt(%add.4909), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4911 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.4910), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4912 = f32[16,4]{1,0} reshape(%mul.4911), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4913 = f32[16,4,128]{2,1,0} broadcast(%mul.4912), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4914 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.4900, %mul.4913), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4915 = bf16[16,4,128]{2,1,0} convert(%mul.4914), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_22_self_attn_k_norm_weight__.143 = bf16[128]{0} parameter(142), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.22.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.4916 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_22_self_attn_k_norm_weight__.143), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4917 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.4916), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4918 = bf16[128]{0} reshape(%mul.4917), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4919 = bf16[16,4,128]{2,1,0} broadcast(%mul.4918), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4920 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.4915, %mul.4919), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4954 = bf16[16,4,64]{2,1,0} slice(%mul.4920), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4952 = bf16[16,1,64]{2,1,0} reshape(%slice.4926), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4956 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4952), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4957 = bf16[16,64]{1,0} reshape(%mul.4956), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4958 = bf16[16,4,64]{2,1,0} broadcast(%mul.4957), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4959 = bf16[16,4,64]{2,1,0} multiply(%slice.4954, %mul.4958), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4955 = bf16[16,4,64]{2,1,0} slice(%mul.4920), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4953 = bf16[16,1,64]{2,1,0} reshape(%slice.4927), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4960 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4953), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4961 = bf16[16,64]{1,0} reshape(%mul.4960), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4962 = bf16[16,4,64]{2,1,0} broadcast(%mul.4961), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4963 = bf16[16,4,64]{2,1,0} multiply(%slice.4955, %mul.4962), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.4964 = bf16[16,4,64]{2,1,0} subtract(%mul.4959, %mul.4963), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.4965 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4952), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4966 = bf16[16,64]{1,0} reshape(%mul.4965), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4967 = bf16[16,4,64]{2,1,0} broadcast(%mul.4966), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4968 = bf16[16,4,64]{2,1,0} multiply(%slice.4955, %mul.4967), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4969 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.4953), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4970 = bf16[16,64]{1,0} reshape(%mul.4969), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4971 = bf16[16,4,64]{2,1,0} broadcast(%mul.4970), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4972 = bf16[16,4,64]{2,1,0} multiply(%slice.4954, %mul.4971), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.4973 = bf16[16,4,64]{2,1,0} add(%mul.4968, %mul.4972), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.4974 = bf16[16,4,128]{2,1,0} concatenate(%sub.4964, %add.4973), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.4975 = bf16[16,512]{1,0} reshape(%concatenate.4974), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.4876 = bf16[16,4,128]{2,1,0} slice(%reshape.4873), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.4877 = bf16[16,512]{1,0} reshape(%slice.4876), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.4976 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_22_.458, %reshape.4951, %reshape.4975, %reshape.4877, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.4977 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.4976), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_23_.459 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(458), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[23]"}
  %jit__jax_attn_func_.4978 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.4976), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_22_self_attn_o_proj_weight__.144 = bf16[2048,4096]{1,0} parameter(143), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.22.self_attn.o_proj.weight\']"}
  %dot_general.4979 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.4978, %params_and_buffers__vllm_model_language_model_model_layers_22_self_attn_o_proj_weight__.144), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.4980 = f32[16,2048]{1,0} convert(%dot_general.4979), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4851 = bf16[16,2048]{1,0} convert(%add.4850), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4981 = f32[16,2048]{1,0} convert(%convert_element_type.4851), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.4982 = f32[16,2048]{1,0} add(%convert_element_type.4980, %convert_element_type.4981), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.4984 = f32[16,2048]{1,0} power(%add.4982, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4989 = f32[16]{0} reduce(%pow.4984, %constant.512), dimensions={1}, to_apply=%region_121.4988, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4990 = f32[16,1]{1,0} reshape(%reduce_sum.4989), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4991 = f32[16,1]{1,0} divide(%broadcast_in_dim.4990, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4992 = f32[16,1]{1,0} add(%div.4991, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4993 = f32[16,1]{1,0} rsqrt(%add.4992), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4994 = f32[16,1]{1,0} broadcast(%rsqrt.4993), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4995 = f32[16]{0} reshape(%mul.4994), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4996 = f32[16,2048]{1,0} broadcast(%mul.4995), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4997 = f32[16,2048]{1,0} multiply(%add.4982, %mul.4996), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4998 = bf16[16,2048]{1,0} convert(%mul.4997), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_22_post_attention_layernorm_weight__.142 = bf16[2048]{0} parameter(141), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.22.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.4999 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_22_post_attention_layernorm_weight__.142), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5000 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.4999), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5001 = bf16[2048]{0} reshape(%mul.5000), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5002 = bf16[16,2048]{1,0} broadcast(%mul.5001), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5003 = bf16[16,2048]{1,0} multiply(%convert_element_type.4998, %mul.5002), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_22_mlp_experts_w13_weight__.139 = bf16[128,1536,2048]{2,1,0} parameter(138), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.22.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_22_mlp_experts_w2_weight__.140 = bf16[128,2048,768]{2,1,0} parameter(139), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.22.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_22_mlp_gate_weight__.141 = bf16[128,2048]{1,0} parameter(140), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.22.mlp.gate.weight\']"}
  %dot_general.5004 = bf16[16,128]{1,0} dot(%mul.5003, %params_and_buffers__vllm_model_language_model_model_layers_22_mlp_gate_weight__.141), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.5005 = bf16[16,2048]{1,0} call(%mul.5003, %params_and_buffers__vllm_model_language_model_model_layers_22_mlp_experts_w13_weight__.139, %params_and_buffers__vllm_model_language_model_model_layers_22_mlp_experts_w2_weight__.140, %dot_general.5004), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.5006 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.5005), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4983 = bf16[16,2048]{1,0} convert(%add.4982), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5007 = f32[16,2048]{1,0} convert(%convert_element_type.4983), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.5008 = f32[16,2048]{1,0} add(%convert_element_type.5006, %convert_element_type.5007), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.5010 = f32[16,2048]{1,0} power(%add.5008, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5015 = f32[16]{0} reduce(%pow.5010, %constant.512), dimensions={1}, to_apply=%region_122.5014, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5016 = f32[16,1]{1,0} reshape(%reduce_sum.5015), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5017 = f32[16,1]{1,0} divide(%broadcast_in_dim.5016, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5018 = f32[16,1]{1,0} add(%div.5017, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5019 = f32[16,1]{1,0} rsqrt(%add.5018), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5020 = f32[16,1]{1,0} broadcast(%rsqrt.5019), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5021 = f32[16]{0} reshape(%mul.5020), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5022 = f32[16,2048]{1,0} broadcast(%mul.5021), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5023 = f32[16,2048]{1,0} multiply(%add.5008, %mul.5022), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5024 = bf16[16,2048]{1,0} convert(%mul.5023), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_23_input_layernorm_weight__.147 = bf16[2048]{0} parameter(146), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.23.input_layernorm.weight\']"}
  %broadcast_in_dim.5025 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_23_input_layernorm_weight__.147), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5026 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.5025), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5027 = bf16[2048]{0} reshape(%mul.5026), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5028 = bf16[16,2048]{1,0} broadcast(%mul.5027), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5029 = bf16[16,2048]{1,0} multiply(%convert_element_type.5024, %mul.5028), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_23_self_attn_qkv_proj_weight__.155 = bf16[5120,2048]{1,0} parameter(154), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.23.self_attn.qkv_proj.weight\']"}
  %dot_general.5030 = bf16[16,5120]{1,0} dot(%mul.5029, %params_and_buffers__vllm_model_language_model_model_layers_23_self_attn_qkv_proj_weight__.155), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.5031 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.5030), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.5032 = bf16[16,4,1024]{2,1,0} slice(%reshape.5031), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.5036 = bf16[16,32,128]{2,1,0} reshape(%slice.5032), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.5037 = f32[16,32,128]{2,1,0} convert(%reshape.5036), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.5038 = f32[16,32,128]{2,1,0} power(%convert_element_type.5037, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5043 = f32[16,32]{1,0} reduce(%pow.5038, %constant.512), dimensions={2}, to_apply=%region_123.5042, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5044 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.5043), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5045 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.5044, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5046 = f32[16,32,1]{2,1,0} add(%div.5045, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5047 = f32[16,32,1]{2,1,0} rsqrt(%add.5046), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5048 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.5047), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5049 = f32[16,32]{1,0} reshape(%mul.5048), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5050 = f32[16,32,128]{2,1,0} broadcast(%mul.5049), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5051 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.5037, %mul.5050), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5052 = bf16[16,32,128]{2,1,0} convert(%mul.5051), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_23_self_attn_q_norm_weight__.154 = bf16[128]{0} parameter(153), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.23.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.5053 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_23_self_attn_q_norm_weight__.154), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5054 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.5053), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5055 = bf16[128]{0} reshape(%mul.5054), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5056 = bf16[16,32,128]{2,1,0} broadcast(%mul.5055), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5057 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.5052, %mul.5056), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5088 = bf16[16,32,64]{2,1,0} slice(%mul.5057), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.5079 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.5080 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.5081 = s32[16]{0} select(%lt.5079, %add.5080, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.5082 = s32[16,1]{1,0} reshape(%select_n.5081), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.5083 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.5082), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.5084 = bf16[16,64]{1,0} slice(%gather.5083), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5086 = bf16[16,1,64]{2,1,0} reshape(%slice.5084), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5090 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5086), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5091 = bf16[16,64]{1,0} reshape(%mul.5090), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5092 = bf16[16,32,64]{2,1,0} broadcast(%mul.5091), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5093 = bf16[16,32,64]{2,1,0} multiply(%slice.5088, %mul.5092), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5089 = bf16[16,32,64]{2,1,0} slice(%mul.5057), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.5085 = bf16[16,64]{1,0} slice(%gather.5083), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5087 = bf16[16,1,64]{2,1,0} reshape(%slice.5085), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5094 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5087), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5095 = bf16[16,64]{1,0} reshape(%mul.5094), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5096 = bf16[16,32,64]{2,1,0} broadcast(%mul.5095), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5097 = bf16[16,32,64]{2,1,0} multiply(%slice.5089, %mul.5096), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.5098 = bf16[16,32,64]{2,1,0} subtract(%mul.5093, %mul.5097), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.5099 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5086), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5100 = bf16[16,64]{1,0} reshape(%mul.5099), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5101 = bf16[16,32,64]{2,1,0} broadcast(%mul.5100), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5102 = bf16[16,32,64]{2,1,0} multiply(%slice.5089, %mul.5101), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5103 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5087), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5104 = bf16[16,64]{1,0} reshape(%mul.5103), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5105 = bf16[16,32,64]{2,1,0} broadcast(%mul.5104), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5106 = bf16[16,32,64]{2,1,0} multiply(%slice.5088, %mul.5105), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.5107 = bf16[16,32,64]{2,1,0} add(%mul.5102, %mul.5106), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.5108 = bf16[16,32,128]{2,1,0} concatenate(%sub.5098, %add.5107), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.5109 = bf16[16,4096]{1,0} reshape(%concatenate.5108), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.5033 = bf16[16,4,128]{2,1,0} slice(%reshape.5031), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.5058 = f32[16,4,128]{2,1,0} convert(%slice.5033), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.5059 = f32[16,4,128]{2,1,0} power(%convert_element_type.5058, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5064 = f32[16,4]{1,0} reduce(%pow.5059, %constant.512), dimensions={2}, to_apply=%region_124.5063, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5065 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.5064), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5066 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.5065, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5067 = f32[16,4,1]{2,1,0} add(%div.5066, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5068 = f32[16,4,1]{2,1,0} rsqrt(%add.5067), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5069 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.5068), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5070 = f32[16,4]{1,0} reshape(%mul.5069), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5071 = f32[16,4,128]{2,1,0} broadcast(%mul.5070), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5072 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.5058, %mul.5071), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5073 = bf16[16,4,128]{2,1,0} convert(%mul.5072), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_23_self_attn_k_norm_weight__.152 = bf16[128]{0} parameter(151), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.23.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.5074 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_23_self_attn_k_norm_weight__.152), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5075 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.5074), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5076 = bf16[128]{0} reshape(%mul.5075), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5077 = bf16[16,4,128]{2,1,0} broadcast(%mul.5076), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5078 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.5073, %mul.5077), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5112 = bf16[16,4,64]{2,1,0} slice(%mul.5078), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5110 = bf16[16,1,64]{2,1,0} reshape(%slice.5084), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5114 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5110), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5115 = bf16[16,64]{1,0} reshape(%mul.5114), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5116 = bf16[16,4,64]{2,1,0} broadcast(%mul.5115), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5117 = bf16[16,4,64]{2,1,0} multiply(%slice.5112, %mul.5116), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5113 = bf16[16,4,64]{2,1,0} slice(%mul.5078), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5111 = bf16[16,1,64]{2,1,0} reshape(%slice.5085), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5118 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5111), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5119 = bf16[16,64]{1,0} reshape(%mul.5118), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5120 = bf16[16,4,64]{2,1,0} broadcast(%mul.5119), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5121 = bf16[16,4,64]{2,1,0} multiply(%slice.5113, %mul.5120), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.5122 = bf16[16,4,64]{2,1,0} subtract(%mul.5117, %mul.5121), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.5123 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5110), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5124 = bf16[16,64]{1,0} reshape(%mul.5123), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5125 = bf16[16,4,64]{2,1,0} broadcast(%mul.5124), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5126 = bf16[16,4,64]{2,1,0} multiply(%slice.5113, %mul.5125), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5127 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5111), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5128 = bf16[16,64]{1,0} reshape(%mul.5127), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5129 = bf16[16,4,64]{2,1,0} broadcast(%mul.5128), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5130 = bf16[16,4,64]{2,1,0} multiply(%slice.5112, %mul.5129), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.5131 = bf16[16,4,64]{2,1,0} add(%mul.5126, %mul.5130), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.5132 = bf16[16,4,128]{2,1,0} concatenate(%sub.5122, %add.5131), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.5133 = bf16[16,512]{1,0} reshape(%concatenate.5132), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.5034 = bf16[16,4,128]{2,1,0} slice(%reshape.5031), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.5035 = bf16[16,512]{1,0} reshape(%slice.5034), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.5134 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_23_.459, %reshape.5109, %reshape.5133, %reshape.5035, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.5135 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.5134), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_24_.460 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(459), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[24]"}
  %jit__jax_attn_func_.5136 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.5134), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_23_self_attn_o_proj_weight__.153 = bf16[2048,4096]{1,0} parameter(152), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.23.self_attn.o_proj.weight\']"}
  %dot_general.5137 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.5136, %params_and_buffers__vllm_model_language_model_model_layers_23_self_attn_o_proj_weight__.153), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.5138 = f32[16,2048]{1,0} convert(%dot_general.5137), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5009 = bf16[16,2048]{1,0} convert(%add.5008), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5139 = f32[16,2048]{1,0} convert(%convert_element_type.5009), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.5140 = f32[16,2048]{1,0} add(%convert_element_type.5138, %convert_element_type.5139), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.5142 = f32[16,2048]{1,0} power(%add.5140, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5147 = f32[16]{0} reduce(%pow.5142, %constant.512), dimensions={1}, to_apply=%region_125.5146, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5148 = f32[16,1]{1,0} reshape(%reduce_sum.5147), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5149 = f32[16,1]{1,0} divide(%broadcast_in_dim.5148, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5150 = f32[16,1]{1,0} add(%div.5149, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5151 = f32[16,1]{1,0} rsqrt(%add.5150), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5152 = f32[16,1]{1,0} broadcast(%rsqrt.5151), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5153 = f32[16]{0} reshape(%mul.5152), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5154 = f32[16,2048]{1,0} broadcast(%mul.5153), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5155 = f32[16,2048]{1,0} multiply(%add.5140, %mul.5154), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5156 = bf16[16,2048]{1,0} convert(%mul.5155), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_23_post_attention_layernorm_weight__.151 = bf16[2048]{0} parameter(150), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.23.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.5157 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_23_post_attention_layernorm_weight__.151), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5158 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.5157), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5159 = bf16[2048]{0} reshape(%mul.5158), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5160 = bf16[16,2048]{1,0} broadcast(%mul.5159), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5161 = bf16[16,2048]{1,0} multiply(%convert_element_type.5156, %mul.5160), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_23_mlp_experts_w13_weight__.148 = bf16[128,1536,2048]{2,1,0} parameter(147), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.23.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_23_mlp_experts_w2_weight__.149 = bf16[128,2048,768]{2,1,0} parameter(148), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.23.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_23_mlp_gate_weight__.150 = bf16[128,2048]{1,0} parameter(149), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.23.mlp.gate.weight\']"}
  %dot_general.5162 = bf16[16,128]{1,0} dot(%mul.5161, %params_and_buffers__vllm_model_language_model_model_layers_23_mlp_gate_weight__.150), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.5163 = bf16[16,2048]{1,0} call(%mul.5161, %params_and_buffers__vllm_model_language_model_model_layers_23_mlp_experts_w13_weight__.148, %params_and_buffers__vllm_model_language_model_model_layers_23_mlp_experts_w2_weight__.149, %dot_general.5162), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.5164 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.5163), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5141 = bf16[16,2048]{1,0} convert(%add.5140), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5165 = f32[16,2048]{1,0} convert(%convert_element_type.5141), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.5166 = f32[16,2048]{1,0} add(%convert_element_type.5164, %convert_element_type.5165), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.5168 = f32[16,2048]{1,0} power(%add.5166, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5173 = f32[16]{0} reduce(%pow.5168, %constant.512), dimensions={1}, to_apply=%region_126.5172, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5174 = f32[16,1]{1,0} reshape(%reduce_sum.5173), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5175 = f32[16,1]{1,0} divide(%broadcast_in_dim.5174, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5176 = f32[16,1]{1,0} add(%div.5175, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5177 = f32[16,1]{1,0} rsqrt(%add.5176), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5178 = f32[16,1]{1,0} broadcast(%rsqrt.5177), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5179 = f32[16]{0} reshape(%mul.5178), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5180 = f32[16,2048]{1,0} broadcast(%mul.5179), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5181 = f32[16,2048]{1,0} multiply(%add.5166, %mul.5180), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5182 = bf16[16,2048]{1,0} convert(%mul.5181), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_24_input_layernorm_weight__.156 = bf16[2048]{0} parameter(155), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.24.input_layernorm.weight\']"}
  %broadcast_in_dim.5183 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_24_input_layernorm_weight__.156), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5184 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.5183), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5185 = bf16[2048]{0} reshape(%mul.5184), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5186 = bf16[16,2048]{1,0} broadcast(%mul.5185), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5187 = bf16[16,2048]{1,0} multiply(%convert_element_type.5182, %mul.5186), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_24_self_attn_qkv_proj_weight__.164 = bf16[5120,2048]{1,0} parameter(163), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.24.self_attn.qkv_proj.weight\']"}
  %dot_general.5188 = bf16[16,5120]{1,0} dot(%mul.5187, %params_and_buffers__vllm_model_language_model_model_layers_24_self_attn_qkv_proj_weight__.164), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.5189 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.5188), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.5190 = bf16[16,4,1024]{2,1,0} slice(%reshape.5189), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.5194 = bf16[16,32,128]{2,1,0} reshape(%slice.5190), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.5195 = f32[16,32,128]{2,1,0} convert(%reshape.5194), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.5196 = f32[16,32,128]{2,1,0} power(%convert_element_type.5195, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5201 = f32[16,32]{1,0} reduce(%pow.5196, %constant.512), dimensions={2}, to_apply=%region_127.5200, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5202 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.5201), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5203 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.5202, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5204 = f32[16,32,1]{2,1,0} add(%div.5203, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5205 = f32[16,32,1]{2,1,0} rsqrt(%add.5204), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5206 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.5205), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5207 = f32[16,32]{1,0} reshape(%mul.5206), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5208 = f32[16,32,128]{2,1,0} broadcast(%mul.5207), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5209 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.5195, %mul.5208), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5210 = bf16[16,32,128]{2,1,0} convert(%mul.5209), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_24_self_attn_q_norm_weight__.163 = bf16[128]{0} parameter(162), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.24.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.5211 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_24_self_attn_q_norm_weight__.163), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5212 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.5211), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5213 = bf16[128]{0} reshape(%mul.5212), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5214 = bf16[16,32,128]{2,1,0} broadcast(%mul.5213), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5215 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.5210, %mul.5214), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5246 = bf16[16,32,64]{2,1,0} slice(%mul.5215), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.5237 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.5238 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.5239 = s32[16]{0} select(%lt.5237, %add.5238, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.5240 = s32[16,1]{1,0} reshape(%select_n.5239), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.5241 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.5240), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.5242 = bf16[16,64]{1,0} slice(%gather.5241), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5244 = bf16[16,1,64]{2,1,0} reshape(%slice.5242), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5248 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5244), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5249 = bf16[16,64]{1,0} reshape(%mul.5248), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5250 = bf16[16,32,64]{2,1,0} broadcast(%mul.5249), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5251 = bf16[16,32,64]{2,1,0} multiply(%slice.5246, %mul.5250), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5247 = bf16[16,32,64]{2,1,0} slice(%mul.5215), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.5243 = bf16[16,64]{1,0} slice(%gather.5241), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5245 = bf16[16,1,64]{2,1,0} reshape(%slice.5243), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5252 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5245), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5253 = bf16[16,64]{1,0} reshape(%mul.5252), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5254 = bf16[16,32,64]{2,1,0} broadcast(%mul.5253), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5255 = bf16[16,32,64]{2,1,0} multiply(%slice.5247, %mul.5254), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.5256 = bf16[16,32,64]{2,1,0} subtract(%mul.5251, %mul.5255), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.5257 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5244), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5258 = bf16[16,64]{1,0} reshape(%mul.5257), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5259 = bf16[16,32,64]{2,1,0} broadcast(%mul.5258), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5260 = bf16[16,32,64]{2,1,0} multiply(%slice.5247, %mul.5259), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5261 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5245), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5262 = bf16[16,64]{1,0} reshape(%mul.5261), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5263 = bf16[16,32,64]{2,1,0} broadcast(%mul.5262), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5264 = bf16[16,32,64]{2,1,0} multiply(%slice.5246, %mul.5263), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.5265 = bf16[16,32,64]{2,1,0} add(%mul.5260, %mul.5264), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.5266 = bf16[16,32,128]{2,1,0} concatenate(%sub.5256, %add.5265), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.5267 = bf16[16,4096]{1,0} reshape(%concatenate.5266), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.5191 = bf16[16,4,128]{2,1,0} slice(%reshape.5189), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.5216 = f32[16,4,128]{2,1,0} convert(%slice.5191), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.5217 = f32[16,4,128]{2,1,0} power(%convert_element_type.5216, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5222 = f32[16,4]{1,0} reduce(%pow.5217, %constant.512), dimensions={2}, to_apply=%region_128.5221, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5223 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.5222), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5224 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.5223, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5225 = f32[16,4,1]{2,1,0} add(%div.5224, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5226 = f32[16,4,1]{2,1,0} rsqrt(%add.5225), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5227 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.5226), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5228 = f32[16,4]{1,0} reshape(%mul.5227), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5229 = f32[16,4,128]{2,1,0} broadcast(%mul.5228), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5230 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.5216, %mul.5229), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5231 = bf16[16,4,128]{2,1,0} convert(%mul.5230), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_24_self_attn_k_norm_weight__.161 = bf16[128]{0} parameter(160), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.24.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.5232 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_24_self_attn_k_norm_weight__.161), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5233 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.5232), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5234 = bf16[128]{0} reshape(%mul.5233), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5235 = bf16[16,4,128]{2,1,0} broadcast(%mul.5234), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5236 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.5231, %mul.5235), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5270 = bf16[16,4,64]{2,1,0} slice(%mul.5236), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5268 = bf16[16,1,64]{2,1,0} reshape(%slice.5242), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5272 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5268), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5273 = bf16[16,64]{1,0} reshape(%mul.5272), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5274 = bf16[16,4,64]{2,1,0} broadcast(%mul.5273), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5275 = bf16[16,4,64]{2,1,0} multiply(%slice.5270, %mul.5274), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5271 = bf16[16,4,64]{2,1,0} slice(%mul.5236), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5269 = bf16[16,1,64]{2,1,0} reshape(%slice.5243), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5276 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5269), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5277 = bf16[16,64]{1,0} reshape(%mul.5276), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5278 = bf16[16,4,64]{2,1,0} broadcast(%mul.5277), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5279 = bf16[16,4,64]{2,1,0} multiply(%slice.5271, %mul.5278), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.5280 = bf16[16,4,64]{2,1,0} subtract(%mul.5275, %mul.5279), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.5281 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5268), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5282 = bf16[16,64]{1,0} reshape(%mul.5281), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5283 = bf16[16,4,64]{2,1,0} broadcast(%mul.5282), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5284 = bf16[16,4,64]{2,1,0} multiply(%slice.5271, %mul.5283), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5285 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5269), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5286 = bf16[16,64]{1,0} reshape(%mul.5285), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5287 = bf16[16,4,64]{2,1,0} broadcast(%mul.5286), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5288 = bf16[16,4,64]{2,1,0} multiply(%slice.5270, %mul.5287), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.5289 = bf16[16,4,64]{2,1,0} add(%mul.5284, %mul.5288), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.5290 = bf16[16,4,128]{2,1,0} concatenate(%sub.5280, %add.5289), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.5291 = bf16[16,512]{1,0} reshape(%concatenate.5290), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.5192 = bf16[16,4,128]{2,1,0} slice(%reshape.5189), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.5193 = bf16[16,512]{1,0} reshape(%slice.5192), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.5292 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_24_.460, %reshape.5267, %reshape.5291, %reshape.5193, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.5293 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.5292), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_25_.461 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(460), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[25]"}
  %jit__jax_attn_func_.5294 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.5292), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_24_self_attn_o_proj_weight__.162 = bf16[2048,4096]{1,0} parameter(161), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.24.self_attn.o_proj.weight\']"}
  %dot_general.5295 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.5294, %params_and_buffers__vllm_model_language_model_model_layers_24_self_attn_o_proj_weight__.162), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.5296 = f32[16,2048]{1,0} convert(%dot_general.5295), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5167 = bf16[16,2048]{1,0} convert(%add.5166), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5297 = f32[16,2048]{1,0} convert(%convert_element_type.5167), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.5298 = f32[16,2048]{1,0} add(%convert_element_type.5296, %convert_element_type.5297), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.5300 = f32[16,2048]{1,0} power(%add.5298, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5305 = f32[16]{0} reduce(%pow.5300, %constant.512), dimensions={1}, to_apply=%region_129.5304, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5306 = f32[16,1]{1,0} reshape(%reduce_sum.5305), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5307 = f32[16,1]{1,0} divide(%broadcast_in_dim.5306, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5308 = f32[16,1]{1,0} add(%div.5307, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5309 = f32[16,1]{1,0} rsqrt(%add.5308), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5310 = f32[16,1]{1,0} broadcast(%rsqrt.5309), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5311 = f32[16]{0} reshape(%mul.5310), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5312 = f32[16,2048]{1,0} broadcast(%mul.5311), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5313 = f32[16,2048]{1,0} multiply(%add.5298, %mul.5312), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5314 = bf16[16,2048]{1,0} convert(%mul.5313), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_24_post_attention_layernorm_weight__.160 = bf16[2048]{0} parameter(159), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.24.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.5315 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_24_post_attention_layernorm_weight__.160), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5316 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.5315), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5317 = bf16[2048]{0} reshape(%mul.5316), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5318 = bf16[16,2048]{1,0} broadcast(%mul.5317), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5319 = bf16[16,2048]{1,0} multiply(%convert_element_type.5314, %mul.5318), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_24_mlp_experts_w13_weight__.157 = bf16[128,1536,2048]{2,1,0} parameter(156), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.24.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_24_mlp_experts_w2_weight__.158 = bf16[128,2048,768]{2,1,0} parameter(157), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.24.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_24_mlp_gate_weight__.159 = bf16[128,2048]{1,0} parameter(158), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.24.mlp.gate.weight\']"}
  %dot_general.5320 = bf16[16,128]{1,0} dot(%mul.5319, %params_and_buffers__vllm_model_language_model_model_layers_24_mlp_gate_weight__.159), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.5321 = bf16[16,2048]{1,0} call(%mul.5319, %params_and_buffers__vllm_model_language_model_model_layers_24_mlp_experts_w13_weight__.157, %params_and_buffers__vllm_model_language_model_model_layers_24_mlp_experts_w2_weight__.158, %dot_general.5320), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.5322 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.5321), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5299 = bf16[16,2048]{1,0} convert(%add.5298), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5323 = f32[16,2048]{1,0} convert(%convert_element_type.5299), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.5324 = f32[16,2048]{1,0} add(%convert_element_type.5322, %convert_element_type.5323), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.5326 = f32[16,2048]{1,0} power(%add.5324, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5331 = f32[16]{0} reduce(%pow.5326, %constant.512), dimensions={1}, to_apply=%region_130.5330, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5332 = f32[16,1]{1,0} reshape(%reduce_sum.5331), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5333 = f32[16,1]{1,0} divide(%broadcast_in_dim.5332, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5334 = f32[16,1]{1,0} add(%div.5333, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5335 = f32[16,1]{1,0} rsqrt(%add.5334), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5336 = f32[16,1]{1,0} broadcast(%rsqrt.5335), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5337 = f32[16]{0} reshape(%mul.5336), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5338 = f32[16,2048]{1,0} broadcast(%mul.5337), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5339 = f32[16,2048]{1,0} multiply(%add.5324, %mul.5338), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5340 = bf16[16,2048]{1,0} convert(%mul.5339), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_25_input_layernorm_weight__.165 = bf16[2048]{0} parameter(164), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.25.input_layernorm.weight\']"}
  %broadcast_in_dim.5341 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_25_input_layernorm_weight__.165), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5342 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.5341), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5343 = bf16[2048]{0} reshape(%mul.5342), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5344 = bf16[16,2048]{1,0} broadcast(%mul.5343), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5345 = bf16[16,2048]{1,0} multiply(%convert_element_type.5340, %mul.5344), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_25_self_attn_qkv_proj_weight__.173 = bf16[5120,2048]{1,0} parameter(172), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.25.self_attn.qkv_proj.weight\']"}
  %dot_general.5346 = bf16[16,5120]{1,0} dot(%mul.5345, %params_and_buffers__vllm_model_language_model_model_layers_25_self_attn_qkv_proj_weight__.173), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.5347 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.5346), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.5348 = bf16[16,4,1024]{2,1,0} slice(%reshape.5347), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.5352 = bf16[16,32,128]{2,1,0} reshape(%slice.5348), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.5353 = f32[16,32,128]{2,1,0} convert(%reshape.5352), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.5354 = f32[16,32,128]{2,1,0} power(%convert_element_type.5353, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5359 = f32[16,32]{1,0} reduce(%pow.5354, %constant.512), dimensions={2}, to_apply=%region_131.5358, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5360 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.5359), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5361 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.5360, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5362 = f32[16,32,1]{2,1,0} add(%div.5361, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5363 = f32[16,32,1]{2,1,0} rsqrt(%add.5362), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5364 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.5363), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5365 = f32[16,32]{1,0} reshape(%mul.5364), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5366 = f32[16,32,128]{2,1,0} broadcast(%mul.5365), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5367 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.5353, %mul.5366), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5368 = bf16[16,32,128]{2,1,0} convert(%mul.5367), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_25_self_attn_q_norm_weight__.172 = bf16[128]{0} parameter(171), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.25.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.5369 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_25_self_attn_q_norm_weight__.172), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5370 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.5369), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5371 = bf16[128]{0} reshape(%mul.5370), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5372 = bf16[16,32,128]{2,1,0} broadcast(%mul.5371), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5373 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.5368, %mul.5372), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5404 = bf16[16,32,64]{2,1,0} slice(%mul.5373), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.5395 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.5396 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.5397 = s32[16]{0} select(%lt.5395, %add.5396, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.5398 = s32[16,1]{1,0} reshape(%select_n.5397), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.5399 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.5398), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.5400 = bf16[16,64]{1,0} slice(%gather.5399), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5402 = bf16[16,1,64]{2,1,0} reshape(%slice.5400), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5406 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5402), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5407 = bf16[16,64]{1,0} reshape(%mul.5406), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5408 = bf16[16,32,64]{2,1,0} broadcast(%mul.5407), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5409 = bf16[16,32,64]{2,1,0} multiply(%slice.5404, %mul.5408), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5405 = bf16[16,32,64]{2,1,0} slice(%mul.5373), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.5401 = bf16[16,64]{1,0} slice(%gather.5399), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5403 = bf16[16,1,64]{2,1,0} reshape(%slice.5401), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5410 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5403), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5411 = bf16[16,64]{1,0} reshape(%mul.5410), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5412 = bf16[16,32,64]{2,1,0} broadcast(%mul.5411), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5413 = bf16[16,32,64]{2,1,0} multiply(%slice.5405, %mul.5412), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.5414 = bf16[16,32,64]{2,1,0} subtract(%mul.5409, %mul.5413), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.5415 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5402), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5416 = bf16[16,64]{1,0} reshape(%mul.5415), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5417 = bf16[16,32,64]{2,1,0} broadcast(%mul.5416), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5418 = bf16[16,32,64]{2,1,0} multiply(%slice.5405, %mul.5417), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5419 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5403), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5420 = bf16[16,64]{1,0} reshape(%mul.5419), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5421 = bf16[16,32,64]{2,1,0} broadcast(%mul.5420), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5422 = bf16[16,32,64]{2,1,0} multiply(%slice.5404, %mul.5421), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.5423 = bf16[16,32,64]{2,1,0} add(%mul.5418, %mul.5422), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.5424 = bf16[16,32,128]{2,1,0} concatenate(%sub.5414, %add.5423), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.5425 = bf16[16,4096]{1,0} reshape(%concatenate.5424), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.5349 = bf16[16,4,128]{2,1,0} slice(%reshape.5347), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.5374 = f32[16,4,128]{2,1,0} convert(%slice.5349), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.5375 = f32[16,4,128]{2,1,0} power(%convert_element_type.5374, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5380 = f32[16,4]{1,0} reduce(%pow.5375, %constant.512), dimensions={2}, to_apply=%region_132.5379, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5381 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.5380), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5382 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.5381, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5383 = f32[16,4,1]{2,1,0} add(%div.5382, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5384 = f32[16,4,1]{2,1,0} rsqrt(%add.5383), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5385 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.5384), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5386 = f32[16,4]{1,0} reshape(%mul.5385), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5387 = f32[16,4,128]{2,1,0} broadcast(%mul.5386), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5388 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.5374, %mul.5387), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5389 = bf16[16,4,128]{2,1,0} convert(%mul.5388), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_25_self_attn_k_norm_weight__.170 = bf16[128]{0} parameter(169), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.25.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.5390 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_25_self_attn_k_norm_weight__.170), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5391 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.5390), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5392 = bf16[128]{0} reshape(%mul.5391), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5393 = bf16[16,4,128]{2,1,0} broadcast(%mul.5392), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5394 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.5389, %mul.5393), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5428 = bf16[16,4,64]{2,1,0} slice(%mul.5394), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5426 = bf16[16,1,64]{2,1,0} reshape(%slice.5400), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5430 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5426), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5431 = bf16[16,64]{1,0} reshape(%mul.5430), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5432 = bf16[16,4,64]{2,1,0} broadcast(%mul.5431), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5433 = bf16[16,4,64]{2,1,0} multiply(%slice.5428, %mul.5432), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5429 = bf16[16,4,64]{2,1,0} slice(%mul.5394), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5427 = bf16[16,1,64]{2,1,0} reshape(%slice.5401), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5434 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5427), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5435 = bf16[16,64]{1,0} reshape(%mul.5434), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5436 = bf16[16,4,64]{2,1,0} broadcast(%mul.5435), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5437 = bf16[16,4,64]{2,1,0} multiply(%slice.5429, %mul.5436), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.5438 = bf16[16,4,64]{2,1,0} subtract(%mul.5433, %mul.5437), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.5439 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5426), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5440 = bf16[16,64]{1,0} reshape(%mul.5439), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5441 = bf16[16,4,64]{2,1,0} broadcast(%mul.5440), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5442 = bf16[16,4,64]{2,1,0} multiply(%slice.5429, %mul.5441), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5443 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5427), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5444 = bf16[16,64]{1,0} reshape(%mul.5443), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5445 = bf16[16,4,64]{2,1,0} broadcast(%mul.5444), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5446 = bf16[16,4,64]{2,1,0} multiply(%slice.5428, %mul.5445), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.5447 = bf16[16,4,64]{2,1,0} add(%mul.5442, %mul.5446), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.5448 = bf16[16,4,128]{2,1,0} concatenate(%sub.5438, %add.5447), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.5449 = bf16[16,512]{1,0} reshape(%concatenate.5448), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.5350 = bf16[16,4,128]{2,1,0} slice(%reshape.5347), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.5351 = bf16[16,512]{1,0} reshape(%slice.5350), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.5450 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_25_.461, %reshape.5425, %reshape.5449, %reshape.5351, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.5451 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.5450), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_26_.462 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(461), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[26]"}
  %jit__jax_attn_func_.5452 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.5450), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_25_self_attn_o_proj_weight__.171 = bf16[2048,4096]{1,0} parameter(170), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.25.self_attn.o_proj.weight\']"}
  %dot_general.5453 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.5452, %params_and_buffers__vllm_model_language_model_model_layers_25_self_attn_o_proj_weight__.171), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.5454 = f32[16,2048]{1,0} convert(%dot_general.5453), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5325 = bf16[16,2048]{1,0} convert(%add.5324), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5455 = f32[16,2048]{1,0} convert(%convert_element_type.5325), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.5456 = f32[16,2048]{1,0} add(%convert_element_type.5454, %convert_element_type.5455), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.5458 = f32[16,2048]{1,0} power(%add.5456, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5463 = f32[16]{0} reduce(%pow.5458, %constant.512), dimensions={1}, to_apply=%region_133.5462, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5464 = f32[16,1]{1,0} reshape(%reduce_sum.5463), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5465 = f32[16,1]{1,0} divide(%broadcast_in_dim.5464, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5466 = f32[16,1]{1,0} add(%div.5465, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5467 = f32[16,1]{1,0} rsqrt(%add.5466), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5468 = f32[16,1]{1,0} broadcast(%rsqrt.5467), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5469 = f32[16]{0} reshape(%mul.5468), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5470 = f32[16,2048]{1,0} broadcast(%mul.5469), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5471 = f32[16,2048]{1,0} multiply(%add.5456, %mul.5470), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5472 = bf16[16,2048]{1,0} convert(%mul.5471), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_25_post_attention_layernorm_weight__.169 = bf16[2048]{0} parameter(168), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.25.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.5473 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_25_post_attention_layernorm_weight__.169), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5474 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.5473), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5475 = bf16[2048]{0} reshape(%mul.5474), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5476 = bf16[16,2048]{1,0} broadcast(%mul.5475), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5477 = bf16[16,2048]{1,0} multiply(%convert_element_type.5472, %mul.5476), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_25_mlp_experts_w13_weight__.166 = bf16[128,1536,2048]{2,1,0} parameter(165), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.25.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_25_mlp_experts_w2_weight__.167 = bf16[128,2048,768]{2,1,0} parameter(166), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.25.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_25_mlp_gate_weight__.168 = bf16[128,2048]{1,0} parameter(167), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.25.mlp.gate.weight\']"}
  %dot_general.5478 = bf16[16,128]{1,0} dot(%mul.5477, %params_and_buffers__vllm_model_language_model_model_layers_25_mlp_gate_weight__.168), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.5479 = bf16[16,2048]{1,0} call(%mul.5477, %params_and_buffers__vllm_model_language_model_model_layers_25_mlp_experts_w13_weight__.166, %params_and_buffers__vllm_model_language_model_model_layers_25_mlp_experts_w2_weight__.167, %dot_general.5478), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.5480 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.5479), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5457 = bf16[16,2048]{1,0} convert(%add.5456), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5481 = f32[16,2048]{1,0} convert(%convert_element_type.5457), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.5482 = f32[16,2048]{1,0} add(%convert_element_type.5480, %convert_element_type.5481), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.5484 = f32[16,2048]{1,0} power(%add.5482, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5489 = f32[16]{0} reduce(%pow.5484, %constant.512), dimensions={1}, to_apply=%region_134.5488, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5490 = f32[16,1]{1,0} reshape(%reduce_sum.5489), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5491 = f32[16,1]{1,0} divide(%broadcast_in_dim.5490, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5492 = f32[16,1]{1,0} add(%div.5491, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5493 = f32[16,1]{1,0} rsqrt(%add.5492), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5494 = f32[16,1]{1,0} broadcast(%rsqrt.5493), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5495 = f32[16]{0} reshape(%mul.5494), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5496 = f32[16,2048]{1,0} broadcast(%mul.5495), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5497 = f32[16,2048]{1,0} multiply(%add.5482, %mul.5496), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5498 = bf16[16,2048]{1,0} convert(%mul.5497), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_26_input_layernorm_weight__.174 = bf16[2048]{0} parameter(173), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.26.input_layernorm.weight\']"}
  %broadcast_in_dim.5499 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_26_input_layernorm_weight__.174), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5500 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.5499), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5501 = bf16[2048]{0} reshape(%mul.5500), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5502 = bf16[16,2048]{1,0} broadcast(%mul.5501), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5503 = bf16[16,2048]{1,0} multiply(%convert_element_type.5498, %mul.5502), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_26_self_attn_qkv_proj_weight__.182 = bf16[5120,2048]{1,0} parameter(181), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.26.self_attn.qkv_proj.weight\']"}
  %dot_general.5504 = bf16[16,5120]{1,0} dot(%mul.5503, %params_and_buffers__vllm_model_language_model_model_layers_26_self_attn_qkv_proj_weight__.182), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.5505 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.5504), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.5506 = bf16[16,4,1024]{2,1,0} slice(%reshape.5505), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.5510 = bf16[16,32,128]{2,1,0} reshape(%slice.5506), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.5511 = f32[16,32,128]{2,1,0} convert(%reshape.5510), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.5512 = f32[16,32,128]{2,1,0} power(%convert_element_type.5511, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5517 = f32[16,32]{1,0} reduce(%pow.5512, %constant.512), dimensions={2}, to_apply=%region_135.5516, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5518 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.5517), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5519 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.5518, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5520 = f32[16,32,1]{2,1,0} add(%div.5519, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5521 = f32[16,32,1]{2,1,0} rsqrt(%add.5520), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5522 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.5521), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5523 = f32[16,32]{1,0} reshape(%mul.5522), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5524 = f32[16,32,128]{2,1,0} broadcast(%mul.5523), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5525 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.5511, %mul.5524), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5526 = bf16[16,32,128]{2,1,0} convert(%mul.5525), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_26_self_attn_q_norm_weight__.181 = bf16[128]{0} parameter(180), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.26.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.5527 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_26_self_attn_q_norm_weight__.181), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5528 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.5527), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5529 = bf16[128]{0} reshape(%mul.5528), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5530 = bf16[16,32,128]{2,1,0} broadcast(%mul.5529), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5531 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.5526, %mul.5530), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5562 = bf16[16,32,64]{2,1,0} slice(%mul.5531), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.5553 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.5554 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.5555 = s32[16]{0} select(%lt.5553, %add.5554, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.5556 = s32[16,1]{1,0} reshape(%select_n.5555), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.5557 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.5556), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.5558 = bf16[16,64]{1,0} slice(%gather.5557), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5560 = bf16[16,1,64]{2,1,0} reshape(%slice.5558), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5564 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5560), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5565 = bf16[16,64]{1,0} reshape(%mul.5564), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5566 = bf16[16,32,64]{2,1,0} broadcast(%mul.5565), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5567 = bf16[16,32,64]{2,1,0} multiply(%slice.5562, %mul.5566), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5563 = bf16[16,32,64]{2,1,0} slice(%mul.5531), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.5559 = bf16[16,64]{1,0} slice(%gather.5557), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5561 = bf16[16,1,64]{2,1,0} reshape(%slice.5559), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5568 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5561), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5569 = bf16[16,64]{1,0} reshape(%mul.5568), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5570 = bf16[16,32,64]{2,1,0} broadcast(%mul.5569), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5571 = bf16[16,32,64]{2,1,0} multiply(%slice.5563, %mul.5570), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.5572 = bf16[16,32,64]{2,1,0} subtract(%mul.5567, %mul.5571), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.5573 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5560), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5574 = bf16[16,64]{1,0} reshape(%mul.5573), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5575 = bf16[16,32,64]{2,1,0} broadcast(%mul.5574), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5576 = bf16[16,32,64]{2,1,0} multiply(%slice.5563, %mul.5575), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5577 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5561), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5578 = bf16[16,64]{1,0} reshape(%mul.5577), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5579 = bf16[16,32,64]{2,1,0} broadcast(%mul.5578), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5580 = bf16[16,32,64]{2,1,0} multiply(%slice.5562, %mul.5579), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.5581 = bf16[16,32,64]{2,1,0} add(%mul.5576, %mul.5580), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.5582 = bf16[16,32,128]{2,1,0} concatenate(%sub.5572, %add.5581), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.5583 = bf16[16,4096]{1,0} reshape(%concatenate.5582), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.5507 = bf16[16,4,128]{2,1,0} slice(%reshape.5505), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.5532 = f32[16,4,128]{2,1,0} convert(%slice.5507), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.5533 = f32[16,4,128]{2,1,0} power(%convert_element_type.5532, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5538 = f32[16,4]{1,0} reduce(%pow.5533, %constant.512), dimensions={2}, to_apply=%region_136.5537, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5539 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.5538), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5540 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.5539, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5541 = f32[16,4,1]{2,1,0} add(%div.5540, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5542 = f32[16,4,1]{2,1,0} rsqrt(%add.5541), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5543 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.5542), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5544 = f32[16,4]{1,0} reshape(%mul.5543), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5545 = f32[16,4,128]{2,1,0} broadcast(%mul.5544), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5546 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.5532, %mul.5545), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5547 = bf16[16,4,128]{2,1,0} convert(%mul.5546), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_26_self_attn_k_norm_weight__.179 = bf16[128]{0} parameter(178), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.26.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.5548 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_26_self_attn_k_norm_weight__.179), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5549 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.5548), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5550 = bf16[128]{0} reshape(%mul.5549), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5551 = bf16[16,4,128]{2,1,0} broadcast(%mul.5550), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5552 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.5547, %mul.5551), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5586 = bf16[16,4,64]{2,1,0} slice(%mul.5552), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5584 = bf16[16,1,64]{2,1,0} reshape(%slice.5558), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5588 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5584), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5589 = bf16[16,64]{1,0} reshape(%mul.5588), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5590 = bf16[16,4,64]{2,1,0} broadcast(%mul.5589), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5591 = bf16[16,4,64]{2,1,0} multiply(%slice.5586, %mul.5590), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5587 = bf16[16,4,64]{2,1,0} slice(%mul.5552), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5585 = bf16[16,1,64]{2,1,0} reshape(%slice.5559), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5592 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5585), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5593 = bf16[16,64]{1,0} reshape(%mul.5592), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5594 = bf16[16,4,64]{2,1,0} broadcast(%mul.5593), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5595 = bf16[16,4,64]{2,1,0} multiply(%slice.5587, %mul.5594), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.5596 = bf16[16,4,64]{2,1,0} subtract(%mul.5591, %mul.5595), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.5597 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5584), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5598 = bf16[16,64]{1,0} reshape(%mul.5597), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5599 = bf16[16,4,64]{2,1,0} broadcast(%mul.5598), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5600 = bf16[16,4,64]{2,1,0} multiply(%slice.5587, %mul.5599), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5601 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5585), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5602 = bf16[16,64]{1,0} reshape(%mul.5601), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5603 = bf16[16,4,64]{2,1,0} broadcast(%mul.5602), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5604 = bf16[16,4,64]{2,1,0} multiply(%slice.5586, %mul.5603), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.5605 = bf16[16,4,64]{2,1,0} add(%mul.5600, %mul.5604), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.5606 = bf16[16,4,128]{2,1,0} concatenate(%sub.5596, %add.5605), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.5607 = bf16[16,512]{1,0} reshape(%concatenate.5606), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.5508 = bf16[16,4,128]{2,1,0} slice(%reshape.5505), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.5509 = bf16[16,512]{1,0} reshape(%slice.5508), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.5608 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_26_.462, %reshape.5583, %reshape.5607, %reshape.5509, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.5609 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.5608), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_27_.463 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(462), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[27]"}
  %jit__jax_attn_func_.5610 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.5608), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_26_self_attn_o_proj_weight__.180 = bf16[2048,4096]{1,0} parameter(179), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.26.self_attn.o_proj.weight\']"}
  %dot_general.5611 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.5610, %params_and_buffers__vllm_model_language_model_model_layers_26_self_attn_o_proj_weight__.180), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.5612 = f32[16,2048]{1,0} convert(%dot_general.5611), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5483 = bf16[16,2048]{1,0} convert(%add.5482), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5613 = f32[16,2048]{1,0} convert(%convert_element_type.5483), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.5614 = f32[16,2048]{1,0} add(%convert_element_type.5612, %convert_element_type.5613), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.5616 = f32[16,2048]{1,0} power(%add.5614, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5621 = f32[16]{0} reduce(%pow.5616, %constant.512), dimensions={1}, to_apply=%region_137.5620, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5622 = f32[16,1]{1,0} reshape(%reduce_sum.5621), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5623 = f32[16,1]{1,0} divide(%broadcast_in_dim.5622, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5624 = f32[16,1]{1,0} add(%div.5623, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5625 = f32[16,1]{1,0} rsqrt(%add.5624), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5626 = f32[16,1]{1,0} broadcast(%rsqrt.5625), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5627 = f32[16]{0} reshape(%mul.5626), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5628 = f32[16,2048]{1,0} broadcast(%mul.5627), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5629 = f32[16,2048]{1,0} multiply(%add.5614, %mul.5628), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5630 = bf16[16,2048]{1,0} convert(%mul.5629), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_26_post_attention_layernorm_weight__.178 = bf16[2048]{0} parameter(177), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.26.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.5631 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_26_post_attention_layernorm_weight__.178), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5632 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.5631), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5633 = bf16[2048]{0} reshape(%mul.5632), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5634 = bf16[16,2048]{1,0} broadcast(%mul.5633), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5635 = bf16[16,2048]{1,0} multiply(%convert_element_type.5630, %mul.5634), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_26_mlp_experts_w13_weight__.175 = bf16[128,1536,2048]{2,1,0} parameter(174), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.26.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_26_mlp_experts_w2_weight__.176 = bf16[128,2048,768]{2,1,0} parameter(175), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.26.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_26_mlp_gate_weight__.177 = bf16[128,2048]{1,0} parameter(176), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.26.mlp.gate.weight\']"}
  %dot_general.5636 = bf16[16,128]{1,0} dot(%mul.5635, %params_and_buffers__vllm_model_language_model_model_layers_26_mlp_gate_weight__.177), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.5637 = bf16[16,2048]{1,0} call(%mul.5635, %params_and_buffers__vllm_model_language_model_model_layers_26_mlp_experts_w13_weight__.175, %params_and_buffers__vllm_model_language_model_model_layers_26_mlp_experts_w2_weight__.176, %dot_general.5636), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.5638 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.5637), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5615 = bf16[16,2048]{1,0} convert(%add.5614), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5639 = f32[16,2048]{1,0} convert(%convert_element_type.5615), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.5640 = f32[16,2048]{1,0} add(%convert_element_type.5638, %convert_element_type.5639), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.5642 = f32[16,2048]{1,0} power(%add.5640, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5647 = f32[16]{0} reduce(%pow.5642, %constant.512), dimensions={1}, to_apply=%region_138.5646, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5648 = f32[16,1]{1,0} reshape(%reduce_sum.5647), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5649 = f32[16,1]{1,0} divide(%broadcast_in_dim.5648, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5650 = f32[16,1]{1,0} add(%div.5649, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5651 = f32[16,1]{1,0} rsqrt(%add.5650), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5652 = f32[16,1]{1,0} broadcast(%rsqrt.5651), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5653 = f32[16]{0} reshape(%mul.5652), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5654 = f32[16,2048]{1,0} broadcast(%mul.5653), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5655 = f32[16,2048]{1,0} multiply(%add.5640, %mul.5654), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5656 = bf16[16,2048]{1,0} convert(%mul.5655), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_27_input_layernorm_weight__.183 = bf16[2048]{0} parameter(182), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.27.input_layernorm.weight\']"}
  %broadcast_in_dim.5657 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_27_input_layernorm_weight__.183), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5658 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.5657), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5659 = bf16[2048]{0} reshape(%mul.5658), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5660 = bf16[16,2048]{1,0} broadcast(%mul.5659), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5661 = bf16[16,2048]{1,0} multiply(%convert_element_type.5656, %mul.5660), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_27_self_attn_qkv_proj_weight__.191 = bf16[5120,2048]{1,0} parameter(190), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.27.self_attn.qkv_proj.weight\']"}
  %dot_general.5662 = bf16[16,5120]{1,0} dot(%mul.5661, %params_and_buffers__vllm_model_language_model_model_layers_27_self_attn_qkv_proj_weight__.191), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.5663 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.5662), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.5664 = bf16[16,4,1024]{2,1,0} slice(%reshape.5663), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.5668 = bf16[16,32,128]{2,1,0} reshape(%slice.5664), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.5669 = f32[16,32,128]{2,1,0} convert(%reshape.5668), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.5670 = f32[16,32,128]{2,1,0} power(%convert_element_type.5669, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5675 = f32[16,32]{1,0} reduce(%pow.5670, %constant.512), dimensions={2}, to_apply=%region_139.5674, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5676 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.5675), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5677 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.5676, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5678 = f32[16,32,1]{2,1,0} add(%div.5677, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5679 = f32[16,32,1]{2,1,0} rsqrt(%add.5678), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5680 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.5679), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5681 = f32[16,32]{1,0} reshape(%mul.5680), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5682 = f32[16,32,128]{2,1,0} broadcast(%mul.5681), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5683 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.5669, %mul.5682), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5684 = bf16[16,32,128]{2,1,0} convert(%mul.5683), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_27_self_attn_q_norm_weight__.190 = bf16[128]{0} parameter(189), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.27.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.5685 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_27_self_attn_q_norm_weight__.190), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5686 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.5685), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5687 = bf16[128]{0} reshape(%mul.5686), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5688 = bf16[16,32,128]{2,1,0} broadcast(%mul.5687), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5689 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.5684, %mul.5688), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5720 = bf16[16,32,64]{2,1,0} slice(%mul.5689), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.5711 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.5712 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.5713 = s32[16]{0} select(%lt.5711, %add.5712, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.5714 = s32[16,1]{1,0} reshape(%select_n.5713), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.5715 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.5714), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.5716 = bf16[16,64]{1,0} slice(%gather.5715), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5718 = bf16[16,1,64]{2,1,0} reshape(%slice.5716), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5722 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5718), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5723 = bf16[16,64]{1,0} reshape(%mul.5722), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5724 = bf16[16,32,64]{2,1,0} broadcast(%mul.5723), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5725 = bf16[16,32,64]{2,1,0} multiply(%slice.5720, %mul.5724), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5721 = bf16[16,32,64]{2,1,0} slice(%mul.5689), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.5717 = bf16[16,64]{1,0} slice(%gather.5715), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5719 = bf16[16,1,64]{2,1,0} reshape(%slice.5717), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5726 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5719), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5727 = bf16[16,64]{1,0} reshape(%mul.5726), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5728 = bf16[16,32,64]{2,1,0} broadcast(%mul.5727), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5729 = bf16[16,32,64]{2,1,0} multiply(%slice.5721, %mul.5728), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.5730 = bf16[16,32,64]{2,1,0} subtract(%mul.5725, %mul.5729), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.5731 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5718), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5732 = bf16[16,64]{1,0} reshape(%mul.5731), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5733 = bf16[16,32,64]{2,1,0} broadcast(%mul.5732), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5734 = bf16[16,32,64]{2,1,0} multiply(%slice.5721, %mul.5733), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5735 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5719), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5736 = bf16[16,64]{1,0} reshape(%mul.5735), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5737 = bf16[16,32,64]{2,1,0} broadcast(%mul.5736), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5738 = bf16[16,32,64]{2,1,0} multiply(%slice.5720, %mul.5737), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.5739 = bf16[16,32,64]{2,1,0} add(%mul.5734, %mul.5738), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.5740 = bf16[16,32,128]{2,1,0} concatenate(%sub.5730, %add.5739), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.5741 = bf16[16,4096]{1,0} reshape(%concatenate.5740), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.5665 = bf16[16,4,128]{2,1,0} slice(%reshape.5663), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.5690 = f32[16,4,128]{2,1,0} convert(%slice.5665), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.5691 = f32[16,4,128]{2,1,0} power(%convert_element_type.5690, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5696 = f32[16,4]{1,0} reduce(%pow.5691, %constant.512), dimensions={2}, to_apply=%region_140.5695, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5697 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.5696), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5698 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.5697, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5699 = f32[16,4,1]{2,1,0} add(%div.5698, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5700 = f32[16,4,1]{2,1,0} rsqrt(%add.5699), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5701 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.5700), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5702 = f32[16,4]{1,0} reshape(%mul.5701), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5703 = f32[16,4,128]{2,1,0} broadcast(%mul.5702), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5704 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.5690, %mul.5703), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5705 = bf16[16,4,128]{2,1,0} convert(%mul.5704), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_27_self_attn_k_norm_weight__.188 = bf16[128]{0} parameter(187), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.27.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.5706 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_27_self_attn_k_norm_weight__.188), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5707 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.5706), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5708 = bf16[128]{0} reshape(%mul.5707), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5709 = bf16[16,4,128]{2,1,0} broadcast(%mul.5708), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5710 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.5705, %mul.5709), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5744 = bf16[16,4,64]{2,1,0} slice(%mul.5710), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5742 = bf16[16,1,64]{2,1,0} reshape(%slice.5716), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5746 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5742), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5747 = bf16[16,64]{1,0} reshape(%mul.5746), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5748 = bf16[16,4,64]{2,1,0} broadcast(%mul.5747), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5749 = bf16[16,4,64]{2,1,0} multiply(%slice.5744, %mul.5748), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5745 = bf16[16,4,64]{2,1,0} slice(%mul.5710), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5743 = bf16[16,1,64]{2,1,0} reshape(%slice.5717), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5750 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5743), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5751 = bf16[16,64]{1,0} reshape(%mul.5750), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5752 = bf16[16,4,64]{2,1,0} broadcast(%mul.5751), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5753 = bf16[16,4,64]{2,1,0} multiply(%slice.5745, %mul.5752), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.5754 = bf16[16,4,64]{2,1,0} subtract(%mul.5749, %mul.5753), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.5755 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5742), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5756 = bf16[16,64]{1,0} reshape(%mul.5755), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5757 = bf16[16,4,64]{2,1,0} broadcast(%mul.5756), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5758 = bf16[16,4,64]{2,1,0} multiply(%slice.5745, %mul.5757), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5759 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5743), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5760 = bf16[16,64]{1,0} reshape(%mul.5759), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5761 = bf16[16,4,64]{2,1,0} broadcast(%mul.5760), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5762 = bf16[16,4,64]{2,1,0} multiply(%slice.5744, %mul.5761), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.5763 = bf16[16,4,64]{2,1,0} add(%mul.5758, %mul.5762), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.5764 = bf16[16,4,128]{2,1,0} concatenate(%sub.5754, %add.5763), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.5765 = bf16[16,512]{1,0} reshape(%concatenate.5764), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.5666 = bf16[16,4,128]{2,1,0} slice(%reshape.5663), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.5667 = bf16[16,512]{1,0} reshape(%slice.5666), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.5766 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_27_.463, %reshape.5741, %reshape.5765, %reshape.5667, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.5767 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.5766), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_28_.464 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(463), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[28]"}
  %jit__jax_attn_func_.5768 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.5766), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_27_self_attn_o_proj_weight__.189 = bf16[2048,4096]{1,0} parameter(188), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.27.self_attn.o_proj.weight\']"}
  %dot_general.5769 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.5768, %params_and_buffers__vllm_model_language_model_model_layers_27_self_attn_o_proj_weight__.189), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.5770 = f32[16,2048]{1,0} convert(%dot_general.5769), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5641 = bf16[16,2048]{1,0} convert(%add.5640), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5771 = f32[16,2048]{1,0} convert(%convert_element_type.5641), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.5772 = f32[16,2048]{1,0} add(%convert_element_type.5770, %convert_element_type.5771), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.5774 = f32[16,2048]{1,0} power(%add.5772, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5779 = f32[16]{0} reduce(%pow.5774, %constant.512), dimensions={1}, to_apply=%region_141.5778, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5780 = f32[16,1]{1,0} reshape(%reduce_sum.5779), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5781 = f32[16,1]{1,0} divide(%broadcast_in_dim.5780, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5782 = f32[16,1]{1,0} add(%div.5781, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5783 = f32[16,1]{1,0} rsqrt(%add.5782), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5784 = f32[16,1]{1,0} broadcast(%rsqrt.5783), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5785 = f32[16]{0} reshape(%mul.5784), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5786 = f32[16,2048]{1,0} broadcast(%mul.5785), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5787 = f32[16,2048]{1,0} multiply(%add.5772, %mul.5786), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5788 = bf16[16,2048]{1,0} convert(%mul.5787), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_27_post_attention_layernorm_weight__.187 = bf16[2048]{0} parameter(186), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.27.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.5789 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_27_post_attention_layernorm_weight__.187), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5790 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.5789), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5791 = bf16[2048]{0} reshape(%mul.5790), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5792 = bf16[16,2048]{1,0} broadcast(%mul.5791), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5793 = bf16[16,2048]{1,0} multiply(%convert_element_type.5788, %mul.5792), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_27_mlp_experts_w13_weight__.184 = bf16[128,1536,2048]{2,1,0} parameter(183), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.27.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_27_mlp_experts_w2_weight__.185 = bf16[128,2048,768]{2,1,0} parameter(184), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.27.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_27_mlp_gate_weight__.186 = bf16[128,2048]{1,0} parameter(185), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.27.mlp.gate.weight\']"}
  %dot_general.5794 = bf16[16,128]{1,0} dot(%mul.5793, %params_and_buffers__vllm_model_language_model_model_layers_27_mlp_gate_weight__.186), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.5795 = bf16[16,2048]{1,0} call(%mul.5793, %params_and_buffers__vllm_model_language_model_model_layers_27_mlp_experts_w13_weight__.184, %params_and_buffers__vllm_model_language_model_model_layers_27_mlp_experts_w2_weight__.185, %dot_general.5794), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.5796 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.5795), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5773 = bf16[16,2048]{1,0} convert(%add.5772), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5797 = f32[16,2048]{1,0} convert(%convert_element_type.5773), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.5798 = f32[16,2048]{1,0} add(%convert_element_type.5796, %convert_element_type.5797), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.5800 = f32[16,2048]{1,0} power(%add.5798, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5805 = f32[16]{0} reduce(%pow.5800, %constant.512), dimensions={1}, to_apply=%region_142.5804, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5806 = f32[16,1]{1,0} reshape(%reduce_sum.5805), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5807 = f32[16,1]{1,0} divide(%broadcast_in_dim.5806, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5808 = f32[16,1]{1,0} add(%div.5807, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5809 = f32[16,1]{1,0} rsqrt(%add.5808), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5810 = f32[16,1]{1,0} broadcast(%rsqrt.5809), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5811 = f32[16]{0} reshape(%mul.5810), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5812 = f32[16,2048]{1,0} broadcast(%mul.5811), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5813 = f32[16,2048]{1,0} multiply(%add.5798, %mul.5812), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5814 = bf16[16,2048]{1,0} convert(%mul.5813), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_28_input_layernorm_weight__.192 = bf16[2048]{0} parameter(191), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.28.input_layernorm.weight\']"}
  %broadcast_in_dim.5815 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_28_input_layernorm_weight__.192), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5816 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.5815), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5817 = bf16[2048]{0} reshape(%mul.5816), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5818 = bf16[16,2048]{1,0} broadcast(%mul.5817), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5819 = bf16[16,2048]{1,0} multiply(%convert_element_type.5814, %mul.5818), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_28_self_attn_qkv_proj_weight__.200 = bf16[5120,2048]{1,0} parameter(199), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.28.self_attn.qkv_proj.weight\']"}
  %dot_general.5820 = bf16[16,5120]{1,0} dot(%mul.5819, %params_and_buffers__vllm_model_language_model_model_layers_28_self_attn_qkv_proj_weight__.200), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.5821 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.5820), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.5822 = bf16[16,4,1024]{2,1,0} slice(%reshape.5821), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.5826 = bf16[16,32,128]{2,1,0} reshape(%slice.5822), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.5827 = f32[16,32,128]{2,1,0} convert(%reshape.5826), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.5828 = f32[16,32,128]{2,1,0} power(%convert_element_type.5827, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5833 = f32[16,32]{1,0} reduce(%pow.5828, %constant.512), dimensions={2}, to_apply=%region_143.5832, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5834 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.5833), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5835 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.5834, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5836 = f32[16,32,1]{2,1,0} add(%div.5835, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5837 = f32[16,32,1]{2,1,0} rsqrt(%add.5836), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5838 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.5837), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5839 = f32[16,32]{1,0} reshape(%mul.5838), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5840 = f32[16,32,128]{2,1,0} broadcast(%mul.5839), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5841 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.5827, %mul.5840), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5842 = bf16[16,32,128]{2,1,0} convert(%mul.5841), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_28_self_attn_q_norm_weight__.199 = bf16[128]{0} parameter(198), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.28.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.5843 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_28_self_attn_q_norm_weight__.199), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5844 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.5843), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5845 = bf16[128]{0} reshape(%mul.5844), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5846 = bf16[16,32,128]{2,1,0} broadcast(%mul.5845), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5847 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.5842, %mul.5846), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5878 = bf16[16,32,64]{2,1,0} slice(%mul.5847), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.5869 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.5870 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.5871 = s32[16]{0} select(%lt.5869, %add.5870, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.5872 = s32[16,1]{1,0} reshape(%select_n.5871), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.5873 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.5872), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.5874 = bf16[16,64]{1,0} slice(%gather.5873), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5876 = bf16[16,1,64]{2,1,0} reshape(%slice.5874), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5880 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5876), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5881 = bf16[16,64]{1,0} reshape(%mul.5880), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5882 = bf16[16,32,64]{2,1,0} broadcast(%mul.5881), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5883 = bf16[16,32,64]{2,1,0} multiply(%slice.5878, %mul.5882), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5879 = bf16[16,32,64]{2,1,0} slice(%mul.5847), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.5875 = bf16[16,64]{1,0} slice(%gather.5873), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5877 = bf16[16,1,64]{2,1,0} reshape(%slice.5875), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5884 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5877), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5885 = bf16[16,64]{1,0} reshape(%mul.5884), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5886 = bf16[16,32,64]{2,1,0} broadcast(%mul.5885), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5887 = bf16[16,32,64]{2,1,0} multiply(%slice.5879, %mul.5886), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.5888 = bf16[16,32,64]{2,1,0} subtract(%mul.5883, %mul.5887), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.5889 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5876), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5890 = bf16[16,64]{1,0} reshape(%mul.5889), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5891 = bf16[16,32,64]{2,1,0} broadcast(%mul.5890), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5892 = bf16[16,32,64]{2,1,0} multiply(%slice.5879, %mul.5891), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5893 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5877), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5894 = bf16[16,64]{1,0} reshape(%mul.5893), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5895 = bf16[16,32,64]{2,1,0} broadcast(%mul.5894), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5896 = bf16[16,32,64]{2,1,0} multiply(%slice.5878, %mul.5895), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.5897 = bf16[16,32,64]{2,1,0} add(%mul.5892, %mul.5896), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.5898 = bf16[16,32,128]{2,1,0} concatenate(%sub.5888, %add.5897), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.5899 = bf16[16,4096]{1,0} reshape(%concatenate.5898), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.5823 = bf16[16,4,128]{2,1,0} slice(%reshape.5821), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.5848 = f32[16,4,128]{2,1,0} convert(%slice.5823), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.5849 = f32[16,4,128]{2,1,0} power(%convert_element_type.5848, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5854 = f32[16,4]{1,0} reduce(%pow.5849, %constant.512), dimensions={2}, to_apply=%region_144.5853, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5855 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.5854), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5856 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.5855, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5857 = f32[16,4,1]{2,1,0} add(%div.5856, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5858 = f32[16,4,1]{2,1,0} rsqrt(%add.5857), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5859 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.5858), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5860 = f32[16,4]{1,0} reshape(%mul.5859), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5861 = f32[16,4,128]{2,1,0} broadcast(%mul.5860), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5862 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.5848, %mul.5861), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5863 = bf16[16,4,128]{2,1,0} convert(%mul.5862), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_28_self_attn_k_norm_weight__.197 = bf16[128]{0} parameter(196), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.28.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.5864 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_28_self_attn_k_norm_weight__.197), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5865 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.5864), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5866 = bf16[128]{0} reshape(%mul.5865), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5867 = bf16[16,4,128]{2,1,0} broadcast(%mul.5866), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5868 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.5863, %mul.5867), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5902 = bf16[16,4,64]{2,1,0} slice(%mul.5868), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5900 = bf16[16,1,64]{2,1,0} reshape(%slice.5874), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5904 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5900), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5905 = bf16[16,64]{1,0} reshape(%mul.5904), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5906 = bf16[16,4,64]{2,1,0} broadcast(%mul.5905), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5907 = bf16[16,4,64]{2,1,0} multiply(%slice.5902, %mul.5906), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5903 = bf16[16,4,64]{2,1,0} slice(%mul.5868), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5901 = bf16[16,1,64]{2,1,0} reshape(%slice.5875), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5908 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5901), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5909 = bf16[16,64]{1,0} reshape(%mul.5908), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5910 = bf16[16,4,64]{2,1,0} broadcast(%mul.5909), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5911 = bf16[16,4,64]{2,1,0} multiply(%slice.5903, %mul.5910), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.5912 = bf16[16,4,64]{2,1,0} subtract(%mul.5907, %mul.5911), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.5913 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5900), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5914 = bf16[16,64]{1,0} reshape(%mul.5913), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5915 = bf16[16,4,64]{2,1,0} broadcast(%mul.5914), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5916 = bf16[16,4,64]{2,1,0} multiply(%slice.5903, %mul.5915), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5917 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.5901), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5918 = bf16[16,64]{1,0} reshape(%mul.5917), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5919 = bf16[16,4,64]{2,1,0} broadcast(%mul.5918), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5920 = bf16[16,4,64]{2,1,0} multiply(%slice.5902, %mul.5919), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.5921 = bf16[16,4,64]{2,1,0} add(%mul.5916, %mul.5920), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.5922 = bf16[16,4,128]{2,1,0} concatenate(%sub.5912, %add.5921), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.5923 = bf16[16,512]{1,0} reshape(%concatenate.5922), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.5824 = bf16[16,4,128]{2,1,0} slice(%reshape.5821), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.5825 = bf16[16,512]{1,0} reshape(%slice.5824), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.5924 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_28_.464, %reshape.5899, %reshape.5923, %reshape.5825, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.5925 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.5924), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_29_.465 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(464), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[29]"}
  %jit__jax_attn_func_.5926 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.5924), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_28_self_attn_o_proj_weight__.198 = bf16[2048,4096]{1,0} parameter(197), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.28.self_attn.o_proj.weight\']"}
  %dot_general.5927 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.5926, %params_and_buffers__vllm_model_language_model_model_layers_28_self_attn_o_proj_weight__.198), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.5928 = f32[16,2048]{1,0} convert(%dot_general.5927), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5799 = bf16[16,2048]{1,0} convert(%add.5798), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5929 = f32[16,2048]{1,0} convert(%convert_element_type.5799), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.5930 = f32[16,2048]{1,0} add(%convert_element_type.5928, %convert_element_type.5929), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.5932 = f32[16,2048]{1,0} power(%add.5930, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5937 = f32[16]{0} reduce(%pow.5932, %constant.512), dimensions={1}, to_apply=%region_145.5936, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5938 = f32[16,1]{1,0} reshape(%reduce_sum.5937), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5939 = f32[16,1]{1,0} divide(%broadcast_in_dim.5938, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5940 = f32[16,1]{1,0} add(%div.5939, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5941 = f32[16,1]{1,0} rsqrt(%add.5940), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5942 = f32[16,1]{1,0} broadcast(%rsqrt.5941), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5943 = f32[16]{0} reshape(%mul.5942), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5944 = f32[16,2048]{1,0} broadcast(%mul.5943), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5945 = f32[16,2048]{1,0} multiply(%add.5930, %mul.5944), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5946 = bf16[16,2048]{1,0} convert(%mul.5945), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_28_post_attention_layernorm_weight__.196 = bf16[2048]{0} parameter(195), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.28.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.5947 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_28_post_attention_layernorm_weight__.196), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5948 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.5947), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5949 = bf16[2048]{0} reshape(%mul.5948), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5950 = bf16[16,2048]{1,0} broadcast(%mul.5949), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5951 = bf16[16,2048]{1,0} multiply(%convert_element_type.5946, %mul.5950), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_28_mlp_experts_w13_weight__.193 = bf16[128,1536,2048]{2,1,0} parameter(192), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.28.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_28_mlp_experts_w2_weight__.194 = bf16[128,2048,768]{2,1,0} parameter(193), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.28.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_28_mlp_gate_weight__.195 = bf16[128,2048]{1,0} parameter(194), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.28.mlp.gate.weight\']"}
  %dot_general.5952 = bf16[16,128]{1,0} dot(%mul.5951, %params_and_buffers__vllm_model_language_model_model_layers_28_mlp_gate_weight__.195), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.5953 = bf16[16,2048]{1,0} call(%mul.5951, %params_and_buffers__vllm_model_language_model_model_layers_28_mlp_experts_w13_weight__.193, %params_and_buffers__vllm_model_language_model_model_layers_28_mlp_experts_w2_weight__.194, %dot_general.5952), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.5954 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.5953), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5931 = bf16[16,2048]{1,0} convert(%add.5930), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5955 = f32[16,2048]{1,0} convert(%convert_element_type.5931), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.5956 = f32[16,2048]{1,0} add(%convert_element_type.5954, %convert_element_type.5955), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.5958 = f32[16,2048]{1,0} power(%add.5956, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5963 = f32[16]{0} reduce(%pow.5958, %constant.512), dimensions={1}, to_apply=%region_146.5962, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5964 = f32[16,1]{1,0} reshape(%reduce_sum.5963), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5965 = f32[16,1]{1,0} divide(%broadcast_in_dim.5964, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5966 = f32[16,1]{1,0} add(%div.5965, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5967 = f32[16,1]{1,0} rsqrt(%add.5966), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5968 = f32[16,1]{1,0} broadcast(%rsqrt.5967), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5969 = f32[16]{0} reshape(%mul.5968), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5970 = f32[16,2048]{1,0} broadcast(%mul.5969), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5971 = f32[16,2048]{1,0} multiply(%add.5956, %mul.5970), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5972 = bf16[16,2048]{1,0} convert(%mul.5971), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_29_input_layernorm_weight__.201 = bf16[2048]{0} parameter(200), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.29.input_layernorm.weight\']"}
  %broadcast_in_dim.5973 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_29_input_layernorm_weight__.201), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5974 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.5973), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5975 = bf16[2048]{0} reshape(%mul.5974), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5976 = bf16[16,2048]{1,0} broadcast(%mul.5975), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5977 = bf16[16,2048]{1,0} multiply(%convert_element_type.5972, %mul.5976), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_29_self_attn_qkv_proj_weight__.209 = bf16[5120,2048]{1,0} parameter(208), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.29.self_attn.qkv_proj.weight\']"}
  %dot_general.5978 = bf16[16,5120]{1,0} dot(%mul.5977, %params_and_buffers__vllm_model_language_model_model_layers_29_self_attn_qkv_proj_weight__.209), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.5979 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.5978), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.5980 = bf16[16,4,1024]{2,1,0} slice(%reshape.5979), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.5984 = bf16[16,32,128]{2,1,0} reshape(%slice.5980), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.5985 = f32[16,32,128]{2,1,0} convert(%reshape.5984), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.5986 = f32[16,32,128]{2,1,0} power(%convert_element_type.5985, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5991 = f32[16,32]{1,0} reduce(%pow.5986, %constant.512), dimensions={2}, to_apply=%region_147.5990, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5992 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.5991), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5993 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.5992, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5994 = f32[16,32,1]{2,1,0} add(%div.5993, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5995 = f32[16,32,1]{2,1,0} rsqrt(%add.5994), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5996 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.5995), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5997 = f32[16,32]{1,0} reshape(%mul.5996), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5998 = f32[16,32,128]{2,1,0} broadcast(%mul.5997), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5999 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.5985, %mul.5998), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6000 = bf16[16,32,128]{2,1,0} convert(%mul.5999), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_29_self_attn_q_norm_weight__.208 = bf16[128]{0} parameter(207), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.29.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.6001 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_29_self_attn_q_norm_weight__.208), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6002 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.6001), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6003 = bf16[128]{0} reshape(%mul.6002), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6004 = bf16[16,32,128]{2,1,0} broadcast(%mul.6003), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6005 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.6000, %mul.6004), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6036 = bf16[16,32,64]{2,1,0} slice(%mul.6005), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.6027 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.6028 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.6029 = s32[16]{0} select(%lt.6027, %add.6028, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.6030 = s32[16,1]{1,0} reshape(%select_n.6029), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.6031 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.6030), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.6032 = bf16[16,64]{1,0} slice(%gather.6031), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6034 = bf16[16,1,64]{2,1,0} reshape(%slice.6032), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6038 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6034), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6039 = bf16[16,64]{1,0} reshape(%mul.6038), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6040 = bf16[16,32,64]{2,1,0} broadcast(%mul.6039), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6041 = bf16[16,32,64]{2,1,0} multiply(%slice.6036, %mul.6040), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6037 = bf16[16,32,64]{2,1,0} slice(%mul.6005), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.6033 = bf16[16,64]{1,0} slice(%gather.6031), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6035 = bf16[16,1,64]{2,1,0} reshape(%slice.6033), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6042 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6035), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6043 = bf16[16,64]{1,0} reshape(%mul.6042), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6044 = bf16[16,32,64]{2,1,0} broadcast(%mul.6043), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6045 = bf16[16,32,64]{2,1,0} multiply(%slice.6037, %mul.6044), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.6046 = bf16[16,32,64]{2,1,0} subtract(%mul.6041, %mul.6045), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.6047 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6034), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6048 = bf16[16,64]{1,0} reshape(%mul.6047), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6049 = bf16[16,32,64]{2,1,0} broadcast(%mul.6048), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6050 = bf16[16,32,64]{2,1,0} multiply(%slice.6037, %mul.6049), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6051 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6035), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6052 = bf16[16,64]{1,0} reshape(%mul.6051), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6053 = bf16[16,32,64]{2,1,0} broadcast(%mul.6052), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6054 = bf16[16,32,64]{2,1,0} multiply(%slice.6036, %mul.6053), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.6055 = bf16[16,32,64]{2,1,0} add(%mul.6050, %mul.6054), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.6056 = bf16[16,32,128]{2,1,0} concatenate(%sub.6046, %add.6055), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.6057 = bf16[16,4096]{1,0} reshape(%concatenate.6056), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.5981 = bf16[16,4,128]{2,1,0} slice(%reshape.5979), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.6006 = f32[16,4,128]{2,1,0} convert(%slice.5981), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.6007 = f32[16,4,128]{2,1,0} power(%convert_element_type.6006, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6012 = f32[16,4]{1,0} reduce(%pow.6007, %constant.512), dimensions={2}, to_apply=%region_148.6011, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6013 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.6012), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6014 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.6013, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6015 = f32[16,4,1]{2,1,0} add(%div.6014, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6016 = f32[16,4,1]{2,1,0} rsqrt(%add.6015), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6017 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.6016), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6018 = f32[16,4]{1,0} reshape(%mul.6017), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6019 = f32[16,4,128]{2,1,0} broadcast(%mul.6018), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6020 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.6006, %mul.6019), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6021 = bf16[16,4,128]{2,1,0} convert(%mul.6020), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_29_self_attn_k_norm_weight__.206 = bf16[128]{0} parameter(205), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.29.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.6022 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_29_self_attn_k_norm_weight__.206), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6023 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.6022), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6024 = bf16[128]{0} reshape(%mul.6023), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6025 = bf16[16,4,128]{2,1,0} broadcast(%mul.6024), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6026 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.6021, %mul.6025), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6060 = bf16[16,4,64]{2,1,0} slice(%mul.6026), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6058 = bf16[16,1,64]{2,1,0} reshape(%slice.6032), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6062 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6058), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6063 = bf16[16,64]{1,0} reshape(%mul.6062), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6064 = bf16[16,4,64]{2,1,0} broadcast(%mul.6063), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6065 = bf16[16,4,64]{2,1,0} multiply(%slice.6060, %mul.6064), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6061 = bf16[16,4,64]{2,1,0} slice(%mul.6026), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6059 = bf16[16,1,64]{2,1,0} reshape(%slice.6033), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6066 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6059), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6067 = bf16[16,64]{1,0} reshape(%mul.6066), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6068 = bf16[16,4,64]{2,1,0} broadcast(%mul.6067), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6069 = bf16[16,4,64]{2,1,0} multiply(%slice.6061, %mul.6068), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.6070 = bf16[16,4,64]{2,1,0} subtract(%mul.6065, %mul.6069), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.6071 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6058), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6072 = bf16[16,64]{1,0} reshape(%mul.6071), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6073 = bf16[16,4,64]{2,1,0} broadcast(%mul.6072), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6074 = bf16[16,4,64]{2,1,0} multiply(%slice.6061, %mul.6073), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6075 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6059), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6076 = bf16[16,64]{1,0} reshape(%mul.6075), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6077 = bf16[16,4,64]{2,1,0} broadcast(%mul.6076), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6078 = bf16[16,4,64]{2,1,0} multiply(%slice.6060, %mul.6077), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.6079 = bf16[16,4,64]{2,1,0} add(%mul.6074, %mul.6078), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.6080 = bf16[16,4,128]{2,1,0} concatenate(%sub.6070, %add.6079), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.6081 = bf16[16,512]{1,0} reshape(%concatenate.6080), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.5982 = bf16[16,4,128]{2,1,0} slice(%reshape.5979), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.5983 = bf16[16,512]{1,0} reshape(%slice.5982), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.6082 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_29_.465, %reshape.6057, %reshape.6081, %reshape.5983, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.6083 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.6082), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_30_.466 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(465), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[30]"}
  %jit__jax_attn_func_.6084 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.6082), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_29_self_attn_o_proj_weight__.207 = bf16[2048,4096]{1,0} parameter(206), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.29.self_attn.o_proj.weight\']"}
  %dot_general.6085 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.6084, %params_and_buffers__vllm_model_language_model_model_layers_29_self_attn_o_proj_weight__.207), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.6086 = f32[16,2048]{1,0} convert(%dot_general.6085), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5957 = bf16[16,2048]{1,0} convert(%add.5956), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6087 = f32[16,2048]{1,0} convert(%convert_element_type.5957), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.6088 = f32[16,2048]{1,0} add(%convert_element_type.6086, %convert_element_type.6087), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.6090 = f32[16,2048]{1,0} power(%add.6088, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6095 = f32[16]{0} reduce(%pow.6090, %constant.512), dimensions={1}, to_apply=%region_149.6094, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6096 = f32[16,1]{1,0} reshape(%reduce_sum.6095), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6097 = f32[16,1]{1,0} divide(%broadcast_in_dim.6096, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6098 = f32[16,1]{1,0} add(%div.6097, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6099 = f32[16,1]{1,0} rsqrt(%add.6098), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6100 = f32[16,1]{1,0} broadcast(%rsqrt.6099), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6101 = f32[16]{0} reshape(%mul.6100), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6102 = f32[16,2048]{1,0} broadcast(%mul.6101), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6103 = f32[16,2048]{1,0} multiply(%add.6088, %mul.6102), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6104 = bf16[16,2048]{1,0} convert(%mul.6103), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_29_post_attention_layernorm_weight__.205 = bf16[2048]{0} parameter(204), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.29.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.6105 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_29_post_attention_layernorm_weight__.205), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6106 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.6105), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6107 = bf16[2048]{0} reshape(%mul.6106), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6108 = bf16[16,2048]{1,0} broadcast(%mul.6107), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6109 = bf16[16,2048]{1,0} multiply(%convert_element_type.6104, %mul.6108), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_29_mlp_experts_w13_weight__.202 = bf16[128,1536,2048]{2,1,0} parameter(201), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.29.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_29_mlp_experts_w2_weight__.203 = bf16[128,2048,768]{2,1,0} parameter(202), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.29.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_29_mlp_gate_weight__.204 = bf16[128,2048]{1,0} parameter(203), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.29.mlp.gate.weight\']"}
  %dot_general.6110 = bf16[16,128]{1,0} dot(%mul.6109, %params_and_buffers__vllm_model_language_model_model_layers_29_mlp_gate_weight__.204), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.6111 = bf16[16,2048]{1,0} call(%mul.6109, %params_and_buffers__vllm_model_language_model_model_layers_29_mlp_experts_w13_weight__.202, %params_and_buffers__vllm_model_language_model_model_layers_29_mlp_experts_w2_weight__.203, %dot_general.6110), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.6112 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.6111), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6089 = bf16[16,2048]{1,0} convert(%add.6088), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6113 = f32[16,2048]{1,0} convert(%convert_element_type.6089), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.6114 = f32[16,2048]{1,0} add(%convert_element_type.6112, %convert_element_type.6113), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.6116 = f32[16,2048]{1,0} power(%add.6114, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6121 = f32[16]{0} reduce(%pow.6116, %constant.512), dimensions={1}, to_apply=%region_150.6120, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6122 = f32[16,1]{1,0} reshape(%reduce_sum.6121), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6123 = f32[16,1]{1,0} divide(%broadcast_in_dim.6122, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6124 = f32[16,1]{1,0} add(%div.6123, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6125 = f32[16,1]{1,0} rsqrt(%add.6124), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6126 = f32[16,1]{1,0} broadcast(%rsqrt.6125), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6127 = f32[16]{0} reshape(%mul.6126), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6128 = f32[16,2048]{1,0} broadcast(%mul.6127), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6129 = f32[16,2048]{1,0} multiply(%add.6114, %mul.6128), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6130 = bf16[16,2048]{1,0} convert(%mul.6129), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_30_input_layernorm_weight__.219 = bf16[2048]{0} parameter(218), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.30.input_layernorm.weight\']"}
  %broadcast_in_dim.6131 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_30_input_layernorm_weight__.219), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6132 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.6131), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6133 = bf16[2048]{0} reshape(%mul.6132), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6134 = bf16[16,2048]{1,0} broadcast(%mul.6133), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6135 = bf16[16,2048]{1,0} multiply(%convert_element_type.6130, %mul.6134), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_30_self_attn_qkv_proj_weight__.227 = bf16[5120,2048]{1,0} parameter(226), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.30.self_attn.qkv_proj.weight\']"}
  %dot_general.6136 = bf16[16,5120]{1,0} dot(%mul.6135, %params_and_buffers__vllm_model_language_model_model_layers_30_self_attn_qkv_proj_weight__.227), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.6137 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.6136), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.6138 = bf16[16,4,1024]{2,1,0} slice(%reshape.6137), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.6142 = bf16[16,32,128]{2,1,0} reshape(%slice.6138), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.6143 = f32[16,32,128]{2,1,0} convert(%reshape.6142), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.6144 = f32[16,32,128]{2,1,0} power(%convert_element_type.6143, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6149 = f32[16,32]{1,0} reduce(%pow.6144, %constant.512), dimensions={2}, to_apply=%region_151.6148, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6150 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.6149), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6151 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.6150, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6152 = f32[16,32,1]{2,1,0} add(%div.6151, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6153 = f32[16,32,1]{2,1,0} rsqrt(%add.6152), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6154 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.6153), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6155 = f32[16,32]{1,0} reshape(%mul.6154), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6156 = f32[16,32,128]{2,1,0} broadcast(%mul.6155), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6157 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.6143, %mul.6156), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6158 = bf16[16,32,128]{2,1,0} convert(%mul.6157), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_30_self_attn_q_norm_weight__.226 = bf16[128]{0} parameter(225), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.30.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.6159 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_30_self_attn_q_norm_weight__.226), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6160 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.6159), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6161 = bf16[128]{0} reshape(%mul.6160), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6162 = bf16[16,32,128]{2,1,0} broadcast(%mul.6161), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6163 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.6158, %mul.6162), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6194 = bf16[16,32,64]{2,1,0} slice(%mul.6163), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.6185 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.6186 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.6187 = s32[16]{0} select(%lt.6185, %add.6186, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.6188 = s32[16,1]{1,0} reshape(%select_n.6187), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.6189 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.6188), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.6190 = bf16[16,64]{1,0} slice(%gather.6189), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6192 = bf16[16,1,64]{2,1,0} reshape(%slice.6190), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6196 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6192), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6197 = bf16[16,64]{1,0} reshape(%mul.6196), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6198 = bf16[16,32,64]{2,1,0} broadcast(%mul.6197), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6199 = bf16[16,32,64]{2,1,0} multiply(%slice.6194, %mul.6198), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6195 = bf16[16,32,64]{2,1,0} slice(%mul.6163), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.6191 = bf16[16,64]{1,0} slice(%gather.6189), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6193 = bf16[16,1,64]{2,1,0} reshape(%slice.6191), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6200 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6193), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6201 = bf16[16,64]{1,0} reshape(%mul.6200), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6202 = bf16[16,32,64]{2,1,0} broadcast(%mul.6201), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6203 = bf16[16,32,64]{2,1,0} multiply(%slice.6195, %mul.6202), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.6204 = bf16[16,32,64]{2,1,0} subtract(%mul.6199, %mul.6203), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.6205 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6192), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6206 = bf16[16,64]{1,0} reshape(%mul.6205), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6207 = bf16[16,32,64]{2,1,0} broadcast(%mul.6206), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6208 = bf16[16,32,64]{2,1,0} multiply(%slice.6195, %mul.6207), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6209 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6193), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6210 = bf16[16,64]{1,0} reshape(%mul.6209), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6211 = bf16[16,32,64]{2,1,0} broadcast(%mul.6210), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6212 = bf16[16,32,64]{2,1,0} multiply(%slice.6194, %mul.6211), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.6213 = bf16[16,32,64]{2,1,0} add(%mul.6208, %mul.6212), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.6214 = bf16[16,32,128]{2,1,0} concatenate(%sub.6204, %add.6213), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.6215 = bf16[16,4096]{1,0} reshape(%concatenate.6214), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.6139 = bf16[16,4,128]{2,1,0} slice(%reshape.6137), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.6164 = f32[16,4,128]{2,1,0} convert(%slice.6139), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.6165 = f32[16,4,128]{2,1,0} power(%convert_element_type.6164, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6170 = f32[16,4]{1,0} reduce(%pow.6165, %constant.512), dimensions={2}, to_apply=%region_152.6169, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6171 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.6170), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6172 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.6171, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6173 = f32[16,4,1]{2,1,0} add(%div.6172, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6174 = f32[16,4,1]{2,1,0} rsqrt(%add.6173), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6175 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.6174), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6176 = f32[16,4]{1,0} reshape(%mul.6175), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6177 = f32[16,4,128]{2,1,0} broadcast(%mul.6176), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6178 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.6164, %mul.6177), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6179 = bf16[16,4,128]{2,1,0} convert(%mul.6178), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_30_self_attn_k_norm_weight__.224 = bf16[128]{0} parameter(223), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.30.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.6180 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_30_self_attn_k_norm_weight__.224), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6181 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.6180), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6182 = bf16[128]{0} reshape(%mul.6181), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6183 = bf16[16,4,128]{2,1,0} broadcast(%mul.6182), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6184 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.6179, %mul.6183), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6218 = bf16[16,4,64]{2,1,0} slice(%mul.6184), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6216 = bf16[16,1,64]{2,1,0} reshape(%slice.6190), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6220 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6216), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6221 = bf16[16,64]{1,0} reshape(%mul.6220), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6222 = bf16[16,4,64]{2,1,0} broadcast(%mul.6221), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6223 = bf16[16,4,64]{2,1,0} multiply(%slice.6218, %mul.6222), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6219 = bf16[16,4,64]{2,1,0} slice(%mul.6184), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6217 = bf16[16,1,64]{2,1,0} reshape(%slice.6191), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6224 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6217), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6225 = bf16[16,64]{1,0} reshape(%mul.6224), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6226 = bf16[16,4,64]{2,1,0} broadcast(%mul.6225), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6227 = bf16[16,4,64]{2,1,0} multiply(%slice.6219, %mul.6226), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.6228 = bf16[16,4,64]{2,1,0} subtract(%mul.6223, %mul.6227), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.6229 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6216), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6230 = bf16[16,64]{1,0} reshape(%mul.6229), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6231 = bf16[16,4,64]{2,1,0} broadcast(%mul.6230), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6232 = bf16[16,4,64]{2,1,0} multiply(%slice.6219, %mul.6231), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6233 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6217), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6234 = bf16[16,64]{1,0} reshape(%mul.6233), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6235 = bf16[16,4,64]{2,1,0} broadcast(%mul.6234), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6236 = bf16[16,4,64]{2,1,0} multiply(%slice.6218, %mul.6235), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.6237 = bf16[16,4,64]{2,1,0} add(%mul.6232, %mul.6236), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.6238 = bf16[16,4,128]{2,1,0} concatenate(%sub.6228, %add.6237), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.6239 = bf16[16,512]{1,0} reshape(%concatenate.6238), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.6140 = bf16[16,4,128]{2,1,0} slice(%reshape.6137), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.6141 = bf16[16,512]{1,0} reshape(%slice.6140), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.6240 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_30_.466, %reshape.6215, %reshape.6239, %reshape.6141, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.6241 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.6240), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_31_.467 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(466), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[31]"}
  %jit__jax_attn_func_.6242 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.6240), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_30_self_attn_o_proj_weight__.225 = bf16[2048,4096]{1,0} parameter(224), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.30.self_attn.o_proj.weight\']"}
  %dot_general.6243 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.6242, %params_and_buffers__vllm_model_language_model_model_layers_30_self_attn_o_proj_weight__.225), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.6244 = f32[16,2048]{1,0} convert(%dot_general.6243), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6115 = bf16[16,2048]{1,0} convert(%add.6114), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6245 = f32[16,2048]{1,0} convert(%convert_element_type.6115), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.6246 = f32[16,2048]{1,0} add(%convert_element_type.6244, %convert_element_type.6245), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.6248 = f32[16,2048]{1,0} power(%add.6246, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6253 = f32[16]{0} reduce(%pow.6248, %constant.512), dimensions={1}, to_apply=%region_153.6252, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6254 = f32[16,1]{1,0} reshape(%reduce_sum.6253), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6255 = f32[16,1]{1,0} divide(%broadcast_in_dim.6254, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6256 = f32[16,1]{1,0} add(%div.6255, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6257 = f32[16,1]{1,0} rsqrt(%add.6256), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6258 = f32[16,1]{1,0} broadcast(%rsqrt.6257), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6259 = f32[16]{0} reshape(%mul.6258), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6260 = f32[16,2048]{1,0} broadcast(%mul.6259), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6261 = f32[16,2048]{1,0} multiply(%add.6246, %mul.6260), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6262 = bf16[16,2048]{1,0} convert(%mul.6261), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_30_post_attention_layernorm_weight__.223 = bf16[2048]{0} parameter(222), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.30.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.6263 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_30_post_attention_layernorm_weight__.223), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6264 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.6263), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6265 = bf16[2048]{0} reshape(%mul.6264), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6266 = bf16[16,2048]{1,0} broadcast(%mul.6265), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6267 = bf16[16,2048]{1,0} multiply(%convert_element_type.6262, %mul.6266), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_30_mlp_experts_w13_weight__.220 = bf16[128,1536,2048]{2,1,0} parameter(219), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.30.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_30_mlp_experts_w2_weight__.221 = bf16[128,2048,768]{2,1,0} parameter(220), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.30.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_30_mlp_gate_weight__.222 = bf16[128,2048]{1,0} parameter(221), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.30.mlp.gate.weight\']"}
  %dot_general.6268 = bf16[16,128]{1,0} dot(%mul.6267, %params_and_buffers__vllm_model_language_model_model_layers_30_mlp_gate_weight__.222), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.6269 = bf16[16,2048]{1,0} call(%mul.6267, %params_and_buffers__vllm_model_language_model_model_layers_30_mlp_experts_w13_weight__.220, %params_and_buffers__vllm_model_language_model_model_layers_30_mlp_experts_w2_weight__.221, %dot_general.6268), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.6270 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.6269), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6247 = bf16[16,2048]{1,0} convert(%add.6246), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6271 = f32[16,2048]{1,0} convert(%convert_element_type.6247), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.6272 = f32[16,2048]{1,0} add(%convert_element_type.6270, %convert_element_type.6271), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.6274 = f32[16,2048]{1,0} power(%add.6272, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6279 = f32[16]{0} reduce(%pow.6274, %constant.512), dimensions={1}, to_apply=%region_154.6278, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6280 = f32[16,1]{1,0} reshape(%reduce_sum.6279), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6281 = f32[16,1]{1,0} divide(%broadcast_in_dim.6280, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6282 = f32[16,1]{1,0} add(%div.6281, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6283 = f32[16,1]{1,0} rsqrt(%add.6282), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6284 = f32[16,1]{1,0} broadcast(%rsqrt.6283), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6285 = f32[16]{0} reshape(%mul.6284), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6286 = f32[16,2048]{1,0} broadcast(%mul.6285), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6287 = f32[16,2048]{1,0} multiply(%add.6272, %mul.6286), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6288 = bf16[16,2048]{1,0} convert(%mul.6287), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_31_input_layernorm_weight__.228 = bf16[2048]{0} parameter(227), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.31.input_layernorm.weight\']"}
  %broadcast_in_dim.6289 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_31_input_layernorm_weight__.228), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6290 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.6289), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6291 = bf16[2048]{0} reshape(%mul.6290), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6292 = bf16[16,2048]{1,0} broadcast(%mul.6291), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6293 = bf16[16,2048]{1,0} multiply(%convert_element_type.6288, %mul.6292), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_31_self_attn_qkv_proj_weight__.236 = bf16[5120,2048]{1,0} parameter(235), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.31.self_attn.qkv_proj.weight\']"}
  %dot_general.6294 = bf16[16,5120]{1,0} dot(%mul.6293, %params_and_buffers__vllm_model_language_model_model_layers_31_self_attn_qkv_proj_weight__.236), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.6295 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.6294), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.6296 = bf16[16,4,1024]{2,1,0} slice(%reshape.6295), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.6300 = bf16[16,32,128]{2,1,0} reshape(%slice.6296), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.6301 = f32[16,32,128]{2,1,0} convert(%reshape.6300), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.6302 = f32[16,32,128]{2,1,0} power(%convert_element_type.6301, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6307 = f32[16,32]{1,0} reduce(%pow.6302, %constant.512), dimensions={2}, to_apply=%region_155.6306, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6308 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.6307), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6309 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.6308, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6310 = f32[16,32,1]{2,1,0} add(%div.6309, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6311 = f32[16,32,1]{2,1,0} rsqrt(%add.6310), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6312 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.6311), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6313 = f32[16,32]{1,0} reshape(%mul.6312), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6314 = f32[16,32,128]{2,1,0} broadcast(%mul.6313), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6315 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.6301, %mul.6314), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6316 = bf16[16,32,128]{2,1,0} convert(%mul.6315), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_31_self_attn_q_norm_weight__.235 = bf16[128]{0} parameter(234), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.31.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.6317 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_31_self_attn_q_norm_weight__.235), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6318 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.6317), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6319 = bf16[128]{0} reshape(%mul.6318), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6320 = bf16[16,32,128]{2,1,0} broadcast(%mul.6319), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6321 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.6316, %mul.6320), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6352 = bf16[16,32,64]{2,1,0} slice(%mul.6321), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.6343 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.6344 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.6345 = s32[16]{0} select(%lt.6343, %add.6344, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.6346 = s32[16,1]{1,0} reshape(%select_n.6345), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.6347 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.6346), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.6348 = bf16[16,64]{1,0} slice(%gather.6347), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6350 = bf16[16,1,64]{2,1,0} reshape(%slice.6348), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6354 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6350), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6355 = bf16[16,64]{1,0} reshape(%mul.6354), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6356 = bf16[16,32,64]{2,1,0} broadcast(%mul.6355), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6357 = bf16[16,32,64]{2,1,0} multiply(%slice.6352, %mul.6356), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6353 = bf16[16,32,64]{2,1,0} slice(%mul.6321), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.6349 = bf16[16,64]{1,0} slice(%gather.6347), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6351 = bf16[16,1,64]{2,1,0} reshape(%slice.6349), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6358 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6351), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6359 = bf16[16,64]{1,0} reshape(%mul.6358), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6360 = bf16[16,32,64]{2,1,0} broadcast(%mul.6359), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6361 = bf16[16,32,64]{2,1,0} multiply(%slice.6353, %mul.6360), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.6362 = bf16[16,32,64]{2,1,0} subtract(%mul.6357, %mul.6361), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.6363 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6350), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6364 = bf16[16,64]{1,0} reshape(%mul.6363), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6365 = bf16[16,32,64]{2,1,0} broadcast(%mul.6364), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6366 = bf16[16,32,64]{2,1,0} multiply(%slice.6353, %mul.6365), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6367 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6351), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6368 = bf16[16,64]{1,0} reshape(%mul.6367), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6369 = bf16[16,32,64]{2,1,0} broadcast(%mul.6368), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6370 = bf16[16,32,64]{2,1,0} multiply(%slice.6352, %mul.6369), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.6371 = bf16[16,32,64]{2,1,0} add(%mul.6366, %mul.6370), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.6372 = bf16[16,32,128]{2,1,0} concatenate(%sub.6362, %add.6371), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.6373 = bf16[16,4096]{1,0} reshape(%concatenate.6372), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.6297 = bf16[16,4,128]{2,1,0} slice(%reshape.6295), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.6322 = f32[16,4,128]{2,1,0} convert(%slice.6297), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.6323 = f32[16,4,128]{2,1,0} power(%convert_element_type.6322, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6328 = f32[16,4]{1,0} reduce(%pow.6323, %constant.512), dimensions={2}, to_apply=%region_156.6327, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6329 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.6328), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6330 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.6329, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6331 = f32[16,4,1]{2,1,0} add(%div.6330, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6332 = f32[16,4,1]{2,1,0} rsqrt(%add.6331), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6333 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.6332), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6334 = f32[16,4]{1,0} reshape(%mul.6333), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6335 = f32[16,4,128]{2,1,0} broadcast(%mul.6334), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6336 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.6322, %mul.6335), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6337 = bf16[16,4,128]{2,1,0} convert(%mul.6336), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_31_self_attn_k_norm_weight__.233 = bf16[128]{0} parameter(232), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.31.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.6338 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_31_self_attn_k_norm_weight__.233), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6339 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.6338), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6340 = bf16[128]{0} reshape(%mul.6339), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6341 = bf16[16,4,128]{2,1,0} broadcast(%mul.6340), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6342 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.6337, %mul.6341), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6376 = bf16[16,4,64]{2,1,0} slice(%mul.6342), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6374 = bf16[16,1,64]{2,1,0} reshape(%slice.6348), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6378 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6374), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6379 = bf16[16,64]{1,0} reshape(%mul.6378), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6380 = bf16[16,4,64]{2,1,0} broadcast(%mul.6379), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6381 = bf16[16,4,64]{2,1,0} multiply(%slice.6376, %mul.6380), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6377 = bf16[16,4,64]{2,1,0} slice(%mul.6342), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6375 = bf16[16,1,64]{2,1,0} reshape(%slice.6349), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6382 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6375), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6383 = bf16[16,64]{1,0} reshape(%mul.6382), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6384 = bf16[16,4,64]{2,1,0} broadcast(%mul.6383), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6385 = bf16[16,4,64]{2,1,0} multiply(%slice.6377, %mul.6384), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.6386 = bf16[16,4,64]{2,1,0} subtract(%mul.6381, %mul.6385), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.6387 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6374), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6388 = bf16[16,64]{1,0} reshape(%mul.6387), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6389 = bf16[16,4,64]{2,1,0} broadcast(%mul.6388), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6390 = bf16[16,4,64]{2,1,0} multiply(%slice.6377, %mul.6389), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6391 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6375), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6392 = bf16[16,64]{1,0} reshape(%mul.6391), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6393 = bf16[16,4,64]{2,1,0} broadcast(%mul.6392), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6394 = bf16[16,4,64]{2,1,0} multiply(%slice.6376, %mul.6393), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.6395 = bf16[16,4,64]{2,1,0} add(%mul.6390, %mul.6394), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.6396 = bf16[16,4,128]{2,1,0} concatenate(%sub.6386, %add.6395), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.6397 = bf16[16,512]{1,0} reshape(%concatenate.6396), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.6298 = bf16[16,4,128]{2,1,0} slice(%reshape.6295), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.6299 = bf16[16,512]{1,0} reshape(%slice.6298), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.6398 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_31_.467, %reshape.6373, %reshape.6397, %reshape.6299, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.6399 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.6398), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_32_.468 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(467), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[32]"}
  %jit__jax_attn_func_.6400 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.6398), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_31_self_attn_o_proj_weight__.234 = bf16[2048,4096]{1,0} parameter(233), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.31.self_attn.o_proj.weight\']"}
  %dot_general.6401 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.6400, %params_and_buffers__vllm_model_language_model_model_layers_31_self_attn_o_proj_weight__.234), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.6402 = f32[16,2048]{1,0} convert(%dot_general.6401), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6273 = bf16[16,2048]{1,0} convert(%add.6272), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6403 = f32[16,2048]{1,0} convert(%convert_element_type.6273), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.6404 = f32[16,2048]{1,0} add(%convert_element_type.6402, %convert_element_type.6403), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.6406 = f32[16,2048]{1,0} power(%add.6404, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6411 = f32[16]{0} reduce(%pow.6406, %constant.512), dimensions={1}, to_apply=%region_157.6410, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6412 = f32[16,1]{1,0} reshape(%reduce_sum.6411), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6413 = f32[16,1]{1,0} divide(%broadcast_in_dim.6412, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6414 = f32[16,1]{1,0} add(%div.6413, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6415 = f32[16,1]{1,0} rsqrt(%add.6414), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6416 = f32[16,1]{1,0} broadcast(%rsqrt.6415), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6417 = f32[16]{0} reshape(%mul.6416), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6418 = f32[16,2048]{1,0} broadcast(%mul.6417), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6419 = f32[16,2048]{1,0} multiply(%add.6404, %mul.6418), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6420 = bf16[16,2048]{1,0} convert(%mul.6419), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_31_post_attention_layernorm_weight__.232 = bf16[2048]{0} parameter(231), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.31.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.6421 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_31_post_attention_layernorm_weight__.232), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6422 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.6421), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6423 = bf16[2048]{0} reshape(%mul.6422), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6424 = bf16[16,2048]{1,0} broadcast(%mul.6423), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6425 = bf16[16,2048]{1,0} multiply(%convert_element_type.6420, %mul.6424), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_31_mlp_experts_w13_weight__.229 = bf16[128,1536,2048]{2,1,0} parameter(228), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.31.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_31_mlp_experts_w2_weight__.230 = bf16[128,2048,768]{2,1,0} parameter(229), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.31.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_31_mlp_gate_weight__.231 = bf16[128,2048]{1,0} parameter(230), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.31.mlp.gate.weight\']"}
  %dot_general.6426 = bf16[16,128]{1,0} dot(%mul.6425, %params_and_buffers__vllm_model_language_model_model_layers_31_mlp_gate_weight__.231), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.6427 = bf16[16,2048]{1,0} call(%mul.6425, %params_and_buffers__vllm_model_language_model_model_layers_31_mlp_experts_w13_weight__.229, %params_and_buffers__vllm_model_language_model_model_layers_31_mlp_experts_w2_weight__.230, %dot_general.6426), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.6428 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.6427), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6405 = bf16[16,2048]{1,0} convert(%add.6404), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6429 = f32[16,2048]{1,0} convert(%convert_element_type.6405), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.6430 = f32[16,2048]{1,0} add(%convert_element_type.6428, %convert_element_type.6429), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.6432 = f32[16,2048]{1,0} power(%add.6430, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6437 = f32[16]{0} reduce(%pow.6432, %constant.512), dimensions={1}, to_apply=%region_158.6436, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6438 = f32[16,1]{1,0} reshape(%reduce_sum.6437), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6439 = f32[16,1]{1,0} divide(%broadcast_in_dim.6438, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6440 = f32[16,1]{1,0} add(%div.6439, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6441 = f32[16,1]{1,0} rsqrt(%add.6440), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6442 = f32[16,1]{1,0} broadcast(%rsqrt.6441), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6443 = f32[16]{0} reshape(%mul.6442), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6444 = f32[16,2048]{1,0} broadcast(%mul.6443), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6445 = f32[16,2048]{1,0} multiply(%add.6430, %mul.6444), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6446 = bf16[16,2048]{1,0} convert(%mul.6445), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_32_input_layernorm_weight__.237 = bf16[2048]{0} parameter(236), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.32.input_layernorm.weight\']"}
  %broadcast_in_dim.6447 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_32_input_layernorm_weight__.237), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6448 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.6447), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6449 = bf16[2048]{0} reshape(%mul.6448), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6450 = bf16[16,2048]{1,0} broadcast(%mul.6449), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6451 = bf16[16,2048]{1,0} multiply(%convert_element_type.6446, %mul.6450), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_32_self_attn_qkv_proj_weight__.245 = bf16[5120,2048]{1,0} parameter(244), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.32.self_attn.qkv_proj.weight\']"}
  %dot_general.6452 = bf16[16,5120]{1,0} dot(%mul.6451, %params_and_buffers__vllm_model_language_model_model_layers_32_self_attn_qkv_proj_weight__.245), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.6453 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.6452), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.6454 = bf16[16,4,1024]{2,1,0} slice(%reshape.6453), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.6458 = bf16[16,32,128]{2,1,0} reshape(%slice.6454), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.6459 = f32[16,32,128]{2,1,0} convert(%reshape.6458), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.6460 = f32[16,32,128]{2,1,0} power(%convert_element_type.6459, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6465 = f32[16,32]{1,0} reduce(%pow.6460, %constant.512), dimensions={2}, to_apply=%region_159.6464, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6466 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.6465), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6467 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.6466, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6468 = f32[16,32,1]{2,1,0} add(%div.6467, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6469 = f32[16,32,1]{2,1,0} rsqrt(%add.6468), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6470 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.6469), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6471 = f32[16,32]{1,0} reshape(%mul.6470), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6472 = f32[16,32,128]{2,1,0} broadcast(%mul.6471), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6473 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.6459, %mul.6472), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6474 = bf16[16,32,128]{2,1,0} convert(%mul.6473), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_32_self_attn_q_norm_weight__.244 = bf16[128]{0} parameter(243), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.32.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.6475 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_32_self_attn_q_norm_weight__.244), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6476 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.6475), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6477 = bf16[128]{0} reshape(%mul.6476), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6478 = bf16[16,32,128]{2,1,0} broadcast(%mul.6477), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6479 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.6474, %mul.6478), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6510 = bf16[16,32,64]{2,1,0} slice(%mul.6479), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.6501 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.6502 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.6503 = s32[16]{0} select(%lt.6501, %add.6502, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.6504 = s32[16,1]{1,0} reshape(%select_n.6503), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.6505 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.6504), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.6506 = bf16[16,64]{1,0} slice(%gather.6505), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6508 = bf16[16,1,64]{2,1,0} reshape(%slice.6506), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6512 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6508), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6513 = bf16[16,64]{1,0} reshape(%mul.6512), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6514 = bf16[16,32,64]{2,1,0} broadcast(%mul.6513), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6515 = bf16[16,32,64]{2,1,0} multiply(%slice.6510, %mul.6514), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6511 = bf16[16,32,64]{2,1,0} slice(%mul.6479), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.6507 = bf16[16,64]{1,0} slice(%gather.6505), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6509 = bf16[16,1,64]{2,1,0} reshape(%slice.6507), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6516 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6509), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6517 = bf16[16,64]{1,0} reshape(%mul.6516), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6518 = bf16[16,32,64]{2,1,0} broadcast(%mul.6517), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6519 = bf16[16,32,64]{2,1,0} multiply(%slice.6511, %mul.6518), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.6520 = bf16[16,32,64]{2,1,0} subtract(%mul.6515, %mul.6519), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.6521 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6508), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6522 = bf16[16,64]{1,0} reshape(%mul.6521), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6523 = bf16[16,32,64]{2,1,0} broadcast(%mul.6522), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6524 = bf16[16,32,64]{2,1,0} multiply(%slice.6511, %mul.6523), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6525 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6509), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6526 = bf16[16,64]{1,0} reshape(%mul.6525), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6527 = bf16[16,32,64]{2,1,0} broadcast(%mul.6526), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6528 = bf16[16,32,64]{2,1,0} multiply(%slice.6510, %mul.6527), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.6529 = bf16[16,32,64]{2,1,0} add(%mul.6524, %mul.6528), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.6530 = bf16[16,32,128]{2,1,0} concatenate(%sub.6520, %add.6529), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.6531 = bf16[16,4096]{1,0} reshape(%concatenate.6530), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.6455 = bf16[16,4,128]{2,1,0} slice(%reshape.6453), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.6480 = f32[16,4,128]{2,1,0} convert(%slice.6455), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.6481 = f32[16,4,128]{2,1,0} power(%convert_element_type.6480, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6486 = f32[16,4]{1,0} reduce(%pow.6481, %constant.512), dimensions={2}, to_apply=%region_160.6485, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6487 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.6486), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6488 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.6487, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6489 = f32[16,4,1]{2,1,0} add(%div.6488, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6490 = f32[16,4,1]{2,1,0} rsqrt(%add.6489), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6491 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.6490), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6492 = f32[16,4]{1,0} reshape(%mul.6491), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6493 = f32[16,4,128]{2,1,0} broadcast(%mul.6492), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6494 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.6480, %mul.6493), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6495 = bf16[16,4,128]{2,1,0} convert(%mul.6494), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_32_self_attn_k_norm_weight__.242 = bf16[128]{0} parameter(241), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.32.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.6496 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_32_self_attn_k_norm_weight__.242), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6497 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.6496), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6498 = bf16[128]{0} reshape(%mul.6497), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6499 = bf16[16,4,128]{2,1,0} broadcast(%mul.6498), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6500 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.6495, %mul.6499), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6534 = bf16[16,4,64]{2,1,0} slice(%mul.6500), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6532 = bf16[16,1,64]{2,1,0} reshape(%slice.6506), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6536 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6532), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6537 = bf16[16,64]{1,0} reshape(%mul.6536), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6538 = bf16[16,4,64]{2,1,0} broadcast(%mul.6537), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6539 = bf16[16,4,64]{2,1,0} multiply(%slice.6534, %mul.6538), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6535 = bf16[16,4,64]{2,1,0} slice(%mul.6500), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6533 = bf16[16,1,64]{2,1,0} reshape(%slice.6507), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6540 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6533), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6541 = bf16[16,64]{1,0} reshape(%mul.6540), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6542 = bf16[16,4,64]{2,1,0} broadcast(%mul.6541), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6543 = bf16[16,4,64]{2,1,0} multiply(%slice.6535, %mul.6542), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.6544 = bf16[16,4,64]{2,1,0} subtract(%mul.6539, %mul.6543), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.6545 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6532), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6546 = bf16[16,64]{1,0} reshape(%mul.6545), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6547 = bf16[16,4,64]{2,1,0} broadcast(%mul.6546), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6548 = bf16[16,4,64]{2,1,0} multiply(%slice.6535, %mul.6547), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6549 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6533), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6550 = bf16[16,64]{1,0} reshape(%mul.6549), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6551 = bf16[16,4,64]{2,1,0} broadcast(%mul.6550), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6552 = bf16[16,4,64]{2,1,0} multiply(%slice.6534, %mul.6551), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.6553 = bf16[16,4,64]{2,1,0} add(%mul.6548, %mul.6552), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.6554 = bf16[16,4,128]{2,1,0} concatenate(%sub.6544, %add.6553), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.6555 = bf16[16,512]{1,0} reshape(%concatenate.6554), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.6456 = bf16[16,4,128]{2,1,0} slice(%reshape.6453), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.6457 = bf16[16,512]{1,0} reshape(%slice.6456), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.6556 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_32_.468, %reshape.6531, %reshape.6555, %reshape.6457, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.6557 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.6556), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_33_.469 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(468), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[33]"}
  %jit__jax_attn_func_.6558 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.6556), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_32_self_attn_o_proj_weight__.243 = bf16[2048,4096]{1,0} parameter(242), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.32.self_attn.o_proj.weight\']"}
  %dot_general.6559 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.6558, %params_and_buffers__vllm_model_language_model_model_layers_32_self_attn_o_proj_weight__.243), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.6560 = f32[16,2048]{1,0} convert(%dot_general.6559), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6431 = bf16[16,2048]{1,0} convert(%add.6430), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6561 = f32[16,2048]{1,0} convert(%convert_element_type.6431), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.6562 = f32[16,2048]{1,0} add(%convert_element_type.6560, %convert_element_type.6561), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.6564 = f32[16,2048]{1,0} power(%add.6562, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6569 = f32[16]{0} reduce(%pow.6564, %constant.512), dimensions={1}, to_apply=%region_161.6568, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6570 = f32[16,1]{1,0} reshape(%reduce_sum.6569), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6571 = f32[16,1]{1,0} divide(%broadcast_in_dim.6570, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6572 = f32[16,1]{1,0} add(%div.6571, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6573 = f32[16,1]{1,0} rsqrt(%add.6572), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6574 = f32[16,1]{1,0} broadcast(%rsqrt.6573), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6575 = f32[16]{0} reshape(%mul.6574), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6576 = f32[16,2048]{1,0} broadcast(%mul.6575), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6577 = f32[16,2048]{1,0} multiply(%add.6562, %mul.6576), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6578 = bf16[16,2048]{1,0} convert(%mul.6577), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_32_post_attention_layernorm_weight__.241 = bf16[2048]{0} parameter(240), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.32.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.6579 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_32_post_attention_layernorm_weight__.241), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6580 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.6579), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6581 = bf16[2048]{0} reshape(%mul.6580), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6582 = bf16[16,2048]{1,0} broadcast(%mul.6581), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6583 = bf16[16,2048]{1,0} multiply(%convert_element_type.6578, %mul.6582), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_32_mlp_experts_w13_weight__.238 = bf16[128,1536,2048]{2,1,0} parameter(237), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.32.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_32_mlp_experts_w2_weight__.239 = bf16[128,2048,768]{2,1,0} parameter(238), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.32.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_32_mlp_gate_weight__.240 = bf16[128,2048]{1,0} parameter(239), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.32.mlp.gate.weight\']"}
  %dot_general.6584 = bf16[16,128]{1,0} dot(%mul.6583, %params_and_buffers__vllm_model_language_model_model_layers_32_mlp_gate_weight__.240), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.6585 = bf16[16,2048]{1,0} call(%mul.6583, %params_and_buffers__vllm_model_language_model_model_layers_32_mlp_experts_w13_weight__.238, %params_and_buffers__vllm_model_language_model_model_layers_32_mlp_experts_w2_weight__.239, %dot_general.6584), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.6586 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.6585), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6563 = bf16[16,2048]{1,0} convert(%add.6562), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6587 = f32[16,2048]{1,0} convert(%convert_element_type.6563), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.6588 = f32[16,2048]{1,0} add(%convert_element_type.6586, %convert_element_type.6587), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.6590 = f32[16,2048]{1,0} power(%add.6588, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6595 = f32[16]{0} reduce(%pow.6590, %constant.512), dimensions={1}, to_apply=%region_162.6594, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6596 = f32[16,1]{1,0} reshape(%reduce_sum.6595), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6597 = f32[16,1]{1,0} divide(%broadcast_in_dim.6596, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6598 = f32[16,1]{1,0} add(%div.6597, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6599 = f32[16,1]{1,0} rsqrt(%add.6598), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6600 = f32[16,1]{1,0} broadcast(%rsqrt.6599), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6601 = f32[16]{0} reshape(%mul.6600), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6602 = f32[16,2048]{1,0} broadcast(%mul.6601), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6603 = f32[16,2048]{1,0} multiply(%add.6588, %mul.6602), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6604 = bf16[16,2048]{1,0} convert(%mul.6603), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_33_input_layernorm_weight__.246 = bf16[2048]{0} parameter(245), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.33.input_layernorm.weight\']"}
  %broadcast_in_dim.6605 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_33_input_layernorm_weight__.246), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6606 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.6605), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6607 = bf16[2048]{0} reshape(%mul.6606), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6608 = bf16[16,2048]{1,0} broadcast(%mul.6607), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6609 = bf16[16,2048]{1,0} multiply(%convert_element_type.6604, %mul.6608), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_33_self_attn_qkv_proj_weight__.254 = bf16[5120,2048]{1,0} parameter(253), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.33.self_attn.qkv_proj.weight\']"}
  %dot_general.6610 = bf16[16,5120]{1,0} dot(%mul.6609, %params_and_buffers__vllm_model_language_model_model_layers_33_self_attn_qkv_proj_weight__.254), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.6611 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.6610), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.6612 = bf16[16,4,1024]{2,1,0} slice(%reshape.6611), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.6616 = bf16[16,32,128]{2,1,0} reshape(%slice.6612), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.6617 = f32[16,32,128]{2,1,0} convert(%reshape.6616), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.6618 = f32[16,32,128]{2,1,0} power(%convert_element_type.6617, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6623 = f32[16,32]{1,0} reduce(%pow.6618, %constant.512), dimensions={2}, to_apply=%region_163.6622, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6624 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.6623), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6625 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.6624, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6626 = f32[16,32,1]{2,1,0} add(%div.6625, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6627 = f32[16,32,1]{2,1,0} rsqrt(%add.6626), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6628 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.6627), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6629 = f32[16,32]{1,0} reshape(%mul.6628), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6630 = f32[16,32,128]{2,1,0} broadcast(%mul.6629), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6631 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.6617, %mul.6630), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6632 = bf16[16,32,128]{2,1,0} convert(%mul.6631), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_33_self_attn_q_norm_weight__.253 = bf16[128]{0} parameter(252), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.33.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.6633 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_33_self_attn_q_norm_weight__.253), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6634 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.6633), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6635 = bf16[128]{0} reshape(%mul.6634), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6636 = bf16[16,32,128]{2,1,0} broadcast(%mul.6635), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6637 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.6632, %mul.6636), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6668 = bf16[16,32,64]{2,1,0} slice(%mul.6637), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.6659 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.6660 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.6661 = s32[16]{0} select(%lt.6659, %add.6660, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.6662 = s32[16,1]{1,0} reshape(%select_n.6661), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.6663 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.6662), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.6664 = bf16[16,64]{1,0} slice(%gather.6663), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6666 = bf16[16,1,64]{2,1,0} reshape(%slice.6664), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6670 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6666), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6671 = bf16[16,64]{1,0} reshape(%mul.6670), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6672 = bf16[16,32,64]{2,1,0} broadcast(%mul.6671), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6673 = bf16[16,32,64]{2,1,0} multiply(%slice.6668, %mul.6672), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6669 = bf16[16,32,64]{2,1,0} slice(%mul.6637), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.6665 = bf16[16,64]{1,0} slice(%gather.6663), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6667 = bf16[16,1,64]{2,1,0} reshape(%slice.6665), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6674 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6667), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6675 = bf16[16,64]{1,0} reshape(%mul.6674), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6676 = bf16[16,32,64]{2,1,0} broadcast(%mul.6675), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6677 = bf16[16,32,64]{2,1,0} multiply(%slice.6669, %mul.6676), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.6678 = bf16[16,32,64]{2,1,0} subtract(%mul.6673, %mul.6677), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.6679 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6666), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6680 = bf16[16,64]{1,0} reshape(%mul.6679), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6681 = bf16[16,32,64]{2,1,0} broadcast(%mul.6680), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6682 = bf16[16,32,64]{2,1,0} multiply(%slice.6669, %mul.6681), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6683 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6667), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6684 = bf16[16,64]{1,0} reshape(%mul.6683), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6685 = bf16[16,32,64]{2,1,0} broadcast(%mul.6684), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6686 = bf16[16,32,64]{2,1,0} multiply(%slice.6668, %mul.6685), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.6687 = bf16[16,32,64]{2,1,0} add(%mul.6682, %mul.6686), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.6688 = bf16[16,32,128]{2,1,0} concatenate(%sub.6678, %add.6687), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.6689 = bf16[16,4096]{1,0} reshape(%concatenate.6688), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.6613 = bf16[16,4,128]{2,1,0} slice(%reshape.6611), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.6638 = f32[16,4,128]{2,1,0} convert(%slice.6613), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.6639 = f32[16,4,128]{2,1,0} power(%convert_element_type.6638, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6644 = f32[16,4]{1,0} reduce(%pow.6639, %constant.512), dimensions={2}, to_apply=%region_164.6643, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6645 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.6644), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6646 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.6645, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6647 = f32[16,4,1]{2,1,0} add(%div.6646, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6648 = f32[16,4,1]{2,1,0} rsqrt(%add.6647), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6649 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.6648), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6650 = f32[16,4]{1,0} reshape(%mul.6649), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6651 = f32[16,4,128]{2,1,0} broadcast(%mul.6650), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6652 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.6638, %mul.6651), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6653 = bf16[16,4,128]{2,1,0} convert(%mul.6652), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_33_self_attn_k_norm_weight__.251 = bf16[128]{0} parameter(250), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.33.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.6654 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_33_self_attn_k_norm_weight__.251), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6655 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.6654), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6656 = bf16[128]{0} reshape(%mul.6655), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6657 = bf16[16,4,128]{2,1,0} broadcast(%mul.6656), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6658 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.6653, %mul.6657), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6692 = bf16[16,4,64]{2,1,0} slice(%mul.6658), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6690 = bf16[16,1,64]{2,1,0} reshape(%slice.6664), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6694 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6690), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6695 = bf16[16,64]{1,0} reshape(%mul.6694), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6696 = bf16[16,4,64]{2,1,0} broadcast(%mul.6695), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6697 = bf16[16,4,64]{2,1,0} multiply(%slice.6692, %mul.6696), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6693 = bf16[16,4,64]{2,1,0} slice(%mul.6658), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6691 = bf16[16,1,64]{2,1,0} reshape(%slice.6665), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6698 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6691), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6699 = bf16[16,64]{1,0} reshape(%mul.6698), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6700 = bf16[16,4,64]{2,1,0} broadcast(%mul.6699), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6701 = bf16[16,4,64]{2,1,0} multiply(%slice.6693, %mul.6700), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.6702 = bf16[16,4,64]{2,1,0} subtract(%mul.6697, %mul.6701), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.6703 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6690), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6704 = bf16[16,64]{1,0} reshape(%mul.6703), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6705 = bf16[16,4,64]{2,1,0} broadcast(%mul.6704), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6706 = bf16[16,4,64]{2,1,0} multiply(%slice.6693, %mul.6705), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6707 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6691), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6708 = bf16[16,64]{1,0} reshape(%mul.6707), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6709 = bf16[16,4,64]{2,1,0} broadcast(%mul.6708), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6710 = bf16[16,4,64]{2,1,0} multiply(%slice.6692, %mul.6709), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.6711 = bf16[16,4,64]{2,1,0} add(%mul.6706, %mul.6710), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.6712 = bf16[16,4,128]{2,1,0} concatenate(%sub.6702, %add.6711), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.6713 = bf16[16,512]{1,0} reshape(%concatenate.6712), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.6614 = bf16[16,4,128]{2,1,0} slice(%reshape.6611), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.6615 = bf16[16,512]{1,0} reshape(%slice.6614), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.6714 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_33_.469, %reshape.6689, %reshape.6713, %reshape.6615, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.6715 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.6714), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_34_.470 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(469), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[34]"}
  %jit__jax_attn_func_.6716 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.6714), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_33_self_attn_o_proj_weight__.252 = bf16[2048,4096]{1,0} parameter(251), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.33.self_attn.o_proj.weight\']"}
  %dot_general.6717 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.6716, %params_and_buffers__vllm_model_language_model_model_layers_33_self_attn_o_proj_weight__.252), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.6718 = f32[16,2048]{1,0} convert(%dot_general.6717), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6589 = bf16[16,2048]{1,0} convert(%add.6588), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6719 = f32[16,2048]{1,0} convert(%convert_element_type.6589), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.6720 = f32[16,2048]{1,0} add(%convert_element_type.6718, %convert_element_type.6719), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.6722 = f32[16,2048]{1,0} power(%add.6720, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6727 = f32[16]{0} reduce(%pow.6722, %constant.512), dimensions={1}, to_apply=%region_165.6726, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6728 = f32[16,1]{1,0} reshape(%reduce_sum.6727), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6729 = f32[16,1]{1,0} divide(%broadcast_in_dim.6728, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6730 = f32[16,1]{1,0} add(%div.6729, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6731 = f32[16,1]{1,0} rsqrt(%add.6730), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6732 = f32[16,1]{1,0} broadcast(%rsqrt.6731), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6733 = f32[16]{0} reshape(%mul.6732), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6734 = f32[16,2048]{1,0} broadcast(%mul.6733), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6735 = f32[16,2048]{1,0} multiply(%add.6720, %mul.6734), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6736 = bf16[16,2048]{1,0} convert(%mul.6735), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_33_post_attention_layernorm_weight__.250 = bf16[2048]{0} parameter(249), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.33.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.6737 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_33_post_attention_layernorm_weight__.250), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6738 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.6737), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6739 = bf16[2048]{0} reshape(%mul.6738), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6740 = bf16[16,2048]{1,0} broadcast(%mul.6739), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6741 = bf16[16,2048]{1,0} multiply(%convert_element_type.6736, %mul.6740), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_33_mlp_experts_w13_weight__.247 = bf16[128,1536,2048]{2,1,0} parameter(246), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.33.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_33_mlp_experts_w2_weight__.248 = bf16[128,2048,768]{2,1,0} parameter(247), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.33.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_33_mlp_gate_weight__.249 = bf16[128,2048]{1,0} parameter(248), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.33.mlp.gate.weight\']"}
  %dot_general.6742 = bf16[16,128]{1,0} dot(%mul.6741, %params_and_buffers__vllm_model_language_model_model_layers_33_mlp_gate_weight__.249), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.6743 = bf16[16,2048]{1,0} call(%mul.6741, %params_and_buffers__vllm_model_language_model_model_layers_33_mlp_experts_w13_weight__.247, %params_and_buffers__vllm_model_language_model_model_layers_33_mlp_experts_w2_weight__.248, %dot_general.6742), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.6744 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.6743), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6721 = bf16[16,2048]{1,0} convert(%add.6720), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6745 = f32[16,2048]{1,0} convert(%convert_element_type.6721), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.6746 = f32[16,2048]{1,0} add(%convert_element_type.6744, %convert_element_type.6745), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.6748 = f32[16,2048]{1,0} power(%add.6746, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6753 = f32[16]{0} reduce(%pow.6748, %constant.512), dimensions={1}, to_apply=%region_166.6752, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6754 = f32[16,1]{1,0} reshape(%reduce_sum.6753), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6755 = f32[16,1]{1,0} divide(%broadcast_in_dim.6754, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6756 = f32[16,1]{1,0} add(%div.6755, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6757 = f32[16,1]{1,0} rsqrt(%add.6756), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6758 = f32[16,1]{1,0} broadcast(%rsqrt.6757), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6759 = f32[16]{0} reshape(%mul.6758), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6760 = f32[16,2048]{1,0} broadcast(%mul.6759), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6761 = f32[16,2048]{1,0} multiply(%add.6746, %mul.6760), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6762 = bf16[16,2048]{1,0} convert(%mul.6761), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_34_input_layernorm_weight__.255 = bf16[2048]{0} parameter(254), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.34.input_layernorm.weight\']"}
  %broadcast_in_dim.6763 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_34_input_layernorm_weight__.255), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6764 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.6763), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6765 = bf16[2048]{0} reshape(%mul.6764), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6766 = bf16[16,2048]{1,0} broadcast(%mul.6765), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6767 = bf16[16,2048]{1,0} multiply(%convert_element_type.6762, %mul.6766), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_34_self_attn_qkv_proj_weight__.263 = bf16[5120,2048]{1,0} parameter(262), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.34.self_attn.qkv_proj.weight\']"}
  %dot_general.6768 = bf16[16,5120]{1,0} dot(%mul.6767, %params_and_buffers__vllm_model_language_model_model_layers_34_self_attn_qkv_proj_weight__.263), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.6769 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.6768), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.6770 = bf16[16,4,1024]{2,1,0} slice(%reshape.6769), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.6774 = bf16[16,32,128]{2,1,0} reshape(%slice.6770), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.6775 = f32[16,32,128]{2,1,0} convert(%reshape.6774), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.6776 = f32[16,32,128]{2,1,0} power(%convert_element_type.6775, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6781 = f32[16,32]{1,0} reduce(%pow.6776, %constant.512), dimensions={2}, to_apply=%region_167.6780, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6782 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.6781), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6783 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.6782, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6784 = f32[16,32,1]{2,1,0} add(%div.6783, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6785 = f32[16,32,1]{2,1,0} rsqrt(%add.6784), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6786 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.6785), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6787 = f32[16,32]{1,0} reshape(%mul.6786), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6788 = f32[16,32,128]{2,1,0} broadcast(%mul.6787), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6789 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.6775, %mul.6788), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6790 = bf16[16,32,128]{2,1,0} convert(%mul.6789), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_34_self_attn_q_norm_weight__.262 = bf16[128]{0} parameter(261), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.34.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.6791 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_34_self_attn_q_norm_weight__.262), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6792 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.6791), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6793 = bf16[128]{0} reshape(%mul.6792), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6794 = bf16[16,32,128]{2,1,0} broadcast(%mul.6793), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6795 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.6790, %mul.6794), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6826 = bf16[16,32,64]{2,1,0} slice(%mul.6795), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.6817 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.6818 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.6819 = s32[16]{0} select(%lt.6817, %add.6818, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.6820 = s32[16,1]{1,0} reshape(%select_n.6819), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.6821 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.6820), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.6822 = bf16[16,64]{1,0} slice(%gather.6821), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6824 = bf16[16,1,64]{2,1,0} reshape(%slice.6822), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6828 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6824), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6829 = bf16[16,64]{1,0} reshape(%mul.6828), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6830 = bf16[16,32,64]{2,1,0} broadcast(%mul.6829), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6831 = bf16[16,32,64]{2,1,0} multiply(%slice.6826, %mul.6830), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6827 = bf16[16,32,64]{2,1,0} slice(%mul.6795), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.6823 = bf16[16,64]{1,0} slice(%gather.6821), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6825 = bf16[16,1,64]{2,1,0} reshape(%slice.6823), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6832 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6825), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6833 = bf16[16,64]{1,0} reshape(%mul.6832), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6834 = bf16[16,32,64]{2,1,0} broadcast(%mul.6833), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6835 = bf16[16,32,64]{2,1,0} multiply(%slice.6827, %mul.6834), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.6836 = bf16[16,32,64]{2,1,0} subtract(%mul.6831, %mul.6835), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.6837 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6824), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6838 = bf16[16,64]{1,0} reshape(%mul.6837), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6839 = bf16[16,32,64]{2,1,0} broadcast(%mul.6838), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6840 = bf16[16,32,64]{2,1,0} multiply(%slice.6827, %mul.6839), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6841 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6825), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6842 = bf16[16,64]{1,0} reshape(%mul.6841), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6843 = bf16[16,32,64]{2,1,0} broadcast(%mul.6842), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6844 = bf16[16,32,64]{2,1,0} multiply(%slice.6826, %mul.6843), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.6845 = bf16[16,32,64]{2,1,0} add(%mul.6840, %mul.6844), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.6846 = bf16[16,32,128]{2,1,0} concatenate(%sub.6836, %add.6845), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.6847 = bf16[16,4096]{1,0} reshape(%concatenate.6846), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.6771 = bf16[16,4,128]{2,1,0} slice(%reshape.6769), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.6796 = f32[16,4,128]{2,1,0} convert(%slice.6771), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.6797 = f32[16,4,128]{2,1,0} power(%convert_element_type.6796, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6802 = f32[16,4]{1,0} reduce(%pow.6797, %constant.512), dimensions={2}, to_apply=%region_168.6801, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6803 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.6802), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6804 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.6803, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6805 = f32[16,4,1]{2,1,0} add(%div.6804, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6806 = f32[16,4,1]{2,1,0} rsqrt(%add.6805), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6807 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.6806), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6808 = f32[16,4]{1,0} reshape(%mul.6807), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6809 = f32[16,4,128]{2,1,0} broadcast(%mul.6808), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6810 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.6796, %mul.6809), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6811 = bf16[16,4,128]{2,1,0} convert(%mul.6810), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_34_self_attn_k_norm_weight__.260 = bf16[128]{0} parameter(259), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.34.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.6812 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_34_self_attn_k_norm_weight__.260), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6813 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.6812), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6814 = bf16[128]{0} reshape(%mul.6813), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6815 = bf16[16,4,128]{2,1,0} broadcast(%mul.6814), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6816 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.6811, %mul.6815), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6850 = bf16[16,4,64]{2,1,0} slice(%mul.6816), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6848 = bf16[16,1,64]{2,1,0} reshape(%slice.6822), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6852 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6848), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6853 = bf16[16,64]{1,0} reshape(%mul.6852), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6854 = bf16[16,4,64]{2,1,0} broadcast(%mul.6853), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6855 = bf16[16,4,64]{2,1,0} multiply(%slice.6850, %mul.6854), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6851 = bf16[16,4,64]{2,1,0} slice(%mul.6816), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6849 = bf16[16,1,64]{2,1,0} reshape(%slice.6823), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6856 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6849), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6857 = bf16[16,64]{1,0} reshape(%mul.6856), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6858 = bf16[16,4,64]{2,1,0} broadcast(%mul.6857), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6859 = bf16[16,4,64]{2,1,0} multiply(%slice.6851, %mul.6858), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.6860 = bf16[16,4,64]{2,1,0} subtract(%mul.6855, %mul.6859), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.6861 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6848), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6862 = bf16[16,64]{1,0} reshape(%mul.6861), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6863 = bf16[16,4,64]{2,1,0} broadcast(%mul.6862), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6864 = bf16[16,4,64]{2,1,0} multiply(%slice.6851, %mul.6863), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6865 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6849), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6866 = bf16[16,64]{1,0} reshape(%mul.6865), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6867 = bf16[16,4,64]{2,1,0} broadcast(%mul.6866), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6868 = bf16[16,4,64]{2,1,0} multiply(%slice.6850, %mul.6867), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.6869 = bf16[16,4,64]{2,1,0} add(%mul.6864, %mul.6868), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.6870 = bf16[16,4,128]{2,1,0} concatenate(%sub.6860, %add.6869), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.6871 = bf16[16,512]{1,0} reshape(%concatenate.6870), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.6772 = bf16[16,4,128]{2,1,0} slice(%reshape.6769), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.6773 = bf16[16,512]{1,0} reshape(%slice.6772), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.6872 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_34_.470, %reshape.6847, %reshape.6871, %reshape.6773, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.6873 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.6872), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_35_.471 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(470), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[35]"}
  %jit__jax_attn_func_.6874 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.6872), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_34_self_attn_o_proj_weight__.261 = bf16[2048,4096]{1,0} parameter(260), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.34.self_attn.o_proj.weight\']"}
  %dot_general.6875 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.6874, %params_and_buffers__vllm_model_language_model_model_layers_34_self_attn_o_proj_weight__.261), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.6876 = f32[16,2048]{1,0} convert(%dot_general.6875), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6747 = bf16[16,2048]{1,0} convert(%add.6746), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6877 = f32[16,2048]{1,0} convert(%convert_element_type.6747), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.6878 = f32[16,2048]{1,0} add(%convert_element_type.6876, %convert_element_type.6877), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.6880 = f32[16,2048]{1,0} power(%add.6878, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6885 = f32[16]{0} reduce(%pow.6880, %constant.512), dimensions={1}, to_apply=%region_169.6884, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6886 = f32[16,1]{1,0} reshape(%reduce_sum.6885), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6887 = f32[16,1]{1,0} divide(%broadcast_in_dim.6886, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6888 = f32[16,1]{1,0} add(%div.6887, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6889 = f32[16,1]{1,0} rsqrt(%add.6888), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6890 = f32[16,1]{1,0} broadcast(%rsqrt.6889), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6891 = f32[16]{0} reshape(%mul.6890), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6892 = f32[16,2048]{1,0} broadcast(%mul.6891), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6893 = f32[16,2048]{1,0} multiply(%add.6878, %mul.6892), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6894 = bf16[16,2048]{1,0} convert(%mul.6893), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_34_post_attention_layernorm_weight__.259 = bf16[2048]{0} parameter(258), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.34.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.6895 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_34_post_attention_layernorm_weight__.259), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6896 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.6895), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6897 = bf16[2048]{0} reshape(%mul.6896), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6898 = bf16[16,2048]{1,0} broadcast(%mul.6897), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6899 = bf16[16,2048]{1,0} multiply(%convert_element_type.6894, %mul.6898), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_34_mlp_experts_w13_weight__.256 = bf16[128,1536,2048]{2,1,0} parameter(255), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.34.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_34_mlp_experts_w2_weight__.257 = bf16[128,2048,768]{2,1,0} parameter(256), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.34.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_34_mlp_gate_weight__.258 = bf16[128,2048]{1,0} parameter(257), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.34.mlp.gate.weight\']"}
  %dot_general.6900 = bf16[16,128]{1,0} dot(%mul.6899, %params_and_buffers__vllm_model_language_model_model_layers_34_mlp_gate_weight__.258), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.6901 = bf16[16,2048]{1,0} call(%mul.6899, %params_and_buffers__vllm_model_language_model_model_layers_34_mlp_experts_w13_weight__.256, %params_and_buffers__vllm_model_language_model_model_layers_34_mlp_experts_w2_weight__.257, %dot_general.6900), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.6902 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.6901), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6879 = bf16[16,2048]{1,0} convert(%add.6878), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6903 = f32[16,2048]{1,0} convert(%convert_element_type.6879), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.6904 = f32[16,2048]{1,0} add(%convert_element_type.6902, %convert_element_type.6903), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.6906 = f32[16,2048]{1,0} power(%add.6904, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6911 = f32[16]{0} reduce(%pow.6906, %constant.512), dimensions={1}, to_apply=%region_170.6910, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6912 = f32[16,1]{1,0} reshape(%reduce_sum.6911), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6913 = f32[16,1]{1,0} divide(%broadcast_in_dim.6912, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6914 = f32[16,1]{1,0} add(%div.6913, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6915 = f32[16,1]{1,0} rsqrt(%add.6914), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6916 = f32[16,1]{1,0} broadcast(%rsqrt.6915), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6917 = f32[16]{0} reshape(%mul.6916), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6918 = f32[16,2048]{1,0} broadcast(%mul.6917), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6919 = f32[16,2048]{1,0} multiply(%add.6904, %mul.6918), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6920 = bf16[16,2048]{1,0} convert(%mul.6919), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_35_input_layernorm_weight__.264 = bf16[2048]{0} parameter(263), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.35.input_layernorm.weight\']"}
  %broadcast_in_dim.6921 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_35_input_layernorm_weight__.264), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6922 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.6921), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6923 = bf16[2048]{0} reshape(%mul.6922), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6924 = bf16[16,2048]{1,0} broadcast(%mul.6923), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6925 = bf16[16,2048]{1,0} multiply(%convert_element_type.6920, %mul.6924), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_35_self_attn_qkv_proj_weight__.272 = bf16[5120,2048]{1,0} parameter(271), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.35.self_attn.qkv_proj.weight\']"}
  %dot_general.6926 = bf16[16,5120]{1,0} dot(%mul.6925, %params_and_buffers__vllm_model_language_model_model_layers_35_self_attn_qkv_proj_weight__.272), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.6927 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.6926), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.6928 = bf16[16,4,1024]{2,1,0} slice(%reshape.6927), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.6932 = bf16[16,32,128]{2,1,0} reshape(%slice.6928), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.6933 = f32[16,32,128]{2,1,0} convert(%reshape.6932), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.6934 = f32[16,32,128]{2,1,0} power(%convert_element_type.6933, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6939 = f32[16,32]{1,0} reduce(%pow.6934, %constant.512), dimensions={2}, to_apply=%region_171.6938, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6940 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.6939), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6941 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.6940, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6942 = f32[16,32,1]{2,1,0} add(%div.6941, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6943 = f32[16,32,1]{2,1,0} rsqrt(%add.6942), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6944 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.6943), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6945 = f32[16,32]{1,0} reshape(%mul.6944), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6946 = f32[16,32,128]{2,1,0} broadcast(%mul.6945), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6947 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.6933, %mul.6946), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6948 = bf16[16,32,128]{2,1,0} convert(%mul.6947), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_35_self_attn_q_norm_weight__.271 = bf16[128]{0} parameter(270), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.35.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.6949 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_35_self_attn_q_norm_weight__.271), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6950 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.6949), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6951 = bf16[128]{0} reshape(%mul.6950), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6952 = bf16[16,32,128]{2,1,0} broadcast(%mul.6951), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6953 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.6948, %mul.6952), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6984 = bf16[16,32,64]{2,1,0} slice(%mul.6953), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.6975 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.6976 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.6977 = s32[16]{0} select(%lt.6975, %add.6976, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.6978 = s32[16,1]{1,0} reshape(%select_n.6977), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.6979 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.6978), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.6980 = bf16[16,64]{1,0} slice(%gather.6979), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6982 = bf16[16,1,64]{2,1,0} reshape(%slice.6980), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6986 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6982), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6987 = bf16[16,64]{1,0} reshape(%mul.6986), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6988 = bf16[16,32,64]{2,1,0} broadcast(%mul.6987), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6989 = bf16[16,32,64]{2,1,0} multiply(%slice.6984, %mul.6988), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6985 = bf16[16,32,64]{2,1,0} slice(%mul.6953), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.6981 = bf16[16,64]{1,0} slice(%gather.6979), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6983 = bf16[16,1,64]{2,1,0} reshape(%slice.6981), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6990 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6983), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6991 = bf16[16,64]{1,0} reshape(%mul.6990), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6992 = bf16[16,32,64]{2,1,0} broadcast(%mul.6991), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6993 = bf16[16,32,64]{2,1,0} multiply(%slice.6985, %mul.6992), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.6994 = bf16[16,32,64]{2,1,0} subtract(%mul.6989, %mul.6993), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.6995 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6982), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6996 = bf16[16,64]{1,0} reshape(%mul.6995), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6997 = bf16[16,32,64]{2,1,0} broadcast(%mul.6996), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6998 = bf16[16,32,64]{2,1,0} multiply(%slice.6985, %mul.6997), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6999 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.6983), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7000 = bf16[16,64]{1,0} reshape(%mul.6999), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7001 = bf16[16,32,64]{2,1,0} broadcast(%mul.7000), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7002 = bf16[16,32,64]{2,1,0} multiply(%slice.6984, %mul.7001), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.7003 = bf16[16,32,64]{2,1,0} add(%mul.6998, %mul.7002), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.7004 = bf16[16,32,128]{2,1,0} concatenate(%sub.6994, %add.7003), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.7005 = bf16[16,4096]{1,0} reshape(%concatenate.7004), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.6929 = bf16[16,4,128]{2,1,0} slice(%reshape.6927), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.6954 = f32[16,4,128]{2,1,0} convert(%slice.6929), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.6955 = f32[16,4,128]{2,1,0} power(%convert_element_type.6954, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6960 = f32[16,4]{1,0} reduce(%pow.6955, %constant.512), dimensions={2}, to_apply=%region_172.6959, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6961 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.6960), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6962 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.6961, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6963 = f32[16,4,1]{2,1,0} add(%div.6962, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6964 = f32[16,4,1]{2,1,0} rsqrt(%add.6963), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6965 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.6964), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6966 = f32[16,4]{1,0} reshape(%mul.6965), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6967 = f32[16,4,128]{2,1,0} broadcast(%mul.6966), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6968 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.6954, %mul.6967), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6969 = bf16[16,4,128]{2,1,0} convert(%mul.6968), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_35_self_attn_k_norm_weight__.269 = bf16[128]{0} parameter(268), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.35.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.6970 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_35_self_attn_k_norm_weight__.269), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6971 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.6970), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6972 = bf16[128]{0} reshape(%mul.6971), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6973 = bf16[16,4,128]{2,1,0} broadcast(%mul.6972), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6974 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.6969, %mul.6973), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7008 = bf16[16,4,64]{2,1,0} slice(%mul.6974), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7006 = bf16[16,1,64]{2,1,0} reshape(%slice.6980), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7010 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7006), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7011 = bf16[16,64]{1,0} reshape(%mul.7010), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7012 = bf16[16,4,64]{2,1,0} broadcast(%mul.7011), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7013 = bf16[16,4,64]{2,1,0} multiply(%slice.7008, %mul.7012), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7009 = bf16[16,4,64]{2,1,0} slice(%mul.6974), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7007 = bf16[16,1,64]{2,1,0} reshape(%slice.6981), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7014 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7007), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7015 = bf16[16,64]{1,0} reshape(%mul.7014), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7016 = bf16[16,4,64]{2,1,0} broadcast(%mul.7015), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7017 = bf16[16,4,64]{2,1,0} multiply(%slice.7009, %mul.7016), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.7018 = bf16[16,4,64]{2,1,0} subtract(%mul.7013, %mul.7017), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.7019 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7006), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7020 = bf16[16,64]{1,0} reshape(%mul.7019), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7021 = bf16[16,4,64]{2,1,0} broadcast(%mul.7020), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7022 = bf16[16,4,64]{2,1,0} multiply(%slice.7009, %mul.7021), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7023 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7007), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7024 = bf16[16,64]{1,0} reshape(%mul.7023), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7025 = bf16[16,4,64]{2,1,0} broadcast(%mul.7024), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7026 = bf16[16,4,64]{2,1,0} multiply(%slice.7008, %mul.7025), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.7027 = bf16[16,4,64]{2,1,0} add(%mul.7022, %mul.7026), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.7028 = bf16[16,4,128]{2,1,0} concatenate(%sub.7018, %add.7027), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.7029 = bf16[16,512]{1,0} reshape(%concatenate.7028), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.6930 = bf16[16,4,128]{2,1,0} slice(%reshape.6927), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.6931 = bf16[16,512]{1,0} reshape(%slice.6930), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.7030 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_35_.471, %reshape.7005, %reshape.7029, %reshape.6931, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.7031 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.7030), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_36_.472 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(471), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[36]"}
  %jit__jax_attn_func_.7032 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.7030), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_35_self_attn_o_proj_weight__.270 = bf16[2048,4096]{1,0} parameter(269), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.35.self_attn.o_proj.weight\']"}
  %dot_general.7033 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.7032, %params_and_buffers__vllm_model_language_model_model_layers_35_self_attn_o_proj_weight__.270), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.7034 = f32[16,2048]{1,0} convert(%dot_general.7033), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6905 = bf16[16,2048]{1,0} convert(%add.6904), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7035 = f32[16,2048]{1,0} convert(%convert_element_type.6905), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.7036 = f32[16,2048]{1,0} add(%convert_element_type.7034, %convert_element_type.7035), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.7038 = f32[16,2048]{1,0} power(%add.7036, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7043 = f32[16]{0} reduce(%pow.7038, %constant.512), dimensions={1}, to_apply=%region_173.7042, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7044 = f32[16,1]{1,0} reshape(%reduce_sum.7043), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7045 = f32[16,1]{1,0} divide(%broadcast_in_dim.7044, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7046 = f32[16,1]{1,0} add(%div.7045, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7047 = f32[16,1]{1,0} rsqrt(%add.7046), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7048 = f32[16,1]{1,0} broadcast(%rsqrt.7047), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7049 = f32[16]{0} reshape(%mul.7048), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7050 = f32[16,2048]{1,0} broadcast(%mul.7049), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7051 = f32[16,2048]{1,0} multiply(%add.7036, %mul.7050), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7052 = bf16[16,2048]{1,0} convert(%mul.7051), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_35_post_attention_layernorm_weight__.268 = bf16[2048]{0} parameter(267), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.35.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.7053 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_35_post_attention_layernorm_weight__.268), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7054 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.7053), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7055 = bf16[2048]{0} reshape(%mul.7054), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7056 = bf16[16,2048]{1,0} broadcast(%mul.7055), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7057 = bf16[16,2048]{1,0} multiply(%convert_element_type.7052, %mul.7056), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_35_mlp_experts_w13_weight__.265 = bf16[128,1536,2048]{2,1,0} parameter(264), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.35.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_35_mlp_experts_w2_weight__.266 = bf16[128,2048,768]{2,1,0} parameter(265), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.35.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_35_mlp_gate_weight__.267 = bf16[128,2048]{1,0} parameter(266), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.35.mlp.gate.weight\']"}
  %dot_general.7058 = bf16[16,128]{1,0} dot(%mul.7057, %params_and_buffers__vllm_model_language_model_model_layers_35_mlp_gate_weight__.267), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.7059 = bf16[16,2048]{1,0} call(%mul.7057, %params_and_buffers__vllm_model_language_model_model_layers_35_mlp_experts_w13_weight__.265, %params_and_buffers__vllm_model_language_model_model_layers_35_mlp_experts_w2_weight__.266, %dot_general.7058), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.7060 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.7059), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7037 = bf16[16,2048]{1,0} convert(%add.7036), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7061 = f32[16,2048]{1,0} convert(%convert_element_type.7037), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.7062 = f32[16,2048]{1,0} add(%convert_element_type.7060, %convert_element_type.7061), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.7064 = f32[16,2048]{1,0} power(%add.7062, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7069 = f32[16]{0} reduce(%pow.7064, %constant.512), dimensions={1}, to_apply=%region_174.7068, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7070 = f32[16,1]{1,0} reshape(%reduce_sum.7069), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7071 = f32[16,1]{1,0} divide(%broadcast_in_dim.7070, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7072 = f32[16,1]{1,0} add(%div.7071, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7073 = f32[16,1]{1,0} rsqrt(%add.7072), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7074 = f32[16,1]{1,0} broadcast(%rsqrt.7073), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7075 = f32[16]{0} reshape(%mul.7074), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7076 = f32[16,2048]{1,0} broadcast(%mul.7075), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7077 = f32[16,2048]{1,0} multiply(%add.7062, %mul.7076), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7078 = bf16[16,2048]{1,0} convert(%mul.7077), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_36_input_layernorm_weight__.273 = bf16[2048]{0} parameter(272), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.36.input_layernorm.weight\']"}
  %broadcast_in_dim.7079 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_36_input_layernorm_weight__.273), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7080 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.7079), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7081 = bf16[2048]{0} reshape(%mul.7080), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7082 = bf16[16,2048]{1,0} broadcast(%mul.7081), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7083 = bf16[16,2048]{1,0} multiply(%convert_element_type.7078, %mul.7082), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_36_self_attn_qkv_proj_weight__.281 = bf16[5120,2048]{1,0} parameter(280), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.36.self_attn.qkv_proj.weight\']"}
  %dot_general.7084 = bf16[16,5120]{1,0} dot(%mul.7083, %params_and_buffers__vllm_model_language_model_model_layers_36_self_attn_qkv_proj_weight__.281), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.7085 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.7084), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.7086 = bf16[16,4,1024]{2,1,0} slice(%reshape.7085), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.7090 = bf16[16,32,128]{2,1,0} reshape(%slice.7086), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.7091 = f32[16,32,128]{2,1,0} convert(%reshape.7090), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.7092 = f32[16,32,128]{2,1,0} power(%convert_element_type.7091, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7097 = f32[16,32]{1,0} reduce(%pow.7092, %constant.512), dimensions={2}, to_apply=%region_175.7096, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7098 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.7097), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7099 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.7098, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7100 = f32[16,32,1]{2,1,0} add(%div.7099, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7101 = f32[16,32,1]{2,1,0} rsqrt(%add.7100), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7102 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.7101), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7103 = f32[16,32]{1,0} reshape(%mul.7102), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7104 = f32[16,32,128]{2,1,0} broadcast(%mul.7103), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7105 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.7091, %mul.7104), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7106 = bf16[16,32,128]{2,1,0} convert(%mul.7105), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_36_self_attn_q_norm_weight__.280 = bf16[128]{0} parameter(279), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.36.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.7107 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_36_self_attn_q_norm_weight__.280), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7108 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.7107), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7109 = bf16[128]{0} reshape(%mul.7108), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7110 = bf16[16,32,128]{2,1,0} broadcast(%mul.7109), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7111 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.7106, %mul.7110), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7142 = bf16[16,32,64]{2,1,0} slice(%mul.7111), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.7133 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.7134 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.7135 = s32[16]{0} select(%lt.7133, %add.7134, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.7136 = s32[16,1]{1,0} reshape(%select_n.7135), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.7137 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.7136), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.7138 = bf16[16,64]{1,0} slice(%gather.7137), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7140 = bf16[16,1,64]{2,1,0} reshape(%slice.7138), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7144 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7140), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7145 = bf16[16,64]{1,0} reshape(%mul.7144), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7146 = bf16[16,32,64]{2,1,0} broadcast(%mul.7145), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7147 = bf16[16,32,64]{2,1,0} multiply(%slice.7142, %mul.7146), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7143 = bf16[16,32,64]{2,1,0} slice(%mul.7111), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.7139 = bf16[16,64]{1,0} slice(%gather.7137), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7141 = bf16[16,1,64]{2,1,0} reshape(%slice.7139), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7148 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7141), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7149 = bf16[16,64]{1,0} reshape(%mul.7148), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7150 = bf16[16,32,64]{2,1,0} broadcast(%mul.7149), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7151 = bf16[16,32,64]{2,1,0} multiply(%slice.7143, %mul.7150), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.7152 = bf16[16,32,64]{2,1,0} subtract(%mul.7147, %mul.7151), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.7153 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7140), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7154 = bf16[16,64]{1,0} reshape(%mul.7153), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7155 = bf16[16,32,64]{2,1,0} broadcast(%mul.7154), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7156 = bf16[16,32,64]{2,1,0} multiply(%slice.7143, %mul.7155), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7157 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7141), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7158 = bf16[16,64]{1,0} reshape(%mul.7157), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7159 = bf16[16,32,64]{2,1,0} broadcast(%mul.7158), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7160 = bf16[16,32,64]{2,1,0} multiply(%slice.7142, %mul.7159), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.7161 = bf16[16,32,64]{2,1,0} add(%mul.7156, %mul.7160), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.7162 = bf16[16,32,128]{2,1,0} concatenate(%sub.7152, %add.7161), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.7163 = bf16[16,4096]{1,0} reshape(%concatenate.7162), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.7087 = bf16[16,4,128]{2,1,0} slice(%reshape.7085), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.7112 = f32[16,4,128]{2,1,0} convert(%slice.7087), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.7113 = f32[16,4,128]{2,1,0} power(%convert_element_type.7112, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7118 = f32[16,4]{1,0} reduce(%pow.7113, %constant.512), dimensions={2}, to_apply=%region_176.7117, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7119 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.7118), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7120 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.7119, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7121 = f32[16,4,1]{2,1,0} add(%div.7120, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7122 = f32[16,4,1]{2,1,0} rsqrt(%add.7121), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7123 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.7122), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7124 = f32[16,4]{1,0} reshape(%mul.7123), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7125 = f32[16,4,128]{2,1,0} broadcast(%mul.7124), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7126 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.7112, %mul.7125), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7127 = bf16[16,4,128]{2,1,0} convert(%mul.7126), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_36_self_attn_k_norm_weight__.278 = bf16[128]{0} parameter(277), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.36.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.7128 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_36_self_attn_k_norm_weight__.278), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7129 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.7128), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7130 = bf16[128]{0} reshape(%mul.7129), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7131 = bf16[16,4,128]{2,1,0} broadcast(%mul.7130), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7132 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.7127, %mul.7131), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7166 = bf16[16,4,64]{2,1,0} slice(%mul.7132), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7164 = bf16[16,1,64]{2,1,0} reshape(%slice.7138), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7168 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7164), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7169 = bf16[16,64]{1,0} reshape(%mul.7168), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7170 = bf16[16,4,64]{2,1,0} broadcast(%mul.7169), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7171 = bf16[16,4,64]{2,1,0} multiply(%slice.7166, %mul.7170), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7167 = bf16[16,4,64]{2,1,0} slice(%mul.7132), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7165 = bf16[16,1,64]{2,1,0} reshape(%slice.7139), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7172 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7165), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7173 = bf16[16,64]{1,0} reshape(%mul.7172), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7174 = bf16[16,4,64]{2,1,0} broadcast(%mul.7173), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7175 = bf16[16,4,64]{2,1,0} multiply(%slice.7167, %mul.7174), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.7176 = bf16[16,4,64]{2,1,0} subtract(%mul.7171, %mul.7175), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.7177 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7164), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7178 = bf16[16,64]{1,0} reshape(%mul.7177), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7179 = bf16[16,4,64]{2,1,0} broadcast(%mul.7178), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7180 = bf16[16,4,64]{2,1,0} multiply(%slice.7167, %mul.7179), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7181 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7165), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7182 = bf16[16,64]{1,0} reshape(%mul.7181), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7183 = bf16[16,4,64]{2,1,0} broadcast(%mul.7182), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7184 = bf16[16,4,64]{2,1,0} multiply(%slice.7166, %mul.7183), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.7185 = bf16[16,4,64]{2,1,0} add(%mul.7180, %mul.7184), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.7186 = bf16[16,4,128]{2,1,0} concatenate(%sub.7176, %add.7185), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.7187 = bf16[16,512]{1,0} reshape(%concatenate.7186), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.7088 = bf16[16,4,128]{2,1,0} slice(%reshape.7085), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.7089 = bf16[16,512]{1,0} reshape(%slice.7088), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.7188 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_36_.472, %reshape.7163, %reshape.7187, %reshape.7089, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.7189 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.7188), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_37_.473 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(472), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[37]"}
  %jit__jax_attn_func_.7190 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.7188), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_36_self_attn_o_proj_weight__.279 = bf16[2048,4096]{1,0} parameter(278), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.36.self_attn.o_proj.weight\']"}
  %dot_general.7191 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.7190, %params_and_buffers__vllm_model_language_model_model_layers_36_self_attn_o_proj_weight__.279), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.7192 = f32[16,2048]{1,0} convert(%dot_general.7191), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7063 = bf16[16,2048]{1,0} convert(%add.7062), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7193 = f32[16,2048]{1,0} convert(%convert_element_type.7063), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.7194 = f32[16,2048]{1,0} add(%convert_element_type.7192, %convert_element_type.7193), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.7196 = f32[16,2048]{1,0} power(%add.7194, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7201 = f32[16]{0} reduce(%pow.7196, %constant.512), dimensions={1}, to_apply=%region_177.7200, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7202 = f32[16,1]{1,0} reshape(%reduce_sum.7201), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7203 = f32[16,1]{1,0} divide(%broadcast_in_dim.7202, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7204 = f32[16,1]{1,0} add(%div.7203, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7205 = f32[16,1]{1,0} rsqrt(%add.7204), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7206 = f32[16,1]{1,0} broadcast(%rsqrt.7205), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7207 = f32[16]{0} reshape(%mul.7206), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7208 = f32[16,2048]{1,0} broadcast(%mul.7207), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7209 = f32[16,2048]{1,0} multiply(%add.7194, %mul.7208), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7210 = bf16[16,2048]{1,0} convert(%mul.7209), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_36_post_attention_layernorm_weight__.277 = bf16[2048]{0} parameter(276), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.36.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.7211 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_36_post_attention_layernorm_weight__.277), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7212 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.7211), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7213 = bf16[2048]{0} reshape(%mul.7212), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7214 = bf16[16,2048]{1,0} broadcast(%mul.7213), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7215 = bf16[16,2048]{1,0} multiply(%convert_element_type.7210, %mul.7214), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_36_mlp_experts_w13_weight__.274 = bf16[128,1536,2048]{2,1,0} parameter(273), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.36.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_36_mlp_experts_w2_weight__.275 = bf16[128,2048,768]{2,1,0} parameter(274), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.36.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_36_mlp_gate_weight__.276 = bf16[128,2048]{1,0} parameter(275), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.36.mlp.gate.weight\']"}
  %dot_general.7216 = bf16[16,128]{1,0} dot(%mul.7215, %params_and_buffers__vllm_model_language_model_model_layers_36_mlp_gate_weight__.276), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.7217 = bf16[16,2048]{1,0} call(%mul.7215, %params_and_buffers__vllm_model_language_model_model_layers_36_mlp_experts_w13_weight__.274, %params_and_buffers__vllm_model_language_model_model_layers_36_mlp_experts_w2_weight__.275, %dot_general.7216), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.7218 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.7217), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7195 = bf16[16,2048]{1,0} convert(%add.7194), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7219 = f32[16,2048]{1,0} convert(%convert_element_type.7195), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.7220 = f32[16,2048]{1,0} add(%convert_element_type.7218, %convert_element_type.7219), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.7222 = f32[16,2048]{1,0} power(%add.7220, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7227 = f32[16]{0} reduce(%pow.7222, %constant.512), dimensions={1}, to_apply=%region_178.7226, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7228 = f32[16,1]{1,0} reshape(%reduce_sum.7227), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7229 = f32[16,1]{1,0} divide(%broadcast_in_dim.7228, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7230 = f32[16,1]{1,0} add(%div.7229, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7231 = f32[16,1]{1,0} rsqrt(%add.7230), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7232 = f32[16,1]{1,0} broadcast(%rsqrt.7231), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7233 = f32[16]{0} reshape(%mul.7232), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7234 = f32[16,2048]{1,0} broadcast(%mul.7233), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7235 = f32[16,2048]{1,0} multiply(%add.7220, %mul.7234), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7236 = bf16[16,2048]{1,0} convert(%mul.7235), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_37_input_layernorm_weight__.282 = bf16[2048]{0} parameter(281), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.37.input_layernorm.weight\']"}
  %broadcast_in_dim.7237 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_37_input_layernorm_weight__.282), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7238 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.7237), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7239 = bf16[2048]{0} reshape(%mul.7238), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7240 = bf16[16,2048]{1,0} broadcast(%mul.7239), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7241 = bf16[16,2048]{1,0} multiply(%convert_element_type.7236, %mul.7240), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_37_self_attn_qkv_proj_weight__.290 = bf16[5120,2048]{1,0} parameter(289), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.37.self_attn.qkv_proj.weight\']"}
  %dot_general.7242 = bf16[16,5120]{1,0} dot(%mul.7241, %params_and_buffers__vllm_model_language_model_model_layers_37_self_attn_qkv_proj_weight__.290), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.7243 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.7242), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.7244 = bf16[16,4,1024]{2,1,0} slice(%reshape.7243), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.7248 = bf16[16,32,128]{2,1,0} reshape(%slice.7244), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.7249 = f32[16,32,128]{2,1,0} convert(%reshape.7248), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.7250 = f32[16,32,128]{2,1,0} power(%convert_element_type.7249, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7255 = f32[16,32]{1,0} reduce(%pow.7250, %constant.512), dimensions={2}, to_apply=%region_179.7254, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7256 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.7255), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7257 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.7256, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7258 = f32[16,32,1]{2,1,0} add(%div.7257, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7259 = f32[16,32,1]{2,1,0} rsqrt(%add.7258), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7260 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.7259), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7261 = f32[16,32]{1,0} reshape(%mul.7260), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7262 = f32[16,32,128]{2,1,0} broadcast(%mul.7261), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7263 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.7249, %mul.7262), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7264 = bf16[16,32,128]{2,1,0} convert(%mul.7263), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_37_self_attn_q_norm_weight__.289 = bf16[128]{0} parameter(288), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.37.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.7265 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_37_self_attn_q_norm_weight__.289), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7266 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.7265), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7267 = bf16[128]{0} reshape(%mul.7266), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7268 = bf16[16,32,128]{2,1,0} broadcast(%mul.7267), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7269 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.7264, %mul.7268), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7300 = bf16[16,32,64]{2,1,0} slice(%mul.7269), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.7291 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.7292 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.7293 = s32[16]{0} select(%lt.7291, %add.7292, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.7294 = s32[16,1]{1,0} reshape(%select_n.7293), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.7295 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.7294), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.7296 = bf16[16,64]{1,0} slice(%gather.7295), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7298 = bf16[16,1,64]{2,1,0} reshape(%slice.7296), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7302 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7298), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7303 = bf16[16,64]{1,0} reshape(%mul.7302), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7304 = bf16[16,32,64]{2,1,0} broadcast(%mul.7303), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7305 = bf16[16,32,64]{2,1,0} multiply(%slice.7300, %mul.7304), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7301 = bf16[16,32,64]{2,1,0} slice(%mul.7269), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.7297 = bf16[16,64]{1,0} slice(%gather.7295), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7299 = bf16[16,1,64]{2,1,0} reshape(%slice.7297), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7306 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7299), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7307 = bf16[16,64]{1,0} reshape(%mul.7306), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7308 = bf16[16,32,64]{2,1,0} broadcast(%mul.7307), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7309 = bf16[16,32,64]{2,1,0} multiply(%slice.7301, %mul.7308), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.7310 = bf16[16,32,64]{2,1,0} subtract(%mul.7305, %mul.7309), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.7311 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7298), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7312 = bf16[16,64]{1,0} reshape(%mul.7311), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7313 = bf16[16,32,64]{2,1,0} broadcast(%mul.7312), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7314 = bf16[16,32,64]{2,1,0} multiply(%slice.7301, %mul.7313), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7315 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7299), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7316 = bf16[16,64]{1,0} reshape(%mul.7315), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7317 = bf16[16,32,64]{2,1,0} broadcast(%mul.7316), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7318 = bf16[16,32,64]{2,1,0} multiply(%slice.7300, %mul.7317), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.7319 = bf16[16,32,64]{2,1,0} add(%mul.7314, %mul.7318), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.7320 = bf16[16,32,128]{2,1,0} concatenate(%sub.7310, %add.7319), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.7321 = bf16[16,4096]{1,0} reshape(%concatenate.7320), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.7245 = bf16[16,4,128]{2,1,0} slice(%reshape.7243), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.7270 = f32[16,4,128]{2,1,0} convert(%slice.7245), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.7271 = f32[16,4,128]{2,1,0} power(%convert_element_type.7270, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7276 = f32[16,4]{1,0} reduce(%pow.7271, %constant.512), dimensions={2}, to_apply=%region_180.7275, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7277 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.7276), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7278 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.7277, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7279 = f32[16,4,1]{2,1,0} add(%div.7278, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7280 = f32[16,4,1]{2,1,0} rsqrt(%add.7279), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7281 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.7280), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7282 = f32[16,4]{1,0} reshape(%mul.7281), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7283 = f32[16,4,128]{2,1,0} broadcast(%mul.7282), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7284 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.7270, %mul.7283), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7285 = bf16[16,4,128]{2,1,0} convert(%mul.7284), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_37_self_attn_k_norm_weight__.287 = bf16[128]{0} parameter(286), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.37.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.7286 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_37_self_attn_k_norm_weight__.287), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7287 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.7286), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7288 = bf16[128]{0} reshape(%mul.7287), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7289 = bf16[16,4,128]{2,1,0} broadcast(%mul.7288), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7290 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.7285, %mul.7289), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7324 = bf16[16,4,64]{2,1,0} slice(%mul.7290), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7322 = bf16[16,1,64]{2,1,0} reshape(%slice.7296), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7326 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7322), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7327 = bf16[16,64]{1,0} reshape(%mul.7326), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7328 = bf16[16,4,64]{2,1,0} broadcast(%mul.7327), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7329 = bf16[16,4,64]{2,1,0} multiply(%slice.7324, %mul.7328), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7325 = bf16[16,4,64]{2,1,0} slice(%mul.7290), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7323 = bf16[16,1,64]{2,1,0} reshape(%slice.7297), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7330 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7323), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7331 = bf16[16,64]{1,0} reshape(%mul.7330), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7332 = bf16[16,4,64]{2,1,0} broadcast(%mul.7331), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7333 = bf16[16,4,64]{2,1,0} multiply(%slice.7325, %mul.7332), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.7334 = bf16[16,4,64]{2,1,0} subtract(%mul.7329, %mul.7333), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.7335 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7322), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7336 = bf16[16,64]{1,0} reshape(%mul.7335), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7337 = bf16[16,4,64]{2,1,0} broadcast(%mul.7336), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7338 = bf16[16,4,64]{2,1,0} multiply(%slice.7325, %mul.7337), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7339 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7323), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7340 = bf16[16,64]{1,0} reshape(%mul.7339), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7341 = bf16[16,4,64]{2,1,0} broadcast(%mul.7340), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7342 = bf16[16,4,64]{2,1,0} multiply(%slice.7324, %mul.7341), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.7343 = bf16[16,4,64]{2,1,0} add(%mul.7338, %mul.7342), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.7344 = bf16[16,4,128]{2,1,0} concatenate(%sub.7334, %add.7343), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.7345 = bf16[16,512]{1,0} reshape(%concatenate.7344), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.7246 = bf16[16,4,128]{2,1,0} slice(%reshape.7243), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.7247 = bf16[16,512]{1,0} reshape(%slice.7246), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.7346 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_37_.473, %reshape.7321, %reshape.7345, %reshape.7247, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.7347 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.7346), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_38_.474 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(473), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[38]"}
  %jit__jax_attn_func_.7348 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.7346), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_37_self_attn_o_proj_weight__.288 = bf16[2048,4096]{1,0} parameter(287), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.37.self_attn.o_proj.weight\']"}
  %dot_general.7349 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.7348, %params_and_buffers__vllm_model_language_model_model_layers_37_self_attn_o_proj_weight__.288), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.7350 = f32[16,2048]{1,0} convert(%dot_general.7349), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7221 = bf16[16,2048]{1,0} convert(%add.7220), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7351 = f32[16,2048]{1,0} convert(%convert_element_type.7221), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.7352 = f32[16,2048]{1,0} add(%convert_element_type.7350, %convert_element_type.7351), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.7354 = f32[16,2048]{1,0} power(%add.7352, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7359 = f32[16]{0} reduce(%pow.7354, %constant.512), dimensions={1}, to_apply=%region_181.7358, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7360 = f32[16,1]{1,0} reshape(%reduce_sum.7359), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7361 = f32[16,1]{1,0} divide(%broadcast_in_dim.7360, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7362 = f32[16,1]{1,0} add(%div.7361, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7363 = f32[16,1]{1,0} rsqrt(%add.7362), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7364 = f32[16,1]{1,0} broadcast(%rsqrt.7363), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7365 = f32[16]{0} reshape(%mul.7364), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7366 = f32[16,2048]{1,0} broadcast(%mul.7365), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7367 = f32[16,2048]{1,0} multiply(%add.7352, %mul.7366), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7368 = bf16[16,2048]{1,0} convert(%mul.7367), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_37_post_attention_layernorm_weight__.286 = bf16[2048]{0} parameter(285), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.37.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.7369 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_37_post_attention_layernorm_weight__.286), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7370 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.7369), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7371 = bf16[2048]{0} reshape(%mul.7370), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7372 = bf16[16,2048]{1,0} broadcast(%mul.7371), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7373 = bf16[16,2048]{1,0} multiply(%convert_element_type.7368, %mul.7372), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_37_mlp_experts_w13_weight__.283 = bf16[128,1536,2048]{2,1,0} parameter(282), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.37.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_37_mlp_experts_w2_weight__.284 = bf16[128,2048,768]{2,1,0} parameter(283), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.37.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_37_mlp_gate_weight__.285 = bf16[128,2048]{1,0} parameter(284), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.37.mlp.gate.weight\']"}
  %dot_general.7374 = bf16[16,128]{1,0} dot(%mul.7373, %params_and_buffers__vllm_model_language_model_model_layers_37_mlp_gate_weight__.285), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.7375 = bf16[16,2048]{1,0} call(%mul.7373, %params_and_buffers__vllm_model_language_model_model_layers_37_mlp_experts_w13_weight__.283, %params_and_buffers__vllm_model_language_model_model_layers_37_mlp_experts_w2_weight__.284, %dot_general.7374), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.7376 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.7375), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7353 = bf16[16,2048]{1,0} convert(%add.7352), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7377 = f32[16,2048]{1,0} convert(%convert_element_type.7353), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.7378 = f32[16,2048]{1,0} add(%convert_element_type.7376, %convert_element_type.7377), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.7380 = f32[16,2048]{1,0} power(%add.7378, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7385 = f32[16]{0} reduce(%pow.7380, %constant.512), dimensions={1}, to_apply=%region_182.7384, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7386 = f32[16,1]{1,0} reshape(%reduce_sum.7385), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7387 = f32[16,1]{1,0} divide(%broadcast_in_dim.7386, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7388 = f32[16,1]{1,0} add(%div.7387, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7389 = f32[16,1]{1,0} rsqrt(%add.7388), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7390 = f32[16,1]{1,0} broadcast(%rsqrt.7389), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7391 = f32[16]{0} reshape(%mul.7390), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7392 = f32[16,2048]{1,0} broadcast(%mul.7391), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7393 = f32[16,2048]{1,0} multiply(%add.7378, %mul.7392), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7394 = bf16[16,2048]{1,0} convert(%mul.7393), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_38_input_layernorm_weight__.291 = bf16[2048]{0} parameter(290), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.38.input_layernorm.weight\']"}
  %broadcast_in_dim.7395 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_38_input_layernorm_weight__.291), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7396 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.7395), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7397 = bf16[2048]{0} reshape(%mul.7396), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7398 = bf16[16,2048]{1,0} broadcast(%mul.7397), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7399 = bf16[16,2048]{1,0} multiply(%convert_element_type.7394, %mul.7398), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_38_self_attn_qkv_proj_weight__.299 = bf16[5120,2048]{1,0} parameter(298), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.38.self_attn.qkv_proj.weight\']"}
  %dot_general.7400 = bf16[16,5120]{1,0} dot(%mul.7399, %params_and_buffers__vllm_model_language_model_model_layers_38_self_attn_qkv_proj_weight__.299), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.7401 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.7400), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.7402 = bf16[16,4,1024]{2,1,0} slice(%reshape.7401), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.7406 = bf16[16,32,128]{2,1,0} reshape(%slice.7402), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.7407 = f32[16,32,128]{2,1,0} convert(%reshape.7406), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.7408 = f32[16,32,128]{2,1,0} power(%convert_element_type.7407, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7413 = f32[16,32]{1,0} reduce(%pow.7408, %constant.512), dimensions={2}, to_apply=%region_183.7412, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7414 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.7413), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7415 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.7414, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7416 = f32[16,32,1]{2,1,0} add(%div.7415, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7417 = f32[16,32,1]{2,1,0} rsqrt(%add.7416), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7418 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.7417), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7419 = f32[16,32]{1,0} reshape(%mul.7418), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7420 = f32[16,32,128]{2,1,0} broadcast(%mul.7419), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7421 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.7407, %mul.7420), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7422 = bf16[16,32,128]{2,1,0} convert(%mul.7421), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_38_self_attn_q_norm_weight__.298 = bf16[128]{0} parameter(297), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.38.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.7423 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_38_self_attn_q_norm_weight__.298), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7424 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.7423), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7425 = bf16[128]{0} reshape(%mul.7424), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7426 = bf16[16,32,128]{2,1,0} broadcast(%mul.7425), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7427 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.7422, %mul.7426), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7458 = bf16[16,32,64]{2,1,0} slice(%mul.7427), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.7449 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.7450 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.7451 = s32[16]{0} select(%lt.7449, %add.7450, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.7452 = s32[16,1]{1,0} reshape(%select_n.7451), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.7453 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.7452), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.7454 = bf16[16,64]{1,0} slice(%gather.7453), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7456 = bf16[16,1,64]{2,1,0} reshape(%slice.7454), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7460 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7456), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7461 = bf16[16,64]{1,0} reshape(%mul.7460), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7462 = bf16[16,32,64]{2,1,0} broadcast(%mul.7461), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7463 = bf16[16,32,64]{2,1,0} multiply(%slice.7458, %mul.7462), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7459 = bf16[16,32,64]{2,1,0} slice(%mul.7427), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.7455 = bf16[16,64]{1,0} slice(%gather.7453), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7457 = bf16[16,1,64]{2,1,0} reshape(%slice.7455), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7464 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7457), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7465 = bf16[16,64]{1,0} reshape(%mul.7464), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7466 = bf16[16,32,64]{2,1,0} broadcast(%mul.7465), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7467 = bf16[16,32,64]{2,1,0} multiply(%slice.7459, %mul.7466), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.7468 = bf16[16,32,64]{2,1,0} subtract(%mul.7463, %mul.7467), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.7469 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7456), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7470 = bf16[16,64]{1,0} reshape(%mul.7469), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7471 = bf16[16,32,64]{2,1,0} broadcast(%mul.7470), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7472 = bf16[16,32,64]{2,1,0} multiply(%slice.7459, %mul.7471), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7473 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7457), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7474 = bf16[16,64]{1,0} reshape(%mul.7473), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7475 = bf16[16,32,64]{2,1,0} broadcast(%mul.7474), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7476 = bf16[16,32,64]{2,1,0} multiply(%slice.7458, %mul.7475), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.7477 = bf16[16,32,64]{2,1,0} add(%mul.7472, %mul.7476), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.7478 = bf16[16,32,128]{2,1,0} concatenate(%sub.7468, %add.7477), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.7479 = bf16[16,4096]{1,0} reshape(%concatenate.7478), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.7403 = bf16[16,4,128]{2,1,0} slice(%reshape.7401), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.7428 = f32[16,4,128]{2,1,0} convert(%slice.7403), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.7429 = f32[16,4,128]{2,1,0} power(%convert_element_type.7428, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7434 = f32[16,4]{1,0} reduce(%pow.7429, %constant.512), dimensions={2}, to_apply=%region_184.7433, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7435 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.7434), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7436 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.7435, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7437 = f32[16,4,1]{2,1,0} add(%div.7436, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7438 = f32[16,4,1]{2,1,0} rsqrt(%add.7437), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7439 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.7438), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7440 = f32[16,4]{1,0} reshape(%mul.7439), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7441 = f32[16,4,128]{2,1,0} broadcast(%mul.7440), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7442 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.7428, %mul.7441), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7443 = bf16[16,4,128]{2,1,0} convert(%mul.7442), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_38_self_attn_k_norm_weight__.296 = bf16[128]{0} parameter(295), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.38.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.7444 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_38_self_attn_k_norm_weight__.296), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7445 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.7444), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7446 = bf16[128]{0} reshape(%mul.7445), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7447 = bf16[16,4,128]{2,1,0} broadcast(%mul.7446), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7448 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.7443, %mul.7447), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7482 = bf16[16,4,64]{2,1,0} slice(%mul.7448), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7480 = bf16[16,1,64]{2,1,0} reshape(%slice.7454), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7484 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7480), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7485 = bf16[16,64]{1,0} reshape(%mul.7484), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7486 = bf16[16,4,64]{2,1,0} broadcast(%mul.7485), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7487 = bf16[16,4,64]{2,1,0} multiply(%slice.7482, %mul.7486), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7483 = bf16[16,4,64]{2,1,0} slice(%mul.7448), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7481 = bf16[16,1,64]{2,1,0} reshape(%slice.7455), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7488 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7481), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7489 = bf16[16,64]{1,0} reshape(%mul.7488), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7490 = bf16[16,4,64]{2,1,0} broadcast(%mul.7489), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7491 = bf16[16,4,64]{2,1,0} multiply(%slice.7483, %mul.7490), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.7492 = bf16[16,4,64]{2,1,0} subtract(%mul.7487, %mul.7491), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.7493 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7480), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7494 = bf16[16,64]{1,0} reshape(%mul.7493), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7495 = bf16[16,4,64]{2,1,0} broadcast(%mul.7494), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7496 = bf16[16,4,64]{2,1,0} multiply(%slice.7483, %mul.7495), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7497 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7481), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7498 = bf16[16,64]{1,0} reshape(%mul.7497), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7499 = bf16[16,4,64]{2,1,0} broadcast(%mul.7498), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7500 = bf16[16,4,64]{2,1,0} multiply(%slice.7482, %mul.7499), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.7501 = bf16[16,4,64]{2,1,0} add(%mul.7496, %mul.7500), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.7502 = bf16[16,4,128]{2,1,0} concatenate(%sub.7492, %add.7501), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.7503 = bf16[16,512]{1,0} reshape(%concatenate.7502), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.7404 = bf16[16,4,128]{2,1,0} slice(%reshape.7401), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.7405 = bf16[16,512]{1,0} reshape(%slice.7404), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.7504 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_38_.474, %reshape.7479, %reshape.7503, %reshape.7405, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.7505 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.7504), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_39_.475 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(474), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[39]"}
  %jit__jax_attn_func_.7506 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.7504), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_38_self_attn_o_proj_weight__.297 = bf16[2048,4096]{1,0} parameter(296), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.38.self_attn.o_proj.weight\']"}
  %dot_general.7507 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.7506, %params_and_buffers__vllm_model_language_model_model_layers_38_self_attn_o_proj_weight__.297), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.7508 = f32[16,2048]{1,0} convert(%dot_general.7507), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7379 = bf16[16,2048]{1,0} convert(%add.7378), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7509 = f32[16,2048]{1,0} convert(%convert_element_type.7379), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.7510 = f32[16,2048]{1,0} add(%convert_element_type.7508, %convert_element_type.7509), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.7512 = f32[16,2048]{1,0} power(%add.7510, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7517 = f32[16]{0} reduce(%pow.7512, %constant.512), dimensions={1}, to_apply=%region_185.7516, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7518 = f32[16,1]{1,0} reshape(%reduce_sum.7517), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7519 = f32[16,1]{1,0} divide(%broadcast_in_dim.7518, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7520 = f32[16,1]{1,0} add(%div.7519, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7521 = f32[16,1]{1,0} rsqrt(%add.7520), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7522 = f32[16,1]{1,0} broadcast(%rsqrt.7521), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7523 = f32[16]{0} reshape(%mul.7522), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7524 = f32[16,2048]{1,0} broadcast(%mul.7523), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7525 = f32[16,2048]{1,0} multiply(%add.7510, %mul.7524), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7526 = bf16[16,2048]{1,0} convert(%mul.7525), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_38_post_attention_layernorm_weight__.295 = bf16[2048]{0} parameter(294), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.38.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.7527 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_38_post_attention_layernorm_weight__.295), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7528 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.7527), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7529 = bf16[2048]{0} reshape(%mul.7528), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7530 = bf16[16,2048]{1,0} broadcast(%mul.7529), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7531 = bf16[16,2048]{1,0} multiply(%convert_element_type.7526, %mul.7530), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_38_mlp_experts_w13_weight__.292 = bf16[128,1536,2048]{2,1,0} parameter(291), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.38.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_38_mlp_experts_w2_weight__.293 = bf16[128,2048,768]{2,1,0} parameter(292), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.38.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_38_mlp_gate_weight__.294 = bf16[128,2048]{1,0} parameter(293), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.38.mlp.gate.weight\']"}
  %dot_general.7532 = bf16[16,128]{1,0} dot(%mul.7531, %params_and_buffers__vllm_model_language_model_model_layers_38_mlp_gate_weight__.294), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.7533 = bf16[16,2048]{1,0} call(%mul.7531, %params_and_buffers__vllm_model_language_model_model_layers_38_mlp_experts_w13_weight__.292, %params_and_buffers__vllm_model_language_model_model_layers_38_mlp_experts_w2_weight__.293, %dot_general.7532), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.7534 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.7533), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7511 = bf16[16,2048]{1,0} convert(%add.7510), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7535 = f32[16,2048]{1,0} convert(%convert_element_type.7511), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.7536 = f32[16,2048]{1,0} add(%convert_element_type.7534, %convert_element_type.7535), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.7538 = f32[16,2048]{1,0} power(%add.7536, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7543 = f32[16]{0} reduce(%pow.7538, %constant.512), dimensions={1}, to_apply=%region_186.7542, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7544 = f32[16,1]{1,0} reshape(%reduce_sum.7543), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7545 = f32[16,1]{1,0} divide(%broadcast_in_dim.7544, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7546 = f32[16,1]{1,0} add(%div.7545, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7547 = f32[16,1]{1,0} rsqrt(%add.7546), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7548 = f32[16,1]{1,0} broadcast(%rsqrt.7547), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7549 = f32[16]{0} reshape(%mul.7548), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7550 = f32[16,2048]{1,0} broadcast(%mul.7549), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7551 = f32[16,2048]{1,0} multiply(%add.7536, %mul.7550), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7552 = bf16[16,2048]{1,0} convert(%mul.7551), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_39_input_layernorm_weight__.300 = bf16[2048]{0} parameter(299), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.39.input_layernorm.weight\']"}
  %broadcast_in_dim.7553 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_39_input_layernorm_weight__.300), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7554 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.7553), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7555 = bf16[2048]{0} reshape(%mul.7554), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7556 = bf16[16,2048]{1,0} broadcast(%mul.7555), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7557 = bf16[16,2048]{1,0} multiply(%convert_element_type.7552, %mul.7556), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_39_self_attn_qkv_proj_weight__.308 = bf16[5120,2048]{1,0} parameter(307), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.39.self_attn.qkv_proj.weight\']"}
  %dot_general.7558 = bf16[16,5120]{1,0} dot(%mul.7557, %params_and_buffers__vllm_model_language_model_model_layers_39_self_attn_qkv_proj_weight__.308), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.7559 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.7558), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.7560 = bf16[16,4,1024]{2,1,0} slice(%reshape.7559), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.7564 = bf16[16,32,128]{2,1,0} reshape(%slice.7560), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.7565 = f32[16,32,128]{2,1,0} convert(%reshape.7564), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.7566 = f32[16,32,128]{2,1,0} power(%convert_element_type.7565, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7571 = f32[16,32]{1,0} reduce(%pow.7566, %constant.512), dimensions={2}, to_apply=%region_187.7570, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7572 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.7571), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7573 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.7572, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7574 = f32[16,32,1]{2,1,0} add(%div.7573, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7575 = f32[16,32,1]{2,1,0} rsqrt(%add.7574), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7576 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.7575), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7577 = f32[16,32]{1,0} reshape(%mul.7576), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7578 = f32[16,32,128]{2,1,0} broadcast(%mul.7577), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7579 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.7565, %mul.7578), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7580 = bf16[16,32,128]{2,1,0} convert(%mul.7579), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_39_self_attn_q_norm_weight__.307 = bf16[128]{0} parameter(306), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.39.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.7581 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_39_self_attn_q_norm_weight__.307), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7582 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.7581), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7583 = bf16[128]{0} reshape(%mul.7582), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7584 = bf16[16,32,128]{2,1,0} broadcast(%mul.7583), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7585 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.7580, %mul.7584), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7616 = bf16[16,32,64]{2,1,0} slice(%mul.7585), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.7607 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.7608 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.7609 = s32[16]{0} select(%lt.7607, %add.7608, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.7610 = s32[16,1]{1,0} reshape(%select_n.7609), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.7611 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.7610), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.7612 = bf16[16,64]{1,0} slice(%gather.7611), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7614 = bf16[16,1,64]{2,1,0} reshape(%slice.7612), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7618 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7614), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7619 = bf16[16,64]{1,0} reshape(%mul.7618), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7620 = bf16[16,32,64]{2,1,0} broadcast(%mul.7619), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7621 = bf16[16,32,64]{2,1,0} multiply(%slice.7616, %mul.7620), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7617 = bf16[16,32,64]{2,1,0} slice(%mul.7585), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.7613 = bf16[16,64]{1,0} slice(%gather.7611), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7615 = bf16[16,1,64]{2,1,0} reshape(%slice.7613), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7622 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7615), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7623 = bf16[16,64]{1,0} reshape(%mul.7622), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7624 = bf16[16,32,64]{2,1,0} broadcast(%mul.7623), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7625 = bf16[16,32,64]{2,1,0} multiply(%slice.7617, %mul.7624), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.7626 = bf16[16,32,64]{2,1,0} subtract(%mul.7621, %mul.7625), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.7627 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7614), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7628 = bf16[16,64]{1,0} reshape(%mul.7627), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7629 = bf16[16,32,64]{2,1,0} broadcast(%mul.7628), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7630 = bf16[16,32,64]{2,1,0} multiply(%slice.7617, %mul.7629), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7631 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7615), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7632 = bf16[16,64]{1,0} reshape(%mul.7631), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7633 = bf16[16,32,64]{2,1,0} broadcast(%mul.7632), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7634 = bf16[16,32,64]{2,1,0} multiply(%slice.7616, %mul.7633), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.7635 = bf16[16,32,64]{2,1,0} add(%mul.7630, %mul.7634), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.7636 = bf16[16,32,128]{2,1,0} concatenate(%sub.7626, %add.7635), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.7637 = bf16[16,4096]{1,0} reshape(%concatenate.7636), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.7561 = bf16[16,4,128]{2,1,0} slice(%reshape.7559), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.7586 = f32[16,4,128]{2,1,0} convert(%slice.7561), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.7587 = f32[16,4,128]{2,1,0} power(%convert_element_type.7586, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7592 = f32[16,4]{1,0} reduce(%pow.7587, %constant.512), dimensions={2}, to_apply=%region_188.7591, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7593 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.7592), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7594 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.7593, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7595 = f32[16,4,1]{2,1,0} add(%div.7594, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7596 = f32[16,4,1]{2,1,0} rsqrt(%add.7595), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7597 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.7596), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7598 = f32[16,4]{1,0} reshape(%mul.7597), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7599 = f32[16,4,128]{2,1,0} broadcast(%mul.7598), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7600 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.7586, %mul.7599), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7601 = bf16[16,4,128]{2,1,0} convert(%mul.7600), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_39_self_attn_k_norm_weight__.305 = bf16[128]{0} parameter(304), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.39.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.7602 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_39_self_attn_k_norm_weight__.305), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7603 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.7602), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7604 = bf16[128]{0} reshape(%mul.7603), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7605 = bf16[16,4,128]{2,1,0} broadcast(%mul.7604), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7606 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.7601, %mul.7605), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7640 = bf16[16,4,64]{2,1,0} slice(%mul.7606), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7638 = bf16[16,1,64]{2,1,0} reshape(%slice.7612), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7642 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7638), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7643 = bf16[16,64]{1,0} reshape(%mul.7642), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7644 = bf16[16,4,64]{2,1,0} broadcast(%mul.7643), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7645 = bf16[16,4,64]{2,1,0} multiply(%slice.7640, %mul.7644), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7641 = bf16[16,4,64]{2,1,0} slice(%mul.7606), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7639 = bf16[16,1,64]{2,1,0} reshape(%slice.7613), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7646 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7639), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7647 = bf16[16,64]{1,0} reshape(%mul.7646), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7648 = bf16[16,4,64]{2,1,0} broadcast(%mul.7647), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7649 = bf16[16,4,64]{2,1,0} multiply(%slice.7641, %mul.7648), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.7650 = bf16[16,4,64]{2,1,0} subtract(%mul.7645, %mul.7649), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.7651 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7638), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7652 = bf16[16,64]{1,0} reshape(%mul.7651), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7653 = bf16[16,4,64]{2,1,0} broadcast(%mul.7652), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7654 = bf16[16,4,64]{2,1,0} multiply(%slice.7641, %mul.7653), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7655 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7639), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7656 = bf16[16,64]{1,0} reshape(%mul.7655), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7657 = bf16[16,4,64]{2,1,0} broadcast(%mul.7656), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7658 = bf16[16,4,64]{2,1,0} multiply(%slice.7640, %mul.7657), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.7659 = bf16[16,4,64]{2,1,0} add(%mul.7654, %mul.7658), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.7660 = bf16[16,4,128]{2,1,0} concatenate(%sub.7650, %add.7659), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.7661 = bf16[16,512]{1,0} reshape(%concatenate.7660), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.7562 = bf16[16,4,128]{2,1,0} slice(%reshape.7559), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.7563 = bf16[16,512]{1,0} reshape(%slice.7562), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.7662 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_39_.475, %reshape.7637, %reshape.7661, %reshape.7563, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.7663 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.7662), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_40_.476 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(475), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[40]"}
  %jit__jax_attn_func_.7664 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.7662), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_39_self_attn_o_proj_weight__.306 = bf16[2048,4096]{1,0} parameter(305), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.39.self_attn.o_proj.weight\']"}
  %dot_general.7665 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.7664, %params_and_buffers__vllm_model_language_model_model_layers_39_self_attn_o_proj_weight__.306), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.7666 = f32[16,2048]{1,0} convert(%dot_general.7665), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7537 = bf16[16,2048]{1,0} convert(%add.7536), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7667 = f32[16,2048]{1,0} convert(%convert_element_type.7537), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.7668 = f32[16,2048]{1,0} add(%convert_element_type.7666, %convert_element_type.7667), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.7670 = f32[16,2048]{1,0} power(%add.7668, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7675 = f32[16]{0} reduce(%pow.7670, %constant.512), dimensions={1}, to_apply=%region_189.7674, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7676 = f32[16,1]{1,0} reshape(%reduce_sum.7675), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7677 = f32[16,1]{1,0} divide(%broadcast_in_dim.7676, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7678 = f32[16,1]{1,0} add(%div.7677, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7679 = f32[16,1]{1,0} rsqrt(%add.7678), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7680 = f32[16,1]{1,0} broadcast(%rsqrt.7679), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7681 = f32[16]{0} reshape(%mul.7680), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7682 = f32[16,2048]{1,0} broadcast(%mul.7681), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7683 = f32[16,2048]{1,0} multiply(%add.7668, %mul.7682), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7684 = bf16[16,2048]{1,0} convert(%mul.7683), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_39_post_attention_layernorm_weight__.304 = bf16[2048]{0} parameter(303), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.39.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.7685 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_39_post_attention_layernorm_weight__.304), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7686 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.7685), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7687 = bf16[2048]{0} reshape(%mul.7686), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7688 = bf16[16,2048]{1,0} broadcast(%mul.7687), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7689 = bf16[16,2048]{1,0} multiply(%convert_element_type.7684, %mul.7688), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_39_mlp_experts_w13_weight__.301 = bf16[128,1536,2048]{2,1,0} parameter(300), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.39.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_39_mlp_experts_w2_weight__.302 = bf16[128,2048,768]{2,1,0} parameter(301), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.39.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_39_mlp_gate_weight__.303 = bf16[128,2048]{1,0} parameter(302), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.39.mlp.gate.weight\']"}
  %dot_general.7690 = bf16[16,128]{1,0} dot(%mul.7689, %params_and_buffers__vllm_model_language_model_model_layers_39_mlp_gate_weight__.303), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.7691 = bf16[16,2048]{1,0} call(%mul.7689, %params_and_buffers__vllm_model_language_model_model_layers_39_mlp_experts_w13_weight__.301, %params_and_buffers__vllm_model_language_model_model_layers_39_mlp_experts_w2_weight__.302, %dot_general.7690), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.7692 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.7691), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7669 = bf16[16,2048]{1,0} convert(%add.7668), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7693 = f32[16,2048]{1,0} convert(%convert_element_type.7669), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.7694 = f32[16,2048]{1,0} add(%convert_element_type.7692, %convert_element_type.7693), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.7696 = f32[16,2048]{1,0} power(%add.7694, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7701 = f32[16]{0} reduce(%pow.7696, %constant.512), dimensions={1}, to_apply=%region_190.7700, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7702 = f32[16,1]{1,0} reshape(%reduce_sum.7701), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7703 = f32[16,1]{1,0} divide(%broadcast_in_dim.7702, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7704 = f32[16,1]{1,0} add(%div.7703, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7705 = f32[16,1]{1,0} rsqrt(%add.7704), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7706 = f32[16,1]{1,0} broadcast(%rsqrt.7705), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7707 = f32[16]{0} reshape(%mul.7706), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7708 = f32[16,2048]{1,0} broadcast(%mul.7707), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7709 = f32[16,2048]{1,0} multiply(%add.7694, %mul.7708), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7710 = bf16[16,2048]{1,0} convert(%mul.7709), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_40_input_layernorm_weight__.318 = bf16[2048]{0} parameter(317), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.40.input_layernorm.weight\']"}
  %broadcast_in_dim.7711 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_40_input_layernorm_weight__.318), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7712 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.7711), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7713 = bf16[2048]{0} reshape(%mul.7712), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7714 = bf16[16,2048]{1,0} broadcast(%mul.7713), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7715 = bf16[16,2048]{1,0} multiply(%convert_element_type.7710, %mul.7714), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_40_self_attn_qkv_proj_weight__.326 = bf16[5120,2048]{1,0} parameter(325), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.40.self_attn.qkv_proj.weight\']"}
  %dot_general.7716 = bf16[16,5120]{1,0} dot(%mul.7715, %params_and_buffers__vllm_model_language_model_model_layers_40_self_attn_qkv_proj_weight__.326), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.7717 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.7716), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.7718 = bf16[16,4,1024]{2,1,0} slice(%reshape.7717), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.7722 = bf16[16,32,128]{2,1,0} reshape(%slice.7718), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.7723 = f32[16,32,128]{2,1,0} convert(%reshape.7722), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.7724 = f32[16,32,128]{2,1,0} power(%convert_element_type.7723, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7729 = f32[16,32]{1,0} reduce(%pow.7724, %constant.512), dimensions={2}, to_apply=%region_191.7728, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7730 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.7729), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7731 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.7730, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7732 = f32[16,32,1]{2,1,0} add(%div.7731, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7733 = f32[16,32,1]{2,1,0} rsqrt(%add.7732), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7734 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.7733), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7735 = f32[16,32]{1,0} reshape(%mul.7734), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7736 = f32[16,32,128]{2,1,0} broadcast(%mul.7735), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7737 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.7723, %mul.7736), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7738 = bf16[16,32,128]{2,1,0} convert(%mul.7737), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_40_self_attn_q_norm_weight__.325 = bf16[128]{0} parameter(324), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.40.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.7739 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_40_self_attn_q_norm_weight__.325), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7740 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.7739), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7741 = bf16[128]{0} reshape(%mul.7740), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7742 = bf16[16,32,128]{2,1,0} broadcast(%mul.7741), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7743 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.7738, %mul.7742), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7774 = bf16[16,32,64]{2,1,0} slice(%mul.7743), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.7765 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.7766 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.7767 = s32[16]{0} select(%lt.7765, %add.7766, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.7768 = s32[16,1]{1,0} reshape(%select_n.7767), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.7769 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.7768), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.7770 = bf16[16,64]{1,0} slice(%gather.7769), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7772 = bf16[16,1,64]{2,1,0} reshape(%slice.7770), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7776 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7772), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7777 = bf16[16,64]{1,0} reshape(%mul.7776), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7778 = bf16[16,32,64]{2,1,0} broadcast(%mul.7777), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7779 = bf16[16,32,64]{2,1,0} multiply(%slice.7774, %mul.7778), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7775 = bf16[16,32,64]{2,1,0} slice(%mul.7743), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.7771 = bf16[16,64]{1,0} slice(%gather.7769), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7773 = bf16[16,1,64]{2,1,0} reshape(%slice.7771), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7780 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7773), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7781 = bf16[16,64]{1,0} reshape(%mul.7780), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7782 = bf16[16,32,64]{2,1,0} broadcast(%mul.7781), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7783 = bf16[16,32,64]{2,1,0} multiply(%slice.7775, %mul.7782), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.7784 = bf16[16,32,64]{2,1,0} subtract(%mul.7779, %mul.7783), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.7785 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7772), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7786 = bf16[16,64]{1,0} reshape(%mul.7785), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7787 = bf16[16,32,64]{2,1,0} broadcast(%mul.7786), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7788 = bf16[16,32,64]{2,1,0} multiply(%slice.7775, %mul.7787), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7789 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7773), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7790 = bf16[16,64]{1,0} reshape(%mul.7789), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7791 = bf16[16,32,64]{2,1,0} broadcast(%mul.7790), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7792 = bf16[16,32,64]{2,1,0} multiply(%slice.7774, %mul.7791), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.7793 = bf16[16,32,64]{2,1,0} add(%mul.7788, %mul.7792), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.7794 = bf16[16,32,128]{2,1,0} concatenate(%sub.7784, %add.7793), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.7795 = bf16[16,4096]{1,0} reshape(%concatenate.7794), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.7719 = bf16[16,4,128]{2,1,0} slice(%reshape.7717), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.7744 = f32[16,4,128]{2,1,0} convert(%slice.7719), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.7745 = f32[16,4,128]{2,1,0} power(%convert_element_type.7744, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7750 = f32[16,4]{1,0} reduce(%pow.7745, %constant.512), dimensions={2}, to_apply=%region_192.7749, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7751 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.7750), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7752 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.7751, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7753 = f32[16,4,1]{2,1,0} add(%div.7752, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7754 = f32[16,4,1]{2,1,0} rsqrt(%add.7753), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7755 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.7754), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7756 = f32[16,4]{1,0} reshape(%mul.7755), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7757 = f32[16,4,128]{2,1,0} broadcast(%mul.7756), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7758 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.7744, %mul.7757), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7759 = bf16[16,4,128]{2,1,0} convert(%mul.7758), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_40_self_attn_k_norm_weight__.323 = bf16[128]{0} parameter(322), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.40.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.7760 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_40_self_attn_k_norm_weight__.323), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7761 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.7760), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7762 = bf16[128]{0} reshape(%mul.7761), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7763 = bf16[16,4,128]{2,1,0} broadcast(%mul.7762), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7764 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.7759, %mul.7763), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7798 = bf16[16,4,64]{2,1,0} slice(%mul.7764), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7796 = bf16[16,1,64]{2,1,0} reshape(%slice.7770), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7800 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7796), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7801 = bf16[16,64]{1,0} reshape(%mul.7800), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7802 = bf16[16,4,64]{2,1,0} broadcast(%mul.7801), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7803 = bf16[16,4,64]{2,1,0} multiply(%slice.7798, %mul.7802), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7799 = bf16[16,4,64]{2,1,0} slice(%mul.7764), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7797 = bf16[16,1,64]{2,1,0} reshape(%slice.7771), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7804 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7797), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7805 = bf16[16,64]{1,0} reshape(%mul.7804), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7806 = bf16[16,4,64]{2,1,0} broadcast(%mul.7805), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7807 = bf16[16,4,64]{2,1,0} multiply(%slice.7799, %mul.7806), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.7808 = bf16[16,4,64]{2,1,0} subtract(%mul.7803, %mul.7807), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.7809 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7796), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7810 = bf16[16,64]{1,0} reshape(%mul.7809), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7811 = bf16[16,4,64]{2,1,0} broadcast(%mul.7810), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7812 = bf16[16,4,64]{2,1,0} multiply(%slice.7799, %mul.7811), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7813 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7797), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7814 = bf16[16,64]{1,0} reshape(%mul.7813), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7815 = bf16[16,4,64]{2,1,0} broadcast(%mul.7814), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7816 = bf16[16,4,64]{2,1,0} multiply(%slice.7798, %mul.7815), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.7817 = bf16[16,4,64]{2,1,0} add(%mul.7812, %mul.7816), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.7818 = bf16[16,4,128]{2,1,0} concatenate(%sub.7808, %add.7817), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.7819 = bf16[16,512]{1,0} reshape(%concatenate.7818), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.7720 = bf16[16,4,128]{2,1,0} slice(%reshape.7717), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.7721 = bf16[16,512]{1,0} reshape(%slice.7720), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.7820 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_40_.476, %reshape.7795, %reshape.7819, %reshape.7721, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.7821 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.7820), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_41_.477 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(476), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[41]"}
  %jit__jax_attn_func_.7822 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.7820), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_40_self_attn_o_proj_weight__.324 = bf16[2048,4096]{1,0} parameter(323), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.40.self_attn.o_proj.weight\']"}
  %dot_general.7823 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.7822, %params_and_buffers__vllm_model_language_model_model_layers_40_self_attn_o_proj_weight__.324), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.7824 = f32[16,2048]{1,0} convert(%dot_general.7823), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7695 = bf16[16,2048]{1,0} convert(%add.7694), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7825 = f32[16,2048]{1,0} convert(%convert_element_type.7695), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.7826 = f32[16,2048]{1,0} add(%convert_element_type.7824, %convert_element_type.7825), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.7828 = f32[16,2048]{1,0} power(%add.7826, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7833 = f32[16]{0} reduce(%pow.7828, %constant.512), dimensions={1}, to_apply=%region_193.7832, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7834 = f32[16,1]{1,0} reshape(%reduce_sum.7833), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7835 = f32[16,1]{1,0} divide(%broadcast_in_dim.7834, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7836 = f32[16,1]{1,0} add(%div.7835, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7837 = f32[16,1]{1,0} rsqrt(%add.7836), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7838 = f32[16,1]{1,0} broadcast(%rsqrt.7837), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7839 = f32[16]{0} reshape(%mul.7838), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7840 = f32[16,2048]{1,0} broadcast(%mul.7839), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7841 = f32[16,2048]{1,0} multiply(%add.7826, %mul.7840), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7842 = bf16[16,2048]{1,0} convert(%mul.7841), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_40_post_attention_layernorm_weight__.322 = bf16[2048]{0} parameter(321), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.40.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.7843 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_40_post_attention_layernorm_weight__.322), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7844 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.7843), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7845 = bf16[2048]{0} reshape(%mul.7844), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7846 = bf16[16,2048]{1,0} broadcast(%mul.7845), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7847 = bf16[16,2048]{1,0} multiply(%convert_element_type.7842, %mul.7846), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_40_mlp_experts_w13_weight__.319 = bf16[128,1536,2048]{2,1,0} parameter(318), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.40.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_40_mlp_experts_w2_weight__.320 = bf16[128,2048,768]{2,1,0} parameter(319), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.40.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_40_mlp_gate_weight__.321 = bf16[128,2048]{1,0} parameter(320), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.40.mlp.gate.weight\']"}
  %dot_general.7848 = bf16[16,128]{1,0} dot(%mul.7847, %params_and_buffers__vllm_model_language_model_model_layers_40_mlp_gate_weight__.321), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.7849 = bf16[16,2048]{1,0} call(%mul.7847, %params_and_buffers__vllm_model_language_model_model_layers_40_mlp_experts_w13_weight__.319, %params_and_buffers__vllm_model_language_model_model_layers_40_mlp_experts_w2_weight__.320, %dot_general.7848), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.7850 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.7849), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7827 = bf16[16,2048]{1,0} convert(%add.7826), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7851 = f32[16,2048]{1,0} convert(%convert_element_type.7827), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.7852 = f32[16,2048]{1,0} add(%convert_element_type.7850, %convert_element_type.7851), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.7854 = f32[16,2048]{1,0} power(%add.7852, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7859 = f32[16]{0} reduce(%pow.7854, %constant.512), dimensions={1}, to_apply=%region_194.7858, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7860 = f32[16,1]{1,0} reshape(%reduce_sum.7859), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7861 = f32[16,1]{1,0} divide(%broadcast_in_dim.7860, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7862 = f32[16,1]{1,0} add(%div.7861, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7863 = f32[16,1]{1,0} rsqrt(%add.7862), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7864 = f32[16,1]{1,0} broadcast(%rsqrt.7863), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7865 = f32[16]{0} reshape(%mul.7864), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7866 = f32[16,2048]{1,0} broadcast(%mul.7865), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7867 = f32[16,2048]{1,0} multiply(%add.7852, %mul.7866), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7868 = bf16[16,2048]{1,0} convert(%mul.7867), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_41_input_layernorm_weight__.327 = bf16[2048]{0} parameter(326), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.41.input_layernorm.weight\']"}
  %broadcast_in_dim.7869 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_41_input_layernorm_weight__.327), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7870 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.7869), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7871 = bf16[2048]{0} reshape(%mul.7870), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7872 = bf16[16,2048]{1,0} broadcast(%mul.7871), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7873 = bf16[16,2048]{1,0} multiply(%convert_element_type.7868, %mul.7872), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_41_self_attn_qkv_proj_weight__.335 = bf16[5120,2048]{1,0} parameter(334), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.41.self_attn.qkv_proj.weight\']"}
  %dot_general.7874 = bf16[16,5120]{1,0} dot(%mul.7873, %params_and_buffers__vllm_model_language_model_model_layers_41_self_attn_qkv_proj_weight__.335), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.7875 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.7874), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.7876 = bf16[16,4,1024]{2,1,0} slice(%reshape.7875), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.7880 = bf16[16,32,128]{2,1,0} reshape(%slice.7876), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.7881 = f32[16,32,128]{2,1,0} convert(%reshape.7880), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.7882 = f32[16,32,128]{2,1,0} power(%convert_element_type.7881, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7887 = f32[16,32]{1,0} reduce(%pow.7882, %constant.512), dimensions={2}, to_apply=%region_195.7886, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7888 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.7887), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7889 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.7888, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7890 = f32[16,32,1]{2,1,0} add(%div.7889, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7891 = f32[16,32,1]{2,1,0} rsqrt(%add.7890), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7892 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.7891), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7893 = f32[16,32]{1,0} reshape(%mul.7892), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7894 = f32[16,32,128]{2,1,0} broadcast(%mul.7893), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7895 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.7881, %mul.7894), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7896 = bf16[16,32,128]{2,1,0} convert(%mul.7895), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_41_self_attn_q_norm_weight__.334 = bf16[128]{0} parameter(333), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.41.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.7897 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_41_self_attn_q_norm_weight__.334), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7898 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.7897), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7899 = bf16[128]{0} reshape(%mul.7898), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7900 = bf16[16,32,128]{2,1,0} broadcast(%mul.7899), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7901 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.7896, %mul.7900), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7932 = bf16[16,32,64]{2,1,0} slice(%mul.7901), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.7923 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.7924 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.7925 = s32[16]{0} select(%lt.7923, %add.7924, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.7926 = s32[16,1]{1,0} reshape(%select_n.7925), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.7927 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.7926), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.7928 = bf16[16,64]{1,0} slice(%gather.7927), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7930 = bf16[16,1,64]{2,1,0} reshape(%slice.7928), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7934 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7930), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7935 = bf16[16,64]{1,0} reshape(%mul.7934), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7936 = bf16[16,32,64]{2,1,0} broadcast(%mul.7935), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7937 = bf16[16,32,64]{2,1,0} multiply(%slice.7932, %mul.7936), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7933 = bf16[16,32,64]{2,1,0} slice(%mul.7901), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.7929 = bf16[16,64]{1,0} slice(%gather.7927), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7931 = bf16[16,1,64]{2,1,0} reshape(%slice.7929), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7938 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7931), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7939 = bf16[16,64]{1,0} reshape(%mul.7938), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7940 = bf16[16,32,64]{2,1,0} broadcast(%mul.7939), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7941 = bf16[16,32,64]{2,1,0} multiply(%slice.7933, %mul.7940), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.7942 = bf16[16,32,64]{2,1,0} subtract(%mul.7937, %mul.7941), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.7943 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7930), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7944 = bf16[16,64]{1,0} reshape(%mul.7943), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7945 = bf16[16,32,64]{2,1,0} broadcast(%mul.7944), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7946 = bf16[16,32,64]{2,1,0} multiply(%slice.7933, %mul.7945), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7947 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7931), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7948 = bf16[16,64]{1,0} reshape(%mul.7947), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7949 = bf16[16,32,64]{2,1,0} broadcast(%mul.7948), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7950 = bf16[16,32,64]{2,1,0} multiply(%slice.7932, %mul.7949), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.7951 = bf16[16,32,64]{2,1,0} add(%mul.7946, %mul.7950), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.7952 = bf16[16,32,128]{2,1,0} concatenate(%sub.7942, %add.7951), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.7953 = bf16[16,4096]{1,0} reshape(%concatenate.7952), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.7877 = bf16[16,4,128]{2,1,0} slice(%reshape.7875), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.7902 = f32[16,4,128]{2,1,0} convert(%slice.7877), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.7903 = f32[16,4,128]{2,1,0} power(%convert_element_type.7902, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7908 = f32[16,4]{1,0} reduce(%pow.7903, %constant.512), dimensions={2}, to_apply=%region_196.7907, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7909 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.7908), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7910 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.7909, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7911 = f32[16,4,1]{2,1,0} add(%div.7910, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7912 = f32[16,4,1]{2,1,0} rsqrt(%add.7911), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7913 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.7912), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7914 = f32[16,4]{1,0} reshape(%mul.7913), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7915 = f32[16,4,128]{2,1,0} broadcast(%mul.7914), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7916 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.7902, %mul.7915), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7917 = bf16[16,4,128]{2,1,0} convert(%mul.7916), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_41_self_attn_k_norm_weight__.332 = bf16[128]{0} parameter(331), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.41.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.7918 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_41_self_attn_k_norm_weight__.332), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7919 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.7918), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7920 = bf16[128]{0} reshape(%mul.7919), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7921 = bf16[16,4,128]{2,1,0} broadcast(%mul.7920), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7922 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.7917, %mul.7921), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7956 = bf16[16,4,64]{2,1,0} slice(%mul.7922), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7954 = bf16[16,1,64]{2,1,0} reshape(%slice.7928), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7958 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7954), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7959 = bf16[16,64]{1,0} reshape(%mul.7958), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7960 = bf16[16,4,64]{2,1,0} broadcast(%mul.7959), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7961 = bf16[16,4,64]{2,1,0} multiply(%slice.7956, %mul.7960), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7957 = bf16[16,4,64]{2,1,0} slice(%mul.7922), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7955 = bf16[16,1,64]{2,1,0} reshape(%slice.7929), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7962 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7955), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7963 = bf16[16,64]{1,0} reshape(%mul.7962), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7964 = bf16[16,4,64]{2,1,0} broadcast(%mul.7963), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7965 = bf16[16,4,64]{2,1,0} multiply(%slice.7957, %mul.7964), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.7966 = bf16[16,4,64]{2,1,0} subtract(%mul.7961, %mul.7965), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.7967 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7954), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7968 = bf16[16,64]{1,0} reshape(%mul.7967), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7969 = bf16[16,4,64]{2,1,0} broadcast(%mul.7968), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7970 = bf16[16,4,64]{2,1,0} multiply(%slice.7957, %mul.7969), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7971 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.7955), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7972 = bf16[16,64]{1,0} reshape(%mul.7971), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7973 = bf16[16,4,64]{2,1,0} broadcast(%mul.7972), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7974 = bf16[16,4,64]{2,1,0} multiply(%slice.7956, %mul.7973), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.7975 = bf16[16,4,64]{2,1,0} add(%mul.7970, %mul.7974), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.7976 = bf16[16,4,128]{2,1,0} concatenate(%sub.7966, %add.7975), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.7977 = bf16[16,512]{1,0} reshape(%concatenate.7976), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.7878 = bf16[16,4,128]{2,1,0} slice(%reshape.7875), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.7879 = bf16[16,512]{1,0} reshape(%slice.7878), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.7978 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_41_.477, %reshape.7953, %reshape.7977, %reshape.7879, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.7979 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.7978), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_42_.478 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(477), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[42]"}
  %jit__jax_attn_func_.7980 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.7978), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_41_self_attn_o_proj_weight__.333 = bf16[2048,4096]{1,0} parameter(332), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.41.self_attn.o_proj.weight\']"}
  %dot_general.7981 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.7980, %params_and_buffers__vllm_model_language_model_model_layers_41_self_attn_o_proj_weight__.333), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.7982 = f32[16,2048]{1,0} convert(%dot_general.7981), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7853 = bf16[16,2048]{1,0} convert(%add.7852), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7983 = f32[16,2048]{1,0} convert(%convert_element_type.7853), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.7984 = f32[16,2048]{1,0} add(%convert_element_type.7982, %convert_element_type.7983), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.7986 = f32[16,2048]{1,0} power(%add.7984, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7991 = f32[16]{0} reduce(%pow.7986, %constant.512), dimensions={1}, to_apply=%region_197.7990, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7992 = f32[16,1]{1,0} reshape(%reduce_sum.7991), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7993 = f32[16,1]{1,0} divide(%broadcast_in_dim.7992, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7994 = f32[16,1]{1,0} add(%div.7993, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7995 = f32[16,1]{1,0} rsqrt(%add.7994), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7996 = f32[16,1]{1,0} broadcast(%rsqrt.7995), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7997 = f32[16]{0} reshape(%mul.7996), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7998 = f32[16,2048]{1,0} broadcast(%mul.7997), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7999 = f32[16,2048]{1,0} multiply(%add.7984, %mul.7998), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8000 = bf16[16,2048]{1,0} convert(%mul.7999), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_41_post_attention_layernorm_weight__.331 = bf16[2048]{0} parameter(330), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.41.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.8001 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_41_post_attention_layernorm_weight__.331), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8002 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.8001), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8003 = bf16[2048]{0} reshape(%mul.8002), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8004 = bf16[16,2048]{1,0} broadcast(%mul.8003), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8005 = bf16[16,2048]{1,0} multiply(%convert_element_type.8000, %mul.8004), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_41_mlp_experts_w13_weight__.328 = bf16[128,1536,2048]{2,1,0} parameter(327), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.41.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_41_mlp_experts_w2_weight__.329 = bf16[128,2048,768]{2,1,0} parameter(328), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.41.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_41_mlp_gate_weight__.330 = bf16[128,2048]{1,0} parameter(329), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.41.mlp.gate.weight\']"}
  %dot_general.8006 = bf16[16,128]{1,0} dot(%mul.8005, %params_and_buffers__vllm_model_language_model_model_layers_41_mlp_gate_weight__.330), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.8007 = bf16[16,2048]{1,0} call(%mul.8005, %params_and_buffers__vllm_model_language_model_model_layers_41_mlp_experts_w13_weight__.328, %params_and_buffers__vllm_model_language_model_model_layers_41_mlp_experts_w2_weight__.329, %dot_general.8006), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.8008 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.8007), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7985 = bf16[16,2048]{1,0} convert(%add.7984), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8009 = f32[16,2048]{1,0} convert(%convert_element_type.7985), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.8010 = f32[16,2048]{1,0} add(%convert_element_type.8008, %convert_element_type.8009), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.8012 = f32[16,2048]{1,0} power(%add.8010, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8017 = f32[16]{0} reduce(%pow.8012, %constant.512), dimensions={1}, to_apply=%region_198.8016, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8018 = f32[16,1]{1,0} reshape(%reduce_sum.8017), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8019 = f32[16,1]{1,0} divide(%broadcast_in_dim.8018, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8020 = f32[16,1]{1,0} add(%div.8019, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8021 = f32[16,1]{1,0} rsqrt(%add.8020), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8022 = f32[16,1]{1,0} broadcast(%rsqrt.8021), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8023 = f32[16]{0} reshape(%mul.8022), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8024 = f32[16,2048]{1,0} broadcast(%mul.8023), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8025 = f32[16,2048]{1,0} multiply(%add.8010, %mul.8024), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8026 = bf16[16,2048]{1,0} convert(%mul.8025), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_42_input_layernorm_weight__.336 = bf16[2048]{0} parameter(335), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.42.input_layernorm.weight\']"}
  %broadcast_in_dim.8027 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_42_input_layernorm_weight__.336), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8028 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.8027), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8029 = bf16[2048]{0} reshape(%mul.8028), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8030 = bf16[16,2048]{1,0} broadcast(%mul.8029), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8031 = bf16[16,2048]{1,0} multiply(%convert_element_type.8026, %mul.8030), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_42_self_attn_qkv_proj_weight__.344 = bf16[5120,2048]{1,0} parameter(343), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.42.self_attn.qkv_proj.weight\']"}
  %dot_general.8032 = bf16[16,5120]{1,0} dot(%mul.8031, %params_and_buffers__vllm_model_language_model_model_layers_42_self_attn_qkv_proj_weight__.344), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.8033 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.8032), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.8034 = bf16[16,4,1024]{2,1,0} slice(%reshape.8033), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.8038 = bf16[16,32,128]{2,1,0} reshape(%slice.8034), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.8039 = f32[16,32,128]{2,1,0} convert(%reshape.8038), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.8040 = f32[16,32,128]{2,1,0} power(%convert_element_type.8039, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8045 = f32[16,32]{1,0} reduce(%pow.8040, %constant.512), dimensions={2}, to_apply=%region_199.8044, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8046 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.8045), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8047 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.8046, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8048 = f32[16,32,1]{2,1,0} add(%div.8047, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8049 = f32[16,32,1]{2,1,0} rsqrt(%add.8048), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8050 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.8049), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8051 = f32[16,32]{1,0} reshape(%mul.8050), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8052 = f32[16,32,128]{2,1,0} broadcast(%mul.8051), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8053 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.8039, %mul.8052), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8054 = bf16[16,32,128]{2,1,0} convert(%mul.8053), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_42_self_attn_q_norm_weight__.343 = bf16[128]{0} parameter(342), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.42.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.8055 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_42_self_attn_q_norm_weight__.343), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8056 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.8055), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8057 = bf16[128]{0} reshape(%mul.8056), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8058 = bf16[16,32,128]{2,1,0} broadcast(%mul.8057), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8059 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.8054, %mul.8058), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8090 = bf16[16,32,64]{2,1,0} slice(%mul.8059), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.8081 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.8082 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.8083 = s32[16]{0} select(%lt.8081, %add.8082, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.8084 = s32[16,1]{1,0} reshape(%select_n.8083), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.8085 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.8084), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.8086 = bf16[16,64]{1,0} slice(%gather.8085), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8088 = bf16[16,1,64]{2,1,0} reshape(%slice.8086), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8092 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8088), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8093 = bf16[16,64]{1,0} reshape(%mul.8092), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8094 = bf16[16,32,64]{2,1,0} broadcast(%mul.8093), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8095 = bf16[16,32,64]{2,1,0} multiply(%slice.8090, %mul.8094), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8091 = bf16[16,32,64]{2,1,0} slice(%mul.8059), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.8087 = bf16[16,64]{1,0} slice(%gather.8085), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8089 = bf16[16,1,64]{2,1,0} reshape(%slice.8087), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8096 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8089), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8097 = bf16[16,64]{1,0} reshape(%mul.8096), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8098 = bf16[16,32,64]{2,1,0} broadcast(%mul.8097), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8099 = bf16[16,32,64]{2,1,0} multiply(%slice.8091, %mul.8098), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.8100 = bf16[16,32,64]{2,1,0} subtract(%mul.8095, %mul.8099), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.8101 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8088), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8102 = bf16[16,64]{1,0} reshape(%mul.8101), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8103 = bf16[16,32,64]{2,1,0} broadcast(%mul.8102), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8104 = bf16[16,32,64]{2,1,0} multiply(%slice.8091, %mul.8103), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8105 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8089), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8106 = bf16[16,64]{1,0} reshape(%mul.8105), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8107 = bf16[16,32,64]{2,1,0} broadcast(%mul.8106), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8108 = bf16[16,32,64]{2,1,0} multiply(%slice.8090, %mul.8107), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.8109 = bf16[16,32,64]{2,1,0} add(%mul.8104, %mul.8108), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.8110 = bf16[16,32,128]{2,1,0} concatenate(%sub.8100, %add.8109), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.8111 = bf16[16,4096]{1,0} reshape(%concatenate.8110), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.8035 = bf16[16,4,128]{2,1,0} slice(%reshape.8033), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.8060 = f32[16,4,128]{2,1,0} convert(%slice.8035), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.8061 = f32[16,4,128]{2,1,0} power(%convert_element_type.8060, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8066 = f32[16,4]{1,0} reduce(%pow.8061, %constant.512), dimensions={2}, to_apply=%region_200.8065, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8067 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.8066), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8068 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.8067, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8069 = f32[16,4,1]{2,1,0} add(%div.8068, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8070 = f32[16,4,1]{2,1,0} rsqrt(%add.8069), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8071 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.8070), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8072 = f32[16,4]{1,0} reshape(%mul.8071), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8073 = f32[16,4,128]{2,1,0} broadcast(%mul.8072), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8074 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.8060, %mul.8073), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8075 = bf16[16,4,128]{2,1,0} convert(%mul.8074), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_42_self_attn_k_norm_weight__.341 = bf16[128]{0} parameter(340), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.42.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.8076 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_42_self_attn_k_norm_weight__.341), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8077 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.8076), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8078 = bf16[128]{0} reshape(%mul.8077), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8079 = bf16[16,4,128]{2,1,0} broadcast(%mul.8078), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8080 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.8075, %mul.8079), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8114 = bf16[16,4,64]{2,1,0} slice(%mul.8080), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8112 = bf16[16,1,64]{2,1,0} reshape(%slice.8086), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8116 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8112), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8117 = bf16[16,64]{1,0} reshape(%mul.8116), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8118 = bf16[16,4,64]{2,1,0} broadcast(%mul.8117), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8119 = bf16[16,4,64]{2,1,0} multiply(%slice.8114, %mul.8118), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8115 = bf16[16,4,64]{2,1,0} slice(%mul.8080), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8113 = bf16[16,1,64]{2,1,0} reshape(%slice.8087), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8120 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8113), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8121 = bf16[16,64]{1,0} reshape(%mul.8120), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8122 = bf16[16,4,64]{2,1,0} broadcast(%mul.8121), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8123 = bf16[16,4,64]{2,1,0} multiply(%slice.8115, %mul.8122), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.8124 = bf16[16,4,64]{2,1,0} subtract(%mul.8119, %mul.8123), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.8125 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8112), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8126 = bf16[16,64]{1,0} reshape(%mul.8125), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8127 = bf16[16,4,64]{2,1,0} broadcast(%mul.8126), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8128 = bf16[16,4,64]{2,1,0} multiply(%slice.8115, %mul.8127), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8129 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8113), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8130 = bf16[16,64]{1,0} reshape(%mul.8129), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8131 = bf16[16,4,64]{2,1,0} broadcast(%mul.8130), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8132 = bf16[16,4,64]{2,1,0} multiply(%slice.8114, %mul.8131), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.8133 = bf16[16,4,64]{2,1,0} add(%mul.8128, %mul.8132), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.8134 = bf16[16,4,128]{2,1,0} concatenate(%sub.8124, %add.8133), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.8135 = bf16[16,512]{1,0} reshape(%concatenate.8134), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.8036 = bf16[16,4,128]{2,1,0} slice(%reshape.8033), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.8037 = bf16[16,512]{1,0} reshape(%slice.8036), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.8136 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_42_.478, %reshape.8111, %reshape.8135, %reshape.8037, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.8137 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.8136), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_43_.479 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(478), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[43]"}
  %jit__jax_attn_func_.8138 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.8136), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_42_self_attn_o_proj_weight__.342 = bf16[2048,4096]{1,0} parameter(341), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.42.self_attn.o_proj.weight\']"}
  %dot_general.8139 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.8138, %params_and_buffers__vllm_model_language_model_model_layers_42_self_attn_o_proj_weight__.342), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.8140 = f32[16,2048]{1,0} convert(%dot_general.8139), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8011 = bf16[16,2048]{1,0} convert(%add.8010), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8141 = f32[16,2048]{1,0} convert(%convert_element_type.8011), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.8142 = f32[16,2048]{1,0} add(%convert_element_type.8140, %convert_element_type.8141), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.8144 = f32[16,2048]{1,0} power(%add.8142, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8149 = f32[16]{0} reduce(%pow.8144, %constant.512), dimensions={1}, to_apply=%region_201.8148, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8150 = f32[16,1]{1,0} reshape(%reduce_sum.8149), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8151 = f32[16,1]{1,0} divide(%broadcast_in_dim.8150, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8152 = f32[16,1]{1,0} add(%div.8151, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8153 = f32[16,1]{1,0} rsqrt(%add.8152), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8154 = f32[16,1]{1,0} broadcast(%rsqrt.8153), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8155 = f32[16]{0} reshape(%mul.8154), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8156 = f32[16,2048]{1,0} broadcast(%mul.8155), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8157 = f32[16,2048]{1,0} multiply(%add.8142, %mul.8156), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8158 = bf16[16,2048]{1,0} convert(%mul.8157), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_42_post_attention_layernorm_weight__.340 = bf16[2048]{0} parameter(339), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.42.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.8159 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_42_post_attention_layernorm_weight__.340), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8160 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.8159), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8161 = bf16[2048]{0} reshape(%mul.8160), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8162 = bf16[16,2048]{1,0} broadcast(%mul.8161), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8163 = bf16[16,2048]{1,0} multiply(%convert_element_type.8158, %mul.8162), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_42_mlp_experts_w13_weight__.337 = bf16[128,1536,2048]{2,1,0} parameter(336), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.42.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_42_mlp_experts_w2_weight__.338 = bf16[128,2048,768]{2,1,0} parameter(337), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.42.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_42_mlp_gate_weight__.339 = bf16[128,2048]{1,0} parameter(338), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.42.mlp.gate.weight\']"}
  %dot_general.8164 = bf16[16,128]{1,0} dot(%mul.8163, %params_and_buffers__vllm_model_language_model_model_layers_42_mlp_gate_weight__.339), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.8165 = bf16[16,2048]{1,0} call(%mul.8163, %params_and_buffers__vllm_model_language_model_model_layers_42_mlp_experts_w13_weight__.337, %params_and_buffers__vllm_model_language_model_model_layers_42_mlp_experts_w2_weight__.338, %dot_general.8164), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.8166 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.8165), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8143 = bf16[16,2048]{1,0} convert(%add.8142), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8167 = f32[16,2048]{1,0} convert(%convert_element_type.8143), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.8168 = f32[16,2048]{1,0} add(%convert_element_type.8166, %convert_element_type.8167), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.8170 = f32[16,2048]{1,0} power(%add.8168, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8175 = f32[16]{0} reduce(%pow.8170, %constant.512), dimensions={1}, to_apply=%region_202.8174, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8176 = f32[16,1]{1,0} reshape(%reduce_sum.8175), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8177 = f32[16,1]{1,0} divide(%broadcast_in_dim.8176, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8178 = f32[16,1]{1,0} add(%div.8177, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8179 = f32[16,1]{1,0} rsqrt(%add.8178), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8180 = f32[16,1]{1,0} broadcast(%rsqrt.8179), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8181 = f32[16]{0} reshape(%mul.8180), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8182 = f32[16,2048]{1,0} broadcast(%mul.8181), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8183 = f32[16,2048]{1,0} multiply(%add.8168, %mul.8182), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8184 = bf16[16,2048]{1,0} convert(%mul.8183), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_43_input_layernorm_weight__.345 = bf16[2048]{0} parameter(344), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.43.input_layernorm.weight\']"}
  %broadcast_in_dim.8185 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_43_input_layernorm_weight__.345), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8186 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.8185), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8187 = bf16[2048]{0} reshape(%mul.8186), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8188 = bf16[16,2048]{1,0} broadcast(%mul.8187), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8189 = bf16[16,2048]{1,0} multiply(%convert_element_type.8184, %mul.8188), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_43_self_attn_qkv_proj_weight__.353 = bf16[5120,2048]{1,0} parameter(352), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.43.self_attn.qkv_proj.weight\']"}
  %dot_general.8190 = bf16[16,5120]{1,0} dot(%mul.8189, %params_and_buffers__vllm_model_language_model_model_layers_43_self_attn_qkv_proj_weight__.353), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.8191 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.8190), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.8192 = bf16[16,4,1024]{2,1,0} slice(%reshape.8191), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.8196 = bf16[16,32,128]{2,1,0} reshape(%slice.8192), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.8197 = f32[16,32,128]{2,1,0} convert(%reshape.8196), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.8198 = f32[16,32,128]{2,1,0} power(%convert_element_type.8197, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8203 = f32[16,32]{1,0} reduce(%pow.8198, %constant.512), dimensions={2}, to_apply=%region_203.8202, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8204 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.8203), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8205 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.8204, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8206 = f32[16,32,1]{2,1,0} add(%div.8205, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8207 = f32[16,32,1]{2,1,0} rsqrt(%add.8206), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8208 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.8207), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8209 = f32[16,32]{1,0} reshape(%mul.8208), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8210 = f32[16,32,128]{2,1,0} broadcast(%mul.8209), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8211 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.8197, %mul.8210), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8212 = bf16[16,32,128]{2,1,0} convert(%mul.8211), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_43_self_attn_q_norm_weight__.352 = bf16[128]{0} parameter(351), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.43.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.8213 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_43_self_attn_q_norm_weight__.352), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8214 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.8213), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8215 = bf16[128]{0} reshape(%mul.8214), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8216 = bf16[16,32,128]{2,1,0} broadcast(%mul.8215), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8217 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.8212, %mul.8216), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8248 = bf16[16,32,64]{2,1,0} slice(%mul.8217), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.8239 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.8240 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.8241 = s32[16]{0} select(%lt.8239, %add.8240, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.8242 = s32[16,1]{1,0} reshape(%select_n.8241), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.8243 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.8242), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.8244 = bf16[16,64]{1,0} slice(%gather.8243), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8246 = bf16[16,1,64]{2,1,0} reshape(%slice.8244), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8250 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8246), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8251 = bf16[16,64]{1,0} reshape(%mul.8250), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8252 = bf16[16,32,64]{2,1,0} broadcast(%mul.8251), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8253 = bf16[16,32,64]{2,1,0} multiply(%slice.8248, %mul.8252), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8249 = bf16[16,32,64]{2,1,0} slice(%mul.8217), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.8245 = bf16[16,64]{1,0} slice(%gather.8243), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8247 = bf16[16,1,64]{2,1,0} reshape(%slice.8245), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8254 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8247), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8255 = bf16[16,64]{1,0} reshape(%mul.8254), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8256 = bf16[16,32,64]{2,1,0} broadcast(%mul.8255), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8257 = bf16[16,32,64]{2,1,0} multiply(%slice.8249, %mul.8256), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.8258 = bf16[16,32,64]{2,1,0} subtract(%mul.8253, %mul.8257), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.8259 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8246), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8260 = bf16[16,64]{1,0} reshape(%mul.8259), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8261 = bf16[16,32,64]{2,1,0} broadcast(%mul.8260), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8262 = bf16[16,32,64]{2,1,0} multiply(%slice.8249, %mul.8261), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8263 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8247), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8264 = bf16[16,64]{1,0} reshape(%mul.8263), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8265 = bf16[16,32,64]{2,1,0} broadcast(%mul.8264), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8266 = bf16[16,32,64]{2,1,0} multiply(%slice.8248, %mul.8265), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.8267 = bf16[16,32,64]{2,1,0} add(%mul.8262, %mul.8266), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.8268 = bf16[16,32,128]{2,1,0} concatenate(%sub.8258, %add.8267), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.8269 = bf16[16,4096]{1,0} reshape(%concatenate.8268), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.8193 = bf16[16,4,128]{2,1,0} slice(%reshape.8191), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.8218 = f32[16,4,128]{2,1,0} convert(%slice.8193), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.8219 = f32[16,4,128]{2,1,0} power(%convert_element_type.8218, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8224 = f32[16,4]{1,0} reduce(%pow.8219, %constant.512), dimensions={2}, to_apply=%region_204.8223, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8225 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.8224), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8226 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.8225, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8227 = f32[16,4,1]{2,1,0} add(%div.8226, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8228 = f32[16,4,1]{2,1,0} rsqrt(%add.8227), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8229 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.8228), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8230 = f32[16,4]{1,0} reshape(%mul.8229), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8231 = f32[16,4,128]{2,1,0} broadcast(%mul.8230), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8232 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.8218, %mul.8231), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8233 = bf16[16,4,128]{2,1,0} convert(%mul.8232), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_43_self_attn_k_norm_weight__.350 = bf16[128]{0} parameter(349), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.43.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.8234 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_43_self_attn_k_norm_weight__.350), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8235 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.8234), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8236 = bf16[128]{0} reshape(%mul.8235), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8237 = bf16[16,4,128]{2,1,0} broadcast(%mul.8236), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8238 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.8233, %mul.8237), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8272 = bf16[16,4,64]{2,1,0} slice(%mul.8238), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8270 = bf16[16,1,64]{2,1,0} reshape(%slice.8244), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8274 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8270), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8275 = bf16[16,64]{1,0} reshape(%mul.8274), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8276 = bf16[16,4,64]{2,1,0} broadcast(%mul.8275), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8277 = bf16[16,4,64]{2,1,0} multiply(%slice.8272, %mul.8276), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8273 = bf16[16,4,64]{2,1,0} slice(%mul.8238), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8271 = bf16[16,1,64]{2,1,0} reshape(%slice.8245), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8278 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8271), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8279 = bf16[16,64]{1,0} reshape(%mul.8278), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8280 = bf16[16,4,64]{2,1,0} broadcast(%mul.8279), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8281 = bf16[16,4,64]{2,1,0} multiply(%slice.8273, %mul.8280), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.8282 = bf16[16,4,64]{2,1,0} subtract(%mul.8277, %mul.8281), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.8283 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8270), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8284 = bf16[16,64]{1,0} reshape(%mul.8283), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8285 = bf16[16,4,64]{2,1,0} broadcast(%mul.8284), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8286 = bf16[16,4,64]{2,1,0} multiply(%slice.8273, %mul.8285), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8287 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8271), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8288 = bf16[16,64]{1,0} reshape(%mul.8287), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8289 = bf16[16,4,64]{2,1,0} broadcast(%mul.8288), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8290 = bf16[16,4,64]{2,1,0} multiply(%slice.8272, %mul.8289), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.8291 = bf16[16,4,64]{2,1,0} add(%mul.8286, %mul.8290), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.8292 = bf16[16,4,128]{2,1,0} concatenate(%sub.8282, %add.8291), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.8293 = bf16[16,512]{1,0} reshape(%concatenate.8292), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.8194 = bf16[16,4,128]{2,1,0} slice(%reshape.8191), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.8195 = bf16[16,512]{1,0} reshape(%slice.8194), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.8294 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_43_.479, %reshape.8269, %reshape.8293, %reshape.8195, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.8295 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.8294), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_44_.480 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(479), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[44]"}
  %jit__jax_attn_func_.8296 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.8294), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_43_self_attn_o_proj_weight__.351 = bf16[2048,4096]{1,0} parameter(350), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.43.self_attn.o_proj.weight\']"}
  %dot_general.8297 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.8296, %params_and_buffers__vllm_model_language_model_model_layers_43_self_attn_o_proj_weight__.351), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.8298 = f32[16,2048]{1,0} convert(%dot_general.8297), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8169 = bf16[16,2048]{1,0} convert(%add.8168), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8299 = f32[16,2048]{1,0} convert(%convert_element_type.8169), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.8300 = f32[16,2048]{1,0} add(%convert_element_type.8298, %convert_element_type.8299), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.8302 = f32[16,2048]{1,0} power(%add.8300, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8307 = f32[16]{0} reduce(%pow.8302, %constant.512), dimensions={1}, to_apply=%region_205.8306, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8308 = f32[16,1]{1,0} reshape(%reduce_sum.8307), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8309 = f32[16,1]{1,0} divide(%broadcast_in_dim.8308, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8310 = f32[16,1]{1,0} add(%div.8309, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8311 = f32[16,1]{1,0} rsqrt(%add.8310), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8312 = f32[16,1]{1,0} broadcast(%rsqrt.8311), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8313 = f32[16]{0} reshape(%mul.8312), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8314 = f32[16,2048]{1,0} broadcast(%mul.8313), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8315 = f32[16,2048]{1,0} multiply(%add.8300, %mul.8314), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8316 = bf16[16,2048]{1,0} convert(%mul.8315), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_43_post_attention_layernorm_weight__.349 = bf16[2048]{0} parameter(348), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.43.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.8317 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_43_post_attention_layernorm_weight__.349), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8318 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.8317), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8319 = bf16[2048]{0} reshape(%mul.8318), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8320 = bf16[16,2048]{1,0} broadcast(%mul.8319), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8321 = bf16[16,2048]{1,0} multiply(%convert_element_type.8316, %mul.8320), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_43_mlp_experts_w13_weight__.346 = bf16[128,1536,2048]{2,1,0} parameter(345), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.43.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_43_mlp_experts_w2_weight__.347 = bf16[128,2048,768]{2,1,0} parameter(346), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.43.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_43_mlp_gate_weight__.348 = bf16[128,2048]{1,0} parameter(347), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.43.mlp.gate.weight\']"}
  %dot_general.8322 = bf16[16,128]{1,0} dot(%mul.8321, %params_and_buffers__vllm_model_language_model_model_layers_43_mlp_gate_weight__.348), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.8323 = bf16[16,2048]{1,0} call(%mul.8321, %params_and_buffers__vllm_model_language_model_model_layers_43_mlp_experts_w13_weight__.346, %params_and_buffers__vllm_model_language_model_model_layers_43_mlp_experts_w2_weight__.347, %dot_general.8322), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.8324 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.8323), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8301 = bf16[16,2048]{1,0} convert(%add.8300), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8325 = f32[16,2048]{1,0} convert(%convert_element_type.8301), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.8326 = f32[16,2048]{1,0} add(%convert_element_type.8324, %convert_element_type.8325), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.8328 = f32[16,2048]{1,0} power(%add.8326, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8333 = f32[16]{0} reduce(%pow.8328, %constant.512), dimensions={1}, to_apply=%region_206.8332, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8334 = f32[16,1]{1,0} reshape(%reduce_sum.8333), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8335 = f32[16,1]{1,0} divide(%broadcast_in_dim.8334, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8336 = f32[16,1]{1,0} add(%div.8335, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8337 = f32[16,1]{1,0} rsqrt(%add.8336), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8338 = f32[16,1]{1,0} broadcast(%rsqrt.8337), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8339 = f32[16]{0} reshape(%mul.8338), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8340 = f32[16,2048]{1,0} broadcast(%mul.8339), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8341 = f32[16,2048]{1,0} multiply(%add.8326, %mul.8340), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8342 = bf16[16,2048]{1,0} convert(%mul.8341), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_44_input_layernorm_weight__.354 = bf16[2048]{0} parameter(353), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.44.input_layernorm.weight\']"}
  %broadcast_in_dim.8343 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_44_input_layernorm_weight__.354), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8344 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.8343), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8345 = bf16[2048]{0} reshape(%mul.8344), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8346 = bf16[16,2048]{1,0} broadcast(%mul.8345), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8347 = bf16[16,2048]{1,0} multiply(%convert_element_type.8342, %mul.8346), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_44_self_attn_qkv_proj_weight__.362 = bf16[5120,2048]{1,0} parameter(361), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.44.self_attn.qkv_proj.weight\']"}
  %dot_general.8348 = bf16[16,5120]{1,0} dot(%mul.8347, %params_and_buffers__vllm_model_language_model_model_layers_44_self_attn_qkv_proj_weight__.362), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.8349 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.8348), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.8350 = bf16[16,4,1024]{2,1,0} slice(%reshape.8349), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.8354 = bf16[16,32,128]{2,1,0} reshape(%slice.8350), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.8355 = f32[16,32,128]{2,1,0} convert(%reshape.8354), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.8356 = f32[16,32,128]{2,1,0} power(%convert_element_type.8355, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8361 = f32[16,32]{1,0} reduce(%pow.8356, %constant.512), dimensions={2}, to_apply=%region_207.8360, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8362 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.8361), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8363 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.8362, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8364 = f32[16,32,1]{2,1,0} add(%div.8363, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8365 = f32[16,32,1]{2,1,0} rsqrt(%add.8364), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8366 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.8365), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8367 = f32[16,32]{1,0} reshape(%mul.8366), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8368 = f32[16,32,128]{2,1,0} broadcast(%mul.8367), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8369 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.8355, %mul.8368), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8370 = bf16[16,32,128]{2,1,0} convert(%mul.8369), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_44_self_attn_q_norm_weight__.361 = bf16[128]{0} parameter(360), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.44.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.8371 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_44_self_attn_q_norm_weight__.361), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8372 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.8371), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8373 = bf16[128]{0} reshape(%mul.8372), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8374 = bf16[16,32,128]{2,1,0} broadcast(%mul.8373), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8375 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.8370, %mul.8374), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8406 = bf16[16,32,64]{2,1,0} slice(%mul.8375), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.8397 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.8398 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.8399 = s32[16]{0} select(%lt.8397, %add.8398, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.8400 = s32[16,1]{1,0} reshape(%select_n.8399), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.8401 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.8400), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.8402 = bf16[16,64]{1,0} slice(%gather.8401), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8404 = bf16[16,1,64]{2,1,0} reshape(%slice.8402), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8408 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8404), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8409 = bf16[16,64]{1,0} reshape(%mul.8408), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8410 = bf16[16,32,64]{2,1,0} broadcast(%mul.8409), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8411 = bf16[16,32,64]{2,1,0} multiply(%slice.8406, %mul.8410), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8407 = bf16[16,32,64]{2,1,0} slice(%mul.8375), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.8403 = bf16[16,64]{1,0} slice(%gather.8401), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8405 = bf16[16,1,64]{2,1,0} reshape(%slice.8403), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8412 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8405), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8413 = bf16[16,64]{1,0} reshape(%mul.8412), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8414 = bf16[16,32,64]{2,1,0} broadcast(%mul.8413), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8415 = bf16[16,32,64]{2,1,0} multiply(%slice.8407, %mul.8414), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.8416 = bf16[16,32,64]{2,1,0} subtract(%mul.8411, %mul.8415), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.8417 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8404), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8418 = bf16[16,64]{1,0} reshape(%mul.8417), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8419 = bf16[16,32,64]{2,1,0} broadcast(%mul.8418), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8420 = bf16[16,32,64]{2,1,0} multiply(%slice.8407, %mul.8419), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8421 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8405), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8422 = bf16[16,64]{1,0} reshape(%mul.8421), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8423 = bf16[16,32,64]{2,1,0} broadcast(%mul.8422), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8424 = bf16[16,32,64]{2,1,0} multiply(%slice.8406, %mul.8423), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.8425 = bf16[16,32,64]{2,1,0} add(%mul.8420, %mul.8424), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.8426 = bf16[16,32,128]{2,1,0} concatenate(%sub.8416, %add.8425), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.8427 = bf16[16,4096]{1,0} reshape(%concatenate.8426), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.8351 = bf16[16,4,128]{2,1,0} slice(%reshape.8349), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.8376 = f32[16,4,128]{2,1,0} convert(%slice.8351), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.8377 = f32[16,4,128]{2,1,0} power(%convert_element_type.8376, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8382 = f32[16,4]{1,0} reduce(%pow.8377, %constant.512), dimensions={2}, to_apply=%region_208.8381, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8383 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.8382), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8384 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.8383, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8385 = f32[16,4,1]{2,1,0} add(%div.8384, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8386 = f32[16,4,1]{2,1,0} rsqrt(%add.8385), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8387 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.8386), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8388 = f32[16,4]{1,0} reshape(%mul.8387), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8389 = f32[16,4,128]{2,1,0} broadcast(%mul.8388), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8390 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.8376, %mul.8389), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8391 = bf16[16,4,128]{2,1,0} convert(%mul.8390), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_44_self_attn_k_norm_weight__.359 = bf16[128]{0} parameter(358), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.44.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.8392 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_44_self_attn_k_norm_weight__.359), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8393 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.8392), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8394 = bf16[128]{0} reshape(%mul.8393), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8395 = bf16[16,4,128]{2,1,0} broadcast(%mul.8394), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8396 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.8391, %mul.8395), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8430 = bf16[16,4,64]{2,1,0} slice(%mul.8396), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8428 = bf16[16,1,64]{2,1,0} reshape(%slice.8402), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8432 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8428), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8433 = bf16[16,64]{1,0} reshape(%mul.8432), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8434 = bf16[16,4,64]{2,1,0} broadcast(%mul.8433), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8435 = bf16[16,4,64]{2,1,0} multiply(%slice.8430, %mul.8434), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8431 = bf16[16,4,64]{2,1,0} slice(%mul.8396), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8429 = bf16[16,1,64]{2,1,0} reshape(%slice.8403), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8436 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8429), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8437 = bf16[16,64]{1,0} reshape(%mul.8436), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8438 = bf16[16,4,64]{2,1,0} broadcast(%mul.8437), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8439 = bf16[16,4,64]{2,1,0} multiply(%slice.8431, %mul.8438), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.8440 = bf16[16,4,64]{2,1,0} subtract(%mul.8435, %mul.8439), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.8441 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8428), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8442 = bf16[16,64]{1,0} reshape(%mul.8441), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8443 = bf16[16,4,64]{2,1,0} broadcast(%mul.8442), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8444 = bf16[16,4,64]{2,1,0} multiply(%slice.8431, %mul.8443), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8445 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8429), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8446 = bf16[16,64]{1,0} reshape(%mul.8445), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8447 = bf16[16,4,64]{2,1,0} broadcast(%mul.8446), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8448 = bf16[16,4,64]{2,1,0} multiply(%slice.8430, %mul.8447), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.8449 = bf16[16,4,64]{2,1,0} add(%mul.8444, %mul.8448), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.8450 = bf16[16,4,128]{2,1,0} concatenate(%sub.8440, %add.8449), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.8451 = bf16[16,512]{1,0} reshape(%concatenate.8450), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.8352 = bf16[16,4,128]{2,1,0} slice(%reshape.8349), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.8353 = bf16[16,512]{1,0} reshape(%slice.8352), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.8452 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_44_.480, %reshape.8427, %reshape.8451, %reshape.8353, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.8453 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.8452), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_45_.481 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(480), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[45]"}
  %jit__jax_attn_func_.8454 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.8452), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_44_self_attn_o_proj_weight__.360 = bf16[2048,4096]{1,0} parameter(359), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.44.self_attn.o_proj.weight\']"}
  %dot_general.8455 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.8454, %params_and_buffers__vllm_model_language_model_model_layers_44_self_attn_o_proj_weight__.360), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.8456 = f32[16,2048]{1,0} convert(%dot_general.8455), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8327 = bf16[16,2048]{1,0} convert(%add.8326), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8457 = f32[16,2048]{1,0} convert(%convert_element_type.8327), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.8458 = f32[16,2048]{1,0} add(%convert_element_type.8456, %convert_element_type.8457), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.8460 = f32[16,2048]{1,0} power(%add.8458, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8465 = f32[16]{0} reduce(%pow.8460, %constant.512), dimensions={1}, to_apply=%region_209.8464, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8466 = f32[16,1]{1,0} reshape(%reduce_sum.8465), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8467 = f32[16,1]{1,0} divide(%broadcast_in_dim.8466, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8468 = f32[16,1]{1,0} add(%div.8467, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8469 = f32[16,1]{1,0} rsqrt(%add.8468), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8470 = f32[16,1]{1,0} broadcast(%rsqrt.8469), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8471 = f32[16]{0} reshape(%mul.8470), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8472 = f32[16,2048]{1,0} broadcast(%mul.8471), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8473 = f32[16,2048]{1,0} multiply(%add.8458, %mul.8472), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8474 = bf16[16,2048]{1,0} convert(%mul.8473), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_44_post_attention_layernorm_weight__.358 = bf16[2048]{0} parameter(357), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.44.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.8475 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_44_post_attention_layernorm_weight__.358), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8476 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.8475), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8477 = bf16[2048]{0} reshape(%mul.8476), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8478 = bf16[16,2048]{1,0} broadcast(%mul.8477), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8479 = bf16[16,2048]{1,0} multiply(%convert_element_type.8474, %mul.8478), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_44_mlp_experts_w13_weight__.355 = bf16[128,1536,2048]{2,1,0} parameter(354), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.44.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_44_mlp_experts_w2_weight__.356 = bf16[128,2048,768]{2,1,0} parameter(355), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.44.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_44_mlp_gate_weight__.357 = bf16[128,2048]{1,0} parameter(356), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.44.mlp.gate.weight\']"}
  %dot_general.8480 = bf16[16,128]{1,0} dot(%mul.8479, %params_and_buffers__vllm_model_language_model_model_layers_44_mlp_gate_weight__.357), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.8481 = bf16[16,2048]{1,0} call(%mul.8479, %params_and_buffers__vllm_model_language_model_model_layers_44_mlp_experts_w13_weight__.355, %params_and_buffers__vllm_model_language_model_model_layers_44_mlp_experts_w2_weight__.356, %dot_general.8480), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.8482 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.8481), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8459 = bf16[16,2048]{1,0} convert(%add.8458), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8483 = f32[16,2048]{1,0} convert(%convert_element_type.8459), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.8484 = f32[16,2048]{1,0} add(%convert_element_type.8482, %convert_element_type.8483), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.8486 = f32[16,2048]{1,0} power(%add.8484, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8491 = f32[16]{0} reduce(%pow.8486, %constant.512), dimensions={1}, to_apply=%region_210.8490, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8492 = f32[16,1]{1,0} reshape(%reduce_sum.8491), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8493 = f32[16,1]{1,0} divide(%broadcast_in_dim.8492, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8494 = f32[16,1]{1,0} add(%div.8493, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8495 = f32[16,1]{1,0} rsqrt(%add.8494), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8496 = f32[16,1]{1,0} broadcast(%rsqrt.8495), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8497 = f32[16]{0} reshape(%mul.8496), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8498 = f32[16,2048]{1,0} broadcast(%mul.8497), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8499 = f32[16,2048]{1,0} multiply(%add.8484, %mul.8498), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8500 = bf16[16,2048]{1,0} convert(%mul.8499), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_45_input_layernorm_weight__.363 = bf16[2048]{0} parameter(362), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.45.input_layernorm.weight\']"}
  %broadcast_in_dim.8501 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_45_input_layernorm_weight__.363), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8502 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.8501), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8503 = bf16[2048]{0} reshape(%mul.8502), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8504 = bf16[16,2048]{1,0} broadcast(%mul.8503), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8505 = bf16[16,2048]{1,0} multiply(%convert_element_type.8500, %mul.8504), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_45_self_attn_qkv_proj_weight__.371 = bf16[5120,2048]{1,0} parameter(370), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.45.self_attn.qkv_proj.weight\']"}
  %dot_general.8506 = bf16[16,5120]{1,0} dot(%mul.8505, %params_and_buffers__vllm_model_language_model_model_layers_45_self_attn_qkv_proj_weight__.371), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.8507 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.8506), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.8508 = bf16[16,4,1024]{2,1,0} slice(%reshape.8507), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.8512 = bf16[16,32,128]{2,1,0} reshape(%slice.8508), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.8513 = f32[16,32,128]{2,1,0} convert(%reshape.8512), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.8514 = f32[16,32,128]{2,1,0} power(%convert_element_type.8513, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8519 = f32[16,32]{1,0} reduce(%pow.8514, %constant.512), dimensions={2}, to_apply=%region_211.8518, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8520 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.8519), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8521 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.8520, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8522 = f32[16,32,1]{2,1,0} add(%div.8521, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8523 = f32[16,32,1]{2,1,0} rsqrt(%add.8522), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8524 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.8523), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8525 = f32[16,32]{1,0} reshape(%mul.8524), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8526 = f32[16,32,128]{2,1,0} broadcast(%mul.8525), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8527 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.8513, %mul.8526), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8528 = bf16[16,32,128]{2,1,0} convert(%mul.8527), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_45_self_attn_q_norm_weight__.370 = bf16[128]{0} parameter(369), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.45.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.8529 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_45_self_attn_q_norm_weight__.370), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8530 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.8529), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8531 = bf16[128]{0} reshape(%mul.8530), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8532 = bf16[16,32,128]{2,1,0} broadcast(%mul.8531), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8533 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.8528, %mul.8532), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8564 = bf16[16,32,64]{2,1,0} slice(%mul.8533), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.8555 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.8556 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.8557 = s32[16]{0} select(%lt.8555, %add.8556, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.8558 = s32[16,1]{1,0} reshape(%select_n.8557), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.8559 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.8558), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.8560 = bf16[16,64]{1,0} slice(%gather.8559), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8562 = bf16[16,1,64]{2,1,0} reshape(%slice.8560), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8566 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8562), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8567 = bf16[16,64]{1,0} reshape(%mul.8566), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8568 = bf16[16,32,64]{2,1,0} broadcast(%mul.8567), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8569 = bf16[16,32,64]{2,1,0} multiply(%slice.8564, %mul.8568), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8565 = bf16[16,32,64]{2,1,0} slice(%mul.8533), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.8561 = bf16[16,64]{1,0} slice(%gather.8559), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8563 = bf16[16,1,64]{2,1,0} reshape(%slice.8561), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8570 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8563), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8571 = bf16[16,64]{1,0} reshape(%mul.8570), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8572 = bf16[16,32,64]{2,1,0} broadcast(%mul.8571), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8573 = bf16[16,32,64]{2,1,0} multiply(%slice.8565, %mul.8572), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.8574 = bf16[16,32,64]{2,1,0} subtract(%mul.8569, %mul.8573), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.8575 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8562), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8576 = bf16[16,64]{1,0} reshape(%mul.8575), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8577 = bf16[16,32,64]{2,1,0} broadcast(%mul.8576), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8578 = bf16[16,32,64]{2,1,0} multiply(%slice.8565, %mul.8577), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8579 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8563), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8580 = bf16[16,64]{1,0} reshape(%mul.8579), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8581 = bf16[16,32,64]{2,1,0} broadcast(%mul.8580), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8582 = bf16[16,32,64]{2,1,0} multiply(%slice.8564, %mul.8581), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.8583 = bf16[16,32,64]{2,1,0} add(%mul.8578, %mul.8582), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.8584 = bf16[16,32,128]{2,1,0} concatenate(%sub.8574, %add.8583), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.8585 = bf16[16,4096]{1,0} reshape(%concatenate.8584), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.8509 = bf16[16,4,128]{2,1,0} slice(%reshape.8507), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.8534 = f32[16,4,128]{2,1,0} convert(%slice.8509), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.8535 = f32[16,4,128]{2,1,0} power(%convert_element_type.8534, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8540 = f32[16,4]{1,0} reduce(%pow.8535, %constant.512), dimensions={2}, to_apply=%region_212.8539, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8541 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.8540), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8542 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.8541, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8543 = f32[16,4,1]{2,1,0} add(%div.8542, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8544 = f32[16,4,1]{2,1,0} rsqrt(%add.8543), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8545 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.8544), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8546 = f32[16,4]{1,0} reshape(%mul.8545), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8547 = f32[16,4,128]{2,1,0} broadcast(%mul.8546), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8548 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.8534, %mul.8547), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8549 = bf16[16,4,128]{2,1,0} convert(%mul.8548), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_45_self_attn_k_norm_weight__.368 = bf16[128]{0} parameter(367), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.45.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.8550 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_45_self_attn_k_norm_weight__.368), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8551 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.8550), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8552 = bf16[128]{0} reshape(%mul.8551), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8553 = bf16[16,4,128]{2,1,0} broadcast(%mul.8552), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8554 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.8549, %mul.8553), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8588 = bf16[16,4,64]{2,1,0} slice(%mul.8554), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8586 = bf16[16,1,64]{2,1,0} reshape(%slice.8560), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8590 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8586), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8591 = bf16[16,64]{1,0} reshape(%mul.8590), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8592 = bf16[16,4,64]{2,1,0} broadcast(%mul.8591), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8593 = bf16[16,4,64]{2,1,0} multiply(%slice.8588, %mul.8592), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8589 = bf16[16,4,64]{2,1,0} slice(%mul.8554), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8587 = bf16[16,1,64]{2,1,0} reshape(%slice.8561), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8594 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8587), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8595 = bf16[16,64]{1,0} reshape(%mul.8594), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8596 = bf16[16,4,64]{2,1,0} broadcast(%mul.8595), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8597 = bf16[16,4,64]{2,1,0} multiply(%slice.8589, %mul.8596), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.8598 = bf16[16,4,64]{2,1,0} subtract(%mul.8593, %mul.8597), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.8599 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8586), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8600 = bf16[16,64]{1,0} reshape(%mul.8599), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8601 = bf16[16,4,64]{2,1,0} broadcast(%mul.8600), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8602 = bf16[16,4,64]{2,1,0} multiply(%slice.8589, %mul.8601), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8603 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8587), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8604 = bf16[16,64]{1,0} reshape(%mul.8603), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8605 = bf16[16,4,64]{2,1,0} broadcast(%mul.8604), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8606 = bf16[16,4,64]{2,1,0} multiply(%slice.8588, %mul.8605), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.8607 = bf16[16,4,64]{2,1,0} add(%mul.8602, %mul.8606), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.8608 = bf16[16,4,128]{2,1,0} concatenate(%sub.8598, %add.8607), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.8609 = bf16[16,512]{1,0} reshape(%concatenate.8608), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.8510 = bf16[16,4,128]{2,1,0} slice(%reshape.8507), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.8511 = bf16[16,512]{1,0} reshape(%slice.8510), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.8610 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_45_.481, %reshape.8585, %reshape.8609, %reshape.8511, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.8611 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.8610), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_46_.482 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(481), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[46]"}
  %jit__jax_attn_func_.8612 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.8610), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_45_self_attn_o_proj_weight__.369 = bf16[2048,4096]{1,0} parameter(368), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.45.self_attn.o_proj.weight\']"}
  %dot_general.8613 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.8612, %params_and_buffers__vllm_model_language_model_model_layers_45_self_attn_o_proj_weight__.369), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.8614 = f32[16,2048]{1,0} convert(%dot_general.8613), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8485 = bf16[16,2048]{1,0} convert(%add.8484), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8615 = f32[16,2048]{1,0} convert(%convert_element_type.8485), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.8616 = f32[16,2048]{1,0} add(%convert_element_type.8614, %convert_element_type.8615), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.8618 = f32[16,2048]{1,0} power(%add.8616, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8623 = f32[16]{0} reduce(%pow.8618, %constant.512), dimensions={1}, to_apply=%region_213.8622, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8624 = f32[16,1]{1,0} reshape(%reduce_sum.8623), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8625 = f32[16,1]{1,0} divide(%broadcast_in_dim.8624, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8626 = f32[16,1]{1,0} add(%div.8625, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8627 = f32[16,1]{1,0} rsqrt(%add.8626), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8628 = f32[16,1]{1,0} broadcast(%rsqrt.8627), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8629 = f32[16]{0} reshape(%mul.8628), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8630 = f32[16,2048]{1,0} broadcast(%mul.8629), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8631 = f32[16,2048]{1,0} multiply(%add.8616, %mul.8630), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8632 = bf16[16,2048]{1,0} convert(%mul.8631), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_45_post_attention_layernorm_weight__.367 = bf16[2048]{0} parameter(366), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.45.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.8633 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_45_post_attention_layernorm_weight__.367), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8634 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.8633), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8635 = bf16[2048]{0} reshape(%mul.8634), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8636 = bf16[16,2048]{1,0} broadcast(%mul.8635), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8637 = bf16[16,2048]{1,0} multiply(%convert_element_type.8632, %mul.8636), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_45_mlp_experts_w13_weight__.364 = bf16[128,1536,2048]{2,1,0} parameter(363), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.45.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_45_mlp_experts_w2_weight__.365 = bf16[128,2048,768]{2,1,0} parameter(364), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.45.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_45_mlp_gate_weight__.366 = bf16[128,2048]{1,0} parameter(365), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.45.mlp.gate.weight\']"}
  %dot_general.8638 = bf16[16,128]{1,0} dot(%mul.8637, %params_and_buffers__vllm_model_language_model_model_layers_45_mlp_gate_weight__.366), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.8639 = bf16[16,2048]{1,0} call(%mul.8637, %params_and_buffers__vllm_model_language_model_model_layers_45_mlp_experts_w13_weight__.364, %params_and_buffers__vllm_model_language_model_model_layers_45_mlp_experts_w2_weight__.365, %dot_general.8638), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.8640 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.8639), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8617 = bf16[16,2048]{1,0} convert(%add.8616), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8641 = f32[16,2048]{1,0} convert(%convert_element_type.8617), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.8642 = f32[16,2048]{1,0} add(%convert_element_type.8640, %convert_element_type.8641), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.8644 = f32[16,2048]{1,0} power(%add.8642, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8649 = f32[16]{0} reduce(%pow.8644, %constant.512), dimensions={1}, to_apply=%region_214.8648, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8650 = f32[16,1]{1,0} reshape(%reduce_sum.8649), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8651 = f32[16,1]{1,0} divide(%broadcast_in_dim.8650, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8652 = f32[16,1]{1,0} add(%div.8651, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8653 = f32[16,1]{1,0} rsqrt(%add.8652), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8654 = f32[16,1]{1,0} broadcast(%rsqrt.8653), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8655 = f32[16]{0} reshape(%mul.8654), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8656 = f32[16,2048]{1,0} broadcast(%mul.8655), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8657 = f32[16,2048]{1,0} multiply(%add.8642, %mul.8656), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8658 = bf16[16,2048]{1,0} convert(%mul.8657), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_46_input_layernorm_weight__.372 = bf16[2048]{0} parameter(371), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.46.input_layernorm.weight\']"}
  %broadcast_in_dim.8659 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_46_input_layernorm_weight__.372), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8660 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.8659), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8661 = bf16[2048]{0} reshape(%mul.8660), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8662 = bf16[16,2048]{1,0} broadcast(%mul.8661), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8663 = bf16[16,2048]{1,0} multiply(%convert_element_type.8658, %mul.8662), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_46_self_attn_qkv_proj_weight__.380 = bf16[5120,2048]{1,0} parameter(379), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.46.self_attn.qkv_proj.weight\']"}
  %dot_general.8664 = bf16[16,5120]{1,0} dot(%mul.8663, %params_and_buffers__vllm_model_language_model_model_layers_46_self_attn_qkv_proj_weight__.380), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.8665 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.8664), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.8666 = bf16[16,4,1024]{2,1,0} slice(%reshape.8665), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.8670 = bf16[16,32,128]{2,1,0} reshape(%slice.8666), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.8671 = f32[16,32,128]{2,1,0} convert(%reshape.8670), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.8672 = f32[16,32,128]{2,1,0} power(%convert_element_type.8671, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8677 = f32[16,32]{1,0} reduce(%pow.8672, %constant.512), dimensions={2}, to_apply=%region_215.8676, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8678 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.8677), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8679 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.8678, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8680 = f32[16,32,1]{2,1,0} add(%div.8679, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8681 = f32[16,32,1]{2,1,0} rsqrt(%add.8680), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8682 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.8681), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8683 = f32[16,32]{1,0} reshape(%mul.8682), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8684 = f32[16,32,128]{2,1,0} broadcast(%mul.8683), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8685 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.8671, %mul.8684), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8686 = bf16[16,32,128]{2,1,0} convert(%mul.8685), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_46_self_attn_q_norm_weight__.379 = bf16[128]{0} parameter(378), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.46.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.8687 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_46_self_attn_q_norm_weight__.379), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8688 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.8687), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8689 = bf16[128]{0} reshape(%mul.8688), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8690 = bf16[16,32,128]{2,1,0} broadcast(%mul.8689), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8691 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.8686, %mul.8690), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8722 = bf16[16,32,64]{2,1,0} slice(%mul.8691), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.8713 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.8714 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.8715 = s32[16]{0} select(%lt.8713, %add.8714, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.8716 = s32[16,1]{1,0} reshape(%select_n.8715), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.8717 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.8716), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.8718 = bf16[16,64]{1,0} slice(%gather.8717), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8720 = bf16[16,1,64]{2,1,0} reshape(%slice.8718), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8724 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8720), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8725 = bf16[16,64]{1,0} reshape(%mul.8724), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8726 = bf16[16,32,64]{2,1,0} broadcast(%mul.8725), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8727 = bf16[16,32,64]{2,1,0} multiply(%slice.8722, %mul.8726), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8723 = bf16[16,32,64]{2,1,0} slice(%mul.8691), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.8719 = bf16[16,64]{1,0} slice(%gather.8717), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8721 = bf16[16,1,64]{2,1,0} reshape(%slice.8719), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8728 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8721), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8729 = bf16[16,64]{1,0} reshape(%mul.8728), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8730 = bf16[16,32,64]{2,1,0} broadcast(%mul.8729), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8731 = bf16[16,32,64]{2,1,0} multiply(%slice.8723, %mul.8730), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.8732 = bf16[16,32,64]{2,1,0} subtract(%mul.8727, %mul.8731), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.8733 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8720), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8734 = bf16[16,64]{1,0} reshape(%mul.8733), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8735 = bf16[16,32,64]{2,1,0} broadcast(%mul.8734), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8736 = bf16[16,32,64]{2,1,0} multiply(%slice.8723, %mul.8735), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8737 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8721), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8738 = bf16[16,64]{1,0} reshape(%mul.8737), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8739 = bf16[16,32,64]{2,1,0} broadcast(%mul.8738), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8740 = bf16[16,32,64]{2,1,0} multiply(%slice.8722, %mul.8739), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.8741 = bf16[16,32,64]{2,1,0} add(%mul.8736, %mul.8740), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.8742 = bf16[16,32,128]{2,1,0} concatenate(%sub.8732, %add.8741), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.8743 = bf16[16,4096]{1,0} reshape(%concatenate.8742), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.8667 = bf16[16,4,128]{2,1,0} slice(%reshape.8665), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.8692 = f32[16,4,128]{2,1,0} convert(%slice.8667), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.8693 = f32[16,4,128]{2,1,0} power(%convert_element_type.8692, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8698 = f32[16,4]{1,0} reduce(%pow.8693, %constant.512), dimensions={2}, to_apply=%region_216.8697, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8699 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.8698), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8700 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.8699, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8701 = f32[16,4,1]{2,1,0} add(%div.8700, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8702 = f32[16,4,1]{2,1,0} rsqrt(%add.8701), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8703 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.8702), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8704 = f32[16,4]{1,0} reshape(%mul.8703), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8705 = f32[16,4,128]{2,1,0} broadcast(%mul.8704), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8706 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.8692, %mul.8705), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8707 = bf16[16,4,128]{2,1,0} convert(%mul.8706), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_46_self_attn_k_norm_weight__.377 = bf16[128]{0} parameter(376), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.46.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.8708 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_46_self_attn_k_norm_weight__.377), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8709 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.8708), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8710 = bf16[128]{0} reshape(%mul.8709), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8711 = bf16[16,4,128]{2,1,0} broadcast(%mul.8710), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8712 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.8707, %mul.8711), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8746 = bf16[16,4,64]{2,1,0} slice(%mul.8712), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8744 = bf16[16,1,64]{2,1,0} reshape(%slice.8718), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8748 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8744), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8749 = bf16[16,64]{1,0} reshape(%mul.8748), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8750 = bf16[16,4,64]{2,1,0} broadcast(%mul.8749), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8751 = bf16[16,4,64]{2,1,0} multiply(%slice.8746, %mul.8750), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8747 = bf16[16,4,64]{2,1,0} slice(%mul.8712), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8745 = bf16[16,1,64]{2,1,0} reshape(%slice.8719), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8752 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8745), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8753 = bf16[16,64]{1,0} reshape(%mul.8752), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8754 = bf16[16,4,64]{2,1,0} broadcast(%mul.8753), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8755 = bf16[16,4,64]{2,1,0} multiply(%slice.8747, %mul.8754), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.8756 = bf16[16,4,64]{2,1,0} subtract(%mul.8751, %mul.8755), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.8757 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8744), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8758 = bf16[16,64]{1,0} reshape(%mul.8757), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8759 = bf16[16,4,64]{2,1,0} broadcast(%mul.8758), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8760 = bf16[16,4,64]{2,1,0} multiply(%slice.8747, %mul.8759), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8761 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8745), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8762 = bf16[16,64]{1,0} reshape(%mul.8761), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8763 = bf16[16,4,64]{2,1,0} broadcast(%mul.8762), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8764 = bf16[16,4,64]{2,1,0} multiply(%slice.8746, %mul.8763), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.8765 = bf16[16,4,64]{2,1,0} add(%mul.8760, %mul.8764), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.8766 = bf16[16,4,128]{2,1,0} concatenate(%sub.8756, %add.8765), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.8767 = bf16[16,512]{1,0} reshape(%concatenate.8766), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.8668 = bf16[16,4,128]{2,1,0} slice(%reshape.8665), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.8669 = bf16[16,512]{1,0} reshape(%slice.8668), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.8768 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_46_.482, %reshape.8743, %reshape.8767, %reshape.8669, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.8769 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.8768), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_47_.483 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(482), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[47]"}
  %jit__jax_attn_func_.8770 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.8768), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_46_self_attn_o_proj_weight__.378 = bf16[2048,4096]{1,0} parameter(377), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.46.self_attn.o_proj.weight\']"}
  %dot_general.8771 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.8770, %params_and_buffers__vllm_model_language_model_model_layers_46_self_attn_o_proj_weight__.378), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.8772 = f32[16,2048]{1,0} convert(%dot_general.8771), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8643 = bf16[16,2048]{1,0} convert(%add.8642), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8773 = f32[16,2048]{1,0} convert(%convert_element_type.8643), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.8774 = f32[16,2048]{1,0} add(%convert_element_type.8772, %convert_element_type.8773), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.8776 = f32[16,2048]{1,0} power(%add.8774, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8781 = f32[16]{0} reduce(%pow.8776, %constant.512), dimensions={1}, to_apply=%region_217.8780, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8782 = f32[16,1]{1,0} reshape(%reduce_sum.8781), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8783 = f32[16,1]{1,0} divide(%broadcast_in_dim.8782, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8784 = f32[16,1]{1,0} add(%div.8783, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8785 = f32[16,1]{1,0} rsqrt(%add.8784), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8786 = f32[16,1]{1,0} broadcast(%rsqrt.8785), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8787 = f32[16]{0} reshape(%mul.8786), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8788 = f32[16,2048]{1,0} broadcast(%mul.8787), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8789 = f32[16,2048]{1,0} multiply(%add.8774, %mul.8788), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8790 = bf16[16,2048]{1,0} convert(%mul.8789), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_46_post_attention_layernorm_weight__.376 = bf16[2048]{0} parameter(375), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.46.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.8791 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_46_post_attention_layernorm_weight__.376), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8792 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.8791), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8793 = bf16[2048]{0} reshape(%mul.8792), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8794 = bf16[16,2048]{1,0} broadcast(%mul.8793), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8795 = bf16[16,2048]{1,0} multiply(%convert_element_type.8790, %mul.8794), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_46_mlp_experts_w13_weight__.373 = bf16[128,1536,2048]{2,1,0} parameter(372), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.46.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_46_mlp_experts_w2_weight__.374 = bf16[128,2048,768]{2,1,0} parameter(373), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.46.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_46_mlp_gate_weight__.375 = bf16[128,2048]{1,0} parameter(374), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.46.mlp.gate.weight\']"}
  %dot_general.8796 = bf16[16,128]{1,0} dot(%mul.8795, %params_and_buffers__vllm_model_language_model_model_layers_46_mlp_gate_weight__.375), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.8797 = bf16[16,2048]{1,0} call(%mul.8795, %params_and_buffers__vllm_model_language_model_model_layers_46_mlp_experts_w13_weight__.373, %params_and_buffers__vllm_model_language_model_model_layers_46_mlp_experts_w2_weight__.374, %dot_general.8796), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.8798 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.8797), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8775 = bf16[16,2048]{1,0} convert(%add.8774), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8799 = f32[16,2048]{1,0} convert(%convert_element_type.8775), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.8800 = f32[16,2048]{1,0} add(%convert_element_type.8798, %convert_element_type.8799), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.8802 = f32[16,2048]{1,0} power(%add.8800, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8807 = f32[16]{0} reduce(%pow.8802, %constant.512), dimensions={1}, to_apply=%region_218.8806, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8808 = f32[16,1]{1,0} reshape(%reduce_sum.8807), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8809 = f32[16,1]{1,0} divide(%broadcast_in_dim.8808, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8810 = f32[16,1]{1,0} add(%div.8809, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8811 = f32[16,1]{1,0} rsqrt(%add.8810), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8812 = f32[16,1]{1,0} broadcast(%rsqrt.8811), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8813 = f32[16]{0} reshape(%mul.8812), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8814 = f32[16,2048]{1,0} broadcast(%mul.8813), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8815 = f32[16,2048]{1,0} multiply(%add.8800, %mul.8814), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8816 = bf16[16,2048]{1,0} convert(%mul.8815), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_47_input_layernorm_weight__.381 = bf16[2048]{0} parameter(380), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.47.input_layernorm.weight\']"}
  %broadcast_in_dim.8817 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_47_input_layernorm_weight__.381), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8818 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.8817), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8819 = bf16[2048]{0} reshape(%mul.8818), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8820 = bf16[16,2048]{1,0} broadcast(%mul.8819), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8821 = bf16[16,2048]{1,0} multiply(%convert_element_type.8816, %mul.8820), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_47_self_attn_qkv_proj_weight__.389 = bf16[5120,2048]{1,0} parameter(388), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.47.self_attn.qkv_proj.weight\']"}
  %dot_general.8822 = bf16[16,5120]{1,0} dot(%mul.8821, %params_and_buffers__vllm_model_language_model_model_layers_47_self_attn_qkv_proj_weight__.389), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.8823 = bf16[16,4,1280]{2,1,0} reshape(%dot_general.8822), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.8824 = bf16[16,4,1024]{2,1,0} slice(%reshape.8823), slice={[0:16], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.8828 = bf16[16,32,128]{2,1,0} reshape(%slice.8824), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.8829 = f32[16,32,128]{2,1,0} convert(%reshape.8828), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.8830 = f32[16,32,128]{2,1,0} power(%convert_element_type.8829, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8835 = f32[16,32]{1,0} reduce(%pow.8830, %constant.512), dimensions={2}, to_apply=%region_219.8834, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8836 = f32[16,32,1]{2,1,0} reshape(%reduce_sum.8835), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8837 = f32[16,32,1]{2,1,0} divide(%broadcast_in_dim.8836, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8838 = f32[16,32,1]{2,1,0} add(%div.8837, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8839 = f32[16,32,1]{2,1,0} rsqrt(%add.8838), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8840 = f32[16,32,1]{2,1,0} broadcast(%rsqrt.8839), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8841 = f32[16,32]{1,0} reshape(%mul.8840), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8842 = f32[16,32,128]{2,1,0} broadcast(%mul.8841), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8843 = f32[16,32,128]{2,1,0} multiply(%convert_element_type.8829, %mul.8842), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8844 = bf16[16,32,128]{2,1,0} convert(%mul.8843), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_47_self_attn_q_norm_weight__.388 = bf16[128]{0} parameter(387), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.47.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.8845 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_47_self_attn_q_norm_weight__.388), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8846 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.8845), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8847 = bf16[128]{0} reshape(%mul.8846), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8848 = bf16[16,32,128]{2,1,0} broadcast(%mul.8847), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8849 = bf16[16,32,128]{2,1,0} multiply(%convert_element_type.8844, %mul.8848), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8880 = bf16[16,32,64]{2,1,0} slice(%mul.8849), slice={[0:16], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.8871 = pred[16]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.8872 = s32[16]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.8873 = s32[16]{0} select(%lt.8871, %add.8872, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.8874 = s32[16,1]{1,0} reshape(%select_n.8873), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.8875 = bf16[16,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.8874), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.8876 = bf16[16,64]{1,0} slice(%gather.8875), slice={[0:16], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8878 = bf16[16,1,64]{2,1,0} reshape(%slice.8876), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8882 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8878), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8883 = bf16[16,64]{1,0} reshape(%mul.8882), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8884 = bf16[16,32,64]{2,1,0} broadcast(%mul.8883), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8885 = bf16[16,32,64]{2,1,0} multiply(%slice.8880, %mul.8884), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8881 = bf16[16,32,64]{2,1,0} slice(%mul.8849), slice={[0:16], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.8877 = bf16[16,64]{1,0} slice(%gather.8875), slice={[0:16], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8879 = bf16[16,1,64]{2,1,0} reshape(%slice.8877), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8886 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8879), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8887 = bf16[16,64]{1,0} reshape(%mul.8886), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8888 = bf16[16,32,64]{2,1,0} broadcast(%mul.8887), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8889 = bf16[16,32,64]{2,1,0} multiply(%slice.8881, %mul.8888), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.8890 = bf16[16,32,64]{2,1,0} subtract(%mul.8885, %mul.8889), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.8891 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8878), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8892 = bf16[16,64]{1,0} reshape(%mul.8891), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8893 = bf16[16,32,64]{2,1,0} broadcast(%mul.8892), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8894 = bf16[16,32,64]{2,1,0} multiply(%slice.8881, %mul.8893), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8895 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8879), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8896 = bf16[16,64]{1,0} reshape(%mul.8895), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8897 = bf16[16,32,64]{2,1,0} broadcast(%mul.8896), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8898 = bf16[16,32,64]{2,1,0} multiply(%slice.8880, %mul.8897), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.8899 = bf16[16,32,64]{2,1,0} add(%mul.8894, %mul.8898), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.8900 = bf16[16,32,128]{2,1,0} concatenate(%sub.8890, %add.8899), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.8901 = bf16[16,4096]{1,0} reshape(%concatenate.8900), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.8825 = bf16[16,4,128]{2,1,0} slice(%reshape.8823), slice={[0:16], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.8850 = f32[16,4,128]{2,1,0} convert(%slice.8825), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.8851 = f32[16,4,128]{2,1,0} power(%convert_element_type.8850, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8856 = f32[16,4]{1,0} reduce(%pow.8851, %constant.512), dimensions={2}, to_apply=%region_220.8855, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8857 = f32[16,4,1]{2,1,0} reshape(%reduce_sum.8856), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8858 = f32[16,4,1]{2,1,0} divide(%broadcast_in_dim.8857, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8859 = f32[16,4,1]{2,1,0} add(%div.8858, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8860 = f32[16,4,1]{2,1,0} rsqrt(%add.8859), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8861 = f32[16,4,1]{2,1,0} broadcast(%rsqrt.8860), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8862 = f32[16,4]{1,0} reshape(%mul.8861), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8863 = f32[16,4,128]{2,1,0} broadcast(%mul.8862), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8864 = f32[16,4,128]{2,1,0} multiply(%convert_element_type.8850, %mul.8863), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8865 = bf16[16,4,128]{2,1,0} convert(%mul.8864), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_47_self_attn_k_norm_weight__.386 = bf16[128]{0} parameter(385), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.47.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.8866 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_47_self_attn_k_norm_weight__.386), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8867 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.8866), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8868 = bf16[128]{0} reshape(%mul.8867), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8869 = bf16[16,4,128]{2,1,0} broadcast(%mul.8868), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8870 = bf16[16,4,128]{2,1,0} multiply(%convert_element_type.8865, %mul.8869), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8904 = bf16[16,4,64]{2,1,0} slice(%mul.8870), slice={[0:16], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8902 = bf16[16,1,64]{2,1,0} reshape(%slice.8876), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8906 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8902), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8907 = bf16[16,64]{1,0} reshape(%mul.8906), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8908 = bf16[16,4,64]{2,1,0} broadcast(%mul.8907), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8909 = bf16[16,4,64]{2,1,0} multiply(%slice.8904, %mul.8908), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8905 = bf16[16,4,64]{2,1,0} slice(%mul.8870), slice={[0:16], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8903 = bf16[16,1,64]{2,1,0} reshape(%slice.8877), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8910 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8903), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8911 = bf16[16,64]{1,0} reshape(%mul.8910), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8912 = bf16[16,4,64]{2,1,0} broadcast(%mul.8911), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8913 = bf16[16,4,64]{2,1,0} multiply(%slice.8905, %mul.8912), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.8914 = bf16[16,4,64]{2,1,0} subtract(%mul.8909, %mul.8913), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.8915 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8902), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8916 = bf16[16,64]{1,0} reshape(%mul.8915), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8917 = bf16[16,4,64]{2,1,0} broadcast(%mul.8916), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8918 = bf16[16,4,64]{2,1,0} multiply(%slice.8905, %mul.8917), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8919 = bf16[16,1,64]{2,1,0} broadcast(%broadcast_in_dim.8903), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8920 = bf16[16,64]{1,0} reshape(%mul.8919), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8921 = bf16[16,4,64]{2,1,0} broadcast(%mul.8920), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8922 = bf16[16,4,64]{2,1,0} multiply(%slice.8904, %mul.8921), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.8923 = bf16[16,4,64]{2,1,0} add(%mul.8918, %mul.8922), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.8924 = bf16[16,4,128]{2,1,0} concatenate(%sub.8914, %add.8923), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.8925 = bf16[16,512]{1,0} reshape(%concatenate.8924), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.8826 = bf16[16,4,128]{2,1,0} slice(%reshape.8823), slice={[0:16], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.8827 = bf16[16,512]{1,0} reshape(%slice.8826), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.8926 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,4096]{1,0}) call(%kv_caches_47_.483, %reshape.8901, %reshape.8925, %reshape.8827, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.8927 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.8926), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.8928 = bf16[16,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.8926), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_47_self_attn_o_proj_weight__.387 = bf16[2048,4096]{1,0} parameter(386), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.47.self_attn.o_proj.weight\']"}
  %dot_general.8929 = bf16[16,2048]{1,0} dot(%jit__jax_attn_func_.8928, %params_and_buffers__vllm_model_language_model_model_layers_47_self_attn_o_proj_weight__.387), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.8930 = f32[16,2048]{1,0} convert(%dot_general.8929), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8801 = bf16[16,2048]{1,0} convert(%add.8800), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8931 = f32[16,2048]{1,0} convert(%convert_element_type.8801), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.8932 = f32[16,2048]{1,0} add(%convert_element_type.8930, %convert_element_type.8931), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.8934 = f32[16,2048]{1,0} power(%add.8932, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8939 = f32[16]{0} reduce(%pow.8934, %constant.512), dimensions={1}, to_apply=%region_221.8938, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8940 = f32[16,1]{1,0} reshape(%reduce_sum.8939), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8941 = f32[16,1]{1,0} divide(%broadcast_in_dim.8940, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8942 = f32[16,1]{1,0} add(%div.8941, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8943 = f32[16,1]{1,0} rsqrt(%add.8942), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8944 = f32[16,1]{1,0} broadcast(%rsqrt.8943), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8945 = f32[16]{0} reshape(%mul.8944), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8946 = f32[16,2048]{1,0} broadcast(%mul.8945), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8947 = f32[16,2048]{1,0} multiply(%add.8932, %mul.8946), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8948 = bf16[16,2048]{1,0} convert(%mul.8947), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_47_post_attention_layernorm_weight__.385 = bf16[2048]{0} parameter(384), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.47.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.8949 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_47_post_attention_layernorm_weight__.385), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8950 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.8949), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8951 = bf16[2048]{0} reshape(%mul.8950), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8952 = bf16[16,2048]{1,0} broadcast(%mul.8951), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8953 = bf16[16,2048]{1,0} multiply(%convert_element_type.8948, %mul.8952), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_47_mlp_experts_w13_weight__.382 = bf16[128,1536,2048]{2,1,0} parameter(381), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.47.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_47_mlp_experts_w2_weight__.383 = bf16[128,2048,768]{2,1,0} parameter(382), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.47.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_47_mlp_gate_weight__.384 = bf16[128,2048]{1,0} parameter(383), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.47.mlp.gate.weight\']"}
  %dot_general.8954 = bf16[16,128]{1,0} dot(%mul.8953, %params_and_buffers__vllm_model_language_model_model_layers_47_mlp_gate_weight__.384), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.8955 = bf16[16,2048]{1,0} call(%mul.8953, %params_and_buffers__vllm_model_language_model_model_layers_47_mlp_experts_w13_weight__.382, %params_and_buffers__vllm_model_language_model_model_layers_47_mlp_experts_w2_weight__.383, %dot_general.8954), to_apply=%jax_fused_moe_func_padded.1528, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.8956 = f32[16,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.8955), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8933 = bf16[16,2048]{1,0} convert(%add.8932), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8957 = f32[16,2048]{1,0} convert(%convert_element_type.8933), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.8958 = f32[16,2048]{1,0} add(%convert_element_type.8956, %convert_element_type.8957), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.8959 = f32[16,2048]{1,0} power(%add.8958, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8964 = f32[16]{0} reduce(%pow.8959, %constant.512), dimensions={1}, to_apply=%region_222.8963, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8965 = f32[16,1]{1,0} reshape(%reduce_sum.8964), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8966 = f32[16,1]{1,0} divide(%broadcast_in_dim.8965, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8967 = f32[16,1]{1,0} add(%div.8966, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8968 = f32[16,1]{1,0} rsqrt(%add.8967), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8969 = f32[16,1]{1,0} broadcast(%rsqrt.8968), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8970 = f32[16]{0} reshape(%mul.8969), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8971 = f32[16,2048]{1,0} broadcast(%mul.8970), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8972 = f32[16,2048]{1,0} multiply(%add.8958, %mul.8971), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8973 = bf16[16,2048]{1,0} convert(%mul.8972), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_norm_weight__.435 = bf16[2048]{0} parameter(434), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.norm.weight\']"}
  %broadcast_in_dim.8974 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_norm_weight__.435), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8975 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.8974), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8976 = bf16[2048]{0} reshape(%mul.8975), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8977 = bf16[16,2048]{1,0} broadcast(%mul.8976), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8978 = bf16[16,2048]{1,0} multiply(%convert_element_type.8973, %mul.8977), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  ROOT %tuple.8979 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, /*index=5*/bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, /*index=10*/bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, /*index=15*/bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, /*index=20*/bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, /*index=25*/bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, /*index=30*/bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, /*index=35*/bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, /*index=40*/bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, /*index=45*/bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[16,2048]{1,0}) tuple(%jit__jax_attn_func_.765, %jit__jax_attn_func_.1659, %jit__jax_attn_func_.1817, %jit__jax_attn_func_.1975, %jit__jax_attn_func_.2133, /*index=5*/%jit__jax_attn_func_.2291, %jit__jax_attn_func_.2449, %jit__jax_attn_func_.2607, %jit__jax_attn_func_.2765, %jit__jax_attn_func_.2923, /*index=10*/%jit__jax_attn_func_.3081, %jit__jax_attn_func_.3239, %jit__jax_attn_func_.3397, %jit__jax_attn_func_.3555, %jit__jax_attn_func_.3713, /*index=15*/%jit__jax_attn_func_.3871, %jit__jax_attn_func_.4029, %jit__jax_attn_func_.4187, %jit__jax_attn_func_.4345, %jit__jax_attn_func_.4503, /*index=20*/%jit__jax_attn_func_.4661, %jit__jax_attn_func_.4819, %jit__jax_attn_func_.4977, %jit__jax_attn_func_.5135, %jit__jax_attn_func_.5293, /*index=25*/%jit__jax_attn_func_.5451, %jit__jax_attn_func_.5609, %jit__jax_attn_func_.5767, %jit__jax_attn_func_.5925, %jit__jax_attn_func_.6083, /*index=30*/%jit__jax_attn_func_.6241, %jit__jax_attn_func_.6399, %jit__jax_attn_func_.6557, %jit__jax_attn_func_.6715, %jit__jax_attn_func_.6873, /*index=35*/%jit__jax_attn_func_.7031, %jit__jax_attn_func_.7189, %jit__jax_attn_func_.7347, %jit__jax_attn_func_.7505, %jit__jax_attn_func_.7663, /*index=40*/%jit__jax_attn_func_.7821, %jit__jax_attn_func_.7979, %jit__jax_attn_func_.8137, %jit__jax_attn_func_.8295, %jit__jax_attn_func_.8453, /*index=45*/%jit__jax_attn_func_.8611, %jit__jax_attn_func_.8769, %jit__jax_attn_func_.8927, %mul.8978)
}

