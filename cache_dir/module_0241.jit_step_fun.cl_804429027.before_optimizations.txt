HloModule jit_step_fun, buffer_donor={ (435, {}), (436, {}), (437, {}), (438, {}), (439, {}), (440, {}), (441, {}), (442, {}), (443, {}), (444, {}), (445, {}), (446, {}), (447, {}), (448, {}), (449, {}), (450, {}), (451, {}), (452, {}), (453, {}), (454, {}), (455, {}), (456, {}), (457, {}), (458, {}), (459, {}), (460, {}), (461, {}), (462, {}), (463, {}), (464, {}), (465, {}), (466, {}), (467, {}), (468, {}), (469, {}), (470, {}), (471, {}), (472, {}), (473, {}), (474, {}), (475, {}), (476, {}), (477, {}), (478, {}), (479, {}), (480, {}), (481, {}), (482, {}) }, entry_computation_layout={(bf16[152064,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, /*index=5*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, /*index=10*/bf16[262144,128]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, /*index=15*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, /*index=20*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=25*/bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=30*/bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=35*/bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, /*index=40*/bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, /*index=45*/bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, /*index=50*/bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=55*/bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, /*index=60*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, /*index=65*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=70*/bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=75*/bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=80*/bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, /*index=85*/bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, /*index=90*/bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, /*index=95*/bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=100*/bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, /*index=105*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, /*index=110*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=115*/bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=120*/bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=125*/bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, /*index=130*/bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, /*index=135*/bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, /*index=140*/bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=145*/bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, /*index=150*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, /*index=155*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=160*/bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=165*/bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=170*/bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, /*index=175*/bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, /*index=180*/bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, /*index=185*/bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=190*/bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, /*index=195*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, /*index=200*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=205*/bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=210*/bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=215*/bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, /*index=220*/bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, /*index=225*/bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, /*index=230*/bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=235*/bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, /*index=240*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, /*index=245*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=250*/bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=255*/bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=260*/bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, /*index=265*/bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, /*index=270*/bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, /*index=275*/bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=280*/bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, /*index=285*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, /*index=290*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=295*/bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=300*/bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=305*/bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, /*index=310*/bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, /*index=315*/bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, /*index=320*/bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=325*/bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, /*index=330*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, /*index=335*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=340*/bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=345*/bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=350*/bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, /*index=355*/bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, /*index=360*/bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, /*index=365*/bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=370*/bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, /*index=375*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, /*index=380*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=385*/bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=390*/bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=395*/bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, /*index=400*/bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, /*index=405*/bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, /*index=410*/bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, /*index=415*/bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, /*index=420*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, /*index=425*/bf16[2048]{0:T(1024)(128)(2,1)}, bf16[128,1536,2048]{2,1,0:T(8,128)(2,1)}, bf16[128,2048,768]{2,1,0:T(8,128)(2,1)}, bf16[128,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=430*/bf16[128]{0:T(256)(128)(2,1)}, bf16[2048,4096]{1,0:T(8,128)(2,1)}, bf16[128]{0:T(256)(128)(2,1)}, bf16[5120,2048]{1,0:T(8,128)(2,1)}, bf16[2048]{0:T(1024)(128)(2,1)}, /*index=435*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=440*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=445*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=450*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=455*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=460*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=465*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=470*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=475*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=480*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, s32[32]{0:T(128)}, s32[32]{0:T(128)}, /*index=485*/s32[131072]{0:T(1024)}, s32[256]{0:T(256)}, s32[257]{0:T(512)}, s32[3]{0:T(128)})->(bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=5*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=10*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=15*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=20*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=25*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=30*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=35*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=40*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, /*index=45*/bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[14813,32,4,2,128]{4,3,2,1,0:T(2,128)(2,1)}, bf16[32,2048]{1,0:T(8,128)(2,1)})}, allow_spmd_sharding_propagation_to_parameters={false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false}, allow_spmd_sharding_propagation_to_output={true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true}, num_partitions=4, frontend_attributes={xla.sdy.meshes={mesh = #sdy.mesh<["data"=1, "model"=4]>}}

%_where.532 (Arg_0.528: pred[32], Arg_1.529: s32[32], Arg_2.530: s32[32]) -> s32[32] {
  %Arg_0.528 = pred[32]{0} parameter(0)
  %Arg_1.529 = s32[32]{0} parameter(1)
  %Arg_2.530 = s32[32]{0} parameter(2)
  ROOT %select_n.531 = s32[32]{0} select(%Arg_0.528, %Arg_1.529, %Arg_2.530), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
}

%region_0.541 (reduce_and.538: pred[], reduce_and.539: pred[]) -> pred[] {
  %reduce_and.538 = pred[] parameter(0), metadata={op_name="reduce_and"}
  %reduce_and.539 = pred[] parameter(1), metadata={op_name="reduce_and"}
  ROOT %reduce_and.540 = pred[] and(%reduce_and.538, %reduce_and.539), metadata={op_name="reduce_and" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
}

%_take.546 (Arg_0.513: bf16[152064,2048], Arg_1.514: s32[32]) -> bf16[32,2048] {
  %Arg_1.514 = s32[32]{0} parameter(1)
  %constant.524 = s32[] constant(0)
  %lt.525 = s32[32]{0} broadcast(%constant.524), dimensions={}, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
  %lt.526 = pred[32]{0} compare(%Arg_1.514, %lt.525), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
  %constant.521 = s32[] constant(152064)
  %add.522 = s32[32]{0} broadcast(%constant.521), dimensions={}, metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
  %add.527 = s32[32]{0} add(%Arg_1.514, %add.522), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
  %jit__where_.533 = s32[32]{0} call(%lt.526, %add.527, %Arg_1.514), to_apply=%_where.532, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
  %broadcast_in_dim.534 = s32[32,1]{1,0} reshape(%jit__where_.533), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
  %constant.519 = s32[] constant(0)
  %ge.520 = s32[32,1]{1,0} broadcast(%constant.519), dimensions={}, metadata={op_name="ge" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
  %ge.535 = pred[32,1]{1,0} compare(%broadcast_in_dim.534, %ge.520), direction=GE, metadata={op_name="ge" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
  %constant.517 = s32[] constant(152063)
  %le.518 = s32[32,1]{1,0} broadcast(%constant.517), dimensions={}, metadata={op_name="le" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
  %le.536 = pred[32,1]{1,0} compare(%broadcast_in_dim.534, %le.518), direction=LE, metadata={op_name="le" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
  %and.537 = pred[32,1]{1,0} and(%ge.535, %le.536), metadata={op_name="and" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
  %constant.523 = pred[] constant(true)
  %reduce_and.542 = pred[32]{0} reduce(%and.537, %constant.523), dimensions={1}, to_apply=%region_0.541, metadata={op_name="reduce_and" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
  %broadcast_in_dim.544 = pred[32,2048]{1,0} broadcast(%reduce_and.542), dimensions={0}, metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
  %Arg_0.513 = bf16[152064,2048]{1,0} parameter(0)
  %gather.543 = bf16[32,2048]{1,0} gather(%Arg_0.513, %broadcast_in_dim.534), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,2048}, metadata={op_name="gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
  %constant.515 = bf16[] constant(nan)
  %broadcast_in_dim.516 = bf16[32,2048]{1,0} broadcast(%constant.515), dimensions={}, metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
  ROOT %select_n.545 = bf16[32,2048]{1,0} select(%broadcast_in_dim.544, %gather.543, %broadcast_in_dim.516), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
}

%region_1.553 (reduce_sum.550: f32[], reduce_sum.551: f32[]) -> f32[] {
  %reduce_sum.550 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.551 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.552 = f32[] add(%reduce_sum.550, %reduce_sum.551), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_2.581 (reduce_sum.578: f32[], reduce_sum.579: f32[]) -> f32[] {
  %reduce_sum.578 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.579 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.580 = f32[] add(%reduce_sum.578, %reduce_sum.579), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_3.602 (reduce_sum.599: f32[], reduce_sum.600: f32[]) -> f32[] {
  %reduce_sum.599 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.600 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.601 = f32[] add(%reduce_sum.599, %reduce_sum.600), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%_pad.727 (Arg_0.725: bf16[32,1,8,128], Arg_1.726: s32[]) -> bf16[32,1,8,128] {
  ROOT %Arg_0.725 = bf16[32,1,8,128]{3,2,1,0} parameter(0)
  %Arg_1.726 = s32[] parameter(1)
}

%_pad_67.734 (Arg_0.732: bf16[32,2,128], Arg_1.733: s32[]) -> bf16[32,2,128] {
  ROOT %Arg_0.732 = bf16[32,2,128]{2,1,0} parameter(0)
  %Arg_1.733 = s32[] parameter(1)
}

%ragged_paged_attention.744 (Arg_0.709: bf16[32,8,128], Arg_1.710: bf16[32,1,128], Arg_2.711: bf16[32,1,128], Arg_3.712: bf16[14813,32,1,2,128], Arg_4.713: s32[256], Arg_5.714: s32[131072], Arg_6.715: s32[257], Arg_7.716: s32[3]) -> (bf16[32,8,128], bf16[14813,32,1,2,128]) {
  %Arg_7.716 = s32[3]{0} parameter(7)
  %slice.737 = s32[1]{0} slice(%Arg_7.716), slice={[2:3]}, metadata={op_name="slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/kernels/ragged_paged_attention/v3/kernel.py" source_line=1338 source_end_line=1338 source_column=12 source_end_column=27}
  %squeeze.738 = s32[] reshape(%slice.737), metadata={op_name="squeeze" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/kernels/ragged_paged_attention/v3/kernel.py" source_line=1338 source_end_line=1338 source_column=12 source_end_column=27}
  %Arg_4.713 = s32[256]{0} parameter(4)
  %Arg_5.714 = s32[131072]{0} parameter(5)
  %Arg_6.715 = s32[257]{0} parameter(6)
  %constant.721 = s32[] constant(0)
  %broadcast.722 = s32[3]{0} broadcast(%constant.721), dimensions={}
  %constant.719 = s32[] constant(-1)
  %broadcast.720 = s32[4]{0} broadcast(%constant.719), dimensions={}
  %constant.717 = s32[] constant(-1)
  %broadcast.718 = s32[6]{0} broadcast(%constant.717), dimensions={}
  %Arg_0.709 = bf16[32,8,128]{2,1,0} parameter(0)
  %reshape.724 = bf16[32,1,8,128]{3,2,1,0} reshape(%Arg_0.709), metadata={op_name="reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/kernels/ragged_paged_attention/v3/kernel.py" source_line=920 source_end_line=925 source_column=12 source_end_column=13}
  %constant.723 = s32[] constant(0)
  %jit__pad_.728 = bf16[32,1,8,128]{3,2,1,0} call(%reshape.724, %constant.723), to_apply=%_pad.727, metadata={op_name="jit(_pad)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/kernels/ragged_paged_attention/v3/kernel.py" source_line=919 source_end_line=933 source_column=8 source_end_column=9}
  %transpose.729 = bf16[1,32,4,2,128]{4,3,2,1,0} reshape(%jit__pad_.728), metadata={op_name="transpose" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/kernels/ragged_paged_attention/v3/kernel.py" source_line=941 source_end_line=941 source_column=9 source_end_column=23}
  %Arg_1.710 = bf16[32,1,128]{2,1,0} parameter(1)
  %Arg_2.711 = bf16[32,1,128]{2,1,0} parameter(2)
  %concatenate.730 = bf16[32,1,256]{2,1,0} concatenate(%Arg_1.710, %Arg_2.711), dimensions={2}, metadata={op_name="concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/kernels/ragged_paged_attention/v3/kernel.py" source_line=885 source_end_line=886 source_column=8 source_end_column=27}
  %reshape.731 = bf16[32,2,128]{2,1,0} reshape(%concatenate.730), metadata={op_name="reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/kernels/ragged_paged_attention/v3/kernel.py" source_line=886 source_end_line=887 source_column=28 source_end_column=52}
  %jit__pad_.735 = bf16[32,2,128]{2,1,0} call(%reshape.731, %constant.723), to_apply=%_pad_67.734, metadata={op_name="jit(_pad)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/kernels/ragged_paged_attention/v3/kernel.py" source_line=884 source_end_line=894 source_column=9 source_end_column=5}
  %reshape.736 = bf16[32,1,2,128]{3,2,1,0} reshape(%jit__pad_.735), metadata={op_name="reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/kernels/ragged_paged_attention/v3/kernel.py" source_line=894 source_end_line=899 source_column=6 source_end_column=5}
  %Arg_3.712 = bf16[14813,32,1,2,128]{4,3,2,1,0} parameter(3)
  %pallas_call.739 = (bf16[1,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,1,2,128]{4,3,2,1,0}) custom-call(%squeeze.738, %Arg_4.713, %Arg_5.714, %Arg_6.715, %Arg_7.716, /*index=5*/%broadcast.722, %broadcast.720, %broadcast.718, %transpose.729, %reshape.736, /*index=10*/%Arg_3.712), custom_call_target="tpu_custom_call", operand_layout_constraints={s32[], s32[256]{0}, s32[131072]{0}, s32[257]{0}, s32[3]{0}, s32[3]{0}, s32[4]{0}, s32[6]{0}, bf16[1,32,4,2,128]{4,3,2,1,0}, bf16[32,1,2,128]{3,2,1,0}, bf16[14813,32,1,2,128]{4,3,2,1,0}}, output_to_operand_aliasing={{0}: (8, {}), {1}: (10, {})}, metadata={op_name="RPA-bq_32-bkvp_64-p_32/pallas_call" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/kernels/ragged_paged_attention/v3/kernel.py" source_line=1442 source_end_line=1442 source_column=31 source_end_column=74}, backend_config={"custom_call_config": {"body": "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", "serialization_format": 1, "needs_layout_passes": true}, "scoped_memory_configs": [{"memory_space":1, "offset": 0, "size": 104857600}]}
  %pallas_call.740 = bf16[1,32,4,2,128]{4,3,2,1,0} get-tuple-element(%pallas_call.739), index=0, metadata={op_name="RPA-bq_32-bkvp_64-p_32/pallas_call" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/kernels/ragged_paged_attention/v3/kernel.py" source_line=1442 source_end_line=1442 source_column=31 source_end_column=74}
  %reshape.742 = bf16[32,8,128]{2,1,0} reshape(%pallas_call.740), metadata={op_name="reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/kernels/ragged_paged_attention/v3/kernel.py" source_line=965 source_end_line=966 source_column=63 source_end_column=60}
  %pallas_call.741 = bf16[14813,32,1,2,128]{4,3,2,1,0} get-tuple-element(%pallas_call.739), index=1, metadata={op_name="RPA-bq_32-bkvp_64-p_32/pallas_call" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/kernels/ragged_paged_attention/v3/kernel.py" source_line=1442 source_end_line=1442 source_column=31 source_end_column=74}
  ROOT %tuple.743 = (bf16[32,8,128]{2,1,0}, bf16[14813,32,1,2,128]{4,3,2,1,0}) tuple(%reshape.742, %pallas_call.741)
}

%xla.sdy.manual_computation_body.749 (shard_map.701: bf16[32,8,128], shard_map.702: bf16[32,1,128], shard_map.703: bf16[32,1,128], shard_map.704: bf16[14813,32,1,2,128], shard_map.705: s32[256], shard_map.706: s32[131072], shard_map.707: s32[257], shard_map.708: s32[3]) -> (bf16[32,8,128], bf16[14813,32,1,2,128]) {
  %shard_map.701 = bf16[32,8,128]{2,1,0} parameter(0), metadata={op_name="shard_map"}
  %shard_map.702 = bf16[32,1,128]{2,1,0} parameter(1), metadata={op_name="shard_map"}
  %shard_map.703 = bf16[32,1,128]{2,1,0} parameter(2), metadata={op_name="shard_map"}
  %shard_map.704 = bf16[14813,32,1,2,128]{4,3,2,1,0} parameter(3), metadata={op_name="shard_map"}
  %shard_map.705 = s32[256]{0} parameter(4), metadata={op_name="shard_map"}
  %shard_map.706 = s32[131072]{0} parameter(5), metadata={op_name="shard_map"}
  %shard_map.707 = s32[257]{0} parameter(6), metadata={op_name="shard_map"}
  %shard_map.708 = s32[3]{0} parameter(7), metadata={op_name="shard_map"}
  %jit_ragged_paged_attention_.745 = (bf16[32,8,128]{2,1,0}, bf16[14813,32,1,2,128]{4,3,2,1,0}) call(%shard_map.701, %shard_map.702, %shard_map.703, %shard_map.704, %shard_map.705, /*index=5*/%shard_map.706, %shard_map.707, %shard_map.708), to_apply=%ragged_paged_attention.744, metadata={op_name="jit(ragged_paged_attention)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=293 source_end_line=300 source_column=15 source_end_column=9}
  %jit_ragged_paged_attention_.746 = bf16[32,8,128]{2,1,0} get-tuple-element(%jit_ragged_paged_attention_.745), index=0, metadata={op_name="jit(ragged_paged_attention)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=293 source_end_line=300 source_column=15 source_end_column=9}
  %jit_ragged_paged_attention_.747 = bf16[14813,32,1,2,128]{4,3,2,1,0} get-tuple-element(%jit_ragged_paged_attention_.745), index=1, metadata={op_name="jit(ragged_paged_attention)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=293 source_end_line=300 source_column=15 source_end_column=9}
  ROOT %tuple.748 = (bf16[32,8,128]{2,1,0}, bf16[14813,32,1,2,128]{4,3,2,1,0}) tuple(%jit_ragged_paged_attention_.746, %jit_ragged_paged_attention_.747)
}

%_ragged_paged_attention.757 (Arg_0.684: bf16[32,32,128], Arg_1.685: bf16[32,4,128], Arg_2.686: bf16[32,4,128], Arg_3.687: bf16[14813,32,4,2,128], Arg_4.688: s32[256], Arg_5.689: s32[131072], Arg_6.690: s32[257], Arg_7.691: s32[3]) -> (bf16[32,32,128], bf16[14813,32,4,2,128]) {
  %Arg_0.684 = bf16[32,32,128]{2,1,0} parameter(0)
  %Arg_1.685 = bf16[32,4,128]{2,1,0} parameter(1)
  %Arg_2.686 = bf16[32,4,128]{2,1,0} parameter(2)
  %Arg_3.687 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(3)
  %Arg_4.688 = s32[256]{0} parameter(4)
  %Arg_5.689 = s32[131072]{0} parameter(5)
  %Arg_6.690 = s32[257]{0} parameter(6)
  %Arg_7.691 = s32[3]{0} parameter(7)
  %shard_map.692 = (bf16[32,8,128]{2,1,0}, bf16[32,1,128]{2,1,0}, bf16[32,1,128]{2,1,0}, bf16[14813,32,1,2,128]{4,3,2,1,0}, s32[256]{0}, /*index=5*/s32[131072]{0}, s32[257]{0}, s32[3]{0}) custom-call(%Arg_0.684, %Arg_1.685, %Arg_2.686, %Arg_3.687, %Arg_4.688, /*index=5*/%Arg_5.689, %Arg_6.690, %Arg_7.691), custom_call_target="xla.sdy.GlobalToLocalShape", custom_call_has_side_effect=true, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {}, {\"model\"}, {}, {}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %shard_map.693 = bf16[32,8,128]{2,1,0} get-tuple-element(%shard_map.692), index=0, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {}, {\"model\"}, {}, {}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %shard_map.694 = bf16[32,1,128]{2,1,0} get-tuple-element(%shard_map.692), index=1, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {}, {\"model\"}, {}, {}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %shard_map.695 = bf16[32,1,128]{2,1,0} get-tuple-element(%shard_map.692), index=2, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {}, {\"model\"}, {}, {}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %shard_map.696 = bf16[14813,32,1,2,128]{4,3,2,1,0} get-tuple-element(%shard_map.692), index=3, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {}, {\"model\"}, {}, {}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %shard_map.697 = s32[256]{0} get-tuple-element(%shard_map.692), index=4, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {}, {\"model\"}, {}, {}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %shard_map.698 = s32[131072]{0} get-tuple-element(%shard_map.692), index=5, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {}, {\"model\"}, {}, {}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %shard_map.699 = s32[257]{0} get-tuple-element(%shard_map.692), index=6, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {}, {\"model\"}, {}, {}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %shard_map.700 = s32[3]{0} get-tuple-element(%shard_map.692), index=7, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {}, {\"model\"}, {}, {}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %shard_map.750 = (bf16[32,8,128]{2,1,0}, bf16[14813,32,1,2,128]{4,3,2,1,0}) call(%shard_map.693, %shard_map.694, %shard_map.695, %shard_map.696, %shard_map.697, /*index=5*/%shard_map.698, %shard_map.699, %shard_map.700), to_apply=%xla.sdy.manual_computation_body.749, frontend_attributes={inlineable="false"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %shard_map.751 = bf16[32,8,128]{2,1,0} get-tuple-element(%shard_map.750), index=0, frontend_attributes={inlineable="false"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %shard_map.752 = bf16[14813,32,1,2,128]{4,3,2,1,0} get-tuple-element(%shard_map.750), index=1, frontend_attributes={inlineable="false"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %shard_map.753 = (bf16[32,32,128]{2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}) custom-call(%shard_map.751, %shard_map.752), custom_call_target="xla.sdy.LocalToGlobalShape", custom_call_has_side_effect=true, frontend_attributes={xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>",xla.sdy.out_shardings="#sdy.sharding_per_value<[<@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {}, {\"model\"}, {}, {}]>]>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %shard_map.754 = bf16[32,32,128]{2,1,0} get-tuple-element(%shard_map.753), index=0, frontend_attributes={xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>",xla.sdy.out_shardings="#sdy.sharding_per_value<[<@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {}, {\"model\"}, {}, {}]>]>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %shard_map.755 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%shard_map.753), index=1, frontend_attributes={xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>",xla.sdy.out_shardings="#sdy.sharding_per_value<[<@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}, {}, {\"model\"}, {}, {}]>]>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  ROOT %tuple.756 = (bf16[32,32,128]{2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}) tuple(%shard_map.754, %shard_map.755)
}

%_jax_attn_func.763 (Arg_0.673: bf16[14813,32,4,2,128], Arg_1.674: bf16[32,4096], Arg_2.675: bf16[32,512], Arg_3.676: bf16[32,512], Arg_4.677: s32[131072], Arg_5.678: s32[256], Arg_6.679: s32[257], Arg_7.680: s32[3]) -> (bf16[14813,32,4,2,128], bf16[32,4096]) {
  %Arg_1.674 = bf16[32,4096]{1,0} parameter(1)
  %reshape.681 = bf16[32,32,128]{2,1,0} reshape(%Arg_1.674), metadata={op_name="reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=161 source_end_line=161 source_column=8 source_end_column=46}
  %Arg_2.675 = bf16[32,512]{1,0} parameter(2)
  %reshape.682 = bf16[32,4,128]{2,1,0} reshape(%Arg_2.675), metadata={op_name="reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=163 source_end_line=163 source_column=8 source_end_column=49}
  %Arg_3.676 = bf16[32,512]{1,0} parameter(3)
  %reshape.683 = bf16[32,4,128]{2,1,0} reshape(%Arg_3.676), metadata={op_name="reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=164 source_end_line=164 source_column=8 source_end_column=49}
  %Arg_0.673 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(0)
  %Arg_5.678 = s32[256]{0} parameter(5)
  %Arg_4.677 = s32[131072]{0} parameter(4)
  %Arg_6.679 = s32[257]{0} parameter(6)
  %Arg_7.680 = s32[3]{0} parameter(7)
  %jit__ragged_paged_attention_.758 = (bf16[32,32,128]{2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}) call(%reshape.681, %reshape.682, %reshape.683, %Arg_0.673, %Arg_5.678, /*index=5*/%Arg_4.677, %Arg_6.679, %Arg_7.680), to_apply=%_ragged_paged_attention.757, metadata={op_name="jit(_ragged_paged_attention)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %jit__ragged_paged_attention_.760 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__ragged_paged_attention_.758), index=1, metadata={op_name="jit(_ragged_paged_attention)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %jit__ragged_paged_attention_.759 = bf16[32,32,128]{2,1,0} get-tuple-element(%jit__ragged_paged_attention_.758), index=0, metadata={op_name="jit(_ragged_paged_attention)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/jax/attention_interface.py" source_line=343 source_end_line=354 source_column=23 source_end_column=9}
  %reshape.761 = bf16[32,4096]{1,0} reshape(%jit__ragged_paged_attention_.759), metadata={op_name="reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=182 source_end_line=182 source_column=14 source_end_column=51}
  ROOT %tuple.762 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) tuple(%jit__ragged_paged_attention_.760, %reshape.761)
}

%region_4.776 (reduce_sum.773: f32[], reduce_sum.774: f32[]) -> f32[] {
  %reduce_sum.773 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.774 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.775 = f32[] add(%reduce_sum.773, %reduce_sum.774), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_5.818 (reduce_max.815: f32[], reduce_max.816: f32[]) -> f32[] {
  %reduce_max.815 = f32[] parameter(0), metadata={op_name="reduce_max"}
  %reduce_max.816 = f32[] parameter(1), metadata={op_name="reduce_max"}
  ROOT %reduce_max.817 = f32[] maximum(%reduce_max.815, %reduce_max.816), metadata={op_name="reduce_max" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
}

%region_6.830 (reduce_sum.827: f32[], reduce_sum.828: f32[]) -> f32[] {
  %reduce_sum.827 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.828 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.829 = f32[] add(%reduce_sum.827, %reduce_sum.828), metadata={op_name="reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
}

%region_7.843 (reduce_sum.840: f32[], reduce_sum.841: f32[]) -> f32[] {
  %reduce_sum.840 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.841 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.842 = f32[] add(%reduce_sum.840, %reduce_sum.841), metadata={op_name="reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=312 source_end_line=312 source_column=38 source_end_column=78}
}

%region_8.859 (sort.854: s32[], sort.855: s32[], sort.856: s32[], sort.857: s32[]) -> pred[] {
  %sort.856 = s32[] parameter(2), metadata={op_name="sort"}
  %sort.857 = s32[] parameter(3), metadata={op_name="sort"}
  %sort.854 = s32[] parameter(0), metadata={op_name="sort"}
  %sort.855 = s32[] parameter(1), metadata={op_name="sort"}
  ROOT %lt_to.858 = pred[] compare(%sort.854, %sort.855), direction=LT, metadata={op_name="lt_to" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=316 source_end_line=316 source_column=27 source_end_column=57}
}

%argsort.863 (Arg_0.852: s32[256]) -> s32[256] {
  %Arg_0.852 = s32[256]{0} parameter(0)
  %iota.853 = s32[256]{0} iota(), iota_dimension=0, metadata={op_name="iota" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=316 source_end_line=316 source_column=27 source_end_column=57}
  %sort.860 = (s32[256]{0}, s32[256]{0}) sort(%Arg_0.852, %iota.853), dimensions={0}, is_stable=true, to_apply=%region_8.859, metadata={op_name="sort" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=316 source_end_line=316 source_column=27 source_end_column=57}
  %sort.861 = s32[256]{0} get-tuple-element(%sort.860), index=0, metadata={op_name="sort" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=316 source_end_line=316 source_column=27 source_end_column=57}
  ROOT %sort.862 = s32[256]{0} get-tuple-element(%sort.860), index=1, metadata={op_name="sort" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=316 source_end_line=316 source_column=27 source_end_column=57}
}

%region_9.872 (sort.867: s32[], sort.868: s32[], sort.869: s32[], sort.870: s32[]) -> pred[] {
  %sort.869 = s32[] parameter(2), metadata={op_name="sort"}
  %sort.870 = s32[] parameter(3), metadata={op_name="sort"}
  %sort.867 = s32[] parameter(0), metadata={op_name="sort"}
  %sort.868 = s32[] parameter(1), metadata={op_name="sort"}
  ROOT %lt_to.871 = pred[] compare(%sort.867, %sort.868), direction=LT, metadata={op_name="lt_to" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=317 source_end_line=317 source_column=34 source_end_column=67}
}

%argsort_93.876 (Arg_0.865: s32[256]) -> s32[256] {
  %Arg_0.865 = s32[256]{0} parameter(0)
  %iota.866 = s32[256]{0} iota(), iota_dimension=0, metadata={op_name="iota" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=317 source_end_line=317 source_column=34 source_end_column=67}
  %sort.873 = (s32[256]{0}, s32[256]{0}) sort(%Arg_0.865, %iota.866), dimensions={0}, is_stable=true, to_apply=%region_9.872, metadata={op_name="sort" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=317 source_end_line=317 source_column=34 source_end_column=67}
  %sort.874 = s32[256]{0} get-tuple-element(%sort.873), index=0, metadata={op_name="sort" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=317 source_end_line=317 source_column=34 source_end_column=67}
  ROOT %sort.875 = s32[256]{0} get-tuple-element(%sort.873), index=1, metadata={op_name="sort" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=317 source_end_line=317 source_column=34 source_end_column=67}
}

%clip.890 (Arg_0.886: s32[256], Arg_1.887: s32[]) -> s32[256] {
  %Arg_1.887 = s32[] parameter(1)
  %max.888 = s32[256]{0} broadcast(%Arg_1.887), dimensions={}, metadata={op_name="max" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=320 source_end_line=320 source_column=18 source_end_column=76}
  %Arg_0.886 = s32[256]{0} parameter(0)
  ROOT %max.889 = s32[256]{0} maximum(%max.888, %Arg_0.886), metadata={op_name="max" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=320 source_end_line=320 source_column=18 source_end_column=76}
}

%region_10.899 (scatter-add.896: s32[], scatter-add.897: s32[]) -> s32[] {
  %scatter-add.896 = s32[] parameter(0), metadata={op_name="scatter-add"}
  %scatter-add.897 = s32[] parameter(1), metadata={op_name="scatter-add"}
  ROOT %add.898 = s32[] add(%scatter-add.896, %scatter-add.897), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=320 source_end_line=320 source_column=18 source_end_column=76}
}

%region_11.964 (reduce_window_sum.961: s32[], reduce_window_sum.962: s32[]) -> s32[] {
  %reduce_window_sum.961 = s32[] parameter(0), metadata={op_name="reduce_window_sum"}
  %reduce_window_sum.962 = s32[] parameter(1), metadata={op_name="reduce_window_sum"}
  ROOT %reduce_window_sum.963 = s32[] add(%reduce_window_sum.961, %reduce_window_sum.962), metadata={op_name="reduce_window_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=126 source_end_line=126 source_column=15 source_end_column=38}
}

%cumsum_120.966 (make_group_metadata.959: s32[128]) -> s32[128] {
  %make_group_metadata.959 = s32[128]{0} parameter(0), metadata={op_name="make_group_metadata"}
  %constant.960 = s32[] constant(0)
  ROOT %reduce_window_sum.965 = s32[128]{0} reduce-window(%make_group_metadata.959, %constant.960), window={size=128 pad=127_0}, to_apply=%region_11.964, metadata={op_name="reduce_window_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=126 source_end_line=126 source_column=15 source_end_column=38}
}

%cumsum.968 (Arg_0.958: s32[128]) -> s32[128] {
  %Arg_0.958 = s32[128]{0} parameter(0)
  ROOT %make_group_metadata.967 = s32[128]{0} call(%Arg_0.958), to_apply=%cumsum_120.966, metadata={op_name="make_group_metadata" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=126 source_end_line=126 source_column=15 source_end_column=38}
}

%_where_130.994 (Arg_0.990: pred[128], Arg_1.991: s32[128], Arg_2.992: s32[128]) -> s32[128] {
  %Arg_0.990 = pred[128]{0} parameter(0)
  %Arg_1.991 = s32[128]{0} parameter(1)
  %Arg_2.992 = s32[128]{0} parameter(2)
  ROOT %select_n.993 = s32[128]{0} select(%Arg_0.990, %Arg_1.991, %Arg_2.992), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
}

%floor_divide.996 (Arg_0.973: s32[128], Arg_1.974: s32[]) -> s32[128] {
  %Arg_0.973 = s32[128]{0} parameter(0)
  %sign.981 = s32[128]{0} sign(%Arg_0.973), metadata={op_name="sign" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  %Arg_1.974 = s32[] parameter(1)
  %sign.982 = s32[] sign(%Arg_1.974), metadata={op_name="sign" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  %ne.983 = s32[128]{0} broadcast(%sign.982), dimensions={}, metadata={op_name="ne" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  %ne.984 = pred[128]{0} compare(%sign.981, %ne.983), direction=NE, metadata={op_name="ne" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  %rem.985 = s32[128]{0} broadcast(%Arg_1.974), dimensions={}, metadata={op_name="rem" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  %rem.986 = s32[128]{0} remainder(%Arg_0.973, %rem.985), metadata={op_name="rem" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  %constant.977 = s32[] constant(0)
  %ne.978 = s32[128]{0} broadcast(%constant.977), dimensions={}, metadata={op_name="ne" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  %ne.987 = pred[128]{0} compare(%rem.986, %ne.978), direction=NE, metadata={op_name="ne" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  %and.988 = pred[128]{0} and(%ne.984, %ne.987), metadata={op_name="and" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  %div.979 = s32[128]{0} broadcast(%Arg_1.974), dimensions={}, metadata={op_name="div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  %div.980 = s32[128]{0} divide(%Arg_0.973, %div.979), metadata={op_name="div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  %constant.975 = s32[] constant(1)
  %sub.976 = s32[128]{0} broadcast(%constant.975), dimensions={}, metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  %sub.989 = s32[128]{0} subtract(%div.980, %sub.976), metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  ROOT %jit__where_.995 = s32[128]{0} call(%and.988, %sub.989, %div.980), to_apply=%_where_130.994, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
}

%_where_136.1010 (Arg_0.1005: pred[128], Arg_1.1006: s32[], Arg_2.1007: s32[128]) -> s32[128] {
  %Arg_0.1005 = pred[128]{0} parameter(0)
  %Arg_1.1006 = s32[] parameter(1)
  %broadcast_in_dim.1008 = s32[128]{0} broadcast(%Arg_1.1006), dimensions={}, metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=154 source_end_line=154 source_column=24 source_end_column=75}
  %Arg_2.1007 = s32[128]{0} parameter(2)
  ROOT %select_n.1009 = s32[128]{0} select(%Arg_0.1005, %broadcast_in_dim.1008, %Arg_2.1007), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=154 source_end_line=154 source_column=24 source_end_column=75}
}

%_roll_static.1018 (Arg_0.1014: s32[128]) -> s32[128] {
  %Arg_0.1014 = s32[128]{0} parameter(0)
  %slice.1015 = s32[1]{0} slice(%Arg_0.1014), slice={[127:128]}, metadata={op_name="slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %slice.1016 = s32[127]{0} slice(%Arg_0.1014), slice={[0:127]}, metadata={op_name="slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  ROOT %concatenate.1017 = s32[128]{0} concatenate(%slice.1015, %slice.1016), dimensions={0}, metadata={op_name="concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
}

%region_12.1022 (scatter.1020: s32[], scatter.1021: s32[]) -> s32[] {
  %scatter.1020 = s32[] parameter(0), metadata={op_name="scatter"}
  ROOT %scatter.1021 = s32[] parameter(1), metadata={op_name="scatter"}
}

%region_13.1032 (scatter-add.1029: s32[], scatter-add.1030: s32[]) -> s32[] {
  %scatter-add.1029 = s32[] parameter(0), metadata={op_name="scatter-add"}
  %scatter-add.1030 = s32[] parameter(1), metadata={op_name="scatter-add"}
  ROOT %add.1031 = s32[] add(%scatter-add.1029, %scatter-add.1030), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
}

%region_14.1040 (reduce_window_sum.1037: s32[], reduce_window_sum.1038: s32[]) -> s32[] {
  %reduce_window_sum.1037 = s32[] parameter(0), metadata={op_name="reduce_window_sum"}
  %reduce_window_sum.1038 = s32[] parameter(1), metadata={op_name="reduce_window_sum"}
  ROOT %reduce_window_sum.1039 = s32[] add(%reduce_window_sum.1037, %reduce_window_sum.1038), metadata={op_name="reduce_window_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
}

%cumsum_150.1042 (make_group_metadata.1035: s32[129]) -> s32[129] {
  %make_group_metadata.1035 = s32[129]{0} parameter(0), metadata={op_name="make_group_metadata"}
  %constant.1036 = s32[] constant(0)
  ROOT %reduce_window_sum.1041 = s32[129]{0} reduce-window(%make_group_metadata.1035, %constant.1036), window={size=129 pad=128_0}, to_apply=%region_14.1040, metadata={op_name="reduce_window_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
}

%cumsum_149.1044 (Arg_0.1034: s32[129]) -> s32[129] {
  %Arg_0.1034 = s32[129]{0} parameter(0)
  ROOT %make_group_metadata.1043 = s32[129]{0} call(%Arg_0.1034), to_apply=%cumsum_150.1042, metadata={op_name="make_group_metadata" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
}

%_where_156.1066 (Arg_0.1062: pred[129], Arg_1.1063: s32[129], Arg_2.1064: s32[129]) -> s32[129] {
  %Arg_0.1062 = pred[129]{0} parameter(0)
  %Arg_1.1063 = s32[129]{0} parameter(1)
  %Arg_2.1064 = s32[129]{0} parameter(2)
  ROOT %select_n.1065 = s32[129]{0} select(%Arg_0.1062, %Arg_1.1063, %Arg_2.1064), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
}

%region_15.1075 (reduce_and.1072: pred[], reduce_and.1073: pred[]) -> pred[] {
  %reduce_and.1072 = pred[] parameter(0), metadata={op_name="reduce_and"}
  %reduce_and.1073 = pred[] parameter(1), metadata={op_name="reduce_and"}
  ROOT %reduce_and.1074 = pred[] and(%reduce_and.1072, %reduce_and.1073), metadata={op_name="reduce_and" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
}

%_take_153.1079 (Arg_0.1047: s32[128], Arg_1.1048: s32[129]) -> s32[129] {
  %Arg_1.1048 = s32[129]{0} parameter(1)
  %constant.1058 = s32[] constant(0)
  %lt.1059 = s32[129]{0} broadcast(%constant.1058), dimensions={}, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %lt.1060 = pred[129]{0} compare(%Arg_1.1048, %lt.1059), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %constant.1055 = s32[] constant(128)
  %add.1056 = s32[129]{0} broadcast(%constant.1055), dimensions={}, metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %add.1061 = s32[129]{0} add(%Arg_1.1048, %add.1056), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %jit__where_.1067 = s32[129]{0} call(%lt.1060, %add.1061, %Arg_1.1048), to_apply=%_where_156.1066, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %broadcast_in_dim.1068 = s32[129,1]{1,0} reshape(%jit__where_.1067), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %constant.1053 = s32[] constant(0)
  %ge.1054 = s32[129,1]{1,0} broadcast(%constant.1053), dimensions={}, metadata={op_name="ge" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %ge.1069 = pred[129,1]{1,0} compare(%broadcast_in_dim.1068, %ge.1054), direction=GE, metadata={op_name="ge" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %constant.1051 = s32[] constant(127)
  %le.1052 = s32[129,1]{1,0} broadcast(%constant.1051), dimensions={}, metadata={op_name="le" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %le.1070 = pred[129,1]{1,0} compare(%broadcast_in_dim.1068, %le.1052), direction=LE, metadata={op_name="le" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %and.1071 = pred[129,1]{1,0} and(%ge.1069, %le.1070), metadata={op_name="and" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %constant.1057 = pred[] constant(true)
  %reduce_and.1076 = pred[129]{0} reduce(%and.1071, %constant.1057), dimensions={1}, to_apply=%region_15.1075, metadata={op_name="reduce_and" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %Arg_0.1047 = s32[128]{0} parameter(0)
  %gather.1077 = s32[129]{0} gather(%Arg_0.1047, %broadcast_in_dim.1068), offset_dims={}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1}, metadata={op_name="gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %constant.1049 = s32[] constant(-2147483648)
  %broadcast_in_dim.1050 = s32[129]{0} broadcast(%constant.1049), dimensions={}, metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  ROOT %select_n.1078 = s32[129]{0} select(%reduce_and.1076, %gather.1077, %broadcast_in_dim.1050), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
}

%_where_169.1093 (Arg_0.1089: pred[], Arg_1.1090: s32[], Arg_2.1091: s32[]) -> s32[] {
  %Arg_0.1089 = pred[] parameter(0)
  %Arg_1.1090 = s32[] parameter(1)
  %Arg_2.1091 = s32[] parameter(2)
  ROOT %select_n.1092 = s32[] select(%Arg_0.1089, %Arg_1.1090, %Arg_2.1091), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
}

%remainder.1106 (Arg_0.1082: s32[128], Arg_1.1083: s32[]) -> s32[128] {
  %Arg_0.1082 = s32[128]{0} parameter(0)
  %Arg_1.1083 = s32[] parameter(1)
  %constant.1087 = s32[] constant(0)
  %eq.1088 = pred[] compare(%Arg_1.1083, %constant.1087), direction=EQ, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
  %constant.1086 = s32[] constant(1)
  %jit__where_.1094 = s32[] call(%eq.1088, %constant.1086, %Arg_1.1083), to_apply=%_where_169.1093, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
  %rem.1095 = s32[128]{0} broadcast(%jit__where_.1094), dimensions={}, metadata={op_name="rem" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
  %rem.1096 = s32[128]{0} remainder(%Arg_0.1082, %rem.1095), metadata={op_name="rem" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
  %constant.1084 = s32[] constant(0)
  %broadcast.1085 = s32[128]{0} broadcast(%constant.1084), dimensions={}
  %lt.1098 = pred[128]{0} compare(%rem.1096, %broadcast.1085), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
  %lt.1099 = pred[] compare(%jit__where_.1094, %constant.1087), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
  %ne.1100 = pred[128]{0} broadcast(%lt.1099), dimensions={}, metadata={op_name="ne" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
  %ne.1101 = pred[128]{0} compare(%lt.1098, %ne.1100), direction=NE, metadata={op_name="ne" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
  %ne.1097 = pred[128]{0} compare(%rem.1096, %broadcast.1085), direction=NE, metadata={op_name="ne" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
  %and.1102 = pred[128]{0} and(%ne.1101, %ne.1097), metadata={op_name="and" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
  %add.1103 = s32[128]{0} broadcast(%jit__where_.1094), dimensions={}, metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
  %add.1104 = s32[128]{0} add(%rem.1096, %add.1103), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
  ROOT %select_n.1105 = s32[128]{0} select(%and.1102, %add.1104, %rem.1096), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
}

%region_16.1121 (reduce_max.1118: f32[], reduce_max.1119: f32[]) -> f32[] {
  %reduce_max.1118 = f32[] parameter(0), metadata={op_name="reduce_max"}
  %reduce_max.1119 = f32[] parameter(1), metadata={op_name="reduce_max"}
  ROOT %reduce_max.1120 = f32[] maximum(%reduce_max.1118, %reduce_max.1119), metadata={op_name="reduce_max" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
}

%region_17.1126 (reduce_min.1123: f32[], reduce_min.1124: f32[]) -> f32[] {
  %reduce_min.1123 = f32[] parameter(0), metadata={op_name="reduce_min"}
  %reduce_min.1124 = f32[] parameter(1), metadata={op_name="reduce_min"}
  ROOT %reduce_min.1125 = f32[] minimum(%reduce_min.1123, %reduce_min.1124), metadata={op_name="reduce_min" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
}

%_ptp.1129 (Arg_0.1115: f32[2]) -> f32[] {
  %Arg_0.1115 = f32[2]{0} parameter(0)
  %constant.1117 = f32[] constant(-inf)
  %reduce_max.1122 = f32[] reduce(%Arg_0.1115, %constant.1117), dimensions={0}, to_apply=%region_16.1121, metadata={op_name="reduce_max" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.1116 = f32[] constant(inf)
  %reduce_min.1127 = f32[] reduce(%Arg_0.1115, %constant.1116), dimensions={0}, to_apply=%region_17.1126, metadata={op_name="reduce_min" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  ROOT %sub.1128 = f32[] subtract(%reduce_max.1122, %reduce_min.1127), metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
}

%_where_182.1136 (Arg_0.1132: pred[], Arg_1.1133: f32[], Arg_2.1134: f32[]) -> f32[] {
  %Arg_0.1132 = pred[] parameter(0)
  %Arg_1.1133 = f32[] parameter(1)
  %Arg_2.1134 = f32[] parameter(2)
  ROOT %select_n.1135 = f32[] select(%Arg_0.1132, %Arg_1.1133, %Arg_2.1134), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
}

%_linspace.1163 (Arg_0.1141: f32[], Arg_1.1142: f32[]) -> f32[3] {
  %Arg_0.1141 = f32[] parameter(0)
  %reshape.1149 = f32[1]{0} reshape(%Arg_0.1141), metadata={op_name="reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %mul.1151 = f32[1]{0} broadcast(%reshape.1149), dimensions={0}, metadata={op_name="mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %mul.1152 = f32[] reshape(%mul.1151), metadata={op_name="mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %mul.1153 = f32[2]{0} broadcast(%mul.1152), dimensions={}, metadata={op_name="mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.1143 = f32[] constant(1)
  %broadcast.1144 = f32[2]{0} broadcast(%constant.1143), dimensions={}
  %iota.1147 = f32[2]{0} iota(), iota_dimension=0, metadata={op_name="iota" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.1145 = f32[] constant(2)
  %broadcast.1146 = f32[2]{0} broadcast(%constant.1145), dimensions={}
  %div.1148 = f32[2]{0} divide(%iota.1147, %broadcast.1146), metadata={op_name="div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %sub.1150 = f32[2]{0} subtract(%broadcast.1144, %div.1148), metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %mul.1154 = f32[2]{0} multiply(%mul.1153, %sub.1150), metadata={op_name="mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %Arg_1.1142 = f32[] parameter(1)
  %reshape.1155 = f32[1]{0} reshape(%Arg_1.1142), metadata={op_name="reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %mul.1156 = f32[1]{0} broadcast(%reshape.1155), dimensions={0}, metadata={op_name="mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %mul.1157 = f32[] reshape(%mul.1156), metadata={op_name="mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %mul.1158 = f32[2]{0} broadcast(%mul.1157), dimensions={}, metadata={op_name="mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %mul.1159 = f32[2]{0} multiply(%mul.1158, %div.1148), metadata={op_name="mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %add.1160 = f32[2]{0} add(%mul.1154, %mul.1159), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %broadcast_in_dim.1161 = f32[1]{0} reshape(%Arg_1.1142), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  ROOT %concatenate.1162 = f32[3]{0} concatenate(%add.1160, %broadcast_in_dim.1161), dimensions={0}, metadata={op_name="concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
}

%_where_207.1217 (Arg_0.1213: pred[128], Arg_1.1214: s32[128], Arg_2.1215: s32[128]) -> s32[128] {
  %Arg_0.1213 = pred[128]{0} parameter(0)
  %Arg_1.1214 = s32[128]{0} parameter(1)
  %Arg_2.1215 = s32[128]{0} parameter(2)
  ROOT %select_n.1216 = s32[128]{0} select(%Arg_0.1213, %Arg_1.1214, %Arg_2.1215), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
}

%_where_209.1223 (Arg_0.1219: pred[128], Arg_1.1220: s32[128], Arg_2.1221: s32[128]) -> s32[128] {
  %Arg_0.1219 = pred[128]{0} parameter(0)
  %Arg_1.1220 = s32[128]{0} parameter(1)
  %Arg_2.1221 = s32[128]{0} parameter(2)
  ROOT %select_n.1222 = s32[128]{0} select(%Arg_0.1219, %Arg_1.1220, %Arg_2.1221), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
}

%closed_call.1226 (Arg_0.1179: f32[3], Arg_1.1180: f32[128], Arg_2.1181: s32[128], Arg_3.1182: s32[128]) -> (s32[128], s32[128]) {
  %Arg_1.1180 = f32[128]{0} parameter(1)
  %ne.1206 = pred[128]{0} compare(%Arg_1.1180, %Arg_1.1180), direction=NE, metadata={op_name="ne" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.1183 = f32[] constant(nan)
  %broadcast.1184 = f32[128]{0} broadcast(%constant.1183), dimensions={}
  %constant.1185 = f32[] constant(0)
  %broadcast.1186 = f32[128]{0} broadcast(%constant.1185), dimensions={}
  %eq.1204 = pred[128]{0} compare(%Arg_1.1180, %broadcast.1186), direction=EQ, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %select_n.1205 = f32[128]{0} select(%eq.1204, %broadcast.1186, %Arg_1.1180), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %select_n.1207 = f32[128]{0} select(%ne.1206, %broadcast.1184, %select_n.1205), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %Arg_0.1179 = f32[3]{0} parameter(0)
  %Arg_2.1181 = s32[128]{0} parameter(2)
  %convert_element_type.1193 = u32[128]{0} convert(%Arg_2.1181), metadata={op_name="convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %Arg_3.1182 = s32[128]{0} parameter(3)
  %convert_element_type.1194 = u32[128]{0} convert(%Arg_3.1182), metadata={op_name="convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %add.1195 = u32[128]{0} add(%convert_element_type.1193, %convert_element_type.1194), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.1191 = u32[] constant(2)
  %div.1192 = u32[128]{0} broadcast(%constant.1191), dimensions={}, metadata={op_name="div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %div.1196 = u32[128]{0} divide(%add.1195, %div.1192), metadata={op_name="div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %convert_element_type.1197 = s32[128]{0} convert(%div.1196), metadata={op_name="convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.1189 = s32[] constant(0)
  %lt.1190 = s32[128]{0} broadcast(%constant.1189), dimensions={}, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %lt.1198 = pred[128]{0} compare(%convert_element_type.1197, %lt.1190), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.1187 = s32[] constant(3)
  %add.1188 = s32[128]{0} broadcast(%constant.1187), dimensions={}, metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %add.1199 = s32[128]{0} add(%convert_element_type.1197, %add.1188), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %select_n.1200 = s32[128]{0} select(%lt.1198, %add.1199, %convert_element_type.1197), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %broadcast_in_dim.1201 = s32[128,1]{1,0} reshape(%select_n.1200), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %gather.1202 = f32[128,1]{1,0} gather(%Arg_0.1179, %broadcast_in_dim.1201), offset_dims={1}, collapsed_slice_dims={}, start_index_map={0}, index_vector_dim=1, slice_sizes={1}, metadata={op_name="gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %squeeze.1203 = f32[128]{0} reshape(%gather.1202), metadata={op_name="squeeze" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %ne.1210 = pred[128]{0} compare(%squeeze.1203, %squeeze.1203), direction=NE, metadata={op_name="ne" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %eq.1208 = pred[128]{0} compare(%squeeze.1203, %broadcast.1186), direction=EQ, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %select_n.1209 = f32[128]{0} select(%eq.1208, %broadcast.1186, %squeeze.1203), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %select_n.1211 = f32[128]{0} select(%ne.1210, %broadcast.1184, %select_n.1209), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %lt_to.1212 = pred[128]{0} compare(%select_n.1207, %select_n.1211), direction=LT, type=TOTALORDER, metadata={op_name="lt_to" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %jit__where_.1218 = s32[128]{0} call(%lt_to.1212, %Arg_2.1181, %convert_element_type.1197), to_apply=%_where_207.1217, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %jit__where_.1224 = s32[128]{0} call(%lt_to.1212, %convert_element_type.1197, %Arg_3.1182), to_apply=%_where_209.1223, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  ROOT %tuple.1225 = (s32[128]{0}, s32[128]{0}) tuple(%jit__where_.1218, %jit__where_.1224)
}

%region_18.1232 (arg_tuple.1172: (s32[], s32[128], s32[128], f32[3], f32[128])) -> (s32[], s32[128], s32[128], f32[3], f32[128]) {
  %arg_tuple.1172 = (s32[], s32[128]{0}, s32[128]{0}, f32[3]{0}, f32[128]{0}) parameter(0)
  %get-tuple-element.1173 = s32[] get-tuple-element(%arg_tuple.1172), index=0
  %constant.1178 = s32[] constant(1)
  %add.1230 = s32[] add(%get-tuple-element.1173, %constant.1178), metadata={op_name="vmap()/while/body/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %get-tuple-element.1176 = f32[3]{0} get-tuple-element(%arg_tuple.1172), index=3
  %get-tuple-element.1177 = f32[128]{0} get-tuple-element(%arg_tuple.1172), index=4
  %get-tuple-element.1174 = s32[128]{0} get-tuple-element(%arg_tuple.1172), index=1
  %get-tuple-element.1175 = s32[128]{0} get-tuple-element(%arg_tuple.1172), index=2
  %closed_call.1227 = (s32[128]{0}, s32[128]{0}) call(%get-tuple-element.1176, %get-tuple-element.1177, %get-tuple-element.1174, %get-tuple-element.1175), to_apply=%closed_call.1226, metadata={op_name="vmap()/while/body/closed_call" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %closed_call.1228 = s32[128]{0} get-tuple-element(%closed_call.1227), index=0, metadata={op_name="vmap()/while/body/closed_call" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %closed_call.1229 = s32[128]{0} get-tuple-element(%closed_call.1227), index=1, metadata={op_name="vmap()/while/body/closed_call" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  ROOT %tuple.1231 = (s32[], s32[128]{0}, s32[128]{0}, f32[3]{0}, f32[128]{0}) tuple(%add.1230, %closed_call.1228, %closed_call.1229, %get-tuple-element.1176, %get-tuple-element.1177)
}

%region_19.1241 (arg_tuple.1233: (s32[], s32[128], s32[128], f32[3], f32[128])) -> pred[] {
  %arg_tuple.1233 = (s32[], s32[128]{0}, s32[128]{0}, f32[3]{0}, f32[128]{0}) parameter(0)
  %get-tuple-element.1235 = s32[128]{0} get-tuple-element(%arg_tuple.1233), index=1
  %get-tuple-element.1236 = s32[128]{0} get-tuple-element(%arg_tuple.1233), index=2
  %get-tuple-element.1237 = f32[3]{0} get-tuple-element(%arg_tuple.1233), index=3
  %get-tuple-element.1238 = f32[128]{0} get-tuple-element(%arg_tuple.1233), index=4
  %get-tuple-element.1234 = s32[] get-tuple-element(%arg_tuple.1233), index=0
  %constant.1239 = s32[] constant(2)
  ROOT %lt.1240 = pred[] compare(%get-tuple-element.1234, %constant.1239), direction=LT, metadata={op_name="vmap()/while/cond/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
}

%searchsorted.1247 (Arg_0.1165: f32[3], Arg_1.1166: f32[128]) -> s32[128] {
  %constant.1167 = s32[] constant(0)
  %constant.1168 = s32[] constant(0)
  %broadcast_in_dim.1169 = s32[128]{0} broadcast(%constant.1168), dimensions={}, metadata={op_name="vmap()/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.1170 = s32[] constant(3)
  %broadcast_in_dim.1171 = s32[128]{0} broadcast(%constant.1170), dimensions={}, metadata={op_name="vmap()/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %Arg_0.1165 = f32[3]{0} parameter(0)
  %Arg_1.1166 = f32[128]{0} parameter(1)
  %while.1242 = (s32[], s32[128]{0}, s32[128]{0}, f32[3]{0}, f32[128]{0}) tuple(%constant.1167, %broadcast_in_dim.1169, %broadcast_in_dim.1171, %Arg_0.1165, %Arg_1.1166), metadata={op_name="vmap()/while" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %while.1243 = (s32[], s32[128]{0}, s32[128]{0}, f32[3]{0}, f32[128]{0}) while(%while.1242), condition=%region_19.1241, body=%region_18.1232, metadata={op_name="vmap()/while" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %while.1244 = s32[] get-tuple-element(%while.1243), index=0, metadata={op_name="vmap()/while" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %while.1245 = s32[128]{0} get-tuple-element(%while.1243), index=1, metadata={op_name="vmap()/while" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  ROOT %while.1246 = s32[128]{0} get-tuple-element(%while.1243), index=2, metadata={op_name="vmap()/while" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
}

%region_20.1261 (scatter-add.1258: f32[], scatter-add.1259: f32[]) -> f32[] {
  %scatter-add.1258 = f32[] parameter(0), metadata={op_name="scatter-add"}
  %scatter-add.1259 = f32[] parameter(1), metadata={op_name="scatter-add"}
  ROOT %add.1260 = f32[] add(%scatter-add.1258, %scatter-add.1259), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
}

%_roll_static_219.1271 (Arg_0.1267: s32[2]) -> s32[2] {
  %Arg_0.1267 = s32[2]{0} parameter(0)
  %slice.1268 = s32[1]{0} slice(%Arg_0.1267), slice={[1:2]}, metadata={op_name="slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %slice.1269 = s32[1]{0} slice(%Arg_0.1267), slice={[0:1]}, metadata={op_name="slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  ROOT %concatenate.1270 = s32[2]{0} concatenate(%slice.1268, %slice.1269), dimensions={0}, metadata={op_name="concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
}

%region_21.1275 (scatter.1273: s32[], scatter.1274: s32[]) -> s32[] {
  %scatter.1273 = s32[] parameter(0), metadata={op_name="scatter"}
  ROOT %scatter.1274 = s32[] parameter(1), metadata={op_name="scatter"}
}

%region_22.1283 (reduce_window_sum.1280: s32[], reduce_window_sum.1281: s32[]) -> s32[] {
  %reduce_window_sum.1280 = s32[] parameter(0), metadata={op_name="reduce_window_sum"}
  %reduce_window_sum.1281 = s32[] parameter(1), metadata={op_name="reduce_window_sum"}
  ROOT %reduce_window_sum.1282 = s32[] add(%reduce_window_sum.1280, %reduce_window_sum.1281), metadata={op_name="reduce_window_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
}

%cumsum_225.1285 (make_group_metadata.1278: s32[2]) -> s32[2] {
  %make_group_metadata.1278 = s32[2]{0} parameter(0), metadata={op_name="make_group_metadata"}
  %constant.1279 = s32[] constant(0)
  ROOT %reduce_window_sum.1284 = s32[2]{0} reduce-window(%make_group_metadata.1278, %constant.1279), window={size=2 pad=1_0}, to_apply=%region_22.1283, metadata={op_name="reduce_window_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
}

%cumsum_224.1287 (Arg_0.1277: s32[2]) -> s32[2] {
  %Arg_0.1277 = s32[2]{0} parameter(0)
  ROOT %make_group_metadata.1286 = s32[2]{0} call(%Arg_0.1277), to_apply=%cumsum_225.1285, metadata={op_name="make_group_metadata" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
}

%region_23.1296 (scatter-add.1293: s32[], scatter-add.1294: s32[]) -> s32[] {
  %scatter-add.1293 = s32[] parameter(0), metadata={op_name="scatter-add"}
  %scatter-add.1294 = s32[] parameter(1), metadata={op_name="scatter-add"}
  ROOT %add.1295 = s32[] add(%scatter-add.1293, %scatter-add.1294), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
}

%region_24.1323 (reduce_and.1320: pred[], reduce_and.1321: pred[]) -> pred[] {
  %reduce_and.1320 = pred[] parameter(0), metadata={op_name="reduce_and"}
  %reduce_and.1321 = pred[] parameter(1), metadata={op_name="reduce_and"}
  ROOT %reduce_and.1322 = pred[] and(%reduce_and.1320, %reduce_and.1321), metadata={op_name="reduce_and" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
}

%_take_233.1327 (Arg_0.1300: s32[2], Arg_1.1301: s32[129]) -> s32[129] {
  %Arg_1.1301 = s32[129]{0} parameter(1)
  %constant.1311 = s32[] constant(0)
  %lt.1312 = s32[129]{0} broadcast(%constant.1311), dimensions={}, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %lt.1313 = pred[129]{0} compare(%Arg_1.1301, %lt.1312), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %constant.1308 = s32[] constant(2)
  %add.1309 = s32[129]{0} broadcast(%constant.1308), dimensions={}, metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %add.1314 = s32[129]{0} add(%Arg_1.1301, %add.1309), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %jit__where_.1315 = s32[129]{0} call(%lt.1313, %add.1314, %Arg_1.1301), to_apply=%_where_156.1066, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %broadcast_in_dim.1316 = s32[129,1]{1,0} reshape(%jit__where_.1315), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %constant.1306 = s32[] constant(0)
  %ge.1307 = s32[129,1]{1,0} broadcast(%constant.1306), dimensions={}, metadata={op_name="ge" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %ge.1317 = pred[129,1]{1,0} compare(%broadcast_in_dim.1316, %ge.1307), direction=GE, metadata={op_name="ge" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %constant.1304 = s32[] constant(1)
  %le.1305 = s32[129,1]{1,0} broadcast(%constant.1304), dimensions={}, metadata={op_name="le" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %le.1318 = pred[129,1]{1,0} compare(%broadcast_in_dim.1316, %le.1305), direction=LE, metadata={op_name="le" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %and.1319 = pred[129,1]{1,0} and(%ge.1317, %le.1318), metadata={op_name="and" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %constant.1310 = pred[] constant(true)
  %reduce_and.1324 = pred[129]{0} reduce(%and.1319, %constant.1310), dimensions={1}, to_apply=%region_24.1323, metadata={op_name="reduce_and" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %Arg_0.1300 = s32[2]{0} parameter(0)
  %gather.1325 = s32[129]{0} gather(%Arg_0.1300, %broadcast_in_dim.1316), offset_dims={}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1}, metadata={op_name="gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %constant.1302 = s32[] constant(-2147483648)
  %broadcast_in_dim.1303 = s32[129]{0} broadcast(%constant.1302), dimensions={}, metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  ROOT %select_n.1326 = s32[129]{0} select(%reduce_and.1324, %gather.1325, %broadcast_in_dim.1303), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
}

%region_25.1335 (reduce_sum.1332: s32[], reduce_sum.1333: s32[]) -> s32[] {
  %reduce_sum.1332 = s32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1333 = s32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1334 = s32[] add(%reduce_sum.1332, %reduce_sum.1333), metadata={op_name="reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=244 source_end_line=244 source_column=24 source_end_column=55}
}

%remainder_243.1357 (Arg_0.1343: s32[], Arg_1.1344: s32[]) -> s32[] {
  %Arg_0.1343 = s32[] parameter(0)
  %Arg_1.1344 = s32[] parameter(1)
  %constant.1346 = s32[] constant(0)
  %eq.1347 = pred[] compare(%Arg_1.1344, %constant.1346), direction=EQ, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  %constant.1345 = s32[] constant(1)
  %jit__where_.1348 = s32[] call(%eq.1347, %constant.1345, %Arg_1.1344), to_apply=%_where_169.1093, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  %rem.1349 = s32[] remainder(%Arg_0.1343, %jit__where_.1348), metadata={op_name="rem" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  %lt.1351 = pred[] compare(%rem.1349, %constant.1346), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  %lt.1352 = pred[] compare(%jit__where_.1348, %constant.1346), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  %ne.1353 = pred[] compare(%lt.1351, %lt.1352), direction=NE, metadata={op_name="ne" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  %ne.1350 = pred[] compare(%rem.1349, %constant.1346), direction=NE, metadata={op_name="ne" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  %and.1354 = pred[] and(%ne.1353, %ne.1350), metadata={op_name="and" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  %add.1355 = s32[] add(%rem.1349, %jit__where_.1348), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  ROOT %select_n.1356 = s32[] select(%and.1354, %add.1355, %rem.1349), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
}

%_roll_dynamic.1365 (Arg_0.1338: s32[129], Arg_1.1339: s32[]) -> s32[129] {
  %Arg_0.1338 = s32[129]{0} parameter(0)
  %concatenate.1359 = s32[258]{0} concatenate(%Arg_0.1338, %Arg_0.1338), dimensions={0}, metadata={op_name="concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  %constant.1342 = s32[] constant(129)
  %Arg_1.1339 = s32[] parameter(1)
  %jit_remainder_.1358 = s32[] call(%Arg_1.1339, %constant.1342), to_apply=%remainder_243.1357, metadata={op_name="jit(remainder)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  %sub.1360 = s32[] subtract(%constant.1342, %jit_remainder_.1358), metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  %constant.1341 = s32[] constant(0)
  %lt.1361 = pred[] compare(%sub.1360, %constant.1341), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  %constant.1340 = s32[] constant(258)
  %add.1362 = s32[] add(%sub.1360, %constant.1340), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  %select_n.1363 = s32[] select(%lt.1361, %add.1362, %sub.1360), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  ROOT %dynamic_slice.1364 = s32[129]{0} dynamic-slice(%concatenate.1359, %select_n.1363), dynamic_slice_sizes={129}, metadata={op_name="dynamic_slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
}

%_where_255.1380 (Arg_0.1375: pred[128], Arg_1.1376: s32[128], Arg_2.1377: s32[]) -> s32[128] {
  %Arg_0.1375 = pred[128]{0} parameter(0)
  %Arg_1.1376 = s32[128]{0} parameter(1)
  %Arg_2.1377 = s32[] parameter(2)
  %broadcast_in_dim.1378 = s32[128]{0} broadcast(%Arg_2.1377), dimensions={}, metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=253 source_end_line=253 source_column=16 source_end_column=60}
  ROOT %select_n.1379 = s32[128]{0} select(%Arg_0.1375, %Arg_1.1376, %broadcast_in_dim.1378), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=253 source_end_line=253 source_column=16 source_end_column=60}
}

%region_26.1385 (reduce_sum.1382: s32[], reduce_sum.1383: s32[]) -> s32[] {
  %reduce_sum.1382 = s32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1383 = s32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1384 = s32[] add(%reduce_sum.1382, %reduce_sum.1383), metadata={op_name="reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=254 source_end_line=254 source_column=14 source_end_column=31}
}

%gmm.1388 (Arg_0.915: bf16[256,2048], Arg_1.916: bf16[128,384,2048], Arg_2.917: s32[128], Arg_3.918: s32[]) -> bf16[256,384] {
  %iota.1369 = s32[128]{0} iota(), iota_dimension=0, metadata={op_name="iota" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=251 source_end_line=251 source_column=9 source_end_column=48}
  %Arg_3.918 = s32[] parameter(3)
  %constant.953 = s32[] constant(128)
  %add.956 = s32[] add(%Arg_3.918, %constant.953), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=116 source_end_line=116 source_column=14 source_end_column=46}
  %constant.952 = s32[] constant(1)
  %sub.957 = s32[] subtract(%add.956, %constant.952), metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=116 source_end_line=116 source_column=14 source_end_column=46}
  %le.1370 = s32[128]{0} broadcast(%sub.957), dimensions={}, metadata={op_name="le" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=252 source_end_line=252 source_column=38 source_end_column=55}
  %le.1371 = pred[128]{0} compare(%iota.1369, %le.1370), direction=LE, metadata={op_name="le" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=252 source_end_line=252 source_column=38 source_end_column=55}
  %ge.1372 = s32[128]{0} broadcast(%Arg_3.918), dimensions={}, metadata={op_name="ge" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=252 source_end_line=252 source_column=57 source_end_column=76}
  %ge.1373 = pred[128]{0} compare(%iota.1369, %ge.1372), direction=GE, metadata={op_name="ge" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=252 source_end_line=252 source_column=57 source_end_column=76}
  %and.1374 = pred[128]{0} and(%le.1371, %ge.1373), metadata={op_name="and" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=252 source_end_line=252 source_column=22 source_end_column=77}
  %Arg_2.917 = s32[128]{0} parameter(2)
  %constant.942 = s32[] constant(0)
  %broadcast.943 = s32[128]{0} broadcast(%constant.942), dimensions={}
  %eq.1004 = pred[128]{0} compare(%Arg_2.917, %broadcast.943), direction=EQ, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=154 source_end_line=154 source_column=34 source_end_column=50}
  %constant.951 = s32[] constant(0)
  %jit_cumsum_.969 = s32[128]{0} call(%Arg_2.917), to_apply=%cumsum.968, metadata={op_name="jit(cumsum)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=126 source_end_line=126 source_column=15 source_end_column=38}
  %constant.946 = s32[] constant(128)
  %broadcast.947 = s32[128]{0} broadcast(%constant.946), dimensions={}
  %add.971 = s32[128]{0} add(%jit_cumsum_.969, %broadcast.947), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=25 source_end_column=40}
  %constant.944 = s32[] constant(1)
  %broadcast.945 = s32[128]{0} broadcast(%constant.944), dimensions={}
  %sub.972 = s32[128]{0} subtract(%add.971, %broadcast.945), metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=25 source_end_column=40}
  %jit_floor_divide_.997 = s32[128]{0} call(%sub.972, %constant.953), to_apply=%floor_divide.996, metadata={op_name="jit(floor_divide)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  %mul.998 = s32[128]{0} multiply(%jit_floor_divide_.997, %broadcast.947), metadata={op_name="mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  %constant.948 = s32[1]{0} constant({0})
  %slice.999 = s32[127]{0} slice(%jit_cumsum_.969), slice={[0:127]}, metadata={op_name="slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=144 source_end_line=144 source_column=38 source_end_column=53}
  %concatenate.1000 = s32[128]{0} concatenate(%constant.948, %slice.999), dimensions={0}, metadata={op_name="concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=143 source_end_line=145 source_column=17 source_end_column=3}
  %jit_floor_divide_.1001 = s32[128]{0} call(%concatenate.1000, %constant.953), to_apply=%floor_divide.996, metadata={op_name="jit(floor_divide)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=146 source_end_line=146 source_column=25 source_end_column=43}
  %mul.1002 = s32[128]{0} multiply(%jit_floor_divide_.1001, %broadcast.947), metadata={op_name="mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=146 source_end_line=146 source_column=25 source_end_column=43}
  %sub.1003 = s32[128]{0} subtract(%mul.998, %mul.1002), metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=153 source_end_line=153 source_column=24 source_end_column=65}
  %jit__where_.1011 = s32[128]{0} call(%eq.1004, %constant.951, %sub.1003), to_apply=%_where_136.1010, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=154 source_end_line=154 source_column=24 source_end_column=75}
  %jit_floor_divide_.1012 = s32[128]{0} call(%jit__where_.1011, %constant.953), to_apply=%floor_divide.996, metadata={op_name="jit(floor_divide)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=174 source_end_line=174 source_column=16 source_end_column=41}
  %jit__where_.1381 = s32[128]{0} call(%and.1374, %jit_floor_divide_.1012, %constant.951), to_apply=%_where_255.1380, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=253 source_end_line=253 source_column=16 source_end_column=60}
  %reduce_sum.1386 = s32[] reduce(%jit__where_.1381, %constant.951), dimensions={0}, to_apply=%region_26.1385, metadata={op_name="reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=254 source_end_line=254 source_column=14 source_end_column=31}
  %concatenate.970 = s32[129]{0} concatenate(%constant.948, %jit_cumsum_.969), dimensions={0}, metadata={op_name="concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=127 source_end_line=127 source_column=18 source_end_column=78}
  %iota.1013 = s32[128]{0} iota(), iota_dimension=0, metadata={op_name="iota" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=188 source_end_line=188 source_column=6 source_end_column=45}
  %constant.940 = s32[] constant(0)
  %broadcast.941 = s32[129]{0} broadcast(%constant.940), dimensions={}
  %jit__roll_static_.1019 = s32[128]{0} call(%jit_floor_divide_.1012), to_apply=%_roll_static.1018, metadata={op_name="jit(_roll_static)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %scatter.1023 = s32[128]{0} scatter(%jit__roll_static_.1019, %constant.948, %constant.951), update_window_dims={}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=0, indices_are_sorted=true, unique_indices=true, to_apply=%region_12.1022, metadata={op_name="scatter" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %jit_cumsum_.1024 = s32[128]{0} call(%scatter.1023), to_apply=%cumsum.968, metadata={op_name="jit(cumsum)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %lt.1025 = pred[128]{0} compare(%jit_cumsum_.1024, %broadcast.943), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %constant.938 = s32[] constant(129)
  %add.939 = s32[128]{0} broadcast(%constant.938), dimensions={}, metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %add.1026 = s32[128]{0} add(%jit_cumsum_.1024, %add.939), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %select_n.1027 = s32[128]{0} select(%lt.1025, %add.1026, %jit_cumsum_.1024), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %broadcast_in_dim.1028 = s32[128,1]{1,0} reshape(%select_n.1027), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %scatter-add.1033 = s32[129]{0} scatter(%broadcast.941, %broadcast_in_dim.1028, %broadcast.945), update_window_dims={}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=1, to_apply=%region_13.1032, metadata={op_name="scatter-add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %jit_cumsum_.1045 = s32[129]{0} call(%scatter-add.1033), to_apply=%cumsum_149.1044, metadata={op_name="jit(cumsum)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %constant.936 = s32[] constant(1)
  %broadcast.937 = s32[129]{0} broadcast(%constant.936), dimensions={}
  %sub.1046 = s32[129]{0} subtract(%jit_cumsum_.1045, %broadcast.937), metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %jit__take_.1080 = s32[129]{0} call(%iota.1013, %sub.1046), to_apply=%_take_153.1079, metadata={op_name="jit(_take)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %lt.1329 = s32[129]{0} broadcast(%Arg_3.918), dimensions={}, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=244 source_end_line=244 source_column=25 source_end_column=48}
  %lt.1330 = pred[129]{0} compare(%jit__take_.1080, %lt.1329), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=244 source_end_line=244 source_column=25 source_end_column=48}
  %convert_element_type.1331 = s32[129]{0} convert(%lt.1330), metadata={op_name="convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=244 source_end_line=244 source_column=24 source_end_column=55}
  %reduce_sum.1336 = s32[] reduce(%convert_element_type.1331, %constant.951), dimensions={0}, to_apply=%region_25.1335, metadata={op_name="reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=244 source_end_line=244 source_column=24 source_end_column=55}
  %neg.1337 = s32[] negate(%reduce_sum.1336), metadata={op_name="neg" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=40 source_end_column=60}
  %jit__roll_dynamic_.1366 = s32[129]{0} call(%jit__take_.1080, %neg.1337), to_apply=%_roll_dynamic.1365, metadata={op_name="jit(_roll_dynamic)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  %iota.1265 = s32[2]{0} iota(), iota_dimension=0, metadata={op_name="iota" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=233 source_end_line=233 source_column=6 source_end_column=42}
  %constant.929 = f32[] constant(0)
  %broadcast.930 = f32[3]{0} broadcast(%constant.929), dimensions={}
  %slice.1081 = s32[128]{0} slice(%concatenate.970), slice={[0:128]}, metadata={op_name="slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
  %jit_remainder_.1107 = s32[128]{0} call(%slice.1081, %constant.953), to_apply=%remainder.1106, metadata={op_name="jit(remainder)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
  %eq.1108 = pred[128]{0} compare(%jit_remainder_.1107, %broadcast.943), direction=EQ, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=6 source_end_column=36}
  %eq.1109 = pred[128]{0} compare(%Arg_2.917, %broadcast.943), direction=EQ, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=38 source_end_column=54}
  %or.1110 = pred[128]{0} or(%eq.1108, %eq.1109), metadata={op_name="or" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=212 source_end_line=214 source_column=22 source_end_column=3}
  %constant.950 = s32[] constant(2)
  %slice.1111 = s32[128]{0} slice(%concatenate.970), slice={[0:128]}, metadata={op_name="slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=222 source_end_line=222 source_column=34 source_end_column=52}
  %jit_floor_divide_.1112 = s32[128]{0} call(%slice.1111, %constant.953), to_apply=%floor_divide.996, metadata={op_name="jit(floor_divide)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=222 source_end_line=222 source_column=34 source_end_column=52}
  %jit__where_.1113 = s32[128]{0} call(%or.1110, %constant.950, %jit_floor_divide_.1112), to_apply=%_where_136.1010, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=221 source_end_line=223 source_column=21 source_end_column=3}
  %convert_element_type.1114 = f32[128]{0} convert(%jit__where_.1113), metadata={op_name="convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.954 = f32[2]{0} constant({0, 1})
  %jit__ptp_.1130 = f32[] call(%constant.954), to_apply=%_ptp.1129, metadata={op_name="jit(_ptp)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.949 = f32[] constant(0)
  %eq.1131 = pred[] compare(%jit__ptp_.1130, %constant.949), direction=EQ, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.933 = f32[] constant(-0.5)
  %jit__where_.1137 = f32[] call(%eq.1131, %constant.933, %constant.949), to_apply=%_where_182.1136, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %jit__ptp_.1138 = f32[] call(%constant.954), to_apply=%_ptp.1129, metadata={op_name="jit(_ptp)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %eq.1139 = pred[] compare(%jit__ptp_.1138, %constant.949), direction=EQ, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.932 = f32[] constant(1.5)
  %constant.931 = f32[] constant(1)
  %jit__where_.1140 = f32[] call(%eq.1139, %constant.932, %constant.931), to_apply=%_where_182.1136, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %jit__linspace_.1164 = f32[3]{0} call(%jit__where_.1137, %jit__where_.1140), to_apply=%_linspace.1163, metadata={op_name="jit(_linspace)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %dynamic_slice.1249 = f32[1]{0} slice(%jit__linspace_.1164), slice={[2:3]}, metadata={op_name="dynamic_slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %squeeze.1250 = f32[] reshape(%dynamic_slice.1249), metadata={op_name="squeeze" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %eq.1251 = f32[128]{0} broadcast(%squeeze.1250), dimensions={}, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %eq.1252 = pred[128]{0} compare(%convert_element_type.1114, %eq.1251), direction=EQ, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %jit_searchsorted_.1248 = s32[128]{0} call(%jit__linspace_.1164, %convert_element_type.1114), to_apply=%searchsorted.1247, metadata={op_name="jit(searchsorted)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %jit__where_.1253 = s32[128]{0} call(%eq.1252, %constant.950, %jit_searchsorted_.1248), to_apply=%_where_136.1010, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %lt.1254 = pred[128]{0} compare(%jit__where_.1253, %broadcast.943), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.927 = s32[] constant(3)
  %add.928 = s32[128]{0} broadcast(%constant.927), dimensions={}, metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %add.1255 = s32[128]{0} add(%jit__where_.1253, %add.928), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %select_n.1256 = s32[128]{0} select(%lt.1254, %add.1255, %jit__where_.1253), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %broadcast_in_dim.1257 = s32[128,1]{1,0} reshape(%select_n.1256), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.934 = f32[] constant(1)
  %broadcast_in_dim.935 = f32[128]{0} broadcast(%constant.934), dimensions={}, metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %scatter-add.1262 = f32[3]{0} scatter(%broadcast.930, %broadcast_in_dim.1257, %broadcast_in_dim.935), update_window_dims={}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=1, to_apply=%region_20.1261, metadata={op_name="scatter-add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %slice.1263 = f32[2]{0} slice(%scatter-add.1262), slice={[1:3]}, metadata={op_name="slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.925 = f32[] constant(1)
  %broadcast.926 = f32[2]{0} broadcast(%constant.925), dimensions={}
  %add.1264 = f32[2]{0} add(%slice.1263, %broadcast.926), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %convert_element_type.1266 = s32[2]{0} convert(%add.1264), metadata={op_name="convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=234 source_end_line=234 source_column=6 source_end_column=35}
  %jit__roll_static_.1272 = s32[2]{0} call(%convert_element_type.1266), to_apply=%_roll_static_219.1271, metadata={op_name="jit(_roll_static)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %scatter.1276 = s32[2]{0} scatter(%jit__roll_static_.1272, %constant.948, %constant.951), update_window_dims={}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=0, indices_are_sorted=true, unique_indices=true, to_apply=%region_21.1275, metadata={op_name="scatter" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %jit_cumsum_.1288 = s32[2]{0} call(%scatter.1276), to_apply=%cumsum_224.1287, metadata={op_name="jit(cumsum)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %constant.923 = s32[] constant(0)
  %broadcast.924 = s32[2]{0} broadcast(%constant.923), dimensions={}
  %lt.1289 = pred[2]{0} compare(%jit_cumsum_.1288, %broadcast.924), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %constant.921 = s32[] constant(129)
  %broadcast.922 = s32[2]{0} broadcast(%constant.921), dimensions={}
  %add.1290 = s32[2]{0} add(%jit_cumsum_.1288, %broadcast.922), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %select_n.1291 = s32[2]{0} select(%lt.1289, %add.1290, %jit_cumsum_.1288), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %broadcast_in_dim.1292 = s32[2,1]{1,0} reshape(%select_n.1291), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %constant.919 = s32[] constant(1)
  %broadcast.920 = s32[2]{0} broadcast(%constant.919), dimensions={}
  %scatter-add.1297 = s32[129]{0} scatter(%broadcast.941, %broadcast_in_dim.1292, %broadcast.920), update_window_dims={}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=1, to_apply=%region_23.1296, metadata={op_name="scatter-add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %jit_cumsum_.1298 = s32[129]{0} call(%scatter-add.1297), to_apply=%cumsum_149.1044, metadata={op_name="jit(cumsum)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %sub.1299 = s32[129]{0} subtract(%jit_cumsum_.1298, %broadcast.937), metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %jit__take_.1328 = s32[129]{0} call(%iota.1265, %sub.1299), to_apply=%_take_233.1327, metadata={op_name="jit(_take)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %neg.1367 = s32[] negate(%reduce_sum.1336), metadata={op_name="neg" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=246 source_end_line=246 source_column=42 source_end_column=62}
  %jit__roll_dynamic_.1368 = s32[129]{0} call(%jit__take_.1328, %neg.1367), to_apply=%_roll_dynamic.1365, metadata={op_name="jit(_roll_dynamic)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=246 source_end_line=246 source_column=15 source_end_column=71}
  %broadcast_in_dim.955 = s32[1]{0} reshape(%Arg_3.918), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=358 source_end_line=358 source_column=19 source_end_column=37}
  %Arg_0.915 = bf16[256,2048]{1,0} parameter(0)
  %Arg_1.916 = bf16[128,384,2048]{2,1,0} parameter(1)
  ROOT %pallas_call.1387 = bf16[256,384]{1,0} custom-call(%reduce_sum.1386, %concatenate.970, %jit__roll_dynamic_.1366, %jit__roll_dynamic_.1368, %broadcast_in_dim.955, /*index=5*/%Arg_0.915, %Arg_1.916), custom_call_target="tpu_custom_call", operand_layout_constraints={s32[], s32[129]{0}, s32[129]{0}, s32[129]{0}, s32[1]{0}, bf16[256,2048]{1,0}, bf16[128,384,2048]{2,1,0}}, metadata={op_name="pallas_call" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=547 source_end_line=553 source_column=8 source_end_column=3}, backend_config={"custom_call_config": {"body": "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", "cost_estimate": {"bytes_accessed": 204144640, "flops": 402653184, "transcendentals": 0}, "serialization_format": 1, "needs_layout_passes": true}}
}

%xla.sdy.manual_computation_body_0.1390 (shard_map.911: s32[], shard_map.912: bf16[256,2048], shard_map.913: bf16[128,384,2048], shard_map.914: s32[128]) -> bf16[256,384] {
  %shard_map.912 = bf16[256,2048]{1,0} parameter(1), metadata={op_name="shard_map"}
  %shard_map.913 = bf16[128,384,2048]{2,1,0} parameter(2), metadata={op_name="shard_map"}
  %shard_map.914 = s32[128]{0} parameter(3), metadata={op_name="shard_map"}
  %shard_map.911 = s32[] parameter(0), metadata={op_name="shard_map"}
  ROOT %jit_gmm_.1389 = bf16[256,384]{1,0} call(%shard_map.912, %shard_map.913, %shard_map.914, %shard_map.911), to_apply=%gmm.1388, metadata={op_name="jit(gmm)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=96 source_end_line=102 source_column=17 source_end_column=28}
}

%silu.1406 (Arg_0.1398: bf16[256,768]) -> bf16[256,768] {
  %Arg_0.1398 = bf16[256,768]{1,0} parameter(0)
  %constant.1399 = bf16[] constant(1)
  %broadcast.1400 = bf16[256,768]{1,0} broadcast(%constant.1399), dimensions={}
  %neg.1401 = bf16[256,768]{1,0} negate(%Arg_0.1398), metadata={op_name="neg" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=342 source_end_line=342 source_column=8 source_end_column=23}
  %exp.1402 = bf16[256,768]{1,0} exponential(%neg.1401), metadata={op_name="exp" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=342 source_end_line=342 source_column=8 source_end_column=23}
  %add.1403 = bf16[256,768]{1,0} add(%exp.1402, %broadcast.1400), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=342 source_end_line=342 source_column=8 source_end_column=23}
  %div.1404 = bf16[256,768]{1,0} divide(%broadcast.1400, %add.1403), metadata={op_name="div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=342 source_end_line=342 source_column=8 source_end_column=23}
  ROOT %mul.1405 = bf16[256,768]{1,0} multiply(%Arg_0.1398, %div.1404), metadata={op_name="mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=342 source_end_line=342 source_column=8 source_end_column=23}
}

%region_27.1480 (scatter.1478: s32[], scatter.1479: s32[]) -> s32[] {
  %scatter.1478 = s32[] parameter(0), metadata={op_name="scatter"}
  ROOT %scatter.1479 = s32[] parameter(1), metadata={op_name="scatter"}
}

%region_28.1490 (scatter-add.1487: s32[], scatter-add.1488: s32[]) -> s32[] {
  %scatter-add.1487 = s32[] parameter(0), metadata={op_name="scatter-add"}
  %scatter-add.1488 = s32[] parameter(1), metadata={op_name="scatter-add"}
  ROOT %add.1489 = s32[] add(%scatter-add.1487, %scatter-add.1488), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
}

%region_29.1524 (scatter-add.1521: f32[], scatter-add.1522: f32[]) -> f32[] {
  %scatter-add.1521 = f32[] parameter(0), metadata={op_name="scatter-add"}
  %scatter-add.1522 = f32[] parameter(1), metadata={op_name="scatter-add"}
  ROOT %add.1523 = f32[] add(%scatter-add.1521, %scatter-add.1522), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
}

%region_30.1533 (scatter.1531: s32[], scatter.1532: s32[]) -> s32[] {
  %scatter.1531 = s32[] parameter(0), metadata={op_name="scatter"}
  ROOT %scatter.1532 = s32[] parameter(1), metadata={op_name="scatter"}
}

%region_31.1543 (scatter-add.1540: s32[], scatter-add.1541: s32[]) -> s32[] {
  %scatter-add.1540 = s32[] parameter(0), metadata={op_name="scatter-add"}
  %scatter-add.1541 = s32[] parameter(1), metadata={op_name="scatter-add"}
  ROOT %add.1542 = s32[] add(%scatter-add.1540, %scatter-add.1541), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
}

%region_32.1554 (reduce_sum.1551: s32[], reduce_sum.1552: s32[]) -> s32[] {
  %reduce_sum.1551 = s32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1552 = s32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1553 = s32[] add(%reduce_sum.1551, %reduce_sum.1552), metadata={op_name="reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=244 source_end_line=244 source_column=24 source_end_column=55}
}

%region_33.1570 (reduce_sum.1567: s32[], reduce_sum.1568: s32[]) -> s32[] {
  %reduce_sum.1567 = s32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1568 = s32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1569 = s32[] add(%reduce_sum.1567, %reduce_sum.1568), metadata={op_name="reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=254 source_end_line=254 source_column=14 source_end_column=31}
}

%gmm_268.1573 (Arg_0.1419: bf16[256,192], Arg_1.1420: bf16[128,2048,192], Arg_2.1421: s32[128], Arg_3.1422: s32[]) -> bf16[256,2048] {
  %iota.1560 = s32[128]{0} iota(), iota_dimension=0, metadata={op_name="iota" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=251 source_end_line=251 source_column=9 source_end_column=48}
  %Arg_3.1422 = s32[] parameter(3)
  %constant.1457 = s32[] constant(128)
  %add.1460 = s32[] add(%Arg_3.1422, %constant.1457), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=116 source_end_line=116 source_column=14 source_end_column=46}
  %constant.1456 = s32[] constant(1)
  %sub.1461 = s32[] subtract(%add.1460, %constant.1456), metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=116 source_end_line=116 source_column=14 source_end_column=46}
  %le.1561 = s32[128]{0} broadcast(%sub.1461), dimensions={}, metadata={op_name="le" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=252 source_end_line=252 source_column=38 source_end_column=55}
  %le.1562 = pred[128]{0} compare(%iota.1560, %le.1561), direction=LE, metadata={op_name="le" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=252 source_end_line=252 source_column=38 source_end_column=55}
  %ge.1563 = s32[128]{0} broadcast(%Arg_3.1422), dimensions={}, metadata={op_name="ge" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=252 source_end_line=252 source_column=57 source_end_column=76}
  %ge.1564 = pred[128]{0} compare(%iota.1560, %ge.1563), direction=GE, metadata={op_name="ge" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=252 source_end_line=252 source_column=57 source_end_column=76}
  %and.1565 = pred[128]{0} and(%le.1562, %ge.1564), metadata={op_name="and" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=252 source_end_line=252 source_column=22 source_end_column=77}
  %Arg_2.1421 = s32[128]{0} parameter(2)
  %constant.1446 = s32[] constant(0)
  %broadcast.1447 = s32[128]{0} broadcast(%constant.1446), dimensions={}
  %eq.1473 = pred[128]{0} compare(%Arg_2.1421, %broadcast.1447), direction=EQ, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=154 source_end_line=154 source_column=34 source_end_column=50}
  %constant.1455 = s32[] constant(0)
  %jit_cumsum_.1462 = s32[128]{0} call(%Arg_2.1421), to_apply=%cumsum.968, metadata={op_name="jit(cumsum)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=126 source_end_line=126 source_column=15 source_end_column=38}
  %constant.1450 = s32[] constant(128)
  %broadcast.1451 = s32[128]{0} broadcast(%constant.1450), dimensions={}
  %add.1464 = s32[128]{0} add(%jit_cumsum_.1462, %broadcast.1451), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=25 source_end_column=40}
  %constant.1448 = s32[] constant(1)
  %broadcast.1449 = s32[128]{0} broadcast(%constant.1448), dimensions={}
  %sub.1465 = s32[128]{0} subtract(%add.1464, %broadcast.1449), metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=25 source_end_column=40}
  %jit_floor_divide_.1466 = s32[128]{0} call(%sub.1465, %constant.1457), to_apply=%floor_divide.996, metadata={op_name="jit(floor_divide)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  %mul.1467 = s32[128]{0} multiply(%jit_floor_divide_.1466, %broadcast.1451), metadata={op_name="mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=140 source_end_line=140 source_column=24 source_end_column=51}
  %constant.1452 = s32[1]{0} constant({0})
  %slice.1468 = s32[127]{0} slice(%jit_cumsum_.1462), slice={[0:127]}, metadata={op_name="slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=144 source_end_line=144 source_column=38 source_end_column=53}
  %concatenate.1469 = s32[128]{0} concatenate(%constant.1452, %slice.1468), dimensions={0}, metadata={op_name="concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=143 source_end_line=145 source_column=17 source_end_column=3}
  %jit_floor_divide_.1470 = s32[128]{0} call(%concatenate.1469, %constant.1457), to_apply=%floor_divide.996, metadata={op_name="jit(floor_divide)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=146 source_end_line=146 source_column=25 source_end_column=43}
  %mul.1471 = s32[128]{0} multiply(%jit_floor_divide_.1470, %broadcast.1451), metadata={op_name="mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=146 source_end_line=146 source_column=25 source_end_column=43}
  %sub.1472 = s32[128]{0} subtract(%mul.1467, %mul.1471), metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=153 source_end_line=153 source_column=24 source_end_column=65}
  %jit__where_.1474 = s32[128]{0} call(%eq.1473, %constant.1455, %sub.1472), to_apply=%_where_136.1010, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=154 source_end_line=154 source_column=24 source_end_column=75}
  %jit_floor_divide_.1475 = s32[128]{0} call(%jit__where_.1474, %constant.1457), to_apply=%floor_divide.996, metadata={op_name="jit(floor_divide)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=174 source_end_line=174 source_column=16 source_end_column=41}
  %jit__where_.1566 = s32[128]{0} call(%and.1565, %jit_floor_divide_.1475, %constant.1455), to_apply=%_where_255.1380, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=253 source_end_line=253 source_column=16 source_end_column=60}
  %reduce_sum.1571 = s32[] reduce(%jit__where_.1566, %constant.1455), dimensions={0}, to_apply=%region_33.1570, metadata={op_name="reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=254 source_end_line=254 source_column=14 source_end_column=31}
  %concatenate.1463 = s32[129]{0} concatenate(%constant.1452, %jit_cumsum_.1462), dimensions={0}, metadata={op_name="concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=127 source_end_line=127 source_column=18 source_end_column=78}
  %iota.1476 = s32[128]{0} iota(), iota_dimension=0, metadata={op_name="iota" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=188 source_end_line=188 source_column=6 source_end_column=45}
  %constant.1444 = s32[] constant(0)
  %broadcast.1445 = s32[129]{0} broadcast(%constant.1444), dimensions={}
  %jit__roll_static_.1477 = s32[128]{0} call(%jit_floor_divide_.1475), to_apply=%_roll_static.1018, metadata={op_name="jit(_roll_static)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %scatter.1481 = s32[128]{0} scatter(%jit__roll_static_.1477, %constant.1452, %constant.1455), update_window_dims={}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=0, indices_are_sorted=true, unique_indices=true, to_apply=%region_27.1480, metadata={op_name="scatter" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %jit_cumsum_.1482 = s32[128]{0} call(%scatter.1481), to_apply=%cumsum.968, metadata={op_name="jit(cumsum)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %lt.1483 = pred[128]{0} compare(%jit_cumsum_.1482, %broadcast.1447), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %constant.1442 = s32[] constant(129)
  %add.1443 = s32[128]{0} broadcast(%constant.1442), dimensions={}, metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %add.1484 = s32[128]{0} add(%jit_cumsum_.1482, %add.1443), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %select_n.1485 = s32[128]{0} select(%lt.1483, %add.1484, %jit_cumsum_.1482), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %broadcast_in_dim.1486 = s32[128,1]{1,0} reshape(%select_n.1485), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %scatter-add.1491 = s32[129]{0} scatter(%broadcast.1445, %broadcast_in_dim.1486, %broadcast.1449), update_window_dims={}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=1, to_apply=%region_28.1490, metadata={op_name="scatter-add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %jit_cumsum_.1492 = s32[129]{0} call(%scatter-add.1491), to_apply=%cumsum_149.1044, metadata={op_name="jit(cumsum)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %constant.1440 = s32[] constant(1)
  %broadcast.1441 = s32[129]{0} broadcast(%constant.1440), dimensions={}
  %sub.1493 = s32[129]{0} subtract(%jit_cumsum_.1492, %broadcast.1441), metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %jit__take_.1494 = s32[129]{0} call(%iota.1476, %sub.1493), to_apply=%_take_153.1079, metadata={op_name="jit(_take)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=187 source_end_line=191 source_column=14 source_end_column=3}
  %lt.1548 = s32[129]{0} broadcast(%Arg_3.1422), dimensions={}, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=244 source_end_line=244 source_column=25 source_end_column=48}
  %lt.1549 = pred[129]{0} compare(%jit__take_.1494, %lt.1548), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=244 source_end_line=244 source_column=25 source_end_column=48}
  %convert_element_type.1550 = s32[129]{0} convert(%lt.1549), metadata={op_name="convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=244 source_end_line=244 source_column=24 source_end_column=55}
  %reduce_sum.1555 = s32[] reduce(%convert_element_type.1550, %constant.1455), dimensions={0}, to_apply=%region_32.1554, metadata={op_name="reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=244 source_end_line=244 source_column=24 source_end_column=55}
  %neg.1556 = s32[] negate(%reduce_sum.1555), metadata={op_name="neg" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=40 source_end_column=60}
  %jit__roll_dynamic_.1557 = s32[129]{0} call(%jit__take_.1494, %neg.1556), to_apply=%_roll_dynamic.1365, metadata={op_name="jit(_roll_dynamic)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=245 source_end_line=245 source_column=14 source_end_column=69}
  %iota.1528 = s32[2]{0} iota(), iota_dimension=0, metadata={op_name="iota" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=233 source_end_line=233 source_column=6 source_end_column=42}
  %constant.1433 = f32[] constant(0)
  %broadcast.1434 = f32[3]{0} broadcast(%constant.1433), dimensions={}
  %slice.1495 = s32[128]{0} slice(%concatenate.1463), slice={[0:128]}, metadata={op_name="slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
  %jit_remainder_.1496 = s32[128]{0} call(%slice.1495, %constant.1457), to_apply=%remainder.1106, metadata={op_name="jit(remainder)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=7 source_end_column=25}
  %eq.1497 = pred[128]{0} compare(%jit_remainder_.1496, %broadcast.1447), direction=EQ, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=6 source_end_column=36}
  %eq.1498 = pred[128]{0} compare(%Arg_2.1421, %broadcast.1447), direction=EQ, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=213 source_end_line=213 source_column=38 source_end_column=54}
  %or.1499 = pred[128]{0} or(%eq.1497, %eq.1498), metadata={op_name="or" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=212 source_end_line=214 source_column=22 source_end_column=3}
  %constant.1454 = s32[] constant(2)
  %slice.1500 = s32[128]{0} slice(%concatenate.1463), slice={[0:128]}, metadata={op_name="slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=222 source_end_line=222 source_column=34 source_end_column=52}
  %jit_floor_divide_.1501 = s32[128]{0} call(%slice.1500, %constant.1457), to_apply=%floor_divide.996, metadata={op_name="jit(floor_divide)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=222 source_end_line=222 source_column=34 source_end_column=52}
  %jit__where_.1502 = s32[128]{0} call(%or.1499, %constant.1454, %jit_floor_divide_.1501), to_apply=%_where_136.1010, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=221 source_end_line=223 source_column=21 source_end_column=3}
  %convert_element_type.1503 = f32[128]{0} convert(%jit__where_.1502), metadata={op_name="convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.1458 = f32[2]{0} constant({0, 1})
  %jit__ptp_.1504 = f32[] call(%constant.1458), to_apply=%_ptp.1129, metadata={op_name="jit(_ptp)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.1453 = f32[] constant(0)
  %eq.1505 = pred[] compare(%jit__ptp_.1504, %constant.1453), direction=EQ, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.1437 = f32[] constant(-0.5)
  %jit__where_.1506 = f32[] call(%eq.1505, %constant.1437, %constant.1453), to_apply=%_where_182.1136, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %jit__ptp_.1507 = f32[] call(%constant.1458), to_apply=%_ptp.1129, metadata={op_name="jit(_ptp)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %eq.1508 = pred[] compare(%jit__ptp_.1507, %constant.1453), direction=EQ, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.1436 = f32[] constant(1.5)
  %constant.1435 = f32[] constant(1)
  %jit__where_.1509 = f32[] call(%eq.1508, %constant.1436, %constant.1435), to_apply=%_where_182.1136, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %jit__linspace_.1510 = f32[3]{0} call(%jit__where_.1506, %jit__where_.1509), to_apply=%_linspace.1163, metadata={op_name="jit(_linspace)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %dynamic_slice.1512 = f32[1]{0} slice(%jit__linspace_.1510), slice={[2:3]}, metadata={op_name="dynamic_slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %squeeze.1513 = f32[] reshape(%dynamic_slice.1512), metadata={op_name="squeeze" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %eq.1514 = f32[128]{0} broadcast(%squeeze.1513), dimensions={}, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %eq.1515 = pred[128]{0} compare(%convert_element_type.1503, %eq.1514), direction=EQ, metadata={op_name="eq" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %jit_searchsorted_.1511 = s32[128]{0} call(%jit__linspace_.1510, %convert_element_type.1503), to_apply=%searchsorted.1247, metadata={op_name="jit(searchsorted)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %jit__where_.1516 = s32[128]{0} call(%eq.1515, %constant.1454, %jit_searchsorted_.1511), to_apply=%_where_136.1010, metadata={op_name="jit(_where)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %lt.1517 = pred[128]{0} compare(%jit__where_.1516, %broadcast.1447), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.1431 = s32[] constant(3)
  %add.1432 = s32[128]{0} broadcast(%constant.1431), dimensions={}, metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %add.1518 = s32[128]{0} add(%jit__where_.1516, %add.1432), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %select_n.1519 = s32[128]{0} select(%lt.1517, %add.1518, %jit__where_.1516), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %broadcast_in_dim.1520 = s32[128,1]{1,0} reshape(%select_n.1519), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.1438 = f32[] constant(1)
  %broadcast_in_dim.1439 = f32[128]{0} broadcast(%constant.1438), dimensions={}, metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %scatter-add.1525 = f32[3]{0} scatter(%broadcast.1434, %broadcast_in_dim.1520, %broadcast_in_dim.1439), update_window_dims={}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=1, to_apply=%region_29.1524, metadata={op_name="scatter-add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %slice.1526 = f32[2]{0} slice(%scatter-add.1525), slice={[1:3]}, metadata={op_name="slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %constant.1429 = f32[] constant(1)
  %broadcast.1430 = f32[2]{0} broadcast(%constant.1429), dimensions={}
  %add.1527 = f32[2]{0} add(%slice.1526, %broadcast.1430), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=226 source_end_line=227 source_column=6 source_end_column=9}
  %convert_element_type.1529 = s32[2]{0} convert(%add.1527), metadata={op_name="convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=234 source_end_line=234 source_column=6 source_end_column=35}
  %jit__roll_static_.1530 = s32[2]{0} call(%convert_element_type.1529), to_apply=%_roll_static_219.1271, metadata={op_name="jit(_roll_static)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %scatter.1534 = s32[2]{0} scatter(%jit__roll_static_.1530, %constant.1452, %constant.1455), update_window_dims={}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=0, indices_are_sorted=true, unique_indices=true, to_apply=%region_30.1533, metadata={op_name="scatter" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %jit_cumsum_.1535 = s32[2]{0} call(%scatter.1534), to_apply=%cumsum_224.1287, metadata={op_name="jit(cumsum)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %constant.1427 = s32[] constant(0)
  %broadcast.1428 = s32[2]{0} broadcast(%constant.1427), dimensions={}
  %lt.1536 = pred[2]{0} compare(%jit_cumsum_.1535, %broadcast.1428), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %constant.1425 = s32[] constant(129)
  %broadcast.1426 = s32[2]{0} broadcast(%constant.1425), dimensions={}
  %add.1537 = s32[2]{0} add(%jit_cumsum_.1535, %broadcast.1426), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %select_n.1538 = s32[2]{0} select(%lt.1536, %add.1537, %jit_cumsum_.1535), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %broadcast_in_dim.1539 = s32[2,1]{1,0} reshape(%select_n.1538), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %constant.1423 = s32[] constant(1)
  %broadcast.1424 = s32[2]{0} broadcast(%constant.1423), dimensions={}
  %scatter-add.1544 = s32[129]{0} scatter(%broadcast.1445, %broadcast_in_dim.1539, %broadcast.1424), update_window_dims={}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=1, to_apply=%region_31.1543, metadata={op_name="scatter-add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %jit_cumsum_.1545 = s32[129]{0} call(%scatter-add.1544), to_apply=%cumsum_149.1044, metadata={op_name="jit(cumsum)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %sub.1546 = s32[129]{0} subtract(%jit_cumsum_.1545, %broadcast.1441), metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %jit__take_.1547 = s32[129]{0} call(%iota.1528, %sub.1546), to_apply=%_take_233.1327, metadata={op_name="jit(_take)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=232 source_end_line=236 source_column=15 source_end_column=3}
  %neg.1558 = s32[] negate(%reduce_sum.1555), metadata={op_name="neg" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=246 source_end_line=246 source_column=42 source_end_column=62}
  %jit__roll_dynamic_.1559 = s32[129]{0} call(%jit__take_.1547, %neg.1558), to_apply=%_roll_dynamic.1365, metadata={op_name="jit(_roll_dynamic)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=246 source_end_line=246 source_column=15 source_end_column=71}
  %broadcast_in_dim.1459 = s32[1]{0} reshape(%Arg_3.1422), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=358 source_end_line=358 source_column=19 source_end_column=37}
  %Arg_0.1419 = bf16[256,192]{1,0} parameter(0)
  %Arg_1.1420 = bf16[128,2048,192]{2,1,0} parameter(1)
  ROOT %pallas_call.1572 = bf16[256,2048]{1,0} custom-call(%reduce_sum.1571, %concatenate.1463, %jit__roll_dynamic_.1557, %jit__roll_dynamic_.1559, %broadcast_in_dim.1459, /*index=5*/%Arg_0.1419, %Arg_1.1420), custom_call_target="tpu_custom_call", operand_layout_constraints={s32[], s32[129]{0}, s32[129]{0}, s32[129]{0}, s32[1]{0}, bf16[256,192]{1,0}, bf16[128,2048,192]{2,1,0}}, metadata={op_name="pallas_call" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/jax/experimental/pallas/ops/tpu/megablox/gmm.py" source_line=547 source_end_line=553 source_column=8 source_end_column=3}, backend_config={"custom_call_config": {"body": "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", "cost_estimate": {"bytes_accessed": 102596608, "flops": 201326592, "transcendentals": 0}, "serialization_format": 1, "needs_layout_passes": true}}
}

%region_34.1578 (psum.1575: bf16[], psum.1576: bf16[]) -> bf16[] {
  %psum.1575 = bf16[] parameter(0), metadata={op_name="psum"}
  %psum.1576 = bf16[] parameter(1), metadata={op_name="psum"}
  ROOT %add.1577 = bf16[] add(%psum.1575, %psum.1576), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=133 source_end_line=133 source_column=15 source_end_column=49}
}

%xla.sdy.manual_computation_body_1.1580 (shard_map.1415: s32[], shard_map.1416: bf16[256,192], shard_map.1417: bf16[128,2048,192], shard_map.1418: s32[128]) -> bf16[256,2048] {
  %shard_map.1416 = bf16[256,192]{1,0} parameter(1), metadata={op_name="shard_map"}
  %shard_map.1417 = bf16[128,2048,192]{2,1,0} parameter(2), metadata={op_name="shard_map"}
  %shard_map.1418 = s32[128]{0} parameter(3), metadata={op_name="shard_map"}
  %shard_map.1415 = s32[] parameter(0), metadata={op_name="shard_map"}
  %jit_gmm_.1574 = bf16[256,2048]{1,0} call(%shard_map.1416, %shard_map.1417, %shard_map.1418, %shard_map.1415), to_apply=%gmm_268.1573, metadata={op_name="jit(gmm)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=132 source_end_line=132 source_column=12 source_end_column=39}
  ROOT %psum.1579 = bf16[256,2048]{1,0} all-reduce(%jit_gmm_.1574), channel_id=1, replica_groups={{0,1,2,3}}, use_global_device_ids=true, to_apply=%region_34.1578, metadata={op_name="psum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=133 source_end_line=133 source_column=15 source_end_column=49}
}

%region_35.1598 (reduce_sum.1595: f32[], reduce_sum.1596: f32[]) -> f32[] {
  %reduce_sum.1595 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1596 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1597 = f32[] add(%reduce_sum.1595, %reduce_sum.1596), metadata={op_name="reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=363 source_end_line=363 source_column=8 source_end_column=22}
}

%jax_fused_moe_func_padded.1602 (Arg_0.793: bf16[32,2048], Arg_1.794: bf16[128,1536,2048], Arg_2.795: bf16[128,2048,768], Arg_3.796: bf16[32,128]) -> bf16[32,2048] {
  %constant.811 = s32[] constant(0)
  %Arg_0.793 = bf16[32,2048]{1,0} parameter(0)
  %iota.878 = s32[32]{0} iota(), iota_dimension=0, metadata={op_name="iota" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=318 source_end_line=318 source_column=20 source_end_column=59}
  %broadcast_in_dim.879 = s32[32,8]{1,0} broadcast(%iota.878), dimensions={0}, metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=318 source_end_line=318 source_column=20 source_end_column=59}
  %reshape.880 = s32[256]{0} reshape(%broadcast_in_dim.879), metadata={op_name="reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=318 source_end_line=318 source_column=20 source_end_column=59}
  %Arg_3.796 = bf16[32,128]{1,0} parameter(3)
  %convert_element_type.814 = f32[32,128]{1,0} convert(%Arg_3.796), metadata={op_name="convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=34 source_end_column=67}
  %constant.813 = f32[] constant(-inf)
  %reduce_max.819 = f32[32]{0} reduce(%convert_element_type.814, %constant.813), dimensions={1}, to_apply=%region_5.818, metadata={op_name="reduce_max" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
  %constant.809 = f32[] constant(-inf)
  %max.810 = f32[32]{0} broadcast(%constant.809), dimensions={}, metadata={op_name="max" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
  %max.820 = f32[32]{0} maximum(%reduce_max.819, %max.810), metadata={op_name="max" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
  %broadcast_in_dim.821 = f32[32,1]{1,0} reshape(%max.820), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
  %sub.822 = f32[32,1]{1,0} broadcast(%broadcast_in_dim.821), dimensions={0,1}, metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
  %sub.823 = f32[32]{0} reshape(%sub.822), metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
  %sub.824 = f32[32,128]{1,0} broadcast(%sub.823), dimensions={0}, metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
  %sub.825 = f32[32,128]{1,0} subtract(%convert_element_type.814, %sub.824), metadata={op_name="sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
  %exp.826 = f32[32,128]{1,0} exponential(%sub.825), metadata={op_name="exp" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
  %constant.812 = f32[] constant(0)
  %reduce_sum.831 = f32[32]{0} reduce(%exp.826, %constant.812), dimensions={1}, to_apply=%region_6.830, metadata={op_name="reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
  %broadcast_in_dim.832 = f32[32,1]{1,0} reshape(%reduce_sum.831), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
  %div.833 = f32[32,1]{1,0} broadcast(%broadcast_in_dim.832), dimensions={0,1}, metadata={op_name="div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
  %div.834 = f32[32]{0} reshape(%div.833), metadata={op_name="div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
  %div.835 = f32[32,128]{1,0} broadcast(%div.834), dimensions={0}, metadata={op_name="div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
  %div.836 = f32[32,128]{1,0} divide(%exp.826, %div.835), metadata={op_name="div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=309 source_end_line=309 source_column=19 source_end_column=77}
  %top_k.837 = (f32[32,8]{1,0}, s32[32,8]{1,0}) topk(%div.836), k=8, largest=true, metadata={op_name="top_k" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=310 source_end_line=310 source_column=33 source_end_column=68}
  %top_k.839 = s32[32,8]{1,0} get-tuple-element(%top_k.837), index=1, metadata={op_name="top_k" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=310 source_end_line=310 source_column=33 source_end_column=68}
  %reshape.851 = s32[256]{0} reshape(%top_k.839), metadata={op_name="reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=315 source_end_line=315 source_column=24 source_end_column=46}
  %jit_argsort_.864 = s32[256]{0} call(%reshape.851), to_apply=%argsort.863, metadata={op_name="jit(argsort)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=316 source_end_line=316 source_column=27 source_end_column=57}
  %constant.807 = s32[] constant(0)
  %broadcast.808 = s32[256]{0} broadcast(%constant.807), dimensions={}
  %lt.881 = pred[256]{0} compare(%jit_argsort_.864, %broadcast.808), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=319 source_end_line=319 source_column=27 source_end_column=62}
  %constant.805 = s32[] constant(256)
  %broadcast.806 = s32[256]{0} broadcast(%constant.805), dimensions={}
  %add.882 = s32[256]{0} add(%jit_argsort_.864, %broadcast.806), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=319 source_end_line=319 source_column=27 source_end_column=62}
  %select_n.883 = s32[256]{0} select(%lt.881, %add.882, %jit_argsort_.864), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=319 source_end_line=319 source_column=27 source_end_column=62}
  %broadcast_in_dim.884 = s32[256,1]{1,0} reshape(%select_n.883), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=319 source_end_line=319 source_column=27 source_end_column=62}
  %gather.885 = s32[256]{0} gather(%reshape.880, %broadcast_in_dim.884), offset_dims={}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1}, metadata={op_name="gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=319 source_end_line=319 source_column=27 source_end_column=62}
  %lt.901 = pred[256]{0} compare(%gather.885, %broadcast.808), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=322 source_end_line=322 source_column=8 source_end_column=43}
  %constant.797 = s32[] constant(32)
  %add.798 = s32[256]{0} broadcast(%constant.797), dimensions={}, metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=322 source_end_line=322 source_column=8 source_end_column=43}
  %add.902 = s32[256]{0} add(%gather.885, %add.798), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=322 source_end_line=322 source_column=8 source_end_column=43}
  %select_n.903 = s32[256]{0} select(%lt.901, %add.902, %gather.885), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=322 source_end_line=322 source_column=8 source_end_column=43}
  %broadcast_in_dim.904 = s32[256,1]{1,0} reshape(%select_n.903), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=322 source_end_line=322 source_column=8 source_end_column=43}
  %gather.905 = bf16[256,2048]{1,0} gather(%Arg_0.793, %broadcast_in_dim.904), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,2048}, metadata={op_name="gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=322 source_end_line=322 source_column=8 source_end_column=43}
  %Arg_1.794 = bf16[128,1536,2048]{2,1,0} parameter(1)
  %constant.803 = s32[] constant(0)
  %broadcast_in_dim.804 = s32[128]{0} broadcast(%constant.803), dimensions={}, metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=320 source_end_line=320 source_column=18 source_end_column=76}
  %jit_clip_.891 = s32[256]{0} call(%reshape.851, %constant.811), to_apply=%clip.890, metadata={op_name="jit(clip)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=320 source_end_line=320 source_column=18 source_end_column=76}
  %lt.892 = pred[256]{0} compare(%jit_clip_.891, %broadcast.808), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=320 source_end_line=320 source_column=18 source_end_column=76}
  %constant.801 = s32[] constant(128)
  %add.802 = s32[256]{0} broadcast(%constant.801), dimensions={}, metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=320 source_end_line=320 source_column=18 source_end_column=76}
  %add.893 = s32[256]{0} add(%jit_clip_.891, %add.802), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=320 source_end_line=320 source_column=18 source_end_column=76}
  %select_n.894 = s32[256]{0} select(%lt.892, %add.893, %jit_clip_.891), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=320 source_end_line=320 source_column=18 source_end_column=76}
  %broadcast_in_dim.895 = s32[256,1]{1,0} reshape(%select_n.894), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=320 source_end_line=320 source_column=18 source_end_column=76}
  %constant.799 = s32[] constant(1)
  %broadcast_in_dim.800 = s32[256]{0} broadcast(%constant.799), dimensions={}, metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=320 source_end_line=320 source_column=18 source_end_column=76}
  %scatter-add.900 = s32[128]{0} scatter(%broadcast_in_dim.804, %broadcast_in_dim.895, %broadcast_in_dim.800), update_window_dims={}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=1, to_apply=%region_10.899, metadata={op_name="scatter-add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=320 source_end_line=320 source_column=18 source_end_column=76}
  %shard_map.906 = (s32[], bf16[256,2048]{1,0}, bf16[128,384,2048]{2,1,0}, s32[128]{0}) custom-call(%constant.811, %gather.905, %Arg_1.794, %scatter-add.900), custom_call_target="xla.sdy.GlobalToLocalShape", custom_call_has_side_effect=true, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, []>, <@mesh, [{}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=96 source_end_line=102 source_column=17 source_end_column=28}
  %shard_map.907 = s32[] get-tuple-element(%shard_map.906), index=0, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, []>, <@mesh, [{}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=96 source_end_line=102 source_column=17 source_end_column=28}
  %shard_map.908 = bf16[256,2048]{1,0} get-tuple-element(%shard_map.906), index=1, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, []>, <@mesh, [{}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=96 source_end_line=102 source_column=17 source_end_column=28}
  %shard_map.909 = bf16[128,384,2048]{2,1,0} get-tuple-element(%shard_map.906), index=2, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, []>, <@mesh, [{}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=96 source_end_line=102 source_column=17 source_end_column=28}
  %shard_map.910 = s32[128]{0} get-tuple-element(%shard_map.906), index=3, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, []>, <@mesh, [{}, {}]>, <@mesh, [{}, {\"model\"}, {}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=96 source_end_line=102 source_column=17 source_end_column=28}
  %shard_map.1391 = bf16[256,384]{1,0} call(%shard_map.907, %shard_map.908, %shard_map.909, %shard_map.910), to_apply=%xla.sdy.manual_computation_body_0.1390, frontend_attributes={inlineable="false"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=96 source_end_line=102 source_column=17 source_end_column=28}
  %shard_map.1392 = bf16[256,1536]{1,0} custom-call(%shard_map.1391), custom_call_target="xla.sdy.LocalToGlobalShape", custom_call_has_side_effect=true, frontend_attributes={xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>",xla.sdy.out_shardings="#sdy.sharding_per_value<[<@mesh, [{}, {\"model\"}]>]>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=96 source_end_line=102 source_column=17 source_end_column=28}
  %reshape.1393 = bf16[256,4,384]{2,1,0} reshape(%shard_map.1392), metadata={op_name="reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.1394 = bf16[256,4,192]{2,1,0} slice(%reshape.1393), slice={[0:256], [0:4], [0:192]}, metadata={op_name="slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.1395 = bf16[256,768]{1,0} reshape(%slice.1394), metadata={op_name="reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit_silu_.1407 = bf16[256,768]{1,0} call(%reshape.1395), to_apply=%silu.1406, metadata={op_name="jit(silu)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=342 source_end_line=342 source_column=8 source_end_column=23}
  %slice.1396 = bf16[256,4,192]{2,1,0} slice(%reshape.1393), slice={[0:256], [0:4], [192:384]}, metadata={op_name="slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.1397 = bf16[256,768]{1,0} reshape(%slice.1396), metadata={op_name="reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %mul.1408 = bf16[256,768]{1,0} multiply(%jit_silu_.1407, %reshape.1397), metadata={op_name="mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=342 source_end_line=342 source_column=8 source_end_column=23}
  %sharding_constraint.1409 = bf16[256,768]{1,0} custom-call(%mul.1408), custom_call_target="Sharding", sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding_per_value<[<@mesh, [{}, {\"model\"}]>]>"}, metadata={op_name="sharding_constraint" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=353 source_end_line=354 source_column=12 source_end_column=53}
  %Arg_2.795 = bf16[128,2048,768]{2,1,0} parameter(2)
  %shard_map.1410 = (s32[], bf16[256,192]{1,0}, bf16[128,2048,192]{2,1,0}, s32[128]{0}) custom-call(%constant.811, %sharding_constraint.1409, %Arg_2.795, %scatter-add.900), custom_call_target="xla.sdy.GlobalToLocalShape", custom_call_has_side_effect=true, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, []>, <@mesh, [{}, {\"model\"}]>, <@mesh, [{}, {}, {\"model\"}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=135 source_end_line=141 source_column=11 source_end_column=28}
  %shard_map.1411 = s32[] get-tuple-element(%shard_map.1410), index=0, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, []>, <@mesh, [{}, {\"model\"}]>, <@mesh, [{}, {}, {\"model\"}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=135 source_end_line=141 source_column=11 source_end_column=28}
  %shard_map.1412 = bf16[256,192]{1,0} get-tuple-element(%shard_map.1410), index=1, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, []>, <@mesh, [{}, {\"model\"}]>, <@mesh, [{}, {}, {\"model\"}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=135 source_end_line=141 source_column=11 source_end_column=28}
  %shard_map.1413 = bf16[128,2048,192]{2,1,0} get-tuple-element(%shard_map.1410), index=2, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, []>, <@mesh, [{}, {\"model\"}]>, <@mesh, [{}, {}, {\"model\"}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=135 source_end_line=141 source_column=11 source_end_column=28}
  %shard_map.1414 = s32[128]{0} get-tuple-element(%shard_map.1410), index=3, frontend_attributes={xla.sdy.in_shardings="#sdy.sharding_per_value<[<@mesh, []>, <@mesh, [{}, {\"model\"}]>, <@mesh, [{}, {}, {\"model\"}]>, <@mesh, [{}]>]>",xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=135 source_end_line=141 source_column=11 source_end_column=28}
  %shard_map.1581 = bf16[256,2048]{1,0} call(%shard_map.1411, %shard_map.1412, %shard_map.1413, %shard_map.1414), to_apply=%xla.sdy.manual_computation_body_1.1580, frontend_attributes={inlineable="false"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=135 source_end_line=141 source_column=11 source_end_column=28}
  %shard_map.1582 = bf16[256,2048]{1,0} custom-call(%shard_map.1581), custom_call_target="xla.sdy.LocalToGlobalShape", custom_call_has_side_effect=true, frontend_attributes={xla.sdy.manual_axes="#sdy<manual_axes{\"data\", \"model\"}>",xla.sdy.out_shardings="#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, metadata={op_name="shard_map" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=135 source_end_line=141 source_column=11 source_end_column=28}
  %jit_argsort_.877 = s32[256]{0} call(%jit_argsort_.864), to_apply=%argsort_93.876, metadata={op_name="jit(argsort)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=317 source_end_line=317 source_column=34 source_end_column=67}
  %lt.1583 = pred[256]{0} compare(%jit_argsort_.877, %broadcast.808), direction=LT, metadata={op_name="lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=361 source_end_line=361 source_column=8 source_end_column=38}
  %add.1584 = s32[256]{0} add(%jit_argsort_.877, %broadcast.806), metadata={op_name="add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=361 source_end_line=361 source_column=8 source_end_column=38}
  %select_n.1585 = s32[256]{0} select(%lt.1583, %add.1584, %jit_argsort_.877), metadata={op_name="select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=361 source_end_line=361 source_column=8 source_end_column=38}
  %broadcast_in_dim.1586 = s32[256,1]{1,0} reshape(%select_n.1585), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=361 source_end_line=361 source_column=8 source_end_column=38}
  %gather.1587 = bf16[256,2048]{1,0} gather(%shard_map.1582, %broadcast_in_dim.1586), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,2048}, metadata={op_name="gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=361 source_end_line=361 source_column=8 source_end_column=38}
  %reshape.1588 = bf16[32,8,2048]{2,1,0} reshape(%gather.1587), metadata={op_name="reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=361 source_end_line=361 source_column=8 source_end_column=38}
  %top_k.838 = f32[32,8]{1,0} get-tuple-element(%top_k.837), index=0, metadata={op_name="top_k" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=310 source_end_line=310 source_column=33 source_end_column=68}
  %reduce_sum.844 = f32[32]{0} reduce(%top_k.838, %constant.812), dimensions={1}, to_apply=%region_7.843, metadata={op_name="reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=312 source_end_line=312 source_column=38 source_end_column=78}
  %broadcast_in_dim.845 = f32[32,1]{1,0} reshape(%reduce_sum.844), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=312 source_end_line=312 source_column=38 source_end_column=78}
  %div.846 = f32[32,1]{1,0} broadcast(%broadcast_in_dim.845), dimensions={0,1}, metadata={op_name="div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=312 source_end_line=312 source_column=23 source_end_column=78}
  %div.847 = f32[32]{0} reshape(%div.846), metadata={op_name="div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=312 source_end_line=312 source_column=23 source_end_column=78}
  %div.848 = f32[32,8]{1,0} broadcast(%div.847), dimensions={0}, metadata={op_name="div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=312 source_end_line=312 source_column=23 source_end_column=78}
  %div.849 = f32[32,8]{1,0} divide(%top_k.838, %div.848), metadata={op_name="div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=312 source_end_line=312 source_column=23 source_end_column=78}
  %convert_element_type.850 = bf16[32,8]{1,0} convert(%div.849), metadata={op_name="convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=313 source_end_line=313 source_column=19 source_end_column=45}
  %broadcast_in_dim.1589 = bf16[32,8,1]{2,1,0} reshape(%convert_element_type.850), metadata={op_name="broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=362 source_end_line=362 source_column=12 source_end_column=50}
  %mul.1590 = bf16[32,8,1]{2,1,0} broadcast(%broadcast_in_dim.1589), dimensions={0,1,2}, metadata={op_name="mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=362 source_end_line=362 source_column=8 source_end_column=50}
  %mul.1591 = bf16[32,8]{1,0} reshape(%mul.1590), metadata={op_name="mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=362 source_end_line=362 source_column=8 source_end_column=50}
  %mul.1592 = bf16[32,8,2048]{2,1,0} broadcast(%mul.1591), dimensions={0,1}, metadata={op_name="mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=362 source_end_line=362 source_column=8 source_end_column=50}
  %mul.1593 = bf16[32,8,2048]{2,1,0} multiply(%reshape.1588, %mul.1592), metadata={op_name="mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=362 source_end_line=362 source_column=8 source_end_column=50}
  %convert_element_type.1594 = f32[32,8,2048]{2,1,0} convert(%mul.1593), metadata={op_name="convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=363 source_end_line=363 source_column=8 source_end_column=22}
  %reduce_sum.1599 = f32[32,2048]{1,0} reduce(%convert_element_type.1594, %constant.812), dimensions={1}, to_apply=%region_35.1598, metadata={op_name="reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=363 source_end_line=363 source_column=8 source_end_column=22}
  %convert_element_type.1600 = bf16[32,2048]{1,0} convert(%reduce_sum.1599), metadata={op_name="convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=363 source_end_line=363 source_column=8 source_end_column=22}
  ROOT %sharding_constraint.1601 = bf16[32,2048]{1,0} custom-call(%convert_element_type.1600), custom_call_target="Sharding", sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, metadata={op_name="sharding_constraint" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/fused_moe.py" source_line=367 source_end_line=367 source_column=12 source_end_column=73}
}

%region_36.1612 (reduce_sum.1609: f32[], reduce_sum.1610: f32[]) -> f32[] {
  %reduce_sum.1609 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1610 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1611 = f32[] add(%reduce_sum.1609, %reduce_sum.1610), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_37.1640 (reduce_sum.1637: f32[], reduce_sum.1638: f32[]) -> f32[] {
  %reduce_sum.1637 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1638 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1639 = f32[] add(%reduce_sum.1637, %reduce_sum.1638), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_38.1661 (reduce_sum.1658: f32[], reduce_sum.1659: f32[]) -> f32[] {
  %reduce_sum.1658 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1659 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1660 = f32[] add(%reduce_sum.1658, %reduce_sum.1659), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_39.1744 (reduce_sum.1741: f32[], reduce_sum.1742: f32[]) -> f32[] {
  %reduce_sum.1741 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1742 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1743 = f32[] add(%reduce_sum.1741, %reduce_sum.1742), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_40.1770 (reduce_sum.1767: f32[], reduce_sum.1768: f32[]) -> f32[] {
  %reduce_sum.1767 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1768 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1769 = f32[] add(%reduce_sum.1767, %reduce_sum.1768), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_41.1798 (reduce_sum.1795: f32[], reduce_sum.1796: f32[]) -> f32[] {
  %reduce_sum.1795 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1796 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1797 = f32[] add(%reduce_sum.1795, %reduce_sum.1796), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_42.1819 (reduce_sum.1816: f32[], reduce_sum.1817: f32[]) -> f32[] {
  %reduce_sum.1816 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1817 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1818 = f32[] add(%reduce_sum.1816, %reduce_sum.1817), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_43.1902 (reduce_sum.1899: f32[], reduce_sum.1900: f32[]) -> f32[] {
  %reduce_sum.1899 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1900 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1901 = f32[] add(%reduce_sum.1899, %reduce_sum.1900), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_44.1928 (reduce_sum.1925: f32[], reduce_sum.1926: f32[]) -> f32[] {
  %reduce_sum.1925 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1926 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1927 = f32[] add(%reduce_sum.1925, %reduce_sum.1926), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_45.1956 (reduce_sum.1953: f32[], reduce_sum.1954: f32[]) -> f32[] {
  %reduce_sum.1953 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1954 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1955 = f32[] add(%reduce_sum.1953, %reduce_sum.1954), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_46.1977 (reduce_sum.1974: f32[], reduce_sum.1975: f32[]) -> f32[] {
  %reduce_sum.1974 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.1975 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.1976 = f32[] add(%reduce_sum.1974, %reduce_sum.1975), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_47.2060 (reduce_sum.2057: f32[], reduce_sum.2058: f32[]) -> f32[] {
  %reduce_sum.2057 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2058 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2059 = f32[] add(%reduce_sum.2057, %reduce_sum.2058), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_48.2086 (reduce_sum.2083: f32[], reduce_sum.2084: f32[]) -> f32[] {
  %reduce_sum.2083 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2084 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2085 = f32[] add(%reduce_sum.2083, %reduce_sum.2084), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_49.2114 (reduce_sum.2111: f32[], reduce_sum.2112: f32[]) -> f32[] {
  %reduce_sum.2111 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2112 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2113 = f32[] add(%reduce_sum.2111, %reduce_sum.2112), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_50.2135 (reduce_sum.2132: f32[], reduce_sum.2133: f32[]) -> f32[] {
  %reduce_sum.2132 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2133 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2134 = f32[] add(%reduce_sum.2132, %reduce_sum.2133), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_51.2218 (reduce_sum.2215: f32[], reduce_sum.2216: f32[]) -> f32[] {
  %reduce_sum.2215 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2216 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2217 = f32[] add(%reduce_sum.2215, %reduce_sum.2216), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_52.2244 (reduce_sum.2241: f32[], reduce_sum.2242: f32[]) -> f32[] {
  %reduce_sum.2241 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2242 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2243 = f32[] add(%reduce_sum.2241, %reduce_sum.2242), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_53.2272 (reduce_sum.2269: f32[], reduce_sum.2270: f32[]) -> f32[] {
  %reduce_sum.2269 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2270 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2271 = f32[] add(%reduce_sum.2269, %reduce_sum.2270), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_54.2293 (reduce_sum.2290: f32[], reduce_sum.2291: f32[]) -> f32[] {
  %reduce_sum.2290 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2291 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2292 = f32[] add(%reduce_sum.2290, %reduce_sum.2291), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_55.2376 (reduce_sum.2373: f32[], reduce_sum.2374: f32[]) -> f32[] {
  %reduce_sum.2373 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2374 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2375 = f32[] add(%reduce_sum.2373, %reduce_sum.2374), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_56.2402 (reduce_sum.2399: f32[], reduce_sum.2400: f32[]) -> f32[] {
  %reduce_sum.2399 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2400 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2401 = f32[] add(%reduce_sum.2399, %reduce_sum.2400), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_57.2430 (reduce_sum.2427: f32[], reduce_sum.2428: f32[]) -> f32[] {
  %reduce_sum.2427 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2428 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2429 = f32[] add(%reduce_sum.2427, %reduce_sum.2428), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_58.2451 (reduce_sum.2448: f32[], reduce_sum.2449: f32[]) -> f32[] {
  %reduce_sum.2448 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2449 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2450 = f32[] add(%reduce_sum.2448, %reduce_sum.2449), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_59.2534 (reduce_sum.2531: f32[], reduce_sum.2532: f32[]) -> f32[] {
  %reduce_sum.2531 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2532 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2533 = f32[] add(%reduce_sum.2531, %reduce_sum.2532), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_60.2560 (reduce_sum.2557: f32[], reduce_sum.2558: f32[]) -> f32[] {
  %reduce_sum.2557 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2558 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2559 = f32[] add(%reduce_sum.2557, %reduce_sum.2558), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_61.2588 (reduce_sum.2585: f32[], reduce_sum.2586: f32[]) -> f32[] {
  %reduce_sum.2585 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2586 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2587 = f32[] add(%reduce_sum.2585, %reduce_sum.2586), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_62.2609 (reduce_sum.2606: f32[], reduce_sum.2607: f32[]) -> f32[] {
  %reduce_sum.2606 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2607 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2608 = f32[] add(%reduce_sum.2606, %reduce_sum.2607), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_63.2692 (reduce_sum.2689: f32[], reduce_sum.2690: f32[]) -> f32[] {
  %reduce_sum.2689 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2690 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2691 = f32[] add(%reduce_sum.2689, %reduce_sum.2690), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_64.2718 (reduce_sum.2715: f32[], reduce_sum.2716: f32[]) -> f32[] {
  %reduce_sum.2715 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2716 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2717 = f32[] add(%reduce_sum.2715, %reduce_sum.2716), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_65.2746 (reduce_sum.2743: f32[], reduce_sum.2744: f32[]) -> f32[] {
  %reduce_sum.2743 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2744 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2745 = f32[] add(%reduce_sum.2743, %reduce_sum.2744), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_66.2767 (reduce_sum.2764: f32[], reduce_sum.2765: f32[]) -> f32[] {
  %reduce_sum.2764 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2765 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2766 = f32[] add(%reduce_sum.2764, %reduce_sum.2765), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_67.2850 (reduce_sum.2847: f32[], reduce_sum.2848: f32[]) -> f32[] {
  %reduce_sum.2847 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2848 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2849 = f32[] add(%reduce_sum.2847, %reduce_sum.2848), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_68.2876 (reduce_sum.2873: f32[], reduce_sum.2874: f32[]) -> f32[] {
  %reduce_sum.2873 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2874 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2875 = f32[] add(%reduce_sum.2873, %reduce_sum.2874), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_69.2904 (reduce_sum.2901: f32[], reduce_sum.2902: f32[]) -> f32[] {
  %reduce_sum.2901 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2902 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2903 = f32[] add(%reduce_sum.2901, %reduce_sum.2902), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_70.2925 (reduce_sum.2922: f32[], reduce_sum.2923: f32[]) -> f32[] {
  %reduce_sum.2922 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.2923 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.2924 = f32[] add(%reduce_sum.2922, %reduce_sum.2923), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_71.3008 (reduce_sum.3005: f32[], reduce_sum.3006: f32[]) -> f32[] {
  %reduce_sum.3005 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3006 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3007 = f32[] add(%reduce_sum.3005, %reduce_sum.3006), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_72.3034 (reduce_sum.3031: f32[], reduce_sum.3032: f32[]) -> f32[] {
  %reduce_sum.3031 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3032 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3033 = f32[] add(%reduce_sum.3031, %reduce_sum.3032), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_73.3062 (reduce_sum.3059: f32[], reduce_sum.3060: f32[]) -> f32[] {
  %reduce_sum.3059 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3060 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3061 = f32[] add(%reduce_sum.3059, %reduce_sum.3060), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_74.3083 (reduce_sum.3080: f32[], reduce_sum.3081: f32[]) -> f32[] {
  %reduce_sum.3080 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3081 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3082 = f32[] add(%reduce_sum.3080, %reduce_sum.3081), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_75.3166 (reduce_sum.3163: f32[], reduce_sum.3164: f32[]) -> f32[] {
  %reduce_sum.3163 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3164 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3165 = f32[] add(%reduce_sum.3163, %reduce_sum.3164), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_76.3192 (reduce_sum.3189: f32[], reduce_sum.3190: f32[]) -> f32[] {
  %reduce_sum.3189 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3190 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3191 = f32[] add(%reduce_sum.3189, %reduce_sum.3190), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_77.3220 (reduce_sum.3217: f32[], reduce_sum.3218: f32[]) -> f32[] {
  %reduce_sum.3217 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3218 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3219 = f32[] add(%reduce_sum.3217, %reduce_sum.3218), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_78.3241 (reduce_sum.3238: f32[], reduce_sum.3239: f32[]) -> f32[] {
  %reduce_sum.3238 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3239 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3240 = f32[] add(%reduce_sum.3238, %reduce_sum.3239), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_79.3324 (reduce_sum.3321: f32[], reduce_sum.3322: f32[]) -> f32[] {
  %reduce_sum.3321 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3322 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3323 = f32[] add(%reduce_sum.3321, %reduce_sum.3322), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_80.3350 (reduce_sum.3347: f32[], reduce_sum.3348: f32[]) -> f32[] {
  %reduce_sum.3347 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3348 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3349 = f32[] add(%reduce_sum.3347, %reduce_sum.3348), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_81.3378 (reduce_sum.3375: f32[], reduce_sum.3376: f32[]) -> f32[] {
  %reduce_sum.3375 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3376 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3377 = f32[] add(%reduce_sum.3375, %reduce_sum.3376), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_82.3399 (reduce_sum.3396: f32[], reduce_sum.3397: f32[]) -> f32[] {
  %reduce_sum.3396 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3397 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3398 = f32[] add(%reduce_sum.3396, %reduce_sum.3397), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_83.3482 (reduce_sum.3479: f32[], reduce_sum.3480: f32[]) -> f32[] {
  %reduce_sum.3479 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3480 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3481 = f32[] add(%reduce_sum.3479, %reduce_sum.3480), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_84.3508 (reduce_sum.3505: f32[], reduce_sum.3506: f32[]) -> f32[] {
  %reduce_sum.3505 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3506 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3507 = f32[] add(%reduce_sum.3505, %reduce_sum.3506), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_85.3536 (reduce_sum.3533: f32[], reduce_sum.3534: f32[]) -> f32[] {
  %reduce_sum.3533 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3534 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3535 = f32[] add(%reduce_sum.3533, %reduce_sum.3534), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_86.3557 (reduce_sum.3554: f32[], reduce_sum.3555: f32[]) -> f32[] {
  %reduce_sum.3554 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3555 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3556 = f32[] add(%reduce_sum.3554, %reduce_sum.3555), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_87.3640 (reduce_sum.3637: f32[], reduce_sum.3638: f32[]) -> f32[] {
  %reduce_sum.3637 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3638 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3639 = f32[] add(%reduce_sum.3637, %reduce_sum.3638), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_88.3666 (reduce_sum.3663: f32[], reduce_sum.3664: f32[]) -> f32[] {
  %reduce_sum.3663 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3664 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3665 = f32[] add(%reduce_sum.3663, %reduce_sum.3664), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_89.3694 (reduce_sum.3691: f32[], reduce_sum.3692: f32[]) -> f32[] {
  %reduce_sum.3691 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3692 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3693 = f32[] add(%reduce_sum.3691, %reduce_sum.3692), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_90.3715 (reduce_sum.3712: f32[], reduce_sum.3713: f32[]) -> f32[] {
  %reduce_sum.3712 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3713 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3714 = f32[] add(%reduce_sum.3712, %reduce_sum.3713), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_91.3798 (reduce_sum.3795: f32[], reduce_sum.3796: f32[]) -> f32[] {
  %reduce_sum.3795 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3796 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3797 = f32[] add(%reduce_sum.3795, %reduce_sum.3796), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_92.3824 (reduce_sum.3821: f32[], reduce_sum.3822: f32[]) -> f32[] {
  %reduce_sum.3821 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3822 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3823 = f32[] add(%reduce_sum.3821, %reduce_sum.3822), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_93.3852 (reduce_sum.3849: f32[], reduce_sum.3850: f32[]) -> f32[] {
  %reduce_sum.3849 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3850 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3851 = f32[] add(%reduce_sum.3849, %reduce_sum.3850), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_94.3873 (reduce_sum.3870: f32[], reduce_sum.3871: f32[]) -> f32[] {
  %reduce_sum.3870 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3871 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3872 = f32[] add(%reduce_sum.3870, %reduce_sum.3871), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_95.3956 (reduce_sum.3953: f32[], reduce_sum.3954: f32[]) -> f32[] {
  %reduce_sum.3953 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3954 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3955 = f32[] add(%reduce_sum.3953, %reduce_sum.3954), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_96.3982 (reduce_sum.3979: f32[], reduce_sum.3980: f32[]) -> f32[] {
  %reduce_sum.3979 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.3980 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.3981 = f32[] add(%reduce_sum.3979, %reduce_sum.3980), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_97.4010 (reduce_sum.4007: f32[], reduce_sum.4008: f32[]) -> f32[] {
  %reduce_sum.4007 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4008 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4009 = f32[] add(%reduce_sum.4007, %reduce_sum.4008), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_98.4031 (reduce_sum.4028: f32[], reduce_sum.4029: f32[]) -> f32[] {
  %reduce_sum.4028 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4029 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4030 = f32[] add(%reduce_sum.4028, %reduce_sum.4029), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_99.4114 (reduce_sum.4111: f32[], reduce_sum.4112: f32[]) -> f32[] {
  %reduce_sum.4111 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4112 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4113 = f32[] add(%reduce_sum.4111, %reduce_sum.4112), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_100.4140 (reduce_sum.4137: f32[], reduce_sum.4138: f32[]) -> f32[] {
  %reduce_sum.4137 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4138 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4139 = f32[] add(%reduce_sum.4137, %reduce_sum.4138), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_101.4168 (reduce_sum.4165: f32[], reduce_sum.4166: f32[]) -> f32[] {
  %reduce_sum.4165 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4166 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4167 = f32[] add(%reduce_sum.4165, %reduce_sum.4166), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_102.4189 (reduce_sum.4186: f32[], reduce_sum.4187: f32[]) -> f32[] {
  %reduce_sum.4186 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4187 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4188 = f32[] add(%reduce_sum.4186, %reduce_sum.4187), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_103.4272 (reduce_sum.4269: f32[], reduce_sum.4270: f32[]) -> f32[] {
  %reduce_sum.4269 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4270 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4271 = f32[] add(%reduce_sum.4269, %reduce_sum.4270), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_104.4298 (reduce_sum.4295: f32[], reduce_sum.4296: f32[]) -> f32[] {
  %reduce_sum.4295 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4296 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4297 = f32[] add(%reduce_sum.4295, %reduce_sum.4296), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_105.4326 (reduce_sum.4323: f32[], reduce_sum.4324: f32[]) -> f32[] {
  %reduce_sum.4323 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4324 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4325 = f32[] add(%reduce_sum.4323, %reduce_sum.4324), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_106.4347 (reduce_sum.4344: f32[], reduce_sum.4345: f32[]) -> f32[] {
  %reduce_sum.4344 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4345 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4346 = f32[] add(%reduce_sum.4344, %reduce_sum.4345), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_107.4430 (reduce_sum.4427: f32[], reduce_sum.4428: f32[]) -> f32[] {
  %reduce_sum.4427 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4428 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4429 = f32[] add(%reduce_sum.4427, %reduce_sum.4428), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_108.4456 (reduce_sum.4453: f32[], reduce_sum.4454: f32[]) -> f32[] {
  %reduce_sum.4453 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4454 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4455 = f32[] add(%reduce_sum.4453, %reduce_sum.4454), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_109.4484 (reduce_sum.4481: f32[], reduce_sum.4482: f32[]) -> f32[] {
  %reduce_sum.4481 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4482 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4483 = f32[] add(%reduce_sum.4481, %reduce_sum.4482), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_110.4505 (reduce_sum.4502: f32[], reduce_sum.4503: f32[]) -> f32[] {
  %reduce_sum.4502 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4503 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4504 = f32[] add(%reduce_sum.4502, %reduce_sum.4503), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_111.4588 (reduce_sum.4585: f32[], reduce_sum.4586: f32[]) -> f32[] {
  %reduce_sum.4585 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4586 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4587 = f32[] add(%reduce_sum.4585, %reduce_sum.4586), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_112.4614 (reduce_sum.4611: f32[], reduce_sum.4612: f32[]) -> f32[] {
  %reduce_sum.4611 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4612 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4613 = f32[] add(%reduce_sum.4611, %reduce_sum.4612), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_113.4642 (reduce_sum.4639: f32[], reduce_sum.4640: f32[]) -> f32[] {
  %reduce_sum.4639 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4640 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4641 = f32[] add(%reduce_sum.4639, %reduce_sum.4640), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_114.4663 (reduce_sum.4660: f32[], reduce_sum.4661: f32[]) -> f32[] {
  %reduce_sum.4660 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4661 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4662 = f32[] add(%reduce_sum.4660, %reduce_sum.4661), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_115.4746 (reduce_sum.4743: f32[], reduce_sum.4744: f32[]) -> f32[] {
  %reduce_sum.4743 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4744 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4745 = f32[] add(%reduce_sum.4743, %reduce_sum.4744), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_116.4772 (reduce_sum.4769: f32[], reduce_sum.4770: f32[]) -> f32[] {
  %reduce_sum.4769 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4770 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4771 = f32[] add(%reduce_sum.4769, %reduce_sum.4770), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_117.4800 (reduce_sum.4797: f32[], reduce_sum.4798: f32[]) -> f32[] {
  %reduce_sum.4797 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4798 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4799 = f32[] add(%reduce_sum.4797, %reduce_sum.4798), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_118.4821 (reduce_sum.4818: f32[], reduce_sum.4819: f32[]) -> f32[] {
  %reduce_sum.4818 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4819 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4820 = f32[] add(%reduce_sum.4818, %reduce_sum.4819), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_119.4904 (reduce_sum.4901: f32[], reduce_sum.4902: f32[]) -> f32[] {
  %reduce_sum.4901 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4902 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4903 = f32[] add(%reduce_sum.4901, %reduce_sum.4902), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_120.4930 (reduce_sum.4927: f32[], reduce_sum.4928: f32[]) -> f32[] {
  %reduce_sum.4927 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4928 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4929 = f32[] add(%reduce_sum.4927, %reduce_sum.4928), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_121.4958 (reduce_sum.4955: f32[], reduce_sum.4956: f32[]) -> f32[] {
  %reduce_sum.4955 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4956 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4957 = f32[] add(%reduce_sum.4955, %reduce_sum.4956), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_122.4979 (reduce_sum.4976: f32[], reduce_sum.4977: f32[]) -> f32[] {
  %reduce_sum.4976 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.4977 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.4978 = f32[] add(%reduce_sum.4976, %reduce_sum.4977), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_123.5062 (reduce_sum.5059: f32[], reduce_sum.5060: f32[]) -> f32[] {
  %reduce_sum.5059 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5060 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5061 = f32[] add(%reduce_sum.5059, %reduce_sum.5060), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_124.5088 (reduce_sum.5085: f32[], reduce_sum.5086: f32[]) -> f32[] {
  %reduce_sum.5085 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5086 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5087 = f32[] add(%reduce_sum.5085, %reduce_sum.5086), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_125.5116 (reduce_sum.5113: f32[], reduce_sum.5114: f32[]) -> f32[] {
  %reduce_sum.5113 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5114 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5115 = f32[] add(%reduce_sum.5113, %reduce_sum.5114), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_126.5137 (reduce_sum.5134: f32[], reduce_sum.5135: f32[]) -> f32[] {
  %reduce_sum.5134 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5135 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5136 = f32[] add(%reduce_sum.5134, %reduce_sum.5135), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_127.5220 (reduce_sum.5217: f32[], reduce_sum.5218: f32[]) -> f32[] {
  %reduce_sum.5217 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5218 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5219 = f32[] add(%reduce_sum.5217, %reduce_sum.5218), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_128.5246 (reduce_sum.5243: f32[], reduce_sum.5244: f32[]) -> f32[] {
  %reduce_sum.5243 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5244 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5245 = f32[] add(%reduce_sum.5243, %reduce_sum.5244), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_129.5274 (reduce_sum.5271: f32[], reduce_sum.5272: f32[]) -> f32[] {
  %reduce_sum.5271 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5272 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5273 = f32[] add(%reduce_sum.5271, %reduce_sum.5272), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_130.5295 (reduce_sum.5292: f32[], reduce_sum.5293: f32[]) -> f32[] {
  %reduce_sum.5292 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5293 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5294 = f32[] add(%reduce_sum.5292, %reduce_sum.5293), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_131.5378 (reduce_sum.5375: f32[], reduce_sum.5376: f32[]) -> f32[] {
  %reduce_sum.5375 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5376 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5377 = f32[] add(%reduce_sum.5375, %reduce_sum.5376), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_132.5404 (reduce_sum.5401: f32[], reduce_sum.5402: f32[]) -> f32[] {
  %reduce_sum.5401 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5402 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5403 = f32[] add(%reduce_sum.5401, %reduce_sum.5402), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_133.5432 (reduce_sum.5429: f32[], reduce_sum.5430: f32[]) -> f32[] {
  %reduce_sum.5429 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5430 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5431 = f32[] add(%reduce_sum.5429, %reduce_sum.5430), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_134.5453 (reduce_sum.5450: f32[], reduce_sum.5451: f32[]) -> f32[] {
  %reduce_sum.5450 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5451 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5452 = f32[] add(%reduce_sum.5450, %reduce_sum.5451), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_135.5536 (reduce_sum.5533: f32[], reduce_sum.5534: f32[]) -> f32[] {
  %reduce_sum.5533 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5534 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5535 = f32[] add(%reduce_sum.5533, %reduce_sum.5534), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_136.5562 (reduce_sum.5559: f32[], reduce_sum.5560: f32[]) -> f32[] {
  %reduce_sum.5559 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5560 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5561 = f32[] add(%reduce_sum.5559, %reduce_sum.5560), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_137.5590 (reduce_sum.5587: f32[], reduce_sum.5588: f32[]) -> f32[] {
  %reduce_sum.5587 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5588 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5589 = f32[] add(%reduce_sum.5587, %reduce_sum.5588), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_138.5611 (reduce_sum.5608: f32[], reduce_sum.5609: f32[]) -> f32[] {
  %reduce_sum.5608 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5609 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5610 = f32[] add(%reduce_sum.5608, %reduce_sum.5609), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_139.5694 (reduce_sum.5691: f32[], reduce_sum.5692: f32[]) -> f32[] {
  %reduce_sum.5691 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5692 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5693 = f32[] add(%reduce_sum.5691, %reduce_sum.5692), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_140.5720 (reduce_sum.5717: f32[], reduce_sum.5718: f32[]) -> f32[] {
  %reduce_sum.5717 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5718 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5719 = f32[] add(%reduce_sum.5717, %reduce_sum.5718), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_141.5748 (reduce_sum.5745: f32[], reduce_sum.5746: f32[]) -> f32[] {
  %reduce_sum.5745 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5746 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5747 = f32[] add(%reduce_sum.5745, %reduce_sum.5746), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_142.5769 (reduce_sum.5766: f32[], reduce_sum.5767: f32[]) -> f32[] {
  %reduce_sum.5766 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5767 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5768 = f32[] add(%reduce_sum.5766, %reduce_sum.5767), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_143.5852 (reduce_sum.5849: f32[], reduce_sum.5850: f32[]) -> f32[] {
  %reduce_sum.5849 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5850 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5851 = f32[] add(%reduce_sum.5849, %reduce_sum.5850), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_144.5878 (reduce_sum.5875: f32[], reduce_sum.5876: f32[]) -> f32[] {
  %reduce_sum.5875 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5876 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5877 = f32[] add(%reduce_sum.5875, %reduce_sum.5876), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_145.5906 (reduce_sum.5903: f32[], reduce_sum.5904: f32[]) -> f32[] {
  %reduce_sum.5903 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5904 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5905 = f32[] add(%reduce_sum.5903, %reduce_sum.5904), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_146.5927 (reduce_sum.5924: f32[], reduce_sum.5925: f32[]) -> f32[] {
  %reduce_sum.5924 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.5925 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.5926 = f32[] add(%reduce_sum.5924, %reduce_sum.5925), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_147.6010 (reduce_sum.6007: f32[], reduce_sum.6008: f32[]) -> f32[] {
  %reduce_sum.6007 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6008 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6009 = f32[] add(%reduce_sum.6007, %reduce_sum.6008), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_148.6036 (reduce_sum.6033: f32[], reduce_sum.6034: f32[]) -> f32[] {
  %reduce_sum.6033 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6034 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6035 = f32[] add(%reduce_sum.6033, %reduce_sum.6034), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_149.6064 (reduce_sum.6061: f32[], reduce_sum.6062: f32[]) -> f32[] {
  %reduce_sum.6061 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6062 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6063 = f32[] add(%reduce_sum.6061, %reduce_sum.6062), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_150.6085 (reduce_sum.6082: f32[], reduce_sum.6083: f32[]) -> f32[] {
  %reduce_sum.6082 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6083 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6084 = f32[] add(%reduce_sum.6082, %reduce_sum.6083), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_151.6168 (reduce_sum.6165: f32[], reduce_sum.6166: f32[]) -> f32[] {
  %reduce_sum.6165 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6166 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6167 = f32[] add(%reduce_sum.6165, %reduce_sum.6166), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_152.6194 (reduce_sum.6191: f32[], reduce_sum.6192: f32[]) -> f32[] {
  %reduce_sum.6191 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6192 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6193 = f32[] add(%reduce_sum.6191, %reduce_sum.6192), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_153.6222 (reduce_sum.6219: f32[], reduce_sum.6220: f32[]) -> f32[] {
  %reduce_sum.6219 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6220 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6221 = f32[] add(%reduce_sum.6219, %reduce_sum.6220), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_154.6243 (reduce_sum.6240: f32[], reduce_sum.6241: f32[]) -> f32[] {
  %reduce_sum.6240 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6241 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6242 = f32[] add(%reduce_sum.6240, %reduce_sum.6241), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_155.6326 (reduce_sum.6323: f32[], reduce_sum.6324: f32[]) -> f32[] {
  %reduce_sum.6323 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6324 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6325 = f32[] add(%reduce_sum.6323, %reduce_sum.6324), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_156.6352 (reduce_sum.6349: f32[], reduce_sum.6350: f32[]) -> f32[] {
  %reduce_sum.6349 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6350 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6351 = f32[] add(%reduce_sum.6349, %reduce_sum.6350), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_157.6380 (reduce_sum.6377: f32[], reduce_sum.6378: f32[]) -> f32[] {
  %reduce_sum.6377 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6378 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6379 = f32[] add(%reduce_sum.6377, %reduce_sum.6378), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_158.6401 (reduce_sum.6398: f32[], reduce_sum.6399: f32[]) -> f32[] {
  %reduce_sum.6398 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6399 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6400 = f32[] add(%reduce_sum.6398, %reduce_sum.6399), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_159.6484 (reduce_sum.6481: f32[], reduce_sum.6482: f32[]) -> f32[] {
  %reduce_sum.6481 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6482 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6483 = f32[] add(%reduce_sum.6481, %reduce_sum.6482), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_160.6510 (reduce_sum.6507: f32[], reduce_sum.6508: f32[]) -> f32[] {
  %reduce_sum.6507 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6508 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6509 = f32[] add(%reduce_sum.6507, %reduce_sum.6508), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_161.6538 (reduce_sum.6535: f32[], reduce_sum.6536: f32[]) -> f32[] {
  %reduce_sum.6535 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6536 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6537 = f32[] add(%reduce_sum.6535, %reduce_sum.6536), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_162.6559 (reduce_sum.6556: f32[], reduce_sum.6557: f32[]) -> f32[] {
  %reduce_sum.6556 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6557 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6558 = f32[] add(%reduce_sum.6556, %reduce_sum.6557), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_163.6642 (reduce_sum.6639: f32[], reduce_sum.6640: f32[]) -> f32[] {
  %reduce_sum.6639 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6640 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6641 = f32[] add(%reduce_sum.6639, %reduce_sum.6640), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_164.6668 (reduce_sum.6665: f32[], reduce_sum.6666: f32[]) -> f32[] {
  %reduce_sum.6665 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6666 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6667 = f32[] add(%reduce_sum.6665, %reduce_sum.6666), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_165.6696 (reduce_sum.6693: f32[], reduce_sum.6694: f32[]) -> f32[] {
  %reduce_sum.6693 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6694 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6695 = f32[] add(%reduce_sum.6693, %reduce_sum.6694), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_166.6717 (reduce_sum.6714: f32[], reduce_sum.6715: f32[]) -> f32[] {
  %reduce_sum.6714 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6715 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6716 = f32[] add(%reduce_sum.6714, %reduce_sum.6715), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_167.6800 (reduce_sum.6797: f32[], reduce_sum.6798: f32[]) -> f32[] {
  %reduce_sum.6797 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6798 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6799 = f32[] add(%reduce_sum.6797, %reduce_sum.6798), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_168.6826 (reduce_sum.6823: f32[], reduce_sum.6824: f32[]) -> f32[] {
  %reduce_sum.6823 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6824 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6825 = f32[] add(%reduce_sum.6823, %reduce_sum.6824), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_169.6854 (reduce_sum.6851: f32[], reduce_sum.6852: f32[]) -> f32[] {
  %reduce_sum.6851 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6852 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6853 = f32[] add(%reduce_sum.6851, %reduce_sum.6852), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_170.6875 (reduce_sum.6872: f32[], reduce_sum.6873: f32[]) -> f32[] {
  %reduce_sum.6872 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6873 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6874 = f32[] add(%reduce_sum.6872, %reduce_sum.6873), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_171.6958 (reduce_sum.6955: f32[], reduce_sum.6956: f32[]) -> f32[] {
  %reduce_sum.6955 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6956 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6957 = f32[] add(%reduce_sum.6955, %reduce_sum.6956), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_172.6984 (reduce_sum.6981: f32[], reduce_sum.6982: f32[]) -> f32[] {
  %reduce_sum.6981 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.6982 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.6983 = f32[] add(%reduce_sum.6981, %reduce_sum.6982), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_173.7012 (reduce_sum.7009: f32[], reduce_sum.7010: f32[]) -> f32[] {
  %reduce_sum.7009 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7010 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7011 = f32[] add(%reduce_sum.7009, %reduce_sum.7010), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_174.7033 (reduce_sum.7030: f32[], reduce_sum.7031: f32[]) -> f32[] {
  %reduce_sum.7030 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7031 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7032 = f32[] add(%reduce_sum.7030, %reduce_sum.7031), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_175.7116 (reduce_sum.7113: f32[], reduce_sum.7114: f32[]) -> f32[] {
  %reduce_sum.7113 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7114 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7115 = f32[] add(%reduce_sum.7113, %reduce_sum.7114), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_176.7142 (reduce_sum.7139: f32[], reduce_sum.7140: f32[]) -> f32[] {
  %reduce_sum.7139 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7140 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7141 = f32[] add(%reduce_sum.7139, %reduce_sum.7140), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_177.7170 (reduce_sum.7167: f32[], reduce_sum.7168: f32[]) -> f32[] {
  %reduce_sum.7167 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7168 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7169 = f32[] add(%reduce_sum.7167, %reduce_sum.7168), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_178.7191 (reduce_sum.7188: f32[], reduce_sum.7189: f32[]) -> f32[] {
  %reduce_sum.7188 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7189 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7190 = f32[] add(%reduce_sum.7188, %reduce_sum.7189), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_179.7274 (reduce_sum.7271: f32[], reduce_sum.7272: f32[]) -> f32[] {
  %reduce_sum.7271 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7272 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7273 = f32[] add(%reduce_sum.7271, %reduce_sum.7272), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_180.7300 (reduce_sum.7297: f32[], reduce_sum.7298: f32[]) -> f32[] {
  %reduce_sum.7297 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7298 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7299 = f32[] add(%reduce_sum.7297, %reduce_sum.7298), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_181.7328 (reduce_sum.7325: f32[], reduce_sum.7326: f32[]) -> f32[] {
  %reduce_sum.7325 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7326 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7327 = f32[] add(%reduce_sum.7325, %reduce_sum.7326), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_182.7349 (reduce_sum.7346: f32[], reduce_sum.7347: f32[]) -> f32[] {
  %reduce_sum.7346 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7347 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7348 = f32[] add(%reduce_sum.7346, %reduce_sum.7347), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_183.7432 (reduce_sum.7429: f32[], reduce_sum.7430: f32[]) -> f32[] {
  %reduce_sum.7429 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7430 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7431 = f32[] add(%reduce_sum.7429, %reduce_sum.7430), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_184.7458 (reduce_sum.7455: f32[], reduce_sum.7456: f32[]) -> f32[] {
  %reduce_sum.7455 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7456 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7457 = f32[] add(%reduce_sum.7455, %reduce_sum.7456), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_185.7486 (reduce_sum.7483: f32[], reduce_sum.7484: f32[]) -> f32[] {
  %reduce_sum.7483 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7484 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7485 = f32[] add(%reduce_sum.7483, %reduce_sum.7484), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_186.7507 (reduce_sum.7504: f32[], reduce_sum.7505: f32[]) -> f32[] {
  %reduce_sum.7504 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7505 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7506 = f32[] add(%reduce_sum.7504, %reduce_sum.7505), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_187.7590 (reduce_sum.7587: f32[], reduce_sum.7588: f32[]) -> f32[] {
  %reduce_sum.7587 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7588 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7589 = f32[] add(%reduce_sum.7587, %reduce_sum.7588), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_188.7616 (reduce_sum.7613: f32[], reduce_sum.7614: f32[]) -> f32[] {
  %reduce_sum.7613 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7614 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7615 = f32[] add(%reduce_sum.7613, %reduce_sum.7614), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_189.7644 (reduce_sum.7641: f32[], reduce_sum.7642: f32[]) -> f32[] {
  %reduce_sum.7641 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7642 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7643 = f32[] add(%reduce_sum.7641, %reduce_sum.7642), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_190.7665 (reduce_sum.7662: f32[], reduce_sum.7663: f32[]) -> f32[] {
  %reduce_sum.7662 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7663 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7664 = f32[] add(%reduce_sum.7662, %reduce_sum.7663), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_191.7748 (reduce_sum.7745: f32[], reduce_sum.7746: f32[]) -> f32[] {
  %reduce_sum.7745 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7746 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7747 = f32[] add(%reduce_sum.7745, %reduce_sum.7746), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_192.7774 (reduce_sum.7771: f32[], reduce_sum.7772: f32[]) -> f32[] {
  %reduce_sum.7771 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7772 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7773 = f32[] add(%reduce_sum.7771, %reduce_sum.7772), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_193.7802 (reduce_sum.7799: f32[], reduce_sum.7800: f32[]) -> f32[] {
  %reduce_sum.7799 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7800 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7801 = f32[] add(%reduce_sum.7799, %reduce_sum.7800), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_194.7823 (reduce_sum.7820: f32[], reduce_sum.7821: f32[]) -> f32[] {
  %reduce_sum.7820 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7821 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7822 = f32[] add(%reduce_sum.7820, %reduce_sum.7821), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_195.7906 (reduce_sum.7903: f32[], reduce_sum.7904: f32[]) -> f32[] {
  %reduce_sum.7903 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7904 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7905 = f32[] add(%reduce_sum.7903, %reduce_sum.7904), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_196.7932 (reduce_sum.7929: f32[], reduce_sum.7930: f32[]) -> f32[] {
  %reduce_sum.7929 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7930 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7931 = f32[] add(%reduce_sum.7929, %reduce_sum.7930), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_197.7960 (reduce_sum.7957: f32[], reduce_sum.7958: f32[]) -> f32[] {
  %reduce_sum.7957 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7958 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7959 = f32[] add(%reduce_sum.7957, %reduce_sum.7958), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_198.7981 (reduce_sum.7978: f32[], reduce_sum.7979: f32[]) -> f32[] {
  %reduce_sum.7978 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.7979 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.7980 = f32[] add(%reduce_sum.7978, %reduce_sum.7979), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_199.8064 (reduce_sum.8061: f32[], reduce_sum.8062: f32[]) -> f32[] {
  %reduce_sum.8061 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8062 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8063 = f32[] add(%reduce_sum.8061, %reduce_sum.8062), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_200.8090 (reduce_sum.8087: f32[], reduce_sum.8088: f32[]) -> f32[] {
  %reduce_sum.8087 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8088 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8089 = f32[] add(%reduce_sum.8087, %reduce_sum.8088), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_201.8118 (reduce_sum.8115: f32[], reduce_sum.8116: f32[]) -> f32[] {
  %reduce_sum.8115 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8116 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8117 = f32[] add(%reduce_sum.8115, %reduce_sum.8116), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_202.8139 (reduce_sum.8136: f32[], reduce_sum.8137: f32[]) -> f32[] {
  %reduce_sum.8136 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8137 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8138 = f32[] add(%reduce_sum.8136, %reduce_sum.8137), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_203.8222 (reduce_sum.8219: f32[], reduce_sum.8220: f32[]) -> f32[] {
  %reduce_sum.8219 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8220 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8221 = f32[] add(%reduce_sum.8219, %reduce_sum.8220), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_204.8248 (reduce_sum.8245: f32[], reduce_sum.8246: f32[]) -> f32[] {
  %reduce_sum.8245 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8246 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8247 = f32[] add(%reduce_sum.8245, %reduce_sum.8246), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_205.8276 (reduce_sum.8273: f32[], reduce_sum.8274: f32[]) -> f32[] {
  %reduce_sum.8273 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8274 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8275 = f32[] add(%reduce_sum.8273, %reduce_sum.8274), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_206.8297 (reduce_sum.8294: f32[], reduce_sum.8295: f32[]) -> f32[] {
  %reduce_sum.8294 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8295 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8296 = f32[] add(%reduce_sum.8294, %reduce_sum.8295), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_207.8380 (reduce_sum.8377: f32[], reduce_sum.8378: f32[]) -> f32[] {
  %reduce_sum.8377 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8378 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8379 = f32[] add(%reduce_sum.8377, %reduce_sum.8378), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_208.8406 (reduce_sum.8403: f32[], reduce_sum.8404: f32[]) -> f32[] {
  %reduce_sum.8403 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8404 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8405 = f32[] add(%reduce_sum.8403, %reduce_sum.8404), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_209.8434 (reduce_sum.8431: f32[], reduce_sum.8432: f32[]) -> f32[] {
  %reduce_sum.8431 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8432 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8433 = f32[] add(%reduce_sum.8431, %reduce_sum.8432), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_210.8455 (reduce_sum.8452: f32[], reduce_sum.8453: f32[]) -> f32[] {
  %reduce_sum.8452 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8453 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8454 = f32[] add(%reduce_sum.8452, %reduce_sum.8453), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_211.8538 (reduce_sum.8535: f32[], reduce_sum.8536: f32[]) -> f32[] {
  %reduce_sum.8535 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8536 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8537 = f32[] add(%reduce_sum.8535, %reduce_sum.8536), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_212.8564 (reduce_sum.8561: f32[], reduce_sum.8562: f32[]) -> f32[] {
  %reduce_sum.8561 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8562 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8563 = f32[] add(%reduce_sum.8561, %reduce_sum.8562), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_213.8592 (reduce_sum.8589: f32[], reduce_sum.8590: f32[]) -> f32[] {
  %reduce_sum.8589 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8590 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8591 = f32[] add(%reduce_sum.8589, %reduce_sum.8590), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_214.8613 (reduce_sum.8610: f32[], reduce_sum.8611: f32[]) -> f32[] {
  %reduce_sum.8610 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8611 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8612 = f32[] add(%reduce_sum.8610, %reduce_sum.8611), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_215.8696 (reduce_sum.8693: f32[], reduce_sum.8694: f32[]) -> f32[] {
  %reduce_sum.8693 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8694 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8695 = f32[] add(%reduce_sum.8693, %reduce_sum.8694), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_216.8722 (reduce_sum.8719: f32[], reduce_sum.8720: f32[]) -> f32[] {
  %reduce_sum.8719 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8720 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8721 = f32[] add(%reduce_sum.8719, %reduce_sum.8720), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_217.8750 (reduce_sum.8747: f32[], reduce_sum.8748: f32[]) -> f32[] {
  %reduce_sum.8747 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8748 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8749 = f32[] add(%reduce_sum.8747, %reduce_sum.8748), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_218.8771 (reduce_sum.8768: f32[], reduce_sum.8769: f32[]) -> f32[] {
  %reduce_sum.8768 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8769 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8770 = f32[] add(%reduce_sum.8768, %reduce_sum.8769), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_219.8854 (reduce_sum.8851: f32[], reduce_sum.8852: f32[]) -> f32[] {
  %reduce_sum.8851 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8852 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8853 = f32[] add(%reduce_sum.8851, %reduce_sum.8852), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_220.8880 (reduce_sum.8877: f32[], reduce_sum.8878: f32[]) -> f32[] {
  %reduce_sum.8877 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8878 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8879 = f32[] add(%reduce_sum.8877, %reduce_sum.8878), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_221.8908 (reduce_sum.8905: f32[], reduce_sum.8906: f32[]) -> f32[] {
  %reduce_sum.8905 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8906 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8907 = f32[] add(%reduce_sum.8905, %reduce_sum.8906), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_222.8929 (reduce_sum.8926: f32[], reduce_sum.8927: f32[]) -> f32[] {
  %reduce_sum.8926 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.8927 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.8928 = f32[] add(%reduce_sum.8926, %reduce_sum.8927), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_223.9012 (reduce_sum.9009: f32[], reduce_sum.9010: f32[]) -> f32[] {
  %reduce_sum.9009 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.9010 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.9011 = f32[] add(%reduce_sum.9009, %reduce_sum.9010), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

%region_224.9037 (reduce_sum.9034: f32[], reduce_sum.9035: f32[]) -> f32[] {
  %reduce_sum.9034 = f32[] parameter(0), metadata={op_name="reduce_sum"}
  %reduce_sum.9035 = f32[] parameter(1), metadata={op_name="reduce_sum"}
  ROOT %reduce_sum.9036 = f32[] add(%reduce_sum.9034, %reduce_sum.9035), metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
}

ENTRY %main.9054 (params_and_buffers__vllm_model_language_model_model_embed_tokens_weight__.1: bf16[152064,2048], params_and_buffers__vllm_model_language_model_model_layers_0_input_layernorm_weight__.2: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_0_mlp_experts_w13_weight__.3: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_0_mlp_experts_w2_weight__.4: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_0_mlp_gate_weight__.5: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_0_post_attention_layernorm_weight__.6: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_k_norm_weight__.7: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_o_proj_weight__.8: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_q_norm_weight__.9: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_qkv_proj_weight__.10: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11: bf16[262144,128], params_and_buffers__vllm_model_language_model_model_layers_1_input_layernorm_weight__.12: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_1_mlp_experts_w13_weight__.13: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_1_mlp_experts_w2_weight__.14: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_1_mlp_gate_weight__.15: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_1_post_attention_layernorm_weight__.16: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_1_self_attn_k_norm_weight__.17: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_1_self_attn_o_proj_weight__.18: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_1_self_attn_q_norm_weight__.19: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_1_self_attn_qkv_proj_weight__.20: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_10_input_layernorm_weight__.21: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_10_mlp_experts_w13_weight__.22: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_10_mlp_experts_w2_weight__.23: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_10_mlp_gate_weight__.24: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_10_post_attention_layernorm_weight__.25: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_10_self_attn_k_norm_weight__.26: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_10_self_attn_o_proj_weight__.27: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_10_self_attn_q_norm_weight__.28: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_10_self_attn_qkv_proj_weight__.29: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_11_input_layernorm_weight__.30: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_11_mlp_experts_w13_weight__.31: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_11_mlp_experts_w2_weight__.32: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_11_mlp_gate_weight__.33: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_11_post_attention_layernorm_weight__.34: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_11_self_attn_k_norm_weight__.35: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_11_self_attn_o_proj_weight__.36: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_11_self_attn_q_norm_weight__.37: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_11_self_attn_qkv_proj_weight__.38: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_12_input_layernorm_weight__.39: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_12_mlp_experts_w13_weight__.40: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_12_mlp_experts_w2_weight__.41: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_12_mlp_gate_weight__.42: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_12_post_attention_layernorm_weight__.43: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_12_self_attn_k_norm_weight__.44: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_12_self_attn_o_proj_weight__.45: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_12_self_attn_q_norm_weight__.46: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_12_self_attn_qkv_proj_weight__.47: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_13_input_layernorm_weight__.48: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_13_mlp_experts_w13_weight__.49: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_13_mlp_experts_w2_weight__.50: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_13_mlp_gate_weight__.51: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_13_post_attention_layernorm_weight__.52: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_13_self_attn_k_norm_weight__.53: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_13_self_attn_o_proj_weight__.54: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_13_self_attn_q_norm_weight__.55: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_13_self_attn_qkv_proj_weight__.56: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_14_input_layernorm_weight__.57: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_14_mlp_experts_w13_weight__.58: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_14_mlp_experts_w2_weight__.59: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_14_mlp_gate_weight__.60: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_14_post_attention_layernorm_weight__.61: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_14_self_attn_k_norm_weight__.62: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_14_self_attn_o_proj_weight__.63: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_14_self_attn_q_norm_weight__.64: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_14_self_attn_qkv_proj_weight__.65: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_15_input_layernorm_weight__.66: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_15_mlp_experts_w13_weight__.67: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_15_mlp_experts_w2_weight__.68: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_15_mlp_gate_weight__.69: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_15_post_attention_layernorm_weight__.70: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_15_self_attn_k_norm_weight__.71: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_15_self_attn_o_proj_weight__.72: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_15_self_attn_q_norm_weight__.73: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_15_self_attn_qkv_proj_weight__.74: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_16_input_layernorm_weight__.75: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_16_mlp_experts_w13_weight__.76: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_16_mlp_experts_w2_weight__.77: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_16_mlp_gate_weight__.78: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_16_post_attention_layernorm_weight__.79: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_16_self_attn_k_norm_weight__.80: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_16_self_attn_o_proj_weight__.81: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_16_self_attn_q_norm_weight__.82: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_16_self_attn_qkv_proj_weight__.83: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_17_input_layernorm_weight__.84: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_17_mlp_experts_w13_weight__.85: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_17_mlp_experts_w2_weight__.86: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_17_mlp_gate_weight__.87: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_17_post_attention_layernorm_weight__.88: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_17_self_attn_k_norm_weight__.89: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_17_self_attn_o_proj_weight__.90: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_17_self_attn_q_norm_weight__.91: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_17_self_attn_qkv_proj_weight__.92: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_18_input_layernorm_weight__.93: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_18_mlp_experts_w13_weight__.94: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_18_mlp_experts_w2_weight__.95: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_18_mlp_gate_weight__.96: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_18_post_attention_layernorm_weight__.97: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_18_self_attn_k_norm_weight__.98: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_18_self_attn_o_proj_weight__.99: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_18_self_attn_q_norm_weight__.100: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_18_self_attn_qkv_proj_weight__.101: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_19_input_layernorm_weight__.102: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_19_mlp_experts_w13_weight__.103: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_19_mlp_experts_w2_weight__.104: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_19_mlp_gate_weight__.105: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_19_post_attention_layernorm_weight__.106: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_19_self_attn_k_norm_weight__.107: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_19_self_attn_o_proj_weight__.108: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_19_self_attn_q_norm_weight__.109: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_19_self_attn_qkv_proj_weight__.110: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_2_input_layernorm_weight__.111: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_2_mlp_experts_w13_weight__.112: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_2_mlp_experts_w2_weight__.113: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_2_mlp_gate_weight__.114: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_2_post_attention_layernorm_weight__.115: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_2_self_attn_k_norm_weight__.116: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_2_self_attn_o_proj_weight__.117: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_2_self_attn_q_norm_weight__.118: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_2_self_attn_qkv_proj_weight__.119: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_20_input_layernorm_weight__.120: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_20_mlp_experts_w13_weight__.121: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_20_mlp_experts_w2_weight__.122: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_20_mlp_gate_weight__.123: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_20_post_attention_layernorm_weight__.124: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_20_self_attn_k_norm_weight__.125: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_20_self_attn_o_proj_weight__.126: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_20_self_attn_q_norm_weight__.127: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_20_self_attn_qkv_proj_weight__.128: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_21_input_layernorm_weight__.129: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_21_mlp_experts_w13_weight__.130: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_21_mlp_experts_w2_weight__.131: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_21_mlp_gate_weight__.132: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_21_post_attention_layernorm_weight__.133: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_21_self_attn_k_norm_weight__.134: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_21_self_attn_o_proj_weight__.135: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_21_self_attn_q_norm_weight__.136: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_21_self_attn_qkv_proj_weight__.137: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_22_input_layernorm_weight__.138: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_22_mlp_experts_w13_weight__.139: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_22_mlp_experts_w2_weight__.140: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_22_mlp_gate_weight__.141: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_22_post_attention_layernorm_weight__.142: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_22_self_attn_k_norm_weight__.143: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_22_self_attn_o_proj_weight__.144: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_22_self_attn_q_norm_weight__.145: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_22_self_attn_qkv_proj_weight__.146: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_23_input_layernorm_weight__.147: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_23_mlp_experts_w13_weight__.148: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_23_mlp_experts_w2_weight__.149: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_23_mlp_gate_weight__.150: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_23_post_attention_layernorm_weight__.151: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_23_self_attn_k_norm_weight__.152: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_23_self_attn_o_proj_weight__.153: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_23_self_attn_q_norm_weight__.154: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_23_self_attn_qkv_proj_weight__.155: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_24_input_layernorm_weight__.156: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_24_mlp_experts_w13_weight__.157: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_24_mlp_experts_w2_weight__.158: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_24_mlp_gate_weight__.159: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_24_post_attention_layernorm_weight__.160: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_24_self_attn_k_norm_weight__.161: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_24_self_attn_o_proj_weight__.162: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_24_self_attn_q_norm_weight__.163: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_24_self_attn_qkv_proj_weight__.164: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_25_input_layernorm_weight__.165: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_25_mlp_experts_w13_weight__.166: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_25_mlp_experts_w2_weight__.167: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_25_mlp_gate_weight__.168: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_25_post_attention_layernorm_weight__.169: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_25_self_attn_k_norm_weight__.170: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_25_self_attn_o_proj_weight__.171: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_25_self_attn_q_norm_weight__.172: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_25_self_attn_qkv_proj_weight__.173: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_26_input_layernorm_weight__.174: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_26_mlp_experts_w13_weight__.175: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_26_mlp_experts_w2_weight__.176: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_26_mlp_gate_weight__.177: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_26_post_attention_layernorm_weight__.178: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_26_self_attn_k_norm_weight__.179: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_26_self_attn_o_proj_weight__.180: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_26_self_attn_q_norm_weight__.181: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_26_self_attn_qkv_proj_weight__.182: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_27_input_layernorm_weight__.183: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_27_mlp_experts_w13_weight__.184: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_27_mlp_experts_w2_weight__.185: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_27_mlp_gate_weight__.186: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_27_post_attention_layernorm_weight__.187: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_27_self_attn_k_norm_weight__.188: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_27_self_attn_o_proj_weight__.189: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_27_self_attn_q_norm_weight__.190: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_27_self_attn_qkv_proj_weight__.191: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_28_input_layernorm_weight__.192: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_28_mlp_experts_w13_weight__.193: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_28_mlp_experts_w2_weight__.194: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_28_mlp_gate_weight__.195: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_28_post_attention_layernorm_weight__.196: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_28_self_attn_k_norm_weight__.197: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_28_self_attn_o_proj_weight__.198: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_28_self_attn_q_norm_weight__.199: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_28_self_attn_qkv_proj_weight__.200: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_29_input_layernorm_weight__.201: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_29_mlp_experts_w13_weight__.202: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_29_mlp_experts_w2_weight__.203: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_29_mlp_gate_weight__.204: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_29_post_attention_layernorm_weight__.205: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_29_self_attn_k_norm_weight__.206: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_29_self_attn_o_proj_weight__.207: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_29_self_attn_q_norm_weight__.208: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_29_self_attn_qkv_proj_weight__.209: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_3_input_layernorm_weight__.210: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_3_mlp_experts_w13_weight__.211: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_3_mlp_experts_w2_weight__.212: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_3_mlp_gate_weight__.213: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_3_post_attention_layernorm_weight__.214: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_3_self_attn_k_norm_weight__.215: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_3_self_attn_o_proj_weight__.216: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_3_self_attn_q_norm_weight__.217: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_3_self_attn_qkv_proj_weight__.218: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_30_input_layernorm_weight__.219: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_30_mlp_experts_w13_weight__.220: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_30_mlp_experts_w2_weight__.221: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_30_mlp_gate_weight__.222: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_30_post_attention_layernorm_weight__.223: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_30_self_attn_k_norm_weight__.224: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_30_self_attn_o_proj_weight__.225: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_30_self_attn_q_norm_weight__.226: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_30_self_attn_qkv_proj_weight__.227: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_31_input_layernorm_weight__.228: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_31_mlp_experts_w13_weight__.229: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_31_mlp_experts_w2_weight__.230: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_31_mlp_gate_weight__.231: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_31_post_attention_layernorm_weight__.232: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_31_self_attn_k_norm_weight__.233: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_31_self_attn_o_proj_weight__.234: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_31_self_attn_q_norm_weight__.235: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_31_self_attn_qkv_proj_weight__.236: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_32_input_layernorm_weight__.237: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_32_mlp_experts_w13_weight__.238: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_32_mlp_experts_w2_weight__.239: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_32_mlp_gate_weight__.240: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_32_post_attention_layernorm_weight__.241: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_32_self_attn_k_norm_weight__.242: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_32_self_attn_o_proj_weight__.243: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_32_self_attn_q_norm_weight__.244: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_32_self_attn_qkv_proj_weight__.245: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_33_input_layernorm_weight__.246: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_33_mlp_experts_w13_weight__.247: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_33_mlp_experts_w2_weight__.248: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_33_mlp_gate_weight__.249: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_33_post_attention_layernorm_weight__.250: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_33_self_attn_k_norm_weight__.251: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_33_self_attn_o_proj_weight__.252: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_33_self_attn_q_norm_weight__.253: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_33_self_attn_qkv_proj_weight__.254: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_34_input_layernorm_weight__.255: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_34_mlp_experts_w13_weight__.256: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_34_mlp_experts_w2_weight__.257: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_34_mlp_gate_weight__.258: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_34_post_attention_layernorm_weight__.259: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_34_self_attn_k_norm_weight__.260: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_34_self_attn_o_proj_weight__.261: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_34_self_attn_q_norm_weight__.262: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_34_self_attn_qkv_proj_weight__.263: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_35_input_layernorm_weight__.264: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_35_mlp_experts_w13_weight__.265: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_35_mlp_experts_w2_weight__.266: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_35_mlp_gate_weight__.267: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_35_post_attention_layernorm_weight__.268: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_35_self_attn_k_norm_weight__.269: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_35_self_attn_o_proj_weight__.270: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_35_self_attn_q_norm_weight__.271: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_35_self_attn_qkv_proj_weight__.272: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_36_input_layernorm_weight__.273: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_36_mlp_experts_w13_weight__.274: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_36_mlp_experts_w2_weight__.275: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_36_mlp_gate_weight__.276: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_36_post_attention_layernorm_weight__.277: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_36_self_attn_k_norm_weight__.278: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_36_self_attn_o_proj_weight__.279: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_36_self_attn_q_norm_weight__.280: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_36_self_attn_qkv_proj_weight__.281: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_37_input_layernorm_weight__.282: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_37_mlp_experts_w13_weight__.283: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_37_mlp_experts_w2_weight__.284: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_37_mlp_gate_weight__.285: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_37_post_attention_layernorm_weight__.286: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_37_self_attn_k_norm_weight__.287: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_37_self_attn_o_proj_weight__.288: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_37_self_attn_q_norm_weight__.289: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_37_self_attn_qkv_proj_weight__.290: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_38_input_layernorm_weight__.291: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_38_mlp_experts_w13_weight__.292: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_38_mlp_experts_w2_weight__.293: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_38_mlp_gate_weight__.294: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_38_post_attention_layernorm_weight__.295: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_38_self_attn_k_norm_weight__.296: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_38_self_attn_o_proj_weight__.297: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_38_self_attn_q_norm_weight__.298: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_38_self_attn_qkv_proj_weight__.299: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_39_input_layernorm_weight__.300: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_39_mlp_experts_w13_weight__.301: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_39_mlp_experts_w2_weight__.302: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_39_mlp_gate_weight__.303: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_39_post_attention_layernorm_weight__.304: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_39_self_attn_k_norm_weight__.305: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_39_self_attn_o_proj_weight__.306: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_39_self_attn_q_norm_weight__.307: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_39_self_attn_qkv_proj_weight__.308: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_4_input_layernorm_weight__.309: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_4_mlp_experts_w13_weight__.310: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_4_mlp_experts_w2_weight__.311: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_4_mlp_gate_weight__.312: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_4_post_attention_layernorm_weight__.313: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_4_self_attn_k_norm_weight__.314: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_4_self_attn_o_proj_weight__.315: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_4_self_attn_q_norm_weight__.316: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_4_self_attn_qkv_proj_weight__.317: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_40_input_layernorm_weight__.318: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_40_mlp_experts_w13_weight__.319: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_40_mlp_experts_w2_weight__.320: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_40_mlp_gate_weight__.321: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_40_post_attention_layernorm_weight__.322: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_40_self_attn_k_norm_weight__.323: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_40_self_attn_o_proj_weight__.324: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_40_self_attn_q_norm_weight__.325: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_40_self_attn_qkv_proj_weight__.326: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_41_input_layernorm_weight__.327: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_41_mlp_experts_w13_weight__.328: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_41_mlp_experts_w2_weight__.329: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_41_mlp_gate_weight__.330: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_41_post_attention_layernorm_weight__.331: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_41_self_attn_k_norm_weight__.332: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_41_self_attn_o_proj_weight__.333: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_41_self_attn_q_norm_weight__.334: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_41_self_attn_qkv_proj_weight__.335: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_42_input_layernorm_weight__.336: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_42_mlp_experts_w13_weight__.337: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_42_mlp_experts_w2_weight__.338: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_42_mlp_gate_weight__.339: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_42_post_attention_layernorm_weight__.340: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_42_self_attn_k_norm_weight__.341: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_42_self_attn_o_proj_weight__.342: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_42_self_attn_q_norm_weight__.343: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_42_self_attn_qkv_proj_weight__.344: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_43_input_layernorm_weight__.345: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_43_mlp_experts_w13_weight__.346: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_43_mlp_experts_w2_weight__.347: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_43_mlp_gate_weight__.348: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_43_post_attention_layernorm_weight__.349: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_43_self_attn_k_norm_weight__.350: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_43_self_attn_o_proj_weight__.351: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_43_self_attn_q_norm_weight__.352: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_43_self_attn_qkv_proj_weight__.353: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_44_input_layernorm_weight__.354: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_44_mlp_experts_w13_weight__.355: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_44_mlp_experts_w2_weight__.356: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_44_mlp_gate_weight__.357: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_44_post_attention_layernorm_weight__.358: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_44_self_attn_k_norm_weight__.359: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_44_self_attn_o_proj_weight__.360: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_44_self_attn_q_norm_weight__.361: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_44_self_attn_qkv_proj_weight__.362: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_45_input_layernorm_weight__.363: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_45_mlp_experts_w13_weight__.364: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_45_mlp_experts_w2_weight__.365: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_45_mlp_gate_weight__.366: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_45_post_attention_layernorm_weight__.367: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_45_self_attn_k_norm_weight__.368: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_45_self_attn_o_proj_weight__.369: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_45_self_attn_q_norm_weight__.370: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_45_self_attn_qkv_proj_weight__.371: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_46_input_layernorm_weight__.372: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_46_mlp_experts_w13_weight__.373: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_46_mlp_experts_w2_weight__.374: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_46_mlp_gate_weight__.375: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_46_post_attention_layernorm_weight__.376: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_46_self_attn_k_norm_weight__.377: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_46_self_attn_o_proj_weight__.378: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_46_self_attn_q_norm_weight__.379: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_46_self_attn_qkv_proj_weight__.380: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_47_input_layernorm_weight__.381: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_47_mlp_experts_w13_weight__.382: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_47_mlp_experts_w2_weight__.383: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_47_mlp_gate_weight__.384: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_47_post_attention_layernorm_weight__.385: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_47_self_attn_k_norm_weight__.386: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_47_self_attn_o_proj_weight__.387: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_47_self_attn_q_norm_weight__.388: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_47_self_attn_qkv_proj_weight__.389: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_5_input_layernorm_weight__.390: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_5_mlp_experts_w13_weight__.391: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_5_mlp_experts_w2_weight__.392: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_5_mlp_gate_weight__.393: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_5_post_attention_layernorm_weight__.394: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_5_self_attn_k_norm_weight__.395: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_5_self_attn_o_proj_weight__.396: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_5_self_attn_q_norm_weight__.397: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_5_self_attn_qkv_proj_weight__.398: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_6_input_layernorm_weight__.399: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_6_mlp_experts_w13_weight__.400: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_6_mlp_experts_w2_weight__.401: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_6_mlp_gate_weight__.402: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_6_post_attention_layernorm_weight__.403: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_6_self_attn_k_norm_weight__.404: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_6_self_attn_o_proj_weight__.405: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_6_self_attn_q_norm_weight__.406: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_6_self_attn_qkv_proj_weight__.407: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_7_input_layernorm_weight__.408: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_7_mlp_experts_w13_weight__.409: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_7_mlp_experts_w2_weight__.410: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_7_mlp_gate_weight__.411: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_7_post_attention_layernorm_weight__.412: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_7_self_attn_k_norm_weight__.413: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_7_self_attn_o_proj_weight__.414: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_7_self_attn_q_norm_weight__.415: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_7_self_attn_qkv_proj_weight__.416: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_8_input_layernorm_weight__.417: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_8_mlp_experts_w13_weight__.418: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_8_mlp_experts_w2_weight__.419: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_8_mlp_gate_weight__.420: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_8_post_attention_layernorm_weight__.421: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_8_self_attn_k_norm_weight__.422: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_8_self_attn_o_proj_weight__.423: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_8_self_attn_q_norm_weight__.424: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_8_self_attn_qkv_proj_weight__.425: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_layers_9_input_layernorm_weight__.426: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_9_mlp_experts_w13_weight__.427: bf16[128,1536,2048], params_and_buffers__vllm_model_language_model_model_layers_9_mlp_experts_w2_weight__.428: bf16[128,2048,768], params_and_buffers__vllm_model_language_model_model_layers_9_mlp_gate_weight__.429: bf16[128,2048], params_and_buffers__vllm_model_language_model_model_layers_9_post_attention_layernorm_weight__.430: bf16[2048], params_and_buffers__vllm_model_language_model_model_layers_9_self_attn_k_norm_weight__.431: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_9_self_attn_o_proj_weight__.432: bf16[2048,4096], params_and_buffers__vllm_model_language_model_model_layers_9_self_attn_q_norm_weight__.433: bf16[128], params_and_buffers__vllm_model_language_model_model_layers_9_self_attn_qkv_proj_weight__.434: bf16[5120,2048], params_and_buffers__vllm_model_language_model_model_norm_weight__.435: bf16[2048], kv_caches_0_.436: bf16[14813,32,4,2,128], kv_caches_1_.437: bf16[14813,32,4,2,128], kv_caches_2_.438: bf16[14813,32,4,2,128], kv_caches_3_.439: bf16[14813,32,4,2,128], kv_caches_4_.440: bf16[14813,32,4,2,128], kv_caches_5_.441: bf16[14813,32,4,2,128], kv_caches_6_.442: bf16[14813,32,4,2,128], kv_caches_7_.443: bf16[14813,32,4,2,128], kv_caches_8_.444: bf16[14813,32,4,2,128], kv_caches_9_.445: bf16[14813,32,4,2,128], kv_caches_10_.446: bf16[14813,32,4,2,128], kv_caches_11_.447: bf16[14813,32,4,2,128], kv_caches_12_.448: bf16[14813,32,4,2,128], kv_caches_13_.449: bf16[14813,32,4,2,128], kv_caches_14_.450: bf16[14813,32,4,2,128], kv_caches_15_.451: bf16[14813,32,4,2,128], kv_caches_16_.452: bf16[14813,32,4,2,128], kv_caches_17_.453: bf16[14813,32,4,2,128], kv_caches_18_.454: bf16[14813,32,4,2,128], kv_caches_19_.455: bf16[14813,32,4,2,128], kv_caches_20_.456: bf16[14813,32,4,2,128], kv_caches_21_.457: bf16[14813,32,4,2,128], kv_caches_22_.458: bf16[14813,32,4,2,128], kv_caches_23_.459: bf16[14813,32,4,2,128], kv_caches_24_.460: bf16[14813,32,4,2,128], kv_caches_25_.461: bf16[14813,32,4,2,128], kv_caches_26_.462: bf16[14813,32,4,2,128], kv_caches_27_.463: bf16[14813,32,4,2,128], kv_caches_28_.464: bf16[14813,32,4,2,128], kv_caches_29_.465: bf16[14813,32,4,2,128], kv_caches_30_.466: bf16[14813,32,4,2,128], kv_caches_31_.467: bf16[14813,32,4,2,128], kv_caches_32_.468: bf16[14813,32,4,2,128], kv_caches_33_.469: bf16[14813,32,4,2,128], kv_caches_34_.470: bf16[14813,32,4,2,128], kv_caches_35_.471: bf16[14813,32,4,2,128], kv_caches_36_.472: bf16[14813,32,4,2,128], kv_caches_37_.473: bf16[14813,32,4,2,128], kv_caches_38_.474: bf16[14813,32,4,2,128], kv_caches_39_.475: bf16[14813,32,4,2,128], kv_caches_40_.476: bf16[14813,32,4,2,128], kv_caches_41_.477: bf16[14813,32,4,2,128], kv_caches_42_.478: bf16[14813,32,4,2,128], kv_caches_43_.479: bf16[14813,32,4,2,128], kv_caches_44_.480: bf16[14813,32,4,2,128], kv_caches_45_.481: bf16[14813,32,4,2,128], kv_caches_46_.482: bf16[14813,32,4,2,128], kv_caches_47_.483: bf16[14813,32,4,2,128], input_ids.484: s32[32], attn_metadata_input_positions.485: s32[32], attn_metadata_block_tables.486: s32[131072], attn_metadata_seq_lens.487: s32[256], attn_metadata_query_start_loc.488: s32[257], attn_metadata_request_distribution.489: s32[3]) -> (bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], /*index=5*/bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], /*index=10*/bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], /*index=15*/bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], /*index=20*/bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], /*index=25*/bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], /*index=30*/bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], /*index=35*/bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], /*index=40*/bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], /*index=45*/bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[14813,32,4,2,128], bf16[32,2048]) {
  %kv_caches_0_.436 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(435), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[0]"}
  %params_and_buffers__vllm_model_language_model_model_embed_tokens_weight__.1 = bf16[152064,2048]{1,0} parameter(0), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.embed_tokens.weight\']"}
  %input_ids.484 = s32[32]{0} parameter(483), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="input_ids"}
  %jit__take_.547 = bf16[32,2048]{1,0} call(%params_and_buffers__vllm_model_language_model_model_embed_tokens_weight__.1, %input_ids.484), to_apply=%_take.546, metadata={op_name="jit(step_fun)/aten::embedding/jit(_take)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=552 source_end_line=552 source_column=9 source_end_column=31}
  %convert_element_type.548 = f32[32,2048]{1,0} convert(%jit__take_.547), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %constant.510 = f32[] constant(2)
  %broadcast.511 = f32[32,2048]{1,0} broadcast(%constant.510), dimensions={}
  %pow.549 = f32[32,2048]{1,0} power(%convert_element_type.548, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %constant.512 = f32[] constant(0)
  %reduce_sum.554 = f32[32]{0} reduce(%pow.549, %constant.512), dimensions={1}, to_apply=%region_1.553, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.555 = f32[32,1]{1,0} reshape(%reduce_sum.554), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %constant.508 = f32[] constant(2048)
  %broadcast.509 = f32[32,1]{1,0} broadcast(%constant.508), dimensions={}
  %div.556 = f32[32,1]{1,0} divide(%broadcast_in_dim.555, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %constant.506 = f32[] constant(1e-06)
  %broadcast.507 = f32[32,1]{1,0} broadcast(%constant.506), dimensions={}
  %add.557 = f32[32,1]{1,0} add(%div.556, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.558 = f32[32,1]{1,0} rsqrt(%add.557), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.559 = f32[32,1]{1,0} broadcast(%rsqrt.558), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.560 = f32[32]{0} reshape(%mul.559), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.561 = f32[32,2048]{1,0} broadcast(%mul.560), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.562 = f32[32,2048]{1,0} multiply(%convert_element_type.548, %mul.561), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.563 = bf16[32,2048]{1,0} convert(%mul.562), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_0_input_layernorm_weight__.2 = bf16[2048]{0} parameter(1), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.0.input_layernorm.weight\']"}
  %broadcast_in_dim.564 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_0_input_layernorm_weight__.2), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.565 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.564), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.566 = bf16[2048]{0} reshape(%mul.565), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.567 = bf16[32,2048]{1,0} broadcast(%mul.566), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.568 = bf16[32,2048]{1,0} multiply(%convert_element_type.563, %mul.567), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_qkv_proj_weight__.10 = bf16[5120,2048]{1,0} parameter(9), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.0.self_attn.qkv_proj.weight\']"}
  %dot_general.569 = bf16[32,5120]{1,0} dot(%mul.568, %params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_qkv_proj_weight__.10), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.570 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.569), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.571 = bf16[32,4,1024]{2,1,0} slice(%reshape.570), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.575 = bf16[32,32,128]{2,1,0} reshape(%slice.571), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.576 = f32[32,32,128]{2,1,0} convert(%reshape.575), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %constant.504 = f32[] constant(2)
  %broadcast.505 = f32[32,32,128]{2,1,0} broadcast(%constant.504), dimensions={}
  %pow.577 = f32[32,32,128]{2,1,0} power(%convert_element_type.576, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.582 = f32[32,32]{1,0} reduce(%pow.577, %constant.512), dimensions={2}, to_apply=%region_2.581, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.583 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.582), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %constant.502 = f32[] constant(128)
  %broadcast.503 = f32[32,32,1]{2,1,0} broadcast(%constant.502), dimensions={}
  %div.584 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.583, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %constant.500 = f32[] constant(1e-06)
  %broadcast.501 = f32[32,32,1]{2,1,0} broadcast(%constant.500), dimensions={}
  %add.585 = f32[32,32,1]{2,1,0} add(%div.584, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.586 = f32[32,32,1]{2,1,0} rsqrt(%add.585), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.587 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.586), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.588 = f32[32,32]{1,0} reshape(%mul.587), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.589 = f32[32,32,128]{2,1,0} broadcast(%mul.588), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.590 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.576, %mul.589), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.591 = bf16[32,32,128]{2,1,0} convert(%mul.590), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_q_norm_weight__.9 = bf16[128]{0} parameter(8), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.0.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.592 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_q_norm_weight__.9), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.593 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.592), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.594 = bf16[128]{0} reshape(%mul.593), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.595 = bf16[32,32,128]{2,1,0} broadcast(%mul.594), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.596 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.591, %mul.595), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.627 = bf16[32,32,64]{2,1,0} slice(%mul.596), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11 = bf16[262144,128]{1,0} parameter(10), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.0.self_attn.rotary_emb.cos_sin_cache\']"}
  %attn_metadata_input_positions.485 = s32[32]{0} parameter(484), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="attn_metadata.input_positions"}
  %constant.492 = s32[] constant(0)
  %broadcast.493 = s32[32]{0} broadcast(%constant.492), dimensions={}
  %lt.618 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %constant.490 = s32[] constant(262144)
  %broadcast.491 = s32[32]{0} broadcast(%constant.490), dimensions={}
  %add.619 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.620 = s32[32]{0} select(%lt.618, %add.619, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.621 = s32[32,1]{1,0} reshape(%select_n.620), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.622 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.621), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.623 = bf16[32,64]{1,0} slice(%gather.622), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.625 = bf16[32,1,64]{2,1,0} reshape(%slice.623), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.629 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.625), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.630 = bf16[32,64]{1,0} reshape(%mul.629), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.631 = bf16[32,32,64]{2,1,0} broadcast(%mul.630), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.632 = bf16[32,32,64]{2,1,0} multiply(%slice.627, %mul.631), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.628 = bf16[32,32,64]{2,1,0} slice(%mul.596), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.624 = bf16[32,64]{1,0} slice(%gather.622), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.626 = bf16[32,1,64]{2,1,0} reshape(%slice.624), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.633 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.626), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.634 = bf16[32,64]{1,0} reshape(%mul.633), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.635 = bf16[32,32,64]{2,1,0} broadcast(%mul.634), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.636 = bf16[32,32,64]{2,1,0} multiply(%slice.628, %mul.635), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.637 = bf16[32,32,64]{2,1,0} subtract(%mul.632, %mul.636), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.638 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.625), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.639 = bf16[32,64]{1,0} reshape(%mul.638), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.640 = bf16[32,32,64]{2,1,0} broadcast(%mul.639), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.641 = bf16[32,32,64]{2,1,0} multiply(%slice.628, %mul.640), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.642 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.626), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.643 = bf16[32,64]{1,0} reshape(%mul.642), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.644 = bf16[32,32,64]{2,1,0} broadcast(%mul.643), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.645 = bf16[32,32,64]{2,1,0} multiply(%slice.627, %mul.644), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.646 = bf16[32,32,64]{2,1,0} add(%mul.641, %mul.645), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.647 = bf16[32,32,128]{2,1,0} concatenate(%sub.637, %add.646), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.648 = bf16[32,4096]{1,0} reshape(%concatenate.647), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.572 = bf16[32,4,128]{2,1,0} slice(%reshape.570), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.597 = f32[32,4,128]{2,1,0} convert(%slice.572), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %constant.498 = f32[] constant(2)
  %broadcast.499 = f32[32,4,128]{2,1,0} broadcast(%constant.498), dimensions={}
  %pow.598 = f32[32,4,128]{2,1,0} power(%convert_element_type.597, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.603 = f32[32,4]{1,0} reduce(%pow.598, %constant.512), dimensions={2}, to_apply=%region_3.602, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.604 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.603), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %constant.496 = f32[] constant(128)
  %broadcast.497 = f32[32,4,1]{2,1,0} broadcast(%constant.496), dimensions={}
  %div.605 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.604, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %constant.494 = f32[] constant(1e-06)
  %broadcast.495 = f32[32,4,1]{2,1,0} broadcast(%constant.494), dimensions={}
  %add.606 = f32[32,4,1]{2,1,0} add(%div.605, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.607 = f32[32,4,1]{2,1,0} rsqrt(%add.606), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.608 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.607), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.609 = f32[32,4]{1,0} reshape(%mul.608), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.610 = f32[32,4,128]{2,1,0} broadcast(%mul.609), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.611 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.597, %mul.610), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.612 = bf16[32,4,128]{2,1,0} convert(%mul.611), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_k_norm_weight__.7 = bf16[128]{0} parameter(6), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.0.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.613 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_k_norm_weight__.7), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.614 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.613), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.615 = bf16[128]{0} reshape(%mul.614), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.616 = bf16[32,4,128]{2,1,0} broadcast(%mul.615), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.617 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.612, %mul.616), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.651 = bf16[32,4,64]{2,1,0} slice(%mul.617), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.649 = bf16[32,1,64]{2,1,0} reshape(%slice.623), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.653 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.649), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.654 = bf16[32,64]{1,0} reshape(%mul.653), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.655 = bf16[32,4,64]{2,1,0} broadcast(%mul.654), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.656 = bf16[32,4,64]{2,1,0} multiply(%slice.651, %mul.655), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.652 = bf16[32,4,64]{2,1,0} slice(%mul.617), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.650 = bf16[32,1,64]{2,1,0} reshape(%slice.624), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.657 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.650), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.658 = bf16[32,64]{1,0} reshape(%mul.657), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.659 = bf16[32,4,64]{2,1,0} broadcast(%mul.658), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.660 = bf16[32,4,64]{2,1,0} multiply(%slice.652, %mul.659), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.661 = bf16[32,4,64]{2,1,0} subtract(%mul.656, %mul.660), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.662 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.649), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.663 = bf16[32,64]{1,0} reshape(%mul.662), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.664 = bf16[32,4,64]{2,1,0} broadcast(%mul.663), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.665 = bf16[32,4,64]{2,1,0} multiply(%slice.652, %mul.664), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.666 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.650), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.667 = bf16[32,64]{1,0} reshape(%mul.666), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.668 = bf16[32,4,64]{2,1,0} broadcast(%mul.667), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.669 = bf16[32,4,64]{2,1,0} multiply(%slice.651, %mul.668), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.670 = bf16[32,4,64]{2,1,0} add(%mul.665, %mul.669), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.671 = bf16[32,4,128]{2,1,0} concatenate(%sub.661, %add.670), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.672 = bf16[32,512]{1,0} reshape(%concatenate.671), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.573 = bf16[32,4,128]{2,1,0} slice(%reshape.570), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.574 = bf16[32,512]{1,0} reshape(%slice.573), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %attn_metadata_block_tables.486 = s32[131072]{0} parameter(485), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="attn_metadata.block_tables"}
  %attn_metadata_seq_lens.487 = s32[256]{0} parameter(486), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="attn_metadata.seq_lens"}
  %attn_metadata_query_start_loc.488 = s32[257]{0} parameter(487), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="attn_metadata.query_start_loc"}
  %attn_metadata_request_distribution.489 = s32[3]{0} parameter(488), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="attn_metadata.request_distribution"}
  %jit__jax_attn_func_.764 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_0_.436, %reshape.648, %reshape.672, %reshape.574, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.765 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.764), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_1_.437 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(436), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[1]"}
  %jit__jax_attn_func_.766 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.764), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_o_proj_weight__.8 = bf16[2048,4096]{1,0} parameter(7), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.0.self_attn.o_proj.weight\']"}
  %dot_general.767 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.766, %params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_o_proj_weight__.8), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.768 = f32[32,2048]{1,0} convert(%dot_general.767), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.769 = f32[32,2048]{1,0} convert(%jit__take_.547), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.770 = f32[32,2048]{1,0} add(%convert_element_type.768, %convert_element_type.769), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.772 = f32[32,2048]{1,0} power(%add.770, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.777 = f32[32]{0} reduce(%pow.772, %constant.512), dimensions={1}, to_apply=%region_4.776, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.778 = f32[32,1]{1,0} reshape(%reduce_sum.777), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.779 = f32[32,1]{1,0} divide(%broadcast_in_dim.778, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.780 = f32[32,1]{1,0} add(%div.779, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.781 = f32[32,1]{1,0} rsqrt(%add.780), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.782 = f32[32,1]{1,0} broadcast(%rsqrt.781), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.783 = f32[32]{0} reshape(%mul.782), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.784 = f32[32,2048]{1,0} broadcast(%mul.783), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.785 = f32[32,2048]{1,0} multiply(%add.770, %mul.784), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.786 = bf16[32,2048]{1,0} convert(%mul.785), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_0_post_attention_layernorm_weight__.6 = bf16[2048]{0} parameter(5), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.0.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.787 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_0_post_attention_layernorm_weight__.6), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.788 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.787), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.789 = bf16[2048]{0} reshape(%mul.788), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.790 = bf16[32,2048]{1,0} broadcast(%mul.789), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.791 = bf16[32,2048]{1,0} multiply(%convert_element_type.786, %mul.790), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_0_mlp_experts_w13_weight__.3 = bf16[128,1536,2048]{2,1,0} parameter(2), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.0.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_0_mlp_experts_w2_weight__.4 = bf16[128,2048,768]{2,1,0} parameter(3), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.0.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_0_mlp_gate_weight__.5 = bf16[128,2048]{1,0} parameter(4), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.0.mlp.gate.weight\']"}
  %dot_general.792 = bf16[32,128]{1,0} dot(%mul.791, %params_and_buffers__vllm_model_language_model_model_layers_0_mlp_gate_weight__.5), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.1603 = bf16[32,2048]{1,0} call(%mul.791, %params_and_buffers__vllm_model_language_model_model_layers_0_mlp_experts_w13_weight__.3, %params_and_buffers__vllm_model_language_model_model_layers_0_mlp_experts_w2_weight__.4, %dot_general.792), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.1604 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.1603), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.771 = bf16[32,2048]{1,0} convert(%add.770), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.1605 = f32[32,2048]{1,0} convert(%convert_element_type.771), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.1606 = f32[32,2048]{1,0} add(%convert_element_type.1604, %convert_element_type.1605), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.1608 = f32[32,2048]{1,0} power(%add.1606, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.1613 = f32[32]{0} reduce(%pow.1608, %constant.512), dimensions={1}, to_apply=%region_36.1612, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.1614 = f32[32,1]{1,0} reshape(%reduce_sum.1613), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.1615 = f32[32,1]{1,0} divide(%broadcast_in_dim.1614, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.1616 = f32[32,1]{1,0} add(%div.1615, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.1617 = f32[32,1]{1,0} rsqrt(%add.1616), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.1618 = f32[32,1]{1,0} broadcast(%rsqrt.1617), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1619 = f32[32]{0} reshape(%mul.1618), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1620 = f32[32,2048]{1,0} broadcast(%mul.1619), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1621 = f32[32,2048]{1,0} multiply(%add.1606, %mul.1620), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.1622 = bf16[32,2048]{1,0} convert(%mul.1621), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_1_input_layernorm_weight__.12 = bf16[2048]{0} parameter(11), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.1.input_layernorm.weight\']"}
  %broadcast_in_dim.1623 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_1_input_layernorm_weight__.12), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1624 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.1623), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1625 = bf16[2048]{0} reshape(%mul.1624), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1626 = bf16[32,2048]{1,0} broadcast(%mul.1625), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1627 = bf16[32,2048]{1,0} multiply(%convert_element_type.1622, %mul.1626), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_1_self_attn_qkv_proj_weight__.20 = bf16[5120,2048]{1,0} parameter(19), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.1.self_attn.qkv_proj.weight\']"}
  %dot_general.1628 = bf16[32,5120]{1,0} dot(%mul.1627, %params_and_buffers__vllm_model_language_model_model_layers_1_self_attn_qkv_proj_weight__.20), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.1629 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.1628), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.1630 = bf16[32,4,1024]{2,1,0} slice(%reshape.1629), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.1634 = bf16[32,32,128]{2,1,0} reshape(%slice.1630), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.1635 = f32[32,32,128]{2,1,0} convert(%reshape.1634), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.1636 = f32[32,32,128]{2,1,0} power(%convert_element_type.1635, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.1641 = f32[32,32]{1,0} reduce(%pow.1636, %constant.512), dimensions={2}, to_apply=%region_37.1640, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.1642 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.1641), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.1643 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.1642, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.1644 = f32[32,32,1]{2,1,0} add(%div.1643, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.1645 = f32[32,32,1]{2,1,0} rsqrt(%add.1644), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.1646 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.1645), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1647 = f32[32,32]{1,0} reshape(%mul.1646), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1648 = f32[32,32,128]{2,1,0} broadcast(%mul.1647), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1649 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.1635, %mul.1648), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.1650 = bf16[32,32,128]{2,1,0} convert(%mul.1649), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_1_self_attn_q_norm_weight__.19 = bf16[128]{0} parameter(18), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.1.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.1651 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_1_self_attn_q_norm_weight__.19), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1652 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.1651), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1653 = bf16[128]{0} reshape(%mul.1652), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1654 = bf16[32,32,128]{2,1,0} broadcast(%mul.1653), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1655 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.1650, %mul.1654), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.1686 = bf16[32,32,64]{2,1,0} slice(%mul.1655), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.1677 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.1678 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.1679 = s32[32]{0} select(%lt.1677, %add.1678, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.1680 = s32[32,1]{1,0} reshape(%select_n.1679), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.1681 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.1680), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.1682 = bf16[32,64]{1,0} slice(%gather.1681), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.1684 = bf16[32,1,64]{2,1,0} reshape(%slice.1682), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.1688 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.1684), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1689 = bf16[32,64]{1,0} reshape(%mul.1688), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1690 = bf16[32,32,64]{2,1,0} broadcast(%mul.1689), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1691 = bf16[32,32,64]{2,1,0} multiply(%slice.1686, %mul.1690), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.1687 = bf16[32,32,64]{2,1,0} slice(%mul.1655), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.1683 = bf16[32,64]{1,0} slice(%gather.1681), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.1685 = bf16[32,1,64]{2,1,0} reshape(%slice.1683), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.1692 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.1685), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1693 = bf16[32,64]{1,0} reshape(%mul.1692), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1694 = bf16[32,32,64]{2,1,0} broadcast(%mul.1693), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1695 = bf16[32,32,64]{2,1,0} multiply(%slice.1687, %mul.1694), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.1696 = bf16[32,32,64]{2,1,0} subtract(%mul.1691, %mul.1695), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.1697 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.1684), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1698 = bf16[32,64]{1,0} reshape(%mul.1697), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1699 = bf16[32,32,64]{2,1,0} broadcast(%mul.1698), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1700 = bf16[32,32,64]{2,1,0} multiply(%slice.1687, %mul.1699), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1701 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.1685), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1702 = bf16[32,64]{1,0} reshape(%mul.1701), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1703 = bf16[32,32,64]{2,1,0} broadcast(%mul.1702), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1704 = bf16[32,32,64]{2,1,0} multiply(%slice.1686, %mul.1703), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.1705 = bf16[32,32,64]{2,1,0} add(%mul.1700, %mul.1704), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.1706 = bf16[32,32,128]{2,1,0} concatenate(%sub.1696, %add.1705), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.1707 = bf16[32,4096]{1,0} reshape(%concatenate.1706), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.1631 = bf16[32,4,128]{2,1,0} slice(%reshape.1629), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.1656 = f32[32,4,128]{2,1,0} convert(%slice.1631), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.1657 = f32[32,4,128]{2,1,0} power(%convert_element_type.1656, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.1662 = f32[32,4]{1,0} reduce(%pow.1657, %constant.512), dimensions={2}, to_apply=%region_38.1661, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.1663 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.1662), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.1664 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.1663, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.1665 = f32[32,4,1]{2,1,0} add(%div.1664, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.1666 = f32[32,4,1]{2,1,0} rsqrt(%add.1665), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.1667 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.1666), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1668 = f32[32,4]{1,0} reshape(%mul.1667), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1669 = f32[32,4,128]{2,1,0} broadcast(%mul.1668), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1670 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.1656, %mul.1669), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.1671 = bf16[32,4,128]{2,1,0} convert(%mul.1670), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_1_self_attn_k_norm_weight__.17 = bf16[128]{0} parameter(16), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.1.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.1672 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_1_self_attn_k_norm_weight__.17), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1673 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.1672), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1674 = bf16[128]{0} reshape(%mul.1673), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1675 = bf16[32,4,128]{2,1,0} broadcast(%mul.1674), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1676 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.1671, %mul.1675), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.1710 = bf16[32,4,64]{2,1,0} slice(%mul.1676), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.1708 = bf16[32,1,64]{2,1,0} reshape(%slice.1682), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.1712 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.1708), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1713 = bf16[32,64]{1,0} reshape(%mul.1712), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1714 = bf16[32,4,64]{2,1,0} broadcast(%mul.1713), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1715 = bf16[32,4,64]{2,1,0} multiply(%slice.1710, %mul.1714), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.1711 = bf16[32,4,64]{2,1,0} slice(%mul.1676), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.1709 = bf16[32,1,64]{2,1,0} reshape(%slice.1683), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.1716 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.1709), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1717 = bf16[32,64]{1,0} reshape(%mul.1716), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1718 = bf16[32,4,64]{2,1,0} broadcast(%mul.1717), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1719 = bf16[32,4,64]{2,1,0} multiply(%slice.1711, %mul.1718), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.1720 = bf16[32,4,64]{2,1,0} subtract(%mul.1715, %mul.1719), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.1721 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.1708), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1722 = bf16[32,64]{1,0} reshape(%mul.1721), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1723 = bf16[32,4,64]{2,1,0} broadcast(%mul.1722), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1724 = bf16[32,4,64]{2,1,0} multiply(%slice.1711, %mul.1723), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1725 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.1709), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1726 = bf16[32,64]{1,0} reshape(%mul.1725), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1727 = bf16[32,4,64]{2,1,0} broadcast(%mul.1726), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1728 = bf16[32,4,64]{2,1,0} multiply(%slice.1710, %mul.1727), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.1729 = bf16[32,4,64]{2,1,0} add(%mul.1724, %mul.1728), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.1730 = bf16[32,4,128]{2,1,0} concatenate(%sub.1720, %add.1729), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.1731 = bf16[32,512]{1,0} reshape(%concatenate.1730), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.1632 = bf16[32,4,128]{2,1,0} slice(%reshape.1629), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.1633 = bf16[32,512]{1,0} reshape(%slice.1632), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.1732 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_1_.437, %reshape.1707, %reshape.1731, %reshape.1633, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.1733 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.1732), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_2_.438 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(437), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[2]"}
  %jit__jax_attn_func_.1734 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.1732), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_1_self_attn_o_proj_weight__.18 = bf16[2048,4096]{1,0} parameter(17), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.1.self_attn.o_proj.weight\']"}
  %dot_general.1735 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.1734, %params_and_buffers__vllm_model_language_model_model_layers_1_self_attn_o_proj_weight__.18), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.1736 = f32[32,2048]{1,0} convert(%dot_general.1735), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.1607 = bf16[32,2048]{1,0} convert(%add.1606), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.1737 = f32[32,2048]{1,0} convert(%convert_element_type.1607), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.1738 = f32[32,2048]{1,0} add(%convert_element_type.1736, %convert_element_type.1737), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.1740 = f32[32,2048]{1,0} power(%add.1738, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.1745 = f32[32]{0} reduce(%pow.1740, %constant.512), dimensions={1}, to_apply=%region_39.1744, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.1746 = f32[32,1]{1,0} reshape(%reduce_sum.1745), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.1747 = f32[32,1]{1,0} divide(%broadcast_in_dim.1746, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.1748 = f32[32,1]{1,0} add(%div.1747, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.1749 = f32[32,1]{1,0} rsqrt(%add.1748), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.1750 = f32[32,1]{1,0} broadcast(%rsqrt.1749), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1751 = f32[32]{0} reshape(%mul.1750), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1752 = f32[32,2048]{1,0} broadcast(%mul.1751), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1753 = f32[32,2048]{1,0} multiply(%add.1738, %mul.1752), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.1754 = bf16[32,2048]{1,0} convert(%mul.1753), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_1_post_attention_layernorm_weight__.16 = bf16[2048]{0} parameter(15), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.1.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.1755 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_1_post_attention_layernorm_weight__.16), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1756 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.1755), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1757 = bf16[2048]{0} reshape(%mul.1756), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1758 = bf16[32,2048]{1,0} broadcast(%mul.1757), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1759 = bf16[32,2048]{1,0} multiply(%convert_element_type.1754, %mul.1758), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_1_mlp_experts_w13_weight__.13 = bf16[128,1536,2048]{2,1,0} parameter(12), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.1.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_1_mlp_experts_w2_weight__.14 = bf16[128,2048,768]{2,1,0} parameter(13), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.1.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_1_mlp_gate_weight__.15 = bf16[128,2048]{1,0} parameter(14), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.1.mlp.gate.weight\']"}
  %dot_general.1760 = bf16[32,128]{1,0} dot(%mul.1759, %params_and_buffers__vllm_model_language_model_model_layers_1_mlp_gate_weight__.15), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.1761 = bf16[32,2048]{1,0} call(%mul.1759, %params_and_buffers__vllm_model_language_model_model_layers_1_mlp_experts_w13_weight__.13, %params_and_buffers__vllm_model_language_model_model_layers_1_mlp_experts_w2_weight__.14, %dot_general.1760), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.1762 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.1761), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.1739 = bf16[32,2048]{1,0} convert(%add.1738), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.1763 = f32[32,2048]{1,0} convert(%convert_element_type.1739), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.1764 = f32[32,2048]{1,0} add(%convert_element_type.1762, %convert_element_type.1763), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.1766 = f32[32,2048]{1,0} power(%add.1764, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.1771 = f32[32]{0} reduce(%pow.1766, %constant.512), dimensions={1}, to_apply=%region_40.1770, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.1772 = f32[32,1]{1,0} reshape(%reduce_sum.1771), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.1773 = f32[32,1]{1,0} divide(%broadcast_in_dim.1772, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.1774 = f32[32,1]{1,0} add(%div.1773, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.1775 = f32[32,1]{1,0} rsqrt(%add.1774), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.1776 = f32[32,1]{1,0} broadcast(%rsqrt.1775), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1777 = f32[32]{0} reshape(%mul.1776), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1778 = f32[32,2048]{1,0} broadcast(%mul.1777), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1779 = f32[32,2048]{1,0} multiply(%add.1764, %mul.1778), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.1780 = bf16[32,2048]{1,0} convert(%mul.1779), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_2_input_layernorm_weight__.111 = bf16[2048]{0} parameter(110), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.2.input_layernorm.weight\']"}
  %broadcast_in_dim.1781 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_2_input_layernorm_weight__.111), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1782 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.1781), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1783 = bf16[2048]{0} reshape(%mul.1782), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1784 = bf16[32,2048]{1,0} broadcast(%mul.1783), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1785 = bf16[32,2048]{1,0} multiply(%convert_element_type.1780, %mul.1784), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_2_self_attn_qkv_proj_weight__.119 = bf16[5120,2048]{1,0} parameter(118), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.2.self_attn.qkv_proj.weight\']"}
  %dot_general.1786 = bf16[32,5120]{1,0} dot(%mul.1785, %params_and_buffers__vllm_model_language_model_model_layers_2_self_attn_qkv_proj_weight__.119), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.1787 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.1786), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.1788 = bf16[32,4,1024]{2,1,0} slice(%reshape.1787), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.1792 = bf16[32,32,128]{2,1,0} reshape(%slice.1788), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.1793 = f32[32,32,128]{2,1,0} convert(%reshape.1792), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.1794 = f32[32,32,128]{2,1,0} power(%convert_element_type.1793, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.1799 = f32[32,32]{1,0} reduce(%pow.1794, %constant.512), dimensions={2}, to_apply=%region_41.1798, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.1800 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.1799), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.1801 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.1800, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.1802 = f32[32,32,1]{2,1,0} add(%div.1801, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.1803 = f32[32,32,1]{2,1,0} rsqrt(%add.1802), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.1804 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.1803), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1805 = f32[32,32]{1,0} reshape(%mul.1804), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1806 = f32[32,32,128]{2,1,0} broadcast(%mul.1805), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1807 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.1793, %mul.1806), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.1808 = bf16[32,32,128]{2,1,0} convert(%mul.1807), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_2_self_attn_q_norm_weight__.118 = bf16[128]{0} parameter(117), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.2.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.1809 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_2_self_attn_q_norm_weight__.118), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1810 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.1809), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1811 = bf16[128]{0} reshape(%mul.1810), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1812 = bf16[32,32,128]{2,1,0} broadcast(%mul.1811), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1813 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.1808, %mul.1812), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.1844 = bf16[32,32,64]{2,1,0} slice(%mul.1813), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.1835 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.1836 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.1837 = s32[32]{0} select(%lt.1835, %add.1836, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.1838 = s32[32,1]{1,0} reshape(%select_n.1837), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.1839 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.1838), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.1840 = bf16[32,64]{1,0} slice(%gather.1839), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.1842 = bf16[32,1,64]{2,1,0} reshape(%slice.1840), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.1846 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.1842), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1847 = bf16[32,64]{1,0} reshape(%mul.1846), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1848 = bf16[32,32,64]{2,1,0} broadcast(%mul.1847), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1849 = bf16[32,32,64]{2,1,0} multiply(%slice.1844, %mul.1848), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.1845 = bf16[32,32,64]{2,1,0} slice(%mul.1813), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.1841 = bf16[32,64]{1,0} slice(%gather.1839), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.1843 = bf16[32,1,64]{2,1,0} reshape(%slice.1841), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.1850 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.1843), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1851 = bf16[32,64]{1,0} reshape(%mul.1850), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1852 = bf16[32,32,64]{2,1,0} broadcast(%mul.1851), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1853 = bf16[32,32,64]{2,1,0} multiply(%slice.1845, %mul.1852), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.1854 = bf16[32,32,64]{2,1,0} subtract(%mul.1849, %mul.1853), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.1855 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.1842), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1856 = bf16[32,64]{1,0} reshape(%mul.1855), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1857 = bf16[32,32,64]{2,1,0} broadcast(%mul.1856), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1858 = bf16[32,32,64]{2,1,0} multiply(%slice.1845, %mul.1857), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1859 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.1843), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1860 = bf16[32,64]{1,0} reshape(%mul.1859), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1861 = bf16[32,32,64]{2,1,0} broadcast(%mul.1860), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1862 = bf16[32,32,64]{2,1,0} multiply(%slice.1844, %mul.1861), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.1863 = bf16[32,32,64]{2,1,0} add(%mul.1858, %mul.1862), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.1864 = bf16[32,32,128]{2,1,0} concatenate(%sub.1854, %add.1863), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.1865 = bf16[32,4096]{1,0} reshape(%concatenate.1864), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.1789 = bf16[32,4,128]{2,1,0} slice(%reshape.1787), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.1814 = f32[32,4,128]{2,1,0} convert(%slice.1789), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.1815 = f32[32,4,128]{2,1,0} power(%convert_element_type.1814, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.1820 = f32[32,4]{1,0} reduce(%pow.1815, %constant.512), dimensions={2}, to_apply=%region_42.1819, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.1821 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.1820), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.1822 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.1821, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.1823 = f32[32,4,1]{2,1,0} add(%div.1822, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.1824 = f32[32,4,1]{2,1,0} rsqrt(%add.1823), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.1825 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.1824), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1826 = f32[32,4]{1,0} reshape(%mul.1825), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1827 = f32[32,4,128]{2,1,0} broadcast(%mul.1826), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1828 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.1814, %mul.1827), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.1829 = bf16[32,4,128]{2,1,0} convert(%mul.1828), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_2_self_attn_k_norm_weight__.116 = bf16[128]{0} parameter(115), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.2.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.1830 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_2_self_attn_k_norm_weight__.116), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1831 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.1830), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1832 = bf16[128]{0} reshape(%mul.1831), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1833 = bf16[32,4,128]{2,1,0} broadcast(%mul.1832), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1834 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.1829, %mul.1833), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.1868 = bf16[32,4,64]{2,1,0} slice(%mul.1834), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.1866 = bf16[32,1,64]{2,1,0} reshape(%slice.1840), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.1870 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.1866), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1871 = bf16[32,64]{1,0} reshape(%mul.1870), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1872 = bf16[32,4,64]{2,1,0} broadcast(%mul.1871), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1873 = bf16[32,4,64]{2,1,0} multiply(%slice.1868, %mul.1872), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.1869 = bf16[32,4,64]{2,1,0} slice(%mul.1834), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.1867 = bf16[32,1,64]{2,1,0} reshape(%slice.1841), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.1874 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.1867), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1875 = bf16[32,64]{1,0} reshape(%mul.1874), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1876 = bf16[32,4,64]{2,1,0} broadcast(%mul.1875), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1877 = bf16[32,4,64]{2,1,0} multiply(%slice.1869, %mul.1876), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.1878 = bf16[32,4,64]{2,1,0} subtract(%mul.1873, %mul.1877), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.1879 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.1866), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1880 = bf16[32,64]{1,0} reshape(%mul.1879), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1881 = bf16[32,4,64]{2,1,0} broadcast(%mul.1880), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1882 = bf16[32,4,64]{2,1,0} multiply(%slice.1869, %mul.1881), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1883 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.1867), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1884 = bf16[32,64]{1,0} reshape(%mul.1883), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1885 = bf16[32,4,64]{2,1,0} broadcast(%mul.1884), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1886 = bf16[32,4,64]{2,1,0} multiply(%slice.1868, %mul.1885), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.1887 = bf16[32,4,64]{2,1,0} add(%mul.1882, %mul.1886), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.1888 = bf16[32,4,128]{2,1,0} concatenate(%sub.1878, %add.1887), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.1889 = bf16[32,512]{1,0} reshape(%concatenate.1888), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.1790 = bf16[32,4,128]{2,1,0} slice(%reshape.1787), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.1791 = bf16[32,512]{1,0} reshape(%slice.1790), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.1890 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_2_.438, %reshape.1865, %reshape.1889, %reshape.1791, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.1891 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.1890), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_3_.439 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(438), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[3]"}
  %jit__jax_attn_func_.1892 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.1890), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_2_self_attn_o_proj_weight__.117 = bf16[2048,4096]{1,0} parameter(116), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.2.self_attn.o_proj.weight\']"}
  %dot_general.1893 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.1892, %params_and_buffers__vllm_model_language_model_model_layers_2_self_attn_o_proj_weight__.117), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.1894 = f32[32,2048]{1,0} convert(%dot_general.1893), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.1765 = bf16[32,2048]{1,0} convert(%add.1764), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.1895 = f32[32,2048]{1,0} convert(%convert_element_type.1765), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.1896 = f32[32,2048]{1,0} add(%convert_element_type.1894, %convert_element_type.1895), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.1898 = f32[32,2048]{1,0} power(%add.1896, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.1903 = f32[32]{0} reduce(%pow.1898, %constant.512), dimensions={1}, to_apply=%region_43.1902, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.1904 = f32[32,1]{1,0} reshape(%reduce_sum.1903), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.1905 = f32[32,1]{1,0} divide(%broadcast_in_dim.1904, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.1906 = f32[32,1]{1,0} add(%div.1905, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.1907 = f32[32,1]{1,0} rsqrt(%add.1906), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.1908 = f32[32,1]{1,0} broadcast(%rsqrt.1907), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1909 = f32[32]{0} reshape(%mul.1908), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1910 = f32[32,2048]{1,0} broadcast(%mul.1909), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1911 = f32[32,2048]{1,0} multiply(%add.1896, %mul.1910), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.1912 = bf16[32,2048]{1,0} convert(%mul.1911), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_2_post_attention_layernorm_weight__.115 = bf16[2048]{0} parameter(114), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.2.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.1913 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_2_post_attention_layernorm_weight__.115), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1914 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.1913), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1915 = bf16[2048]{0} reshape(%mul.1914), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1916 = bf16[32,2048]{1,0} broadcast(%mul.1915), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1917 = bf16[32,2048]{1,0} multiply(%convert_element_type.1912, %mul.1916), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_2_mlp_experts_w13_weight__.112 = bf16[128,1536,2048]{2,1,0} parameter(111), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.2.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_2_mlp_experts_w2_weight__.113 = bf16[128,2048,768]{2,1,0} parameter(112), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.2.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_2_mlp_gate_weight__.114 = bf16[128,2048]{1,0} parameter(113), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.2.mlp.gate.weight\']"}
  %dot_general.1918 = bf16[32,128]{1,0} dot(%mul.1917, %params_and_buffers__vllm_model_language_model_model_layers_2_mlp_gate_weight__.114), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.1919 = bf16[32,2048]{1,0} call(%mul.1917, %params_and_buffers__vllm_model_language_model_model_layers_2_mlp_experts_w13_weight__.112, %params_and_buffers__vllm_model_language_model_model_layers_2_mlp_experts_w2_weight__.113, %dot_general.1918), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.1920 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.1919), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.1897 = bf16[32,2048]{1,0} convert(%add.1896), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.1921 = f32[32,2048]{1,0} convert(%convert_element_type.1897), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.1922 = f32[32,2048]{1,0} add(%convert_element_type.1920, %convert_element_type.1921), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.1924 = f32[32,2048]{1,0} power(%add.1922, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.1929 = f32[32]{0} reduce(%pow.1924, %constant.512), dimensions={1}, to_apply=%region_44.1928, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.1930 = f32[32,1]{1,0} reshape(%reduce_sum.1929), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.1931 = f32[32,1]{1,0} divide(%broadcast_in_dim.1930, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.1932 = f32[32,1]{1,0} add(%div.1931, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.1933 = f32[32,1]{1,0} rsqrt(%add.1932), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.1934 = f32[32,1]{1,0} broadcast(%rsqrt.1933), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1935 = f32[32]{0} reshape(%mul.1934), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1936 = f32[32,2048]{1,0} broadcast(%mul.1935), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1937 = f32[32,2048]{1,0} multiply(%add.1922, %mul.1936), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.1938 = bf16[32,2048]{1,0} convert(%mul.1937), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_3_input_layernorm_weight__.210 = bf16[2048]{0} parameter(209), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.3.input_layernorm.weight\']"}
  %broadcast_in_dim.1939 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_3_input_layernorm_weight__.210), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1940 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.1939), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1941 = bf16[2048]{0} reshape(%mul.1940), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1942 = bf16[32,2048]{1,0} broadcast(%mul.1941), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1943 = bf16[32,2048]{1,0} multiply(%convert_element_type.1938, %mul.1942), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_3_self_attn_qkv_proj_weight__.218 = bf16[5120,2048]{1,0} parameter(217), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.3.self_attn.qkv_proj.weight\']"}
  %dot_general.1944 = bf16[32,5120]{1,0} dot(%mul.1943, %params_and_buffers__vllm_model_language_model_model_layers_3_self_attn_qkv_proj_weight__.218), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.1945 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.1944), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.1946 = bf16[32,4,1024]{2,1,0} slice(%reshape.1945), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.1950 = bf16[32,32,128]{2,1,0} reshape(%slice.1946), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.1951 = f32[32,32,128]{2,1,0} convert(%reshape.1950), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.1952 = f32[32,32,128]{2,1,0} power(%convert_element_type.1951, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.1957 = f32[32,32]{1,0} reduce(%pow.1952, %constant.512), dimensions={2}, to_apply=%region_45.1956, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.1958 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.1957), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.1959 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.1958, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.1960 = f32[32,32,1]{2,1,0} add(%div.1959, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.1961 = f32[32,32,1]{2,1,0} rsqrt(%add.1960), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.1962 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.1961), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1963 = f32[32,32]{1,0} reshape(%mul.1962), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1964 = f32[32,32,128]{2,1,0} broadcast(%mul.1963), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1965 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.1951, %mul.1964), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.1966 = bf16[32,32,128]{2,1,0} convert(%mul.1965), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_3_self_attn_q_norm_weight__.217 = bf16[128]{0} parameter(216), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.3.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.1967 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_3_self_attn_q_norm_weight__.217), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1968 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.1967), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1969 = bf16[128]{0} reshape(%mul.1968), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1970 = bf16[32,32,128]{2,1,0} broadcast(%mul.1969), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1971 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.1966, %mul.1970), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2002 = bf16[32,32,64]{2,1,0} slice(%mul.1971), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.1993 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.1994 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.1995 = s32[32]{0} select(%lt.1993, %add.1994, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.1996 = s32[32,1]{1,0} reshape(%select_n.1995), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.1997 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.1996), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.1998 = bf16[32,64]{1,0} slice(%gather.1997), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2000 = bf16[32,1,64]{2,1,0} reshape(%slice.1998), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2004 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2000), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2005 = bf16[32,64]{1,0} reshape(%mul.2004), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2006 = bf16[32,32,64]{2,1,0} broadcast(%mul.2005), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2007 = bf16[32,32,64]{2,1,0} multiply(%slice.2002, %mul.2006), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2003 = bf16[32,32,64]{2,1,0} slice(%mul.1971), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.1999 = bf16[32,64]{1,0} slice(%gather.1997), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2001 = bf16[32,1,64]{2,1,0} reshape(%slice.1999), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2008 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2001), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2009 = bf16[32,64]{1,0} reshape(%mul.2008), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2010 = bf16[32,32,64]{2,1,0} broadcast(%mul.2009), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2011 = bf16[32,32,64]{2,1,0} multiply(%slice.2003, %mul.2010), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.2012 = bf16[32,32,64]{2,1,0} subtract(%mul.2007, %mul.2011), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.2013 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2000), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2014 = bf16[32,64]{1,0} reshape(%mul.2013), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2015 = bf16[32,32,64]{2,1,0} broadcast(%mul.2014), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2016 = bf16[32,32,64]{2,1,0} multiply(%slice.2003, %mul.2015), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2017 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2001), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2018 = bf16[32,64]{1,0} reshape(%mul.2017), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2019 = bf16[32,32,64]{2,1,0} broadcast(%mul.2018), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2020 = bf16[32,32,64]{2,1,0} multiply(%slice.2002, %mul.2019), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.2021 = bf16[32,32,64]{2,1,0} add(%mul.2016, %mul.2020), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.2022 = bf16[32,32,128]{2,1,0} concatenate(%sub.2012, %add.2021), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.2023 = bf16[32,4096]{1,0} reshape(%concatenate.2022), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.1947 = bf16[32,4,128]{2,1,0} slice(%reshape.1945), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.1972 = f32[32,4,128]{2,1,0} convert(%slice.1947), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.1973 = f32[32,4,128]{2,1,0} power(%convert_element_type.1972, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.1978 = f32[32,4]{1,0} reduce(%pow.1973, %constant.512), dimensions={2}, to_apply=%region_46.1977, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.1979 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.1978), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.1980 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.1979, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.1981 = f32[32,4,1]{2,1,0} add(%div.1980, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.1982 = f32[32,4,1]{2,1,0} rsqrt(%add.1981), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.1983 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.1982), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1984 = f32[32,4]{1,0} reshape(%mul.1983), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1985 = f32[32,4,128]{2,1,0} broadcast(%mul.1984), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1986 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.1972, %mul.1985), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.1987 = bf16[32,4,128]{2,1,0} convert(%mul.1986), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_3_self_attn_k_norm_weight__.215 = bf16[128]{0} parameter(214), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.3.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.1988 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_3_self_attn_k_norm_weight__.215), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1989 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.1988), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1990 = bf16[128]{0} reshape(%mul.1989), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1991 = bf16[32,4,128]{2,1,0} broadcast(%mul.1990), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.1992 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.1987, %mul.1991), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2026 = bf16[32,4,64]{2,1,0} slice(%mul.1992), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2024 = bf16[32,1,64]{2,1,0} reshape(%slice.1998), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2028 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2024), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2029 = bf16[32,64]{1,0} reshape(%mul.2028), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2030 = bf16[32,4,64]{2,1,0} broadcast(%mul.2029), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2031 = bf16[32,4,64]{2,1,0} multiply(%slice.2026, %mul.2030), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2027 = bf16[32,4,64]{2,1,0} slice(%mul.1992), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2025 = bf16[32,1,64]{2,1,0} reshape(%slice.1999), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2032 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2025), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2033 = bf16[32,64]{1,0} reshape(%mul.2032), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2034 = bf16[32,4,64]{2,1,0} broadcast(%mul.2033), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2035 = bf16[32,4,64]{2,1,0} multiply(%slice.2027, %mul.2034), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.2036 = bf16[32,4,64]{2,1,0} subtract(%mul.2031, %mul.2035), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.2037 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2024), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2038 = bf16[32,64]{1,0} reshape(%mul.2037), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2039 = bf16[32,4,64]{2,1,0} broadcast(%mul.2038), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2040 = bf16[32,4,64]{2,1,0} multiply(%slice.2027, %mul.2039), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2041 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2025), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2042 = bf16[32,64]{1,0} reshape(%mul.2041), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2043 = bf16[32,4,64]{2,1,0} broadcast(%mul.2042), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2044 = bf16[32,4,64]{2,1,0} multiply(%slice.2026, %mul.2043), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.2045 = bf16[32,4,64]{2,1,0} add(%mul.2040, %mul.2044), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.2046 = bf16[32,4,128]{2,1,0} concatenate(%sub.2036, %add.2045), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.2047 = bf16[32,512]{1,0} reshape(%concatenate.2046), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.1948 = bf16[32,4,128]{2,1,0} slice(%reshape.1945), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.1949 = bf16[32,512]{1,0} reshape(%slice.1948), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.2048 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_3_.439, %reshape.2023, %reshape.2047, %reshape.1949, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.2049 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.2048), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_4_.440 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(439), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[4]"}
  %jit__jax_attn_func_.2050 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.2048), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_3_self_attn_o_proj_weight__.216 = bf16[2048,4096]{1,0} parameter(215), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.3.self_attn.o_proj.weight\']"}
  %dot_general.2051 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.2050, %params_and_buffers__vllm_model_language_model_model_layers_3_self_attn_o_proj_weight__.216), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.2052 = f32[32,2048]{1,0} convert(%dot_general.2051), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.1923 = bf16[32,2048]{1,0} convert(%add.1922), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2053 = f32[32,2048]{1,0} convert(%convert_element_type.1923), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.2054 = f32[32,2048]{1,0} add(%convert_element_type.2052, %convert_element_type.2053), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.2056 = f32[32,2048]{1,0} power(%add.2054, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2061 = f32[32]{0} reduce(%pow.2056, %constant.512), dimensions={1}, to_apply=%region_47.2060, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2062 = f32[32,1]{1,0} reshape(%reduce_sum.2061), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2063 = f32[32,1]{1,0} divide(%broadcast_in_dim.2062, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2064 = f32[32,1]{1,0} add(%div.2063, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2065 = f32[32,1]{1,0} rsqrt(%add.2064), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2066 = f32[32,1]{1,0} broadcast(%rsqrt.2065), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2067 = f32[32]{0} reshape(%mul.2066), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2068 = f32[32,2048]{1,0} broadcast(%mul.2067), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2069 = f32[32,2048]{1,0} multiply(%add.2054, %mul.2068), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2070 = bf16[32,2048]{1,0} convert(%mul.2069), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_3_post_attention_layernorm_weight__.214 = bf16[2048]{0} parameter(213), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.3.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.2071 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_3_post_attention_layernorm_weight__.214), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2072 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.2071), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2073 = bf16[2048]{0} reshape(%mul.2072), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2074 = bf16[32,2048]{1,0} broadcast(%mul.2073), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2075 = bf16[32,2048]{1,0} multiply(%convert_element_type.2070, %mul.2074), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_3_mlp_experts_w13_weight__.211 = bf16[128,1536,2048]{2,1,0} parameter(210), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.3.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_3_mlp_experts_w2_weight__.212 = bf16[128,2048,768]{2,1,0} parameter(211), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.3.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_3_mlp_gate_weight__.213 = bf16[128,2048]{1,0} parameter(212), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.3.mlp.gate.weight\']"}
  %dot_general.2076 = bf16[32,128]{1,0} dot(%mul.2075, %params_and_buffers__vllm_model_language_model_model_layers_3_mlp_gate_weight__.213), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.2077 = bf16[32,2048]{1,0} call(%mul.2075, %params_and_buffers__vllm_model_language_model_model_layers_3_mlp_experts_w13_weight__.211, %params_and_buffers__vllm_model_language_model_model_layers_3_mlp_experts_w2_weight__.212, %dot_general.2076), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.2078 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.2077), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2055 = bf16[32,2048]{1,0} convert(%add.2054), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2079 = f32[32,2048]{1,0} convert(%convert_element_type.2055), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.2080 = f32[32,2048]{1,0} add(%convert_element_type.2078, %convert_element_type.2079), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.2082 = f32[32,2048]{1,0} power(%add.2080, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2087 = f32[32]{0} reduce(%pow.2082, %constant.512), dimensions={1}, to_apply=%region_48.2086, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2088 = f32[32,1]{1,0} reshape(%reduce_sum.2087), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2089 = f32[32,1]{1,0} divide(%broadcast_in_dim.2088, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2090 = f32[32,1]{1,0} add(%div.2089, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2091 = f32[32,1]{1,0} rsqrt(%add.2090), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2092 = f32[32,1]{1,0} broadcast(%rsqrt.2091), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2093 = f32[32]{0} reshape(%mul.2092), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2094 = f32[32,2048]{1,0} broadcast(%mul.2093), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2095 = f32[32,2048]{1,0} multiply(%add.2080, %mul.2094), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2096 = bf16[32,2048]{1,0} convert(%mul.2095), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_4_input_layernorm_weight__.309 = bf16[2048]{0} parameter(308), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.4.input_layernorm.weight\']"}
  %broadcast_in_dim.2097 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_4_input_layernorm_weight__.309), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2098 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.2097), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2099 = bf16[2048]{0} reshape(%mul.2098), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2100 = bf16[32,2048]{1,0} broadcast(%mul.2099), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2101 = bf16[32,2048]{1,0} multiply(%convert_element_type.2096, %mul.2100), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_4_self_attn_qkv_proj_weight__.317 = bf16[5120,2048]{1,0} parameter(316), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.4.self_attn.qkv_proj.weight\']"}
  %dot_general.2102 = bf16[32,5120]{1,0} dot(%mul.2101, %params_and_buffers__vllm_model_language_model_model_layers_4_self_attn_qkv_proj_weight__.317), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.2103 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.2102), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.2104 = bf16[32,4,1024]{2,1,0} slice(%reshape.2103), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.2108 = bf16[32,32,128]{2,1,0} reshape(%slice.2104), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.2109 = f32[32,32,128]{2,1,0} convert(%reshape.2108), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.2110 = f32[32,32,128]{2,1,0} power(%convert_element_type.2109, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2115 = f32[32,32]{1,0} reduce(%pow.2110, %constant.512), dimensions={2}, to_apply=%region_49.2114, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2116 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.2115), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2117 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.2116, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2118 = f32[32,32,1]{2,1,0} add(%div.2117, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2119 = f32[32,32,1]{2,1,0} rsqrt(%add.2118), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2120 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.2119), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2121 = f32[32,32]{1,0} reshape(%mul.2120), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2122 = f32[32,32,128]{2,1,0} broadcast(%mul.2121), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2123 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.2109, %mul.2122), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2124 = bf16[32,32,128]{2,1,0} convert(%mul.2123), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_4_self_attn_q_norm_weight__.316 = bf16[128]{0} parameter(315), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.4.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.2125 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_4_self_attn_q_norm_weight__.316), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2126 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.2125), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2127 = bf16[128]{0} reshape(%mul.2126), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2128 = bf16[32,32,128]{2,1,0} broadcast(%mul.2127), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2129 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.2124, %mul.2128), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2160 = bf16[32,32,64]{2,1,0} slice(%mul.2129), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.2151 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.2152 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.2153 = s32[32]{0} select(%lt.2151, %add.2152, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.2154 = s32[32,1]{1,0} reshape(%select_n.2153), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.2155 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.2154), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.2156 = bf16[32,64]{1,0} slice(%gather.2155), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2158 = bf16[32,1,64]{2,1,0} reshape(%slice.2156), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2162 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2158), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2163 = bf16[32,64]{1,0} reshape(%mul.2162), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2164 = bf16[32,32,64]{2,1,0} broadcast(%mul.2163), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2165 = bf16[32,32,64]{2,1,0} multiply(%slice.2160, %mul.2164), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2161 = bf16[32,32,64]{2,1,0} slice(%mul.2129), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.2157 = bf16[32,64]{1,0} slice(%gather.2155), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2159 = bf16[32,1,64]{2,1,0} reshape(%slice.2157), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2166 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2159), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2167 = bf16[32,64]{1,0} reshape(%mul.2166), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2168 = bf16[32,32,64]{2,1,0} broadcast(%mul.2167), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2169 = bf16[32,32,64]{2,1,0} multiply(%slice.2161, %mul.2168), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.2170 = bf16[32,32,64]{2,1,0} subtract(%mul.2165, %mul.2169), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.2171 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2158), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2172 = bf16[32,64]{1,0} reshape(%mul.2171), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2173 = bf16[32,32,64]{2,1,0} broadcast(%mul.2172), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2174 = bf16[32,32,64]{2,1,0} multiply(%slice.2161, %mul.2173), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2175 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2159), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2176 = bf16[32,64]{1,0} reshape(%mul.2175), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2177 = bf16[32,32,64]{2,1,0} broadcast(%mul.2176), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2178 = bf16[32,32,64]{2,1,0} multiply(%slice.2160, %mul.2177), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.2179 = bf16[32,32,64]{2,1,0} add(%mul.2174, %mul.2178), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.2180 = bf16[32,32,128]{2,1,0} concatenate(%sub.2170, %add.2179), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.2181 = bf16[32,4096]{1,0} reshape(%concatenate.2180), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.2105 = bf16[32,4,128]{2,1,0} slice(%reshape.2103), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.2130 = f32[32,4,128]{2,1,0} convert(%slice.2105), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.2131 = f32[32,4,128]{2,1,0} power(%convert_element_type.2130, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2136 = f32[32,4]{1,0} reduce(%pow.2131, %constant.512), dimensions={2}, to_apply=%region_50.2135, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2137 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.2136), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2138 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.2137, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2139 = f32[32,4,1]{2,1,0} add(%div.2138, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2140 = f32[32,4,1]{2,1,0} rsqrt(%add.2139), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2141 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.2140), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2142 = f32[32,4]{1,0} reshape(%mul.2141), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2143 = f32[32,4,128]{2,1,0} broadcast(%mul.2142), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2144 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.2130, %mul.2143), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2145 = bf16[32,4,128]{2,1,0} convert(%mul.2144), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_4_self_attn_k_norm_weight__.314 = bf16[128]{0} parameter(313), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.4.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.2146 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_4_self_attn_k_norm_weight__.314), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2147 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.2146), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2148 = bf16[128]{0} reshape(%mul.2147), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2149 = bf16[32,4,128]{2,1,0} broadcast(%mul.2148), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2150 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.2145, %mul.2149), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2184 = bf16[32,4,64]{2,1,0} slice(%mul.2150), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2182 = bf16[32,1,64]{2,1,0} reshape(%slice.2156), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2186 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2182), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2187 = bf16[32,64]{1,0} reshape(%mul.2186), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2188 = bf16[32,4,64]{2,1,0} broadcast(%mul.2187), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2189 = bf16[32,4,64]{2,1,0} multiply(%slice.2184, %mul.2188), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2185 = bf16[32,4,64]{2,1,0} slice(%mul.2150), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2183 = bf16[32,1,64]{2,1,0} reshape(%slice.2157), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2190 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2183), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2191 = bf16[32,64]{1,0} reshape(%mul.2190), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2192 = bf16[32,4,64]{2,1,0} broadcast(%mul.2191), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2193 = bf16[32,4,64]{2,1,0} multiply(%slice.2185, %mul.2192), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.2194 = bf16[32,4,64]{2,1,0} subtract(%mul.2189, %mul.2193), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.2195 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2182), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2196 = bf16[32,64]{1,0} reshape(%mul.2195), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2197 = bf16[32,4,64]{2,1,0} broadcast(%mul.2196), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2198 = bf16[32,4,64]{2,1,0} multiply(%slice.2185, %mul.2197), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2199 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2183), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2200 = bf16[32,64]{1,0} reshape(%mul.2199), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2201 = bf16[32,4,64]{2,1,0} broadcast(%mul.2200), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2202 = bf16[32,4,64]{2,1,0} multiply(%slice.2184, %mul.2201), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.2203 = bf16[32,4,64]{2,1,0} add(%mul.2198, %mul.2202), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.2204 = bf16[32,4,128]{2,1,0} concatenate(%sub.2194, %add.2203), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.2205 = bf16[32,512]{1,0} reshape(%concatenate.2204), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.2106 = bf16[32,4,128]{2,1,0} slice(%reshape.2103), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.2107 = bf16[32,512]{1,0} reshape(%slice.2106), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.2206 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_4_.440, %reshape.2181, %reshape.2205, %reshape.2107, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.2207 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.2206), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_5_.441 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(440), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[5]"}
  %jit__jax_attn_func_.2208 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.2206), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_4_self_attn_o_proj_weight__.315 = bf16[2048,4096]{1,0} parameter(314), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.4.self_attn.o_proj.weight\']"}
  %dot_general.2209 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.2208, %params_and_buffers__vllm_model_language_model_model_layers_4_self_attn_o_proj_weight__.315), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.2210 = f32[32,2048]{1,0} convert(%dot_general.2209), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2081 = bf16[32,2048]{1,0} convert(%add.2080), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2211 = f32[32,2048]{1,0} convert(%convert_element_type.2081), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.2212 = f32[32,2048]{1,0} add(%convert_element_type.2210, %convert_element_type.2211), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.2214 = f32[32,2048]{1,0} power(%add.2212, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2219 = f32[32]{0} reduce(%pow.2214, %constant.512), dimensions={1}, to_apply=%region_51.2218, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2220 = f32[32,1]{1,0} reshape(%reduce_sum.2219), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2221 = f32[32,1]{1,0} divide(%broadcast_in_dim.2220, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2222 = f32[32,1]{1,0} add(%div.2221, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2223 = f32[32,1]{1,0} rsqrt(%add.2222), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2224 = f32[32,1]{1,0} broadcast(%rsqrt.2223), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2225 = f32[32]{0} reshape(%mul.2224), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2226 = f32[32,2048]{1,0} broadcast(%mul.2225), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2227 = f32[32,2048]{1,0} multiply(%add.2212, %mul.2226), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2228 = bf16[32,2048]{1,0} convert(%mul.2227), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_4_post_attention_layernorm_weight__.313 = bf16[2048]{0} parameter(312), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.4.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.2229 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_4_post_attention_layernorm_weight__.313), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2230 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.2229), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2231 = bf16[2048]{0} reshape(%mul.2230), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2232 = bf16[32,2048]{1,0} broadcast(%mul.2231), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2233 = bf16[32,2048]{1,0} multiply(%convert_element_type.2228, %mul.2232), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_4_mlp_experts_w13_weight__.310 = bf16[128,1536,2048]{2,1,0} parameter(309), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.4.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_4_mlp_experts_w2_weight__.311 = bf16[128,2048,768]{2,1,0} parameter(310), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.4.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_4_mlp_gate_weight__.312 = bf16[128,2048]{1,0} parameter(311), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.4.mlp.gate.weight\']"}
  %dot_general.2234 = bf16[32,128]{1,0} dot(%mul.2233, %params_and_buffers__vllm_model_language_model_model_layers_4_mlp_gate_weight__.312), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.2235 = bf16[32,2048]{1,0} call(%mul.2233, %params_and_buffers__vllm_model_language_model_model_layers_4_mlp_experts_w13_weight__.310, %params_and_buffers__vllm_model_language_model_model_layers_4_mlp_experts_w2_weight__.311, %dot_general.2234), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.2236 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.2235), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2213 = bf16[32,2048]{1,0} convert(%add.2212), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2237 = f32[32,2048]{1,0} convert(%convert_element_type.2213), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.2238 = f32[32,2048]{1,0} add(%convert_element_type.2236, %convert_element_type.2237), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.2240 = f32[32,2048]{1,0} power(%add.2238, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2245 = f32[32]{0} reduce(%pow.2240, %constant.512), dimensions={1}, to_apply=%region_52.2244, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2246 = f32[32,1]{1,0} reshape(%reduce_sum.2245), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2247 = f32[32,1]{1,0} divide(%broadcast_in_dim.2246, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2248 = f32[32,1]{1,0} add(%div.2247, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2249 = f32[32,1]{1,0} rsqrt(%add.2248), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2250 = f32[32,1]{1,0} broadcast(%rsqrt.2249), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2251 = f32[32]{0} reshape(%mul.2250), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2252 = f32[32,2048]{1,0} broadcast(%mul.2251), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2253 = f32[32,2048]{1,0} multiply(%add.2238, %mul.2252), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2254 = bf16[32,2048]{1,0} convert(%mul.2253), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_5_input_layernorm_weight__.390 = bf16[2048]{0} parameter(389), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.5.input_layernorm.weight\']"}
  %broadcast_in_dim.2255 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_5_input_layernorm_weight__.390), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2256 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.2255), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2257 = bf16[2048]{0} reshape(%mul.2256), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2258 = bf16[32,2048]{1,0} broadcast(%mul.2257), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2259 = bf16[32,2048]{1,0} multiply(%convert_element_type.2254, %mul.2258), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_5_self_attn_qkv_proj_weight__.398 = bf16[5120,2048]{1,0} parameter(397), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.5.self_attn.qkv_proj.weight\']"}
  %dot_general.2260 = bf16[32,5120]{1,0} dot(%mul.2259, %params_and_buffers__vllm_model_language_model_model_layers_5_self_attn_qkv_proj_weight__.398), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.2261 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.2260), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.2262 = bf16[32,4,1024]{2,1,0} slice(%reshape.2261), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.2266 = bf16[32,32,128]{2,1,0} reshape(%slice.2262), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.2267 = f32[32,32,128]{2,1,0} convert(%reshape.2266), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.2268 = f32[32,32,128]{2,1,0} power(%convert_element_type.2267, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2273 = f32[32,32]{1,0} reduce(%pow.2268, %constant.512), dimensions={2}, to_apply=%region_53.2272, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2274 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.2273), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2275 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.2274, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2276 = f32[32,32,1]{2,1,0} add(%div.2275, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2277 = f32[32,32,1]{2,1,0} rsqrt(%add.2276), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2278 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.2277), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2279 = f32[32,32]{1,0} reshape(%mul.2278), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2280 = f32[32,32,128]{2,1,0} broadcast(%mul.2279), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2281 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.2267, %mul.2280), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2282 = bf16[32,32,128]{2,1,0} convert(%mul.2281), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_5_self_attn_q_norm_weight__.397 = bf16[128]{0} parameter(396), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.5.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.2283 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_5_self_attn_q_norm_weight__.397), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2284 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.2283), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2285 = bf16[128]{0} reshape(%mul.2284), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2286 = bf16[32,32,128]{2,1,0} broadcast(%mul.2285), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2287 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.2282, %mul.2286), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2318 = bf16[32,32,64]{2,1,0} slice(%mul.2287), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.2309 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.2310 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.2311 = s32[32]{0} select(%lt.2309, %add.2310, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.2312 = s32[32,1]{1,0} reshape(%select_n.2311), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.2313 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.2312), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.2314 = bf16[32,64]{1,0} slice(%gather.2313), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2316 = bf16[32,1,64]{2,1,0} reshape(%slice.2314), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2320 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2316), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2321 = bf16[32,64]{1,0} reshape(%mul.2320), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2322 = bf16[32,32,64]{2,1,0} broadcast(%mul.2321), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2323 = bf16[32,32,64]{2,1,0} multiply(%slice.2318, %mul.2322), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2319 = bf16[32,32,64]{2,1,0} slice(%mul.2287), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.2315 = bf16[32,64]{1,0} slice(%gather.2313), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2317 = bf16[32,1,64]{2,1,0} reshape(%slice.2315), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2324 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2317), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2325 = bf16[32,64]{1,0} reshape(%mul.2324), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2326 = bf16[32,32,64]{2,1,0} broadcast(%mul.2325), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2327 = bf16[32,32,64]{2,1,0} multiply(%slice.2319, %mul.2326), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.2328 = bf16[32,32,64]{2,1,0} subtract(%mul.2323, %mul.2327), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.2329 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2316), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2330 = bf16[32,64]{1,0} reshape(%mul.2329), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2331 = bf16[32,32,64]{2,1,0} broadcast(%mul.2330), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2332 = bf16[32,32,64]{2,1,0} multiply(%slice.2319, %mul.2331), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2333 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2317), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2334 = bf16[32,64]{1,0} reshape(%mul.2333), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2335 = bf16[32,32,64]{2,1,0} broadcast(%mul.2334), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2336 = bf16[32,32,64]{2,1,0} multiply(%slice.2318, %mul.2335), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.2337 = bf16[32,32,64]{2,1,0} add(%mul.2332, %mul.2336), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.2338 = bf16[32,32,128]{2,1,0} concatenate(%sub.2328, %add.2337), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.2339 = bf16[32,4096]{1,0} reshape(%concatenate.2338), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.2263 = bf16[32,4,128]{2,1,0} slice(%reshape.2261), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.2288 = f32[32,4,128]{2,1,0} convert(%slice.2263), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.2289 = f32[32,4,128]{2,1,0} power(%convert_element_type.2288, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2294 = f32[32,4]{1,0} reduce(%pow.2289, %constant.512), dimensions={2}, to_apply=%region_54.2293, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2295 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.2294), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2296 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.2295, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2297 = f32[32,4,1]{2,1,0} add(%div.2296, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2298 = f32[32,4,1]{2,1,0} rsqrt(%add.2297), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2299 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.2298), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2300 = f32[32,4]{1,0} reshape(%mul.2299), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2301 = f32[32,4,128]{2,1,0} broadcast(%mul.2300), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2302 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.2288, %mul.2301), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2303 = bf16[32,4,128]{2,1,0} convert(%mul.2302), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_5_self_attn_k_norm_weight__.395 = bf16[128]{0} parameter(394), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.5.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.2304 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_5_self_attn_k_norm_weight__.395), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2305 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.2304), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2306 = bf16[128]{0} reshape(%mul.2305), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2307 = bf16[32,4,128]{2,1,0} broadcast(%mul.2306), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2308 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.2303, %mul.2307), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2342 = bf16[32,4,64]{2,1,0} slice(%mul.2308), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2340 = bf16[32,1,64]{2,1,0} reshape(%slice.2314), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2344 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2340), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2345 = bf16[32,64]{1,0} reshape(%mul.2344), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2346 = bf16[32,4,64]{2,1,0} broadcast(%mul.2345), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2347 = bf16[32,4,64]{2,1,0} multiply(%slice.2342, %mul.2346), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2343 = bf16[32,4,64]{2,1,0} slice(%mul.2308), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2341 = bf16[32,1,64]{2,1,0} reshape(%slice.2315), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2348 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2341), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2349 = bf16[32,64]{1,0} reshape(%mul.2348), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2350 = bf16[32,4,64]{2,1,0} broadcast(%mul.2349), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2351 = bf16[32,4,64]{2,1,0} multiply(%slice.2343, %mul.2350), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.2352 = bf16[32,4,64]{2,1,0} subtract(%mul.2347, %mul.2351), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.2353 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2340), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2354 = bf16[32,64]{1,0} reshape(%mul.2353), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2355 = bf16[32,4,64]{2,1,0} broadcast(%mul.2354), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2356 = bf16[32,4,64]{2,1,0} multiply(%slice.2343, %mul.2355), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2357 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2341), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2358 = bf16[32,64]{1,0} reshape(%mul.2357), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2359 = bf16[32,4,64]{2,1,0} broadcast(%mul.2358), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2360 = bf16[32,4,64]{2,1,0} multiply(%slice.2342, %mul.2359), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.2361 = bf16[32,4,64]{2,1,0} add(%mul.2356, %mul.2360), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.2362 = bf16[32,4,128]{2,1,0} concatenate(%sub.2352, %add.2361), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.2363 = bf16[32,512]{1,0} reshape(%concatenate.2362), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.2264 = bf16[32,4,128]{2,1,0} slice(%reshape.2261), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.2265 = bf16[32,512]{1,0} reshape(%slice.2264), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.2364 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_5_.441, %reshape.2339, %reshape.2363, %reshape.2265, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.2365 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.2364), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_6_.442 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(441), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[6]"}
  %jit__jax_attn_func_.2366 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.2364), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_5_self_attn_o_proj_weight__.396 = bf16[2048,4096]{1,0} parameter(395), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.5.self_attn.o_proj.weight\']"}
  %dot_general.2367 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.2366, %params_and_buffers__vllm_model_language_model_model_layers_5_self_attn_o_proj_weight__.396), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.2368 = f32[32,2048]{1,0} convert(%dot_general.2367), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2239 = bf16[32,2048]{1,0} convert(%add.2238), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2369 = f32[32,2048]{1,0} convert(%convert_element_type.2239), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.2370 = f32[32,2048]{1,0} add(%convert_element_type.2368, %convert_element_type.2369), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.2372 = f32[32,2048]{1,0} power(%add.2370, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2377 = f32[32]{0} reduce(%pow.2372, %constant.512), dimensions={1}, to_apply=%region_55.2376, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2378 = f32[32,1]{1,0} reshape(%reduce_sum.2377), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2379 = f32[32,1]{1,0} divide(%broadcast_in_dim.2378, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2380 = f32[32,1]{1,0} add(%div.2379, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2381 = f32[32,1]{1,0} rsqrt(%add.2380), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2382 = f32[32,1]{1,0} broadcast(%rsqrt.2381), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2383 = f32[32]{0} reshape(%mul.2382), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2384 = f32[32,2048]{1,0} broadcast(%mul.2383), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2385 = f32[32,2048]{1,0} multiply(%add.2370, %mul.2384), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2386 = bf16[32,2048]{1,0} convert(%mul.2385), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_5_post_attention_layernorm_weight__.394 = bf16[2048]{0} parameter(393), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.5.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.2387 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_5_post_attention_layernorm_weight__.394), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2388 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.2387), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2389 = bf16[2048]{0} reshape(%mul.2388), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2390 = bf16[32,2048]{1,0} broadcast(%mul.2389), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2391 = bf16[32,2048]{1,0} multiply(%convert_element_type.2386, %mul.2390), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_5_mlp_experts_w13_weight__.391 = bf16[128,1536,2048]{2,1,0} parameter(390), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.5.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_5_mlp_experts_w2_weight__.392 = bf16[128,2048,768]{2,1,0} parameter(391), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.5.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_5_mlp_gate_weight__.393 = bf16[128,2048]{1,0} parameter(392), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.5.mlp.gate.weight\']"}
  %dot_general.2392 = bf16[32,128]{1,0} dot(%mul.2391, %params_and_buffers__vllm_model_language_model_model_layers_5_mlp_gate_weight__.393), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.2393 = bf16[32,2048]{1,0} call(%mul.2391, %params_and_buffers__vllm_model_language_model_model_layers_5_mlp_experts_w13_weight__.391, %params_and_buffers__vllm_model_language_model_model_layers_5_mlp_experts_w2_weight__.392, %dot_general.2392), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.2394 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.2393), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2371 = bf16[32,2048]{1,0} convert(%add.2370), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2395 = f32[32,2048]{1,0} convert(%convert_element_type.2371), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.2396 = f32[32,2048]{1,0} add(%convert_element_type.2394, %convert_element_type.2395), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.2398 = f32[32,2048]{1,0} power(%add.2396, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2403 = f32[32]{0} reduce(%pow.2398, %constant.512), dimensions={1}, to_apply=%region_56.2402, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2404 = f32[32,1]{1,0} reshape(%reduce_sum.2403), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2405 = f32[32,1]{1,0} divide(%broadcast_in_dim.2404, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2406 = f32[32,1]{1,0} add(%div.2405, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2407 = f32[32,1]{1,0} rsqrt(%add.2406), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2408 = f32[32,1]{1,0} broadcast(%rsqrt.2407), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2409 = f32[32]{0} reshape(%mul.2408), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2410 = f32[32,2048]{1,0} broadcast(%mul.2409), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2411 = f32[32,2048]{1,0} multiply(%add.2396, %mul.2410), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2412 = bf16[32,2048]{1,0} convert(%mul.2411), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_6_input_layernorm_weight__.399 = bf16[2048]{0} parameter(398), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.6.input_layernorm.weight\']"}
  %broadcast_in_dim.2413 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_6_input_layernorm_weight__.399), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2414 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.2413), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2415 = bf16[2048]{0} reshape(%mul.2414), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2416 = bf16[32,2048]{1,0} broadcast(%mul.2415), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2417 = bf16[32,2048]{1,0} multiply(%convert_element_type.2412, %mul.2416), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_6_self_attn_qkv_proj_weight__.407 = bf16[5120,2048]{1,0} parameter(406), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.6.self_attn.qkv_proj.weight\']"}
  %dot_general.2418 = bf16[32,5120]{1,0} dot(%mul.2417, %params_and_buffers__vllm_model_language_model_model_layers_6_self_attn_qkv_proj_weight__.407), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.2419 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.2418), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.2420 = bf16[32,4,1024]{2,1,0} slice(%reshape.2419), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.2424 = bf16[32,32,128]{2,1,0} reshape(%slice.2420), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.2425 = f32[32,32,128]{2,1,0} convert(%reshape.2424), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.2426 = f32[32,32,128]{2,1,0} power(%convert_element_type.2425, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2431 = f32[32,32]{1,0} reduce(%pow.2426, %constant.512), dimensions={2}, to_apply=%region_57.2430, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2432 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.2431), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2433 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.2432, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2434 = f32[32,32,1]{2,1,0} add(%div.2433, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2435 = f32[32,32,1]{2,1,0} rsqrt(%add.2434), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2436 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.2435), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2437 = f32[32,32]{1,0} reshape(%mul.2436), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2438 = f32[32,32,128]{2,1,0} broadcast(%mul.2437), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2439 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.2425, %mul.2438), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2440 = bf16[32,32,128]{2,1,0} convert(%mul.2439), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_6_self_attn_q_norm_weight__.406 = bf16[128]{0} parameter(405), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.6.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.2441 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_6_self_attn_q_norm_weight__.406), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2442 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.2441), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2443 = bf16[128]{0} reshape(%mul.2442), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2444 = bf16[32,32,128]{2,1,0} broadcast(%mul.2443), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2445 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.2440, %mul.2444), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2476 = bf16[32,32,64]{2,1,0} slice(%mul.2445), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.2467 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.2468 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.2469 = s32[32]{0} select(%lt.2467, %add.2468, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.2470 = s32[32,1]{1,0} reshape(%select_n.2469), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.2471 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.2470), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.2472 = bf16[32,64]{1,0} slice(%gather.2471), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2474 = bf16[32,1,64]{2,1,0} reshape(%slice.2472), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2478 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2474), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2479 = bf16[32,64]{1,0} reshape(%mul.2478), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2480 = bf16[32,32,64]{2,1,0} broadcast(%mul.2479), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2481 = bf16[32,32,64]{2,1,0} multiply(%slice.2476, %mul.2480), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2477 = bf16[32,32,64]{2,1,0} slice(%mul.2445), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.2473 = bf16[32,64]{1,0} slice(%gather.2471), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2475 = bf16[32,1,64]{2,1,0} reshape(%slice.2473), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2482 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2475), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2483 = bf16[32,64]{1,0} reshape(%mul.2482), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2484 = bf16[32,32,64]{2,1,0} broadcast(%mul.2483), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2485 = bf16[32,32,64]{2,1,0} multiply(%slice.2477, %mul.2484), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.2486 = bf16[32,32,64]{2,1,0} subtract(%mul.2481, %mul.2485), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.2487 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2474), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2488 = bf16[32,64]{1,0} reshape(%mul.2487), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2489 = bf16[32,32,64]{2,1,0} broadcast(%mul.2488), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2490 = bf16[32,32,64]{2,1,0} multiply(%slice.2477, %mul.2489), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2491 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2475), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2492 = bf16[32,64]{1,0} reshape(%mul.2491), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2493 = bf16[32,32,64]{2,1,0} broadcast(%mul.2492), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2494 = bf16[32,32,64]{2,1,0} multiply(%slice.2476, %mul.2493), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.2495 = bf16[32,32,64]{2,1,0} add(%mul.2490, %mul.2494), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.2496 = bf16[32,32,128]{2,1,0} concatenate(%sub.2486, %add.2495), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.2497 = bf16[32,4096]{1,0} reshape(%concatenate.2496), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.2421 = bf16[32,4,128]{2,1,0} slice(%reshape.2419), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.2446 = f32[32,4,128]{2,1,0} convert(%slice.2421), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.2447 = f32[32,4,128]{2,1,0} power(%convert_element_type.2446, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2452 = f32[32,4]{1,0} reduce(%pow.2447, %constant.512), dimensions={2}, to_apply=%region_58.2451, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2453 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.2452), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2454 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.2453, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2455 = f32[32,4,1]{2,1,0} add(%div.2454, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2456 = f32[32,4,1]{2,1,0} rsqrt(%add.2455), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2457 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.2456), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2458 = f32[32,4]{1,0} reshape(%mul.2457), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2459 = f32[32,4,128]{2,1,0} broadcast(%mul.2458), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2460 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.2446, %mul.2459), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2461 = bf16[32,4,128]{2,1,0} convert(%mul.2460), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_6_self_attn_k_norm_weight__.404 = bf16[128]{0} parameter(403), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.6.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.2462 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_6_self_attn_k_norm_weight__.404), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2463 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.2462), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2464 = bf16[128]{0} reshape(%mul.2463), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2465 = bf16[32,4,128]{2,1,0} broadcast(%mul.2464), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2466 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.2461, %mul.2465), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2500 = bf16[32,4,64]{2,1,0} slice(%mul.2466), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2498 = bf16[32,1,64]{2,1,0} reshape(%slice.2472), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2502 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2498), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2503 = bf16[32,64]{1,0} reshape(%mul.2502), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2504 = bf16[32,4,64]{2,1,0} broadcast(%mul.2503), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2505 = bf16[32,4,64]{2,1,0} multiply(%slice.2500, %mul.2504), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2501 = bf16[32,4,64]{2,1,0} slice(%mul.2466), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2499 = bf16[32,1,64]{2,1,0} reshape(%slice.2473), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2506 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2499), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2507 = bf16[32,64]{1,0} reshape(%mul.2506), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2508 = bf16[32,4,64]{2,1,0} broadcast(%mul.2507), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2509 = bf16[32,4,64]{2,1,0} multiply(%slice.2501, %mul.2508), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.2510 = bf16[32,4,64]{2,1,0} subtract(%mul.2505, %mul.2509), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.2511 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2498), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2512 = bf16[32,64]{1,0} reshape(%mul.2511), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2513 = bf16[32,4,64]{2,1,0} broadcast(%mul.2512), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2514 = bf16[32,4,64]{2,1,0} multiply(%slice.2501, %mul.2513), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2515 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2499), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2516 = bf16[32,64]{1,0} reshape(%mul.2515), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2517 = bf16[32,4,64]{2,1,0} broadcast(%mul.2516), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2518 = bf16[32,4,64]{2,1,0} multiply(%slice.2500, %mul.2517), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.2519 = bf16[32,4,64]{2,1,0} add(%mul.2514, %mul.2518), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.2520 = bf16[32,4,128]{2,1,0} concatenate(%sub.2510, %add.2519), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.2521 = bf16[32,512]{1,0} reshape(%concatenate.2520), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.2422 = bf16[32,4,128]{2,1,0} slice(%reshape.2419), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.2423 = bf16[32,512]{1,0} reshape(%slice.2422), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.2522 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_6_.442, %reshape.2497, %reshape.2521, %reshape.2423, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.2523 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.2522), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_7_.443 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(442), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[7]"}
  %jit__jax_attn_func_.2524 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.2522), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_6_self_attn_o_proj_weight__.405 = bf16[2048,4096]{1,0} parameter(404), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.6.self_attn.o_proj.weight\']"}
  %dot_general.2525 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.2524, %params_and_buffers__vllm_model_language_model_model_layers_6_self_attn_o_proj_weight__.405), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.2526 = f32[32,2048]{1,0} convert(%dot_general.2525), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2397 = bf16[32,2048]{1,0} convert(%add.2396), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2527 = f32[32,2048]{1,0} convert(%convert_element_type.2397), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.2528 = f32[32,2048]{1,0} add(%convert_element_type.2526, %convert_element_type.2527), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.2530 = f32[32,2048]{1,0} power(%add.2528, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2535 = f32[32]{0} reduce(%pow.2530, %constant.512), dimensions={1}, to_apply=%region_59.2534, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2536 = f32[32,1]{1,0} reshape(%reduce_sum.2535), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2537 = f32[32,1]{1,0} divide(%broadcast_in_dim.2536, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2538 = f32[32,1]{1,0} add(%div.2537, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2539 = f32[32,1]{1,0} rsqrt(%add.2538), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2540 = f32[32,1]{1,0} broadcast(%rsqrt.2539), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2541 = f32[32]{0} reshape(%mul.2540), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2542 = f32[32,2048]{1,0} broadcast(%mul.2541), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2543 = f32[32,2048]{1,0} multiply(%add.2528, %mul.2542), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2544 = bf16[32,2048]{1,0} convert(%mul.2543), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_6_post_attention_layernorm_weight__.403 = bf16[2048]{0} parameter(402), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.6.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.2545 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_6_post_attention_layernorm_weight__.403), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2546 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.2545), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2547 = bf16[2048]{0} reshape(%mul.2546), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2548 = bf16[32,2048]{1,0} broadcast(%mul.2547), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2549 = bf16[32,2048]{1,0} multiply(%convert_element_type.2544, %mul.2548), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_6_mlp_experts_w13_weight__.400 = bf16[128,1536,2048]{2,1,0} parameter(399), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.6.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_6_mlp_experts_w2_weight__.401 = bf16[128,2048,768]{2,1,0} parameter(400), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.6.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_6_mlp_gate_weight__.402 = bf16[128,2048]{1,0} parameter(401), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.6.mlp.gate.weight\']"}
  %dot_general.2550 = bf16[32,128]{1,0} dot(%mul.2549, %params_and_buffers__vllm_model_language_model_model_layers_6_mlp_gate_weight__.402), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.2551 = bf16[32,2048]{1,0} call(%mul.2549, %params_and_buffers__vllm_model_language_model_model_layers_6_mlp_experts_w13_weight__.400, %params_and_buffers__vllm_model_language_model_model_layers_6_mlp_experts_w2_weight__.401, %dot_general.2550), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.2552 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.2551), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2529 = bf16[32,2048]{1,0} convert(%add.2528), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2553 = f32[32,2048]{1,0} convert(%convert_element_type.2529), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.2554 = f32[32,2048]{1,0} add(%convert_element_type.2552, %convert_element_type.2553), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.2556 = f32[32,2048]{1,0} power(%add.2554, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2561 = f32[32]{0} reduce(%pow.2556, %constant.512), dimensions={1}, to_apply=%region_60.2560, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2562 = f32[32,1]{1,0} reshape(%reduce_sum.2561), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2563 = f32[32,1]{1,0} divide(%broadcast_in_dim.2562, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2564 = f32[32,1]{1,0} add(%div.2563, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2565 = f32[32,1]{1,0} rsqrt(%add.2564), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2566 = f32[32,1]{1,0} broadcast(%rsqrt.2565), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2567 = f32[32]{0} reshape(%mul.2566), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2568 = f32[32,2048]{1,0} broadcast(%mul.2567), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2569 = f32[32,2048]{1,0} multiply(%add.2554, %mul.2568), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2570 = bf16[32,2048]{1,0} convert(%mul.2569), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_7_input_layernorm_weight__.408 = bf16[2048]{0} parameter(407), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.7.input_layernorm.weight\']"}
  %broadcast_in_dim.2571 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_7_input_layernorm_weight__.408), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2572 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.2571), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2573 = bf16[2048]{0} reshape(%mul.2572), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2574 = bf16[32,2048]{1,0} broadcast(%mul.2573), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2575 = bf16[32,2048]{1,0} multiply(%convert_element_type.2570, %mul.2574), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_7_self_attn_qkv_proj_weight__.416 = bf16[5120,2048]{1,0} parameter(415), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.7.self_attn.qkv_proj.weight\']"}
  %dot_general.2576 = bf16[32,5120]{1,0} dot(%mul.2575, %params_and_buffers__vllm_model_language_model_model_layers_7_self_attn_qkv_proj_weight__.416), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.2577 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.2576), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.2578 = bf16[32,4,1024]{2,1,0} slice(%reshape.2577), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.2582 = bf16[32,32,128]{2,1,0} reshape(%slice.2578), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.2583 = f32[32,32,128]{2,1,0} convert(%reshape.2582), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.2584 = f32[32,32,128]{2,1,0} power(%convert_element_type.2583, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2589 = f32[32,32]{1,0} reduce(%pow.2584, %constant.512), dimensions={2}, to_apply=%region_61.2588, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2590 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.2589), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2591 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.2590, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2592 = f32[32,32,1]{2,1,0} add(%div.2591, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2593 = f32[32,32,1]{2,1,0} rsqrt(%add.2592), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2594 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.2593), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2595 = f32[32,32]{1,0} reshape(%mul.2594), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2596 = f32[32,32,128]{2,1,0} broadcast(%mul.2595), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2597 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.2583, %mul.2596), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2598 = bf16[32,32,128]{2,1,0} convert(%mul.2597), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_7_self_attn_q_norm_weight__.415 = bf16[128]{0} parameter(414), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.7.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.2599 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_7_self_attn_q_norm_weight__.415), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2600 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.2599), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2601 = bf16[128]{0} reshape(%mul.2600), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2602 = bf16[32,32,128]{2,1,0} broadcast(%mul.2601), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2603 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.2598, %mul.2602), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2634 = bf16[32,32,64]{2,1,0} slice(%mul.2603), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.2625 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.2626 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.2627 = s32[32]{0} select(%lt.2625, %add.2626, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.2628 = s32[32,1]{1,0} reshape(%select_n.2627), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.2629 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.2628), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.2630 = bf16[32,64]{1,0} slice(%gather.2629), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2632 = bf16[32,1,64]{2,1,0} reshape(%slice.2630), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2636 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2632), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2637 = bf16[32,64]{1,0} reshape(%mul.2636), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2638 = bf16[32,32,64]{2,1,0} broadcast(%mul.2637), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2639 = bf16[32,32,64]{2,1,0} multiply(%slice.2634, %mul.2638), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2635 = bf16[32,32,64]{2,1,0} slice(%mul.2603), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.2631 = bf16[32,64]{1,0} slice(%gather.2629), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2633 = bf16[32,1,64]{2,1,0} reshape(%slice.2631), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2640 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2633), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2641 = bf16[32,64]{1,0} reshape(%mul.2640), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2642 = bf16[32,32,64]{2,1,0} broadcast(%mul.2641), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2643 = bf16[32,32,64]{2,1,0} multiply(%slice.2635, %mul.2642), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.2644 = bf16[32,32,64]{2,1,0} subtract(%mul.2639, %mul.2643), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.2645 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2632), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2646 = bf16[32,64]{1,0} reshape(%mul.2645), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2647 = bf16[32,32,64]{2,1,0} broadcast(%mul.2646), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2648 = bf16[32,32,64]{2,1,0} multiply(%slice.2635, %mul.2647), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2649 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2633), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2650 = bf16[32,64]{1,0} reshape(%mul.2649), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2651 = bf16[32,32,64]{2,1,0} broadcast(%mul.2650), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2652 = bf16[32,32,64]{2,1,0} multiply(%slice.2634, %mul.2651), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.2653 = bf16[32,32,64]{2,1,0} add(%mul.2648, %mul.2652), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.2654 = bf16[32,32,128]{2,1,0} concatenate(%sub.2644, %add.2653), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.2655 = bf16[32,4096]{1,0} reshape(%concatenate.2654), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.2579 = bf16[32,4,128]{2,1,0} slice(%reshape.2577), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.2604 = f32[32,4,128]{2,1,0} convert(%slice.2579), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.2605 = f32[32,4,128]{2,1,0} power(%convert_element_type.2604, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2610 = f32[32,4]{1,0} reduce(%pow.2605, %constant.512), dimensions={2}, to_apply=%region_62.2609, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2611 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.2610), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2612 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.2611, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2613 = f32[32,4,1]{2,1,0} add(%div.2612, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2614 = f32[32,4,1]{2,1,0} rsqrt(%add.2613), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2615 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.2614), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2616 = f32[32,4]{1,0} reshape(%mul.2615), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2617 = f32[32,4,128]{2,1,0} broadcast(%mul.2616), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2618 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.2604, %mul.2617), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2619 = bf16[32,4,128]{2,1,0} convert(%mul.2618), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_7_self_attn_k_norm_weight__.413 = bf16[128]{0} parameter(412), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.7.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.2620 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_7_self_attn_k_norm_weight__.413), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2621 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.2620), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2622 = bf16[128]{0} reshape(%mul.2621), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2623 = bf16[32,4,128]{2,1,0} broadcast(%mul.2622), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2624 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.2619, %mul.2623), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2658 = bf16[32,4,64]{2,1,0} slice(%mul.2624), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2656 = bf16[32,1,64]{2,1,0} reshape(%slice.2630), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2660 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2656), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2661 = bf16[32,64]{1,0} reshape(%mul.2660), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2662 = bf16[32,4,64]{2,1,0} broadcast(%mul.2661), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2663 = bf16[32,4,64]{2,1,0} multiply(%slice.2658, %mul.2662), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2659 = bf16[32,4,64]{2,1,0} slice(%mul.2624), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2657 = bf16[32,1,64]{2,1,0} reshape(%slice.2631), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2664 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2657), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2665 = bf16[32,64]{1,0} reshape(%mul.2664), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2666 = bf16[32,4,64]{2,1,0} broadcast(%mul.2665), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2667 = bf16[32,4,64]{2,1,0} multiply(%slice.2659, %mul.2666), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.2668 = bf16[32,4,64]{2,1,0} subtract(%mul.2663, %mul.2667), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.2669 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2656), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2670 = bf16[32,64]{1,0} reshape(%mul.2669), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2671 = bf16[32,4,64]{2,1,0} broadcast(%mul.2670), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2672 = bf16[32,4,64]{2,1,0} multiply(%slice.2659, %mul.2671), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2673 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2657), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2674 = bf16[32,64]{1,0} reshape(%mul.2673), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2675 = bf16[32,4,64]{2,1,0} broadcast(%mul.2674), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2676 = bf16[32,4,64]{2,1,0} multiply(%slice.2658, %mul.2675), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.2677 = bf16[32,4,64]{2,1,0} add(%mul.2672, %mul.2676), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.2678 = bf16[32,4,128]{2,1,0} concatenate(%sub.2668, %add.2677), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.2679 = bf16[32,512]{1,0} reshape(%concatenate.2678), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.2580 = bf16[32,4,128]{2,1,0} slice(%reshape.2577), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.2581 = bf16[32,512]{1,0} reshape(%slice.2580), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.2680 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_7_.443, %reshape.2655, %reshape.2679, %reshape.2581, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.2681 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.2680), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_8_.444 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(443), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[8]"}
  %jit__jax_attn_func_.2682 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.2680), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_7_self_attn_o_proj_weight__.414 = bf16[2048,4096]{1,0} parameter(413), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.7.self_attn.o_proj.weight\']"}
  %dot_general.2683 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.2682, %params_and_buffers__vllm_model_language_model_model_layers_7_self_attn_o_proj_weight__.414), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.2684 = f32[32,2048]{1,0} convert(%dot_general.2683), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2555 = bf16[32,2048]{1,0} convert(%add.2554), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2685 = f32[32,2048]{1,0} convert(%convert_element_type.2555), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.2686 = f32[32,2048]{1,0} add(%convert_element_type.2684, %convert_element_type.2685), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.2688 = f32[32,2048]{1,0} power(%add.2686, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2693 = f32[32]{0} reduce(%pow.2688, %constant.512), dimensions={1}, to_apply=%region_63.2692, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2694 = f32[32,1]{1,0} reshape(%reduce_sum.2693), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2695 = f32[32,1]{1,0} divide(%broadcast_in_dim.2694, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2696 = f32[32,1]{1,0} add(%div.2695, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2697 = f32[32,1]{1,0} rsqrt(%add.2696), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2698 = f32[32,1]{1,0} broadcast(%rsqrt.2697), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2699 = f32[32]{0} reshape(%mul.2698), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2700 = f32[32,2048]{1,0} broadcast(%mul.2699), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2701 = f32[32,2048]{1,0} multiply(%add.2686, %mul.2700), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2702 = bf16[32,2048]{1,0} convert(%mul.2701), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_7_post_attention_layernorm_weight__.412 = bf16[2048]{0} parameter(411), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.7.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.2703 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_7_post_attention_layernorm_weight__.412), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2704 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.2703), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2705 = bf16[2048]{0} reshape(%mul.2704), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2706 = bf16[32,2048]{1,0} broadcast(%mul.2705), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2707 = bf16[32,2048]{1,0} multiply(%convert_element_type.2702, %mul.2706), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_7_mlp_experts_w13_weight__.409 = bf16[128,1536,2048]{2,1,0} parameter(408), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.7.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_7_mlp_experts_w2_weight__.410 = bf16[128,2048,768]{2,1,0} parameter(409), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.7.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_7_mlp_gate_weight__.411 = bf16[128,2048]{1,0} parameter(410), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.7.mlp.gate.weight\']"}
  %dot_general.2708 = bf16[32,128]{1,0} dot(%mul.2707, %params_and_buffers__vllm_model_language_model_model_layers_7_mlp_gate_weight__.411), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.2709 = bf16[32,2048]{1,0} call(%mul.2707, %params_and_buffers__vllm_model_language_model_model_layers_7_mlp_experts_w13_weight__.409, %params_and_buffers__vllm_model_language_model_model_layers_7_mlp_experts_w2_weight__.410, %dot_general.2708), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.2710 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.2709), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2687 = bf16[32,2048]{1,0} convert(%add.2686), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2711 = f32[32,2048]{1,0} convert(%convert_element_type.2687), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.2712 = f32[32,2048]{1,0} add(%convert_element_type.2710, %convert_element_type.2711), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.2714 = f32[32,2048]{1,0} power(%add.2712, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2719 = f32[32]{0} reduce(%pow.2714, %constant.512), dimensions={1}, to_apply=%region_64.2718, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2720 = f32[32,1]{1,0} reshape(%reduce_sum.2719), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2721 = f32[32,1]{1,0} divide(%broadcast_in_dim.2720, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2722 = f32[32,1]{1,0} add(%div.2721, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2723 = f32[32,1]{1,0} rsqrt(%add.2722), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2724 = f32[32,1]{1,0} broadcast(%rsqrt.2723), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2725 = f32[32]{0} reshape(%mul.2724), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2726 = f32[32,2048]{1,0} broadcast(%mul.2725), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2727 = f32[32,2048]{1,0} multiply(%add.2712, %mul.2726), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2728 = bf16[32,2048]{1,0} convert(%mul.2727), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_8_input_layernorm_weight__.417 = bf16[2048]{0} parameter(416), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.8.input_layernorm.weight\']"}
  %broadcast_in_dim.2729 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_8_input_layernorm_weight__.417), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2730 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.2729), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2731 = bf16[2048]{0} reshape(%mul.2730), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2732 = bf16[32,2048]{1,0} broadcast(%mul.2731), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2733 = bf16[32,2048]{1,0} multiply(%convert_element_type.2728, %mul.2732), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_8_self_attn_qkv_proj_weight__.425 = bf16[5120,2048]{1,0} parameter(424), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.8.self_attn.qkv_proj.weight\']"}
  %dot_general.2734 = bf16[32,5120]{1,0} dot(%mul.2733, %params_and_buffers__vllm_model_language_model_model_layers_8_self_attn_qkv_proj_weight__.425), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.2735 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.2734), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.2736 = bf16[32,4,1024]{2,1,0} slice(%reshape.2735), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.2740 = bf16[32,32,128]{2,1,0} reshape(%slice.2736), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.2741 = f32[32,32,128]{2,1,0} convert(%reshape.2740), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.2742 = f32[32,32,128]{2,1,0} power(%convert_element_type.2741, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2747 = f32[32,32]{1,0} reduce(%pow.2742, %constant.512), dimensions={2}, to_apply=%region_65.2746, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2748 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.2747), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2749 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.2748, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2750 = f32[32,32,1]{2,1,0} add(%div.2749, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2751 = f32[32,32,1]{2,1,0} rsqrt(%add.2750), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2752 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.2751), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2753 = f32[32,32]{1,0} reshape(%mul.2752), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2754 = f32[32,32,128]{2,1,0} broadcast(%mul.2753), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2755 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.2741, %mul.2754), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2756 = bf16[32,32,128]{2,1,0} convert(%mul.2755), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_8_self_attn_q_norm_weight__.424 = bf16[128]{0} parameter(423), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.8.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.2757 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_8_self_attn_q_norm_weight__.424), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2758 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.2757), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2759 = bf16[128]{0} reshape(%mul.2758), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2760 = bf16[32,32,128]{2,1,0} broadcast(%mul.2759), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2761 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.2756, %mul.2760), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2792 = bf16[32,32,64]{2,1,0} slice(%mul.2761), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.2783 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.2784 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.2785 = s32[32]{0} select(%lt.2783, %add.2784, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.2786 = s32[32,1]{1,0} reshape(%select_n.2785), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.2787 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.2786), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.2788 = bf16[32,64]{1,0} slice(%gather.2787), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2790 = bf16[32,1,64]{2,1,0} reshape(%slice.2788), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2794 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2790), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2795 = bf16[32,64]{1,0} reshape(%mul.2794), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2796 = bf16[32,32,64]{2,1,0} broadcast(%mul.2795), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2797 = bf16[32,32,64]{2,1,0} multiply(%slice.2792, %mul.2796), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2793 = bf16[32,32,64]{2,1,0} slice(%mul.2761), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.2789 = bf16[32,64]{1,0} slice(%gather.2787), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2791 = bf16[32,1,64]{2,1,0} reshape(%slice.2789), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2798 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2791), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2799 = bf16[32,64]{1,0} reshape(%mul.2798), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2800 = bf16[32,32,64]{2,1,0} broadcast(%mul.2799), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2801 = bf16[32,32,64]{2,1,0} multiply(%slice.2793, %mul.2800), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.2802 = bf16[32,32,64]{2,1,0} subtract(%mul.2797, %mul.2801), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.2803 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2790), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2804 = bf16[32,64]{1,0} reshape(%mul.2803), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2805 = bf16[32,32,64]{2,1,0} broadcast(%mul.2804), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2806 = bf16[32,32,64]{2,1,0} multiply(%slice.2793, %mul.2805), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2807 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2791), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2808 = bf16[32,64]{1,0} reshape(%mul.2807), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2809 = bf16[32,32,64]{2,1,0} broadcast(%mul.2808), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2810 = bf16[32,32,64]{2,1,0} multiply(%slice.2792, %mul.2809), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.2811 = bf16[32,32,64]{2,1,0} add(%mul.2806, %mul.2810), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.2812 = bf16[32,32,128]{2,1,0} concatenate(%sub.2802, %add.2811), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.2813 = bf16[32,4096]{1,0} reshape(%concatenate.2812), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.2737 = bf16[32,4,128]{2,1,0} slice(%reshape.2735), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.2762 = f32[32,4,128]{2,1,0} convert(%slice.2737), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.2763 = f32[32,4,128]{2,1,0} power(%convert_element_type.2762, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2768 = f32[32,4]{1,0} reduce(%pow.2763, %constant.512), dimensions={2}, to_apply=%region_66.2767, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2769 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.2768), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2770 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.2769, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2771 = f32[32,4,1]{2,1,0} add(%div.2770, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2772 = f32[32,4,1]{2,1,0} rsqrt(%add.2771), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2773 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.2772), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2774 = f32[32,4]{1,0} reshape(%mul.2773), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2775 = f32[32,4,128]{2,1,0} broadcast(%mul.2774), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2776 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.2762, %mul.2775), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2777 = bf16[32,4,128]{2,1,0} convert(%mul.2776), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_8_self_attn_k_norm_weight__.422 = bf16[128]{0} parameter(421), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.8.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.2778 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_8_self_attn_k_norm_weight__.422), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2779 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.2778), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2780 = bf16[128]{0} reshape(%mul.2779), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2781 = bf16[32,4,128]{2,1,0} broadcast(%mul.2780), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2782 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.2777, %mul.2781), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2816 = bf16[32,4,64]{2,1,0} slice(%mul.2782), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2814 = bf16[32,1,64]{2,1,0} reshape(%slice.2788), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2818 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2814), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2819 = bf16[32,64]{1,0} reshape(%mul.2818), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2820 = bf16[32,4,64]{2,1,0} broadcast(%mul.2819), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2821 = bf16[32,4,64]{2,1,0} multiply(%slice.2816, %mul.2820), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2817 = bf16[32,4,64]{2,1,0} slice(%mul.2782), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2815 = bf16[32,1,64]{2,1,0} reshape(%slice.2789), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2822 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2815), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2823 = bf16[32,64]{1,0} reshape(%mul.2822), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2824 = bf16[32,4,64]{2,1,0} broadcast(%mul.2823), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2825 = bf16[32,4,64]{2,1,0} multiply(%slice.2817, %mul.2824), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.2826 = bf16[32,4,64]{2,1,0} subtract(%mul.2821, %mul.2825), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.2827 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2814), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2828 = bf16[32,64]{1,0} reshape(%mul.2827), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2829 = bf16[32,4,64]{2,1,0} broadcast(%mul.2828), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2830 = bf16[32,4,64]{2,1,0} multiply(%slice.2817, %mul.2829), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2831 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2815), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2832 = bf16[32,64]{1,0} reshape(%mul.2831), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2833 = bf16[32,4,64]{2,1,0} broadcast(%mul.2832), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2834 = bf16[32,4,64]{2,1,0} multiply(%slice.2816, %mul.2833), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.2835 = bf16[32,4,64]{2,1,0} add(%mul.2830, %mul.2834), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.2836 = bf16[32,4,128]{2,1,0} concatenate(%sub.2826, %add.2835), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.2837 = bf16[32,512]{1,0} reshape(%concatenate.2836), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.2738 = bf16[32,4,128]{2,1,0} slice(%reshape.2735), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.2739 = bf16[32,512]{1,0} reshape(%slice.2738), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.2838 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_8_.444, %reshape.2813, %reshape.2837, %reshape.2739, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.2839 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.2838), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_9_.445 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(444), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[9]"}
  %jit__jax_attn_func_.2840 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.2838), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_8_self_attn_o_proj_weight__.423 = bf16[2048,4096]{1,0} parameter(422), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.8.self_attn.o_proj.weight\']"}
  %dot_general.2841 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.2840, %params_and_buffers__vllm_model_language_model_model_layers_8_self_attn_o_proj_weight__.423), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.2842 = f32[32,2048]{1,0} convert(%dot_general.2841), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2713 = bf16[32,2048]{1,0} convert(%add.2712), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2843 = f32[32,2048]{1,0} convert(%convert_element_type.2713), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.2844 = f32[32,2048]{1,0} add(%convert_element_type.2842, %convert_element_type.2843), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.2846 = f32[32,2048]{1,0} power(%add.2844, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2851 = f32[32]{0} reduce(%pow.2846, %constant.512), dimensions={1}, to_apply=%region_67.2850, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2852 = f32[32,1]{1,0} reshape(%reduce_sum.2851), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2853 = f32[32,1]{1,0} divide(%broadcast_in_dim.2852, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2854 = f32[32,1]{1,0} add(%div.2853, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2855 = f32[32,1]{1,0} rsqrt(%add.2854), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2856 = f32[32,1]{1,0} broadcast(%rsqrt.2855), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2857 = f32[32]{0} reshape(%mul.2856), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2858 = f32[32,2048]{1,0} broadcast(%mul.2857), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2859 = f32[32,2048]{1,0} multiply(%add.2844, %mul.2858), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2860 = bf16[32,2048]{1,0} convert(%mul.2859), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_8_post_attention_layernorm_weight__.421 = bf16[2048]{0} parameter(420), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.8.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.2861 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_8_post_attention_layernorm_weight__.421), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2862 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.2861), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2863 = bf16[2048]{0} reshape(%mul.2862), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2864 = bf16[32,2048]{1,0} broadcast(%mul.2863), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2865 = bf16[32,2048]{1,0} multiply(%convert_element_type.2860, %mul.2864), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_8_mlp_experts_w13_weight__.418 = bf16[128,1536,2048]{2,1,0} parameter(417), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.8.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_8_mlp_experts_w2_weight__.419 = bf16[128,2048,768]{2,1,0} parameter(418), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.8.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_8_mlp_gate_weight__.420 = bf16[128,2048]{1,0} parameter(419), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.8.mlp.gate.weight\']"}
  %dot_general.2866 = bf16[32,128]{1,0} dot(%mul.2865, %params_and_buffers__vllm_model_language_model_model_layers_8_mlp_gate_weight__.420), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.2867 = bf16[32,2048]{1,0} call(%mul.2865, %params_and_buffers__vllm_model_language_model_model_layers_8_mlp_experts_w13_weight__.418, %params_and_buffers__vllm_model_language_model_model_layers_8_mlp_experts_w2_weight__.419, %dot_general.2866), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.2868 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.2867), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2845 = bf16[32,2048]{1,0} convert(%add.2844), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2869 = f32[32,2048]{1,0} convert(%convert_element_type.2845), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.2870 = f32[32,2048]{1,0} add(%convert_element_type.2868, %convert_element_type.2869), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.2872 = f32[32,2048]{1,0} power(%add.2870, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2877 = f32[32]{0} reduce(%pow.2872, %constant.512), dimensions={1}, to_apply=%region_68.2876, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2878 = f32[32,1]{1,0} reshape(%reduce_sum.2877), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2879 = f32[32,1]{1,0} divide(%broadcast_in_dim.2878, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2880 = f32[32,1]{1,0} add(%div.2879, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2881 = f32[32,1]{1,0} rsqrt(%add.2880), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2882 = f32[32,1]{1,0} broadcast(%rsqrt.2881), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2883 = f32[32]{0} reshape(%mul.2882), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2884 = f32[32,2048]{1,0} broadcast(%mul.2883), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2885 = f32[32,2048]{1,0} multiply(%add.2870, %mul.2884), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2886 = bf16[32,2048]{1,0} convert(%mul.2885), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_9_input_layernorm_weight__.426 = bf16[2048]{0} parameter(425), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.9.input_layernorm.weight\']"}
  %broadcast_in_dim.2887 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_9_input_layernorm_weight__.426), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2888 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.2887), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2889 = bf16[2048]{0} reshape(%mul.2888), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2890 = bf16[32,2048]{1,0} broadcast(%mul.2889), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2891 = bf16[32,2048]{1,0} multiply(%convert_element_type.2886, %mul.2890), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_9_self_attn_qkv_proj_weight__.434 = bf16[5120,2048]{1,0} parameter(433), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.9.self_attn.qkv_proj.weight\']"}
  %dot_general.2892 = bf16[32,5120]{1,0} dot(%mul.2891, %params_and_buffers__vllm_model_language_model_model_layers_9_self_attn_qkv_proj_weight__.434), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.2893 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.2892), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.2894 = bf16[32,4,1024]{2,1,0} slice(%reshape.2893), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.2898 = bf16[32,32,128]{2,1,0} reshape(%slice.2894), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.2899 = f32[32,32,128]{2,1,0} convert(%reshape.2898), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.2900 = f32[32,32,128]{2,1,0} power(%convert_element_type.2899, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2905 = f32[32,32]{1,0} reduce(%pow.2900, %constant.512), dimensions={2}, to_apply=%region_69.2904, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2906 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.2905), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2907 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.2906, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2908 = f32[32,32,1]{2,1,0} add(%div.2907, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2909 = f32[32,32,1]{2,1,0} rsqrt(%add.2908), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2910 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.2909), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2911 = f32[32,32]{1,0} reshape(%mul.2910), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2912 = f32[32,32,128]{2,1,0} broadcast(%mul.2911), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2913 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.2899, %mul.2912), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2914 = bf16[32,32,128]{2,1,0} convert(%mul.2913), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_9_self_attn_q_norm_weight__.433 = bf16[128]{0} parameter(432), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.9.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.2915 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_9_self_attn_q_norm_weight__.433), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2916 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.2915), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2917 = bf16[128]{0} reshape(%mul.2916), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2918 = bf16[32,32,128]{2,1,0} broadcast(%mul.2917), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2919 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.2914, %mul.2918), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2950 = bf16[32,32,64]{2,1,0} slice(%mul.2919), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.2941 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.2942 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.2943 = s32[32]{0} select(%lt.2941, %add.2942, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.2944 = s32[32,1]{1,0} reshape(%select_n.2943), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.2945 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.2944), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.2946 = bf16[32,64]{1,0} slice(%gather.2945), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2948 = bf16[32,1,64]{2,1,0} reshape(%slice.2946), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2952 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2948), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2953 = bf16[32,64]{1,0} reshape(%mul.2952), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2954 = bf16[32,32,64]{2,1,0} broadcast(%mul.2953), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2955 = bf16[32,32,64]{2,1,0} multiply(%slice.2950, %mul.2954), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2951 = bf16[32,32,64]{2,1,0} slice(%mul.2919), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.2947 = bf16[32,64]{1,0} slice(%gather.2945), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2949 = bf16[32,1,64]{2,1,0} reshape(%slice.2947), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2956 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2949), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2957 = bf16[32,64]{1,0} reshape(%mul.2956), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2958 = bf16[32,32,64]{2,1,0} broadcast(%mul.2957), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2959 = bf16[32,32,64]{2,1,0} multiply(%slice.2951, %mul.2958), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.2960 = bf16[32,32,64]{2,1,0} subtract(%mul.2955, %mul.2959), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.2961 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2948), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2962 = bf16[32,64]{1,0} reshape(%mul.2961), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2963 = bf16[32,32,64]{2,1,0} broadcast(%mul.2962), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2964 = bf16[32,32,64]{2,1,0} multiply(%slice.2951, %mul.2963), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2965 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2949), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2966 = bf16[32,64]{1,0} reshape(%mul.2965), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2967 = bf16[32,32,64]{2,1,0} broadcast(%mul.2966), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2968 = bf16[32,32,64]{2,1,0} multiply(%slice.2950, %mul.2967), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.2969 = bf16[32,32,64]{2,1,0} add(%mul.2964, %mul.2968), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.2970 = bf16[32,32,128]{2,1,0} concatenate(%sub.2960, %add.2969), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.2971 = bf16[32,4096]{1,0} reshape(%concatenate.2970), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.2895 = bf16[32,4,128]{2,1,0} slice(%reshape.2893), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.2920 = f32[32,4,128]{2,1,0} convert(%slice.2895), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.2921 = f32[32,4,128]{2,1,0} power(%convert_element_type.2920, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.2926 = f32[32,4]{1,0} reduce(%pow.2921, %constant.512), dimensions={2}, to_apply=%region_70.2925, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.2927 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.2926), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.2928 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.2927, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.2929 = f32[32,4,1]{2,1,0} add(%div.2928, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.2930 = f32[32,4,1]{2,1,0} rsqrt(%add.2929), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.2931 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.2930), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2932 = f32[32,4]{1,0} reshape(%mul.2931), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2933 = f32[32,4,128]{2,1,0} broadcast(%mul.2932), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2934 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.2920, %mul.2933), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.2935 = bf16[32,4,128]{2,1,0} convert(%mul.2934), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_9_self_attn_k_norm_weight__.431 = bf16[128]{0} parameter(430), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.9.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.2936 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_9_self_attn_k_norm_weight__.431), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2937 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.2936), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2938 = bf16[128]{0} reshape(%mul.2937), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2939 = bf16[32,4,128]{2,1,0} broadcast(%mul.2938), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2940 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.2935, %mul.2939), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2974 = bf16[32,4,64]{2,1,0} slice(%mul.2940), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2972 = bf16[32,1,64]{2,1,0} reshape(%slice.2946), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2976 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2972), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2977 = bf16[32,64]{1,0} reshape(%mul.2976), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2978 = bf16[32,4,64]{2,1,0} broadcast(%mul.2977), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2979 = bf16[32,4,64]{2,1,0} multiply(%slice.2974, %mul.2978), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.2975 = bf16[32,4,64]{2,1,0} slice(%mul.2940), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.2973 = bf16[32,1,64]{2,1,0} reshape(%slice.2947), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.2980 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2973), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2981 = bf16[32,64]{1,0} reshape(%mul.2980), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2982 = bf16[32,4,64]{2,1,0} broadcast(%mul.2981), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2983 = bf16[32,4,64]{2,1,0} multiply(%slice.2975, %mul.2982), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.2984 = bf16[32,4,64]{2,1,0} subtract(%mul.2979, %mul.2983), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.2985 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2972), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2986 = bf16[32,64]{1,0} reshape(%mul.2985), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2987 = bf16[32,4,64]{2,1,0} broadcast(%mul.2986), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2988 = bf16[32,4,64]{2,1,0} multiply(%slice.2975, %mul.2987), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2989 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.2973), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2990 = bf16[32,64]{1,0} reshape(%mul.2989), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2991 = bf16[32,4,64]{2,1,0} broadcast(%mul.2990), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.2992 = bf16[32,4,64]{2,1,0} multiply(%slice.2974, %mul.2991), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.2993 = bf16[32,4,64]{2,1,0} add(%mul.2988, %mul.2992), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.2994 = bf16[32,4,128]{2,1,0} concatenate(%sub.2984, %add.2993), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.2995 = bf16[32,512]{1,0} reshape(%concatenate.2994), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.2896 = bf16[32,4,128]{2,1,0} slice(%reshape.2893), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.2897 = bf16[32,512]{1,0} reshape(%slice.2896), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.2996 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_9_.445, %reshape.2971, %reshape.2995, %reshape.2897, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.2997 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.2996), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_10_.446 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(445), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[10]"}
  %jit__jax_attn_func_.2998 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.2996), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_9_self_attn_o_proj_weight__.432 = bf16[2048,4096]{1,0} parameter(431), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.9.self_attn.o_proj.weight\']"}
  %dot_general.2999 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.2998, %params_and_buffers__vllm_model_language_model_model_layers_9_self_attn_o_proj_weight__.432), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.3000 = f32[32,2048]{1,0} convert(%dot_general.2999), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.2871 = bf16[32,2048]{1,0} convert(%add.2870), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3001 = f32[32,2048]{1,0} convert(%convert_element_type.2871), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.3002 = f32[32,2048]{1,0} add(%convert_element_type.3000, %convert_element_type.3001), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.3004 = f32[32,2048]{1,0} power(%add.3002, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3009 = f32[32]{0} reduce(%pow.3004, %constant.512), dimensions={1}, to_apply=%region_71.3008, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3010 = f32[32,1]{1,0} reshape(%reduce_sum.3009), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3011 = f32[32,1]{1,0} divide(%broadcast_in_dim.3010, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3012 = f32[32,1]{1,0} add(%div.3011, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3013 = f32[32,1]{1,0} rsqrt(%add.3012), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3014 = f32[32,1]{1,0} broadcast(%rsqrt.3013), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3015 = f32[32]{0} reshape(%mul.3014), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3016 = f32[32,2048]{1,0} broadcast(%mul.3015), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3017 = f32[32,2048]{1,0} multiply(%add.3002, %mul.3016), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3018 = bf16[32,2048]{1,0} convert(%mul.3017), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_9_post_attention_layernorm_weight__.430 = bf16[2048]{0} parameter(429), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.9.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.3019 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_9_post_attention_layernorm_weight__.430), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3020 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.3019), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3021 = bf16[2048]{0} reshape(%mul.3020), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3022 = bf16[32,2048]{1,0} broadcast(%mul.3021), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3023 = bf16[32,2048]{1,0} multiply(%convert_element_type.3018, %mul.3022), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_9_mlp_experts_w13_weight__.427 = bf16[128,1536,2048]{2,1,0} parameter(426), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.9.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_9_mlp_experts_w2_weight__.428 = bf16[128,2048,768]{2,1,0} parameter(427), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.9.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_9_mlp_gate_weight__.429 = bf16[128,2048]{1,0} parameter(428), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.9.mlp.gate.weight\']"}
  %dot_general.3024 = bf16[32,128]{1,0} dot(%mul.3023, %params_and_buffers__vllm_model_language_model_model_layers_9_mlp_gate_weight__.429), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.3025 = bf16[32,2048]{1,0} call(%mul.3023, %params_and_buffers__vllm_model_language_model_model_layers_9_mlp_experts_w13_weight__.427, %params_and_buffers__vllm_model_language_model_model_layers_9_mlp_experts_w2_weight__.428, %dot_general.3024), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.3026 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.3025), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3003 = bf16[32,2048]{1,0} convert(%add.3002), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3027 = f32[32,2048]{1,0} convert(%convert_element_type.3003), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.3028 = f32[32,2048]{1,0} add(%convert_element_type.3026, %convert_element_type.3027), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.3030 = f32[32,2048]{1,0} power(%add.3028, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3035 = f32[32]{0} reduce(%pow.3030, %constant.512), dimensions={1}, to_apply=%region_72.3034, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3036 = f32[32,1]{1,0} reshape(%reduce_sum.3035), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3037 = f32[32,1]{1,0} divide(%broadcast_in_dim.3036, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3038 = f32[32,1]{1,0} add(%div.3037, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3039 = f32[32,1]{1,0} rsqrt(%add.3038), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3040 = f32[32,1]{1,0} broadcast(%rsqrt.3039), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3041 = f32[32]{0} reshape(%mul.3040), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3042 = f32[32,2048]{1,0} broadcast(%mul.3041), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3043 = f32[32,2048]{1,0} multiply(%add.3028, %mul.3042), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3044 = bf16[32,2048]{1,0} convert(%mul.3043), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_10_input_layernorm_weight__.21 = bf16[2048]{0} parameter(20), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.10.input_layernorm.weight\']"}
  %broadcast_in_dim.3045 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_10_input_layernorm_weight__.21), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3046 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.3045), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3047 = bf16[2048]{0} reshape(%mul.3046), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3048 = bf16[32,2048]{1,0} broadcast(%mul.3047), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3049 = bf16[32,2048]{1,0} multiply(%convert_element_type.3044, %mul.3048), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_10_self_attn_qkv_proj_weight__.29 = bf16[5120,2048]{1,0} parameter(28), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.10.self_attn.qkv_proj.weight\']"}
  %dot_general.3050 = bf16[32,5120]{1,0} dot(%mul.3049, %params_and_buffers__vllm_model_language_model_model_layers_10_self_attn_qkv_proj_weight__.29), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.3051 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.3050), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.3052 = bf16[32,4,1024]{2,1,0} slice(%reshape.3051), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.3056 = bf16[32,32,128]{2,1,0} reshape(%slice.3052), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.3057 = f32[32,32,128]{2,1,0} convert(%reshape.3056), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.3058 = f32[32,32,128]{2,1,0} power(%convert_element_type.3057, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3063 = f32[32,32]{1,0} reduce(%pow.3058, %constant.512), dimensions={2}, to_apply=%region_73.3062, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3064 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.3063), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3065 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.3064, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3066 = f32[32,32,1]{2,1,0} add(%div.3065, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3067 = f32[32,32,1]{2,1,0} rsqrt(%add.3066), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3068 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.3067), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3069 = f32[32,32]{1,0} reshape(%mul.3068), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3070 = f32[32,32,128]{2,1,0} broadcast(%mul.3069), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3071 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.3057, %mul.3070), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3072 = bf16[32,32,128]{2,1,0} convert(%mul.3071), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_10_self_attn_q_norm_weight__.28 = bf16[128]{0} parameter(27), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.10.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.3073 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_10_self_attn_q_norm_weight__.28), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3074 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.3073), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3075 = bf16[128]{0} reshape(%mul.3074), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3076 = bf16[32,32,128]{2,1,0} broadcast(%mul.3075), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3077 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.3072, %mul.3076), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3108 = bf16[32,32,64]{2,1,0} slice(%mul.3077), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.3099 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.3100 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.3101 = s32[32]{0} select(%lt.3099, %add.3100, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.3102 = s32[32,1]{1,0} reshape(%select_n.3101), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.3103 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.3102), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.3104 = bf16[32,64]{1,0} slice(%gather.3103), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3106 = bf16[32,1,64]{2,1,0} reshape(%slice.3104), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3110 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3106), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3111 = bf16[32,64]{1,0} reshape(%mul.3110), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3112 = bf16[32,32,64]{2,1,0} broadcast(%mul.3111), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3113 = bf16[32,32,64]{2,1,0} multiply(%slice.3108, %mul.3112), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3109 = bf16[32,32,64]{2,1,0} slice(%mul.3077), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.3105 = bf16[32,64]{1,0} slice(%gather.3103), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3107 = bf16[32,1,64]{2,1,0} reshape(%slice.3105), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3114 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3107), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3115 = bf16[32,64]{1,0} reshape(%mul.3114), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3116 = bf16[32,32,64]{2,1,0} broadcast(%mul.3115), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3117 = bf16[32,32,64]{2,1,0} multiply(%slice.3109, %mul.3116), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.3118 = bf16[32,32,64]{2,1,0} subtract(%mul.3113, %mul.3117), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.3119 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3106), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3120 = bf16[32,64]{1,0} reshape(%mul.3119), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3121 = bf16[32,32,64]{2,1,0} broadcast(%mul.3120), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3122 = bf16[32,32,64]{2,1,0} multiply(%slice.3109, %mul.3121), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3123 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3107), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3124 = bf16[32,64]{1,0} reshape(%mul.3123), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3125 = bf16[32,32,64]{2,1,0} broadcast(%mul.3124), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3126 = bf16[32,32,64]{2,1,0} multiply(%slice.3108, %mul.3125), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.3127 = bf16[32,32,64]{2,1,0} add(%mul.3122, %mul.3126), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.3128 = bf16[32,32,128]{2,1,0} concatenate(%sub.3118, %add.3127), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.3129 = bf16[32,4096]{1,0} reshape(%concatenate.3128), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.3053 = bf16[32,4,128]{2,1,0} slice(%reshape.3051), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.3078 = f32[32,4,128]{2,1,0} convert(%slice.3053), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.3079 = f32[32,4,128]{2,1,0} power(%convert_element_type.3078, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3084 = f32[32,4]{1,0} reduce(%pow.3079, %constant.512), dimensions={2}, to_apply=%region_74.3083, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3085 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.3084), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3086 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.3085, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3087 = f32[32,4,1]{2,1,0} add(%div.3086, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3088 = f32[32,4,1]{2,1,0} rsqrt(%add.3087), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3089 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.3088), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3090 = f32[32,4]{1,0} reshape(%mul.3089), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3091 = f32[32,4,128]{2,1,0} broadcast(%mul.3090), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3092 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.3078, %mul.3091), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3093 = bf16[32,4,128]{2,1,0} convert(%mul.3092), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_10_self_attn_k_norm_weight__.26 = bf16[128]{0} parameter(25), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.10.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.3094 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_10_self_attn_k_norm_weight__.26), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3095 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.3094), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3096 = bf16[128]{0} reshape(%mul.3095), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3097 = bf16[32,4,128]{2,1,0} broadcast(%mul.3096), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3098 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.3093, %mul.3097), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3132 = bf16[32,4,64]{2,1,0} slice(%mul.3098), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3130 = bf16[32,1,64]{2,1,0} reshape(%slice.3104), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3134 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3130), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3135 = bf16[32,64]{1,0} reshape(%mul.3134), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3136 = bf16[32,4,64]{2,1,0} broadcast(%mul.3135), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3137 = bf16[32,4,64]{2,1,0} multiply(%slice.3132, %mul.3136), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3133 = bf16[32,4,64]{2,1,0} slice(%mul.3098), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3131 = bf16[32,1,64]{2,1,0} reshape(%slice.3105), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3138 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3131), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3139 = bf16[32,64]{1,0} reshape(%mul.3138), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3140 = bf16[32,4,64]{2,1,0} broadcast(%mul.3139), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3141 = bf16[32,4,64]{2,1,0} multiply(%slice.3133, %mul.3140), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.3142 = bf16[32,4,64]{2,1,0} subtract(%mul.3137, %mul.3141), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.3143 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3130), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3144 = bf16[32,64]{1,0} reshape(%mul.3143), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3145 = bf16[32,4,64]{2,1,0} broadcast(%mul.3144), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3146 = bf16[32,4,64]{2,1,0} multiply(%slice.3133, %mul.3145), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3147 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3131), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3148 = bf16[32,64]{1,0} reshape(%mul.3147), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3149 = bf16[32,4,64]{2,1,0} broadcast(%mul.3148), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3150 = bf16[32,4,64]{2,1,0} multiply(%slice.3132, %mul.3149), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.3151 = bf16[32,4,64]{2,1,0} add(%mul.3146, %mul.3150), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.3152 = bf16[32,4,128]{2,1,0} concatenate(%sub.3142, %add.3151), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.3153 = bf16[32,512]{1,0} reshape(%concatenate.3152), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.3054 = bf16[32,4,128]{2,1,0} slice(%reshape.3051), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.3055 = bf16[32,512]{1,0} reshape(%slice.3054), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.3154 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_10_.446, %reshape.3129, %reshape.3153, %reshape.3055, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.3155 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.3154), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_11_.447 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(446), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[11]"}
  %jit__jax_attn_func_.3156 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.3154), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_10_self_attn_o_proj_weight__.27 = bf16[2048,4096]{1,0} parameter(26), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.10.self_attn.o_proj.weight\']"}
  %dot_general.3157 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.3156, %params_and_buffers__vllm_model_language_model_model_layers_10_self_attn_o_proj_weight__.27), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.3158 = f32[32,2048]{1,0} convert(%dot_general.3157), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3029 = bf16[32,2048]{1,0} convert(%add.3028), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3159 = f32[32,2048]{1,0} convert(%convert_element_type.3029), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.3160 = f32[32,2048]{1,0} add(%convert_element_type.3158, %convert_element_type.3159), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.3162 = f32[32,2048]{1,0} power(%add.3160, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3167 = f32[32]{0} reduce(%pow.3162, %constant.512), dimensions={1}, to_apply=%region_75.3166, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3168 = f32[32,1]{1,0} reshape(%reduce_sum.3167), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3169 = f32[32,1]{1,0} divide(%broadcast_in_dim.3168, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3170 = f32[32,1]{1,0} add(%div.3169, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3171 = f32[32,1]{1,0} rsqrt(%add.3170), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3172 = f32[32,1]{1,0} broadcast(%rsqrt.3171), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3173 = f32[32]{0} reshape(%mul.3172), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3174 = f32[32,2048]{1,0} broadcast(%mul.3173), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3175 = f32[32,2048]{1,0} multiply(%add.3160, %mul.3174), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3176 = bf16[32,2048]{1,0} convert(%mul.3175), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_10_post_attention_layernorm_weight__.25 = bf16[2048]{0} parameter(24), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.10.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.3177 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_10_post_attention_layernorm_weight__.25), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3178 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.3177), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3179 = bf16[2048]{0} reshape(%mul.3178), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3180 = bf16[32,2048]{1,0} broadcast(%mul.3179), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3181 = bf16[32,2048]{1,0} multiply(%convert_element_type.3176, %mul.3180), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_10_mlp_experts_w13_weight__.22 = bf16[128,1536,2048]{2,1,0} parameter(21), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.10.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_10_mlp_experts_w2_weight__.23 = bf16[128,2048,768]{2,1,0} parameter(22), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.10.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_10_mlp_gate_weight__.24 = bf16[128,2048]{1,0} parameter(23), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.10.mlp.gate.weight\']"}
  %dot_general.3182 = bf16[32,128]{1,0} dot(%mul.3181, %params_and_buffers__vllm_model_language_model_model_layers_10_mlp_gate_weight__.24), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.3183 = bf16[32,2048]{1,0} call(%mul.3181, %params_and_buffers__vllm_model_language_model_model_layers_10_mlp_experts_w13_weight__.22, %params_and_buffers__vllm_model_language_model_model_layers_10_mlp_experts_w2_weight__.23, %dot_general.3182), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.3184 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.3183), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3161 = bf16[32,2048]{1,0} convert(%add.3160), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3185 = f32[32,2048]{1,0} convert(%convert_element_type.3161), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.3186 = f32[32,2048]{1,0} add(%convert_element_type.3184, %convert_element_type.3185), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.3188 = f32[32,2048]{1,0} power(%add.3186, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3193 = f32[32]{0} reduce(%pow.3188, %constant.512), dimensions={1}, to_apply=%region_76.3192, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3194 = f32[32,1]{1,0} reshape(%reduce_sum.3193), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3195 = f32[32,1]{1,0} divide(%broadcast_in_dim.3194, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3196 = f32[32,1]{1,0} add(%div.3195, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3197 = f32[32,1]{1,0} rsqrt(%add.3196), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3198 = f32[32,1]{1,0} broadcast(%rsqrt.3197), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3199 = f32[32]{0} reshape(%mul.3198), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3200 = f32[32,2048]{1,0} broadcast(%mul.3199), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3201 = f32[32,2048]{1,0} multiply(%add.3186, %mul.3200), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3202 = bf16[32,2048]{1,0} convert(%mul.3201), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_11_input_layernorm_weight__.30 = bf16[2048]{0} parameter(29), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.11.input_layernorm.weight\']"}
  %broadcast_in_dim.3203 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_11_input_layernorm_weight__.30), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3204 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.3203), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3205 = bf16[2048]{0} reshape(%mul.3204), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3206 = bf16[32,2048]{1,0} broadcast(%mul.3205), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3207 = bf16[32,2048]{1,0} multiply(%convert_element_type.3202, %mul.3206), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_11_self_attn_qkv_proj_weight__.38 = bf16[5120,2048]{1,0} parameter(37), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.11.self_attn.qkv_proj.weight\']"}
  %dot_general.3208 = bf16[32,5120]{1,0} dot(%mul.3207, %params_and_buffers__vllm_model_language_model_model_layers_11_self_attn_qkv_proj_weight__.38), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.3209 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.3208), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.3210 = bf16[32,4,1024]{2,1,0} slice(%reshape.3209), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.3214 = bf16[32,32,128]{2,1,0} reshape(%slice.3210), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.3215 = f32[32,32,128]{2,1,0} convert(%reshape.3214), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.3216 = f32[32,32,128]{2,1,0} power(%convert_element_type.3215, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3221 = f32[32,32]{1,0} reduce(%pow.3216, %constant.512), dimensions={2}, to_apply=%region_77.3220, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3222 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.3221), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3223 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.3222, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3224 = f32[32,32,1]{2,1,0} add(%div.3223, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3225 = f32[32,32,1]{2,1,0} rsqrt(%add.3224), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3226 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.3225), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3227 = f32[32,32]{1,0} reshape(%mul.3226), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3228 = f32[32,32,128]{2,1,0} broadcast(%mul.3227), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3229 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.3215, %mul.3228), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3230 = bf16[32,32,128]{2,1,0} convert(%mul.3229), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_11_self_attn_q_norm_weight__.37 = bf16[128]{0} parameter(36), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.11.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.3231 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_11_self_attn_q_norm_weight__.37), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3232 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.3231), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3233 = bf16[128]{0} reshape(%mul.3232), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3234 = bf16[32,32,128]{2,1,0} broadcast(%mul.3233), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3235 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.3230, %mul.3234), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3266 = bf16[32,32,64]{2,1,0} slice(%mul.3235), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.3257 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.3258 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.3259 = s32[32]{0} select(%lt.3257, %add.3258, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.3260 = s32[32,1]{1,0} reshape(%select_n.3259), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.3261 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.3260), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.3262 = bf16[32,64]{1,0} slice(%gather.3261), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3264 = bf16[32,1,64]{2,1,0} reshape(%slice.3262), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3268 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3264), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3269 = bf16[32,64]{1,0} reshape(%mul.3268), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3270 = bf16[32,32,64]{2,1,0} broadcast(%mul.3269), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3271 = bf16[32,32,64]{2,1,0} multiply(%slice.3266, %mul.3270), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3267 = bf16[32,32,64]{2,1,0} slice(%mul.3235), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.3263 = bf16[32,64]{1,0} slice(%gather.3261), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3265 = bf16[32,1,64]{2,1,0} reshape(%slice.3263), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3272 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3265), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3273 = bf16[32,64]{1,0} reshape(%mul.3272), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3274 = bf16[32,32,64]{2,1,0} broadcast(%mul.3273), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3275 = bf16[32,32,64]{2,1,0} multiply(%slice.3267, %mul.3274), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.3276 = bf16[32,32,64]{2,1,0} subtract(%mul.3271, %mul.3275), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.3277 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3264), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3278 = bf16[32,64]{1,0} reshape(%mul.3277), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3279 = bf16[32,32,64]{2,1,0} broadcast(%mul.3278), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3280 = bf16[32,32,64]{2,1,0} multiply(%slice.3267, %mul.3279), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3281 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3265), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3282 = bf16[32,64]{1,0} reshape(%mul.3281), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3283 = bf16[32,32,64]{2,1,0} broadcast(%mul.3282), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3284 = bf16[32,32,64]{2,1,0} multiply(%slice.3266, %mul.3283), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.3285 = bf16[32,32,64]{2,1,0} add(%mul.3280, %mul.3284), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.3286 = bf16[32,32,128]{2,1,0} concatenate(%sub.3276, %add.3285), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.3287 = bf16[32,4096]{1,0} reshape(%concatenate.3286), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.3211 = bf16[32,4,128]{2,1,0} slice(%reshape.3209), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.3236 = f32[32,4,128]{2,1,0} convert(%slice.3211), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.3237 = f32[32,4,128]{2,1,0} power(%convert_element_type.3236, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3242 = f32[32,4]{1,0} reduce(%pow.3237, %constant.512), dimensions={2}, to_apply=%region_78.3241, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3243 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.3242), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3244 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.3243, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3245 = f32[32,4,1]{2,1,0} add(%div.3244, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3246 = f32[32,4,1]{2,1,0} rsqrt(%add.3245), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3247 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.3246), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3248 = f32[32,4]{1,0} reshape(%mul.3247), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3249 = f32[32,4,128]{2,1,0} broadcast(%mul.3248), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3250 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.3236, %mul.3249), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3251 = bf16[32,4,128]{2,1,0} convert(%mul.3250), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_11_self_attn_k_norm_weight__.35 = bf16[128]{0} parameter(34), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.11.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.3252 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_11_self_attn_k_norm_weight__.35), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3253 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.3252), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3254 = bf16[128]{0} reshape(%mul.3253), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3255 = bf16[32,4,128]{2,1,0} broadcast(%mul.3254), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3256 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.3251, %mul.3255), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3290 = bf16[32,4,64]{2,1,0} slice(%mul.3256), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3288 = bf16[32,1,64]{2,1,0} reshape(%slice.3262), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3292 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3288), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3293 = bf16[32,64]{1,0} reshape(%mul.3292), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3294 = bf16[32,4,64]{2,1,0} broadcast(%mul.3293), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3295 = bf16[32,4,64]{2,1,0} multiply(%slice.3290, %mul.3294), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3291 = bf16[32,4,64]{2,1,0} slice(%mul.3256), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3289 = bf16[32,1,64]{2,1,0} reshape(%slice.3263), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3296 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3289), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3297 = bf16[32,64]{1,0} reshape(%mul.3296), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3298 = bf16[32,4,64]{2,1,0} broadcast(%mul.3297), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3299 = bf16[32,4,64]{2,1,0} multiply(%slice.3291, %mul.3298), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.3300 = bf16[32,4,64]{2,1,0} subtract(%mul.3295, %mul.3299), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.3301 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3288), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3302 = bf16[32,64]{1,0} reshape(%mul.3301), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3303 = bf16[32,4,64]{2,1,0} broadcast(%mul.3302), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3304 = bf16[32,4,64]{2,1,0} multiply(%slice.3291, %mul.3303), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3305 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3289), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3306 = bf16[32,64]{1,0} reshape(%mul.3305), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3307 = bf16[32,4,64]{2,1,0} broadcast(%mul.3306), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3308 = bf16[32,4,64]{2,1,0} multiply(%slice.3290, %mul.3307), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.3309 = bf16[32,4,64]{2,1,0} add(%mul.3304, %mul.3308), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.3310 = bf16[32,4,128]{2,1,0} concatenate(%sub.3300, %add.3309), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.3311 = bf16[32,512]{1,0} reshape(%concatenate.3310), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.3212 = bf16[32,4,128]{2,1,0} slice(%reshape.3209), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.3213 = bf16[32,512]{1,0} reshape(%slice.3212), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.3312 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_11_.447, %reshape.3287, %reshape.3311, %reshape.3213, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.3313 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.3312), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_12_.448 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(447), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[12]"}
  %jit__jax_attn_func_.3314 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.3312), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_11_self_attn_o_proj_weight__.36 = bf16[2048,4096]{1,0} parameter(35), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.11.self_attn.o_proj.weight\']"}
  %dot_general.3315 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.3314, %params_and_buffers__vllm_model_language_model_model_layers_11_self_attn_o_proj_weight__.36), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.3316 = f32[32,2048]{1,0} convert(%dot_general.3315), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3187 = bf16[32,2048]{1,0} convert(%add.3186), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3317 = f32[32,2048]{1,0} convert(%convert_element_type.3187), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.3318 = f32[32,2048]{1,0} add(%convert_element_type.3316, %convert_element_type.3317), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.3320 = f32[32,2048]{1,0} power(%add.3318, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3325 = f32[32]{0} reduce(%pow.3320, %constant.512), dimensions={1}, to_apply=%region_79.3324, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3326 = f32[32,1]{1,0} reshape(%reduce_sum.3325), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3327 = f32[32,1]{1,0} divide(%broadcast_in_dim.3326, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3328 = f32[32,1]{1,0} add(%div.3327, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3329 = f32[32,1]{1,0} rsqrt(%add.3328), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3330 = f32[32,1]{1,0} broadcast(%rsqrt.3329), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3331 = f32[32]{0} reshape(%mul.3330), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3332 = f32[32,2048]{1,0} broadcast(%mul.3331), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3333 = f32[32,2048]{1,0} multiply(%add.3318, %mul.3332), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3334 = bf16[32,2048]{1,0} convert(%mul.3333), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_11_post_attention_layernorm_weight__.34 = bf16[2048]{0} parameter(33), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.11.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.3335 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_11_post_attention_layernorm_weight__.34), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3336 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.3335), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3337 = bf16[2048]{0} reshape(%mul.3336), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3338 = bf16[32,2048]{1,0} broadcast(%mul.3337), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3339 = bf16[32,2048]{1,0} multiply(%convert_element_type.3334, %mul.3338), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_11_mlp_experts_w13_weight__.31 = bf16[128,1536,2048]{2,1,0} parameter(30), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.11.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_11_mlp_experts_w2_weight__.32 = bf16[128,2048,768]{2,1,0} parameter(31), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.11.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_11_mlp_gate_weight__.33 = bf16[128,2048]{1,0} parameter(32), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.11.mlp.gate.weight\']"}
  %dot_general.3340 = bf16[32,128]{1,0} dot(%mul.3339, %params_and_buffers__vllm_model_language_model_model_layers_11_mlp_gate_weight__.33), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.3341 = bf16[32,2048]{1,0} call(%mul.3339, %params_and_buffers__vllm_model_language_model_model_layers_11_mlp_experts_w13_weight__.31, %params_and_buffers__vllm_model_language_model_model_layers_11_mlp_experts_w2_weight__.32, %dot_general.3340), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.3342 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.3341), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3319 = bf16[32,2048]{1,0} convert(%add.3318), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3343 = f32[32,2048]{1,0} convert(%convert_element_type.3319), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.3344 = f32[32,2048]{1,0} add(%convert_element_type.3342, %convert_element_type.3343), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.3346 = f32[32,2048]{1,0} power(%add.3344, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3351 = f32[32]{0} reduce(%pow.3346, %constant.512), dimensions={1}, to_apply=%region_80.3350, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3352 = f32[32,1]{1,0} reshape(%reduce_sum.3351), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3353 = f32[32,1]{1,0} divide(%broadcast_in_dim.3352, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3354 = f32[32,1]{1,0} add(%div.3353, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3355 = f32[32,1]{1,0} rsqrt(%add.3354), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3356 = f32[32,1]{1,0} broadcast(%rsqrt.3355), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3357 = f32[32]{0} reshape(%mul.3356), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3358 = f32[32,2048]{1,0} broadcast(%mul.3357), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3359 = f32[32,2048]{1,0} multiply(%add.3344, %mul.3358), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3360 = bf16[32,2048]{1,0} convert(%mul.3359), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_12_input_layernorm_weight__.39 = bf16[2048]{0} parameter(38), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.12.input_layernorm.weight\']"}
  %broadcast_in_dim.3361 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_12_input_layernorm_weight__.39), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3362 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.3361), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3363 = bf16[2048]{0} reshape(%mul.3362), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3364 = bf16[32,2048]{1,0} broadcast(%mul.3363), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3365 = bf16[32,2048]{1,0} multiply(%convert_element_type.3360, %mul.3364), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_12_self_attn_qkv_proj_weight__.47 = bf16[5120,2048]{1,0} parameter(46), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.12.self_attn.qkv_proj.weight\']"}
  %dot_general.3366 = bf16[32,5120]{1,0} dot(%mul.3365, %params_and_buffers__vllm_model_language_model_model_layers_12_self_attn_qkv_proj_weight__.47), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.3367 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.3366), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.3368 = bf16[32,4,1024]{2,1,0} slice(%reshape.3367), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.3372 = bf16[32,32,128]{2,1,0} reshape(%slice.3368), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.3373 = f32[32,32,128]{2,1,0} convert(%reshape.3372), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.3374 = f32[32,32,128]{2,1,0} power(%convert_element_type.3373, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3379 = f32[32,32]{1,0} reduce(%pow.3374, %constant.512), dimensions={2}, to_apply=%region_81.3378, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3380 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.3379), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3381 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.3380, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3382 = f32[32,32,1]{2,1,0} add(%div.3381, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3383 = f32[32,32,1]{2,1,0} rsqrt(%add.3382), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3384 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.3383), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3385 = f32[32,32]{1,0} reshape(%mul.3384), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3386 = f32[32,32,128]{2,1,0} broadcast(%mul.3385), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3387 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.3373, %mul.3386), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3388 = bf16[32,32,128]{2,1,0} convert(%mul.3387), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_12_self_attn_q_norm_weight__.46 = bf16[128]{0} parameter(45), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.12.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.3389 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_12_self_attn_q_norm_weight__.46), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3390 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.3389), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3391 = bf16[128]{0} reshape(%mul.3390), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3392 = bf16[32,32,128]{2,1,0} broadcast(%mul.3391), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3393 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.3388, %mul.3392), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3424 = bf16[32,32,64]{2,1,0} slice(%mul.3393), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.3415 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.3416 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.3417 = s32[32]{0} select(%lt.3415, %add.3416, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.3418 = s32[32,1]{1,0} reshape(%select_n.3417), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.3419 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.3418), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.3420 = bf16[32,64]{1,0} slice(%gather.3419), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3422 = bf16[32,1,64]{2,1,0} reshape(%slice.3420), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3426 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3422), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3427 = bf16[32,64]{1,0} reshape(%mul.3426), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3428 = bf16[32,32,64]{2,1,0} broadcast(%mul.3427), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3429 = bf16[32,32,64]{2,1,0} multiply(%slice.3424, %mul.3428), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3425 = bf16[32,32,64]{2,1,0} slice(%mul.3393), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.3421 = bf16[32,64]{1,0} slice(%gather.3419), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3423 = bf16[32,1,64]{2,1,0} reshape(%slice.3421), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3430 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3423), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3431 = bf16[32,64]{1,0} reshape(%mul.3430), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3432 = bf16[32,32,64]{2,1,0} broadcast(%mul.3431), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3433 = bf16[32,32,64]{2,1,0} multiply(%slice.3425, %mul.3432), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.3434 = bf16[32,32,64]{2,1,0} subtract(%mul.3429, %mul.3433), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.3435 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3422), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3436 = bf16[32,64]{1,0} reshape(%mul.3435), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3437 = bf16[32,32,64]{2,1,0} broadcast(%mul.3436), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3438 = bf16[32,32,64]{2,1,0} multiply(%slice.3425, %mul.3437), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3439 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3423), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3440 = bf16[32,64]{1,0} reshape(%mul.3439), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3441 = bf16[32,32,64]{2,1,0} broadcast(%mul.3440), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3442 = bf16[32,32,64]{2,1,0} multiply(%slice.3424, %mul.3441), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.3443 = bf16[32,32,64]{2,1,0} add(%mul.3438, %mul.3442), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.3444 = bf16[32,32,128]{2,1,0} concatenate(%sub.3434, %add.3443), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.3445 = bf16[32,4096]{1,0} reshape(%concatenate.3444), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.3369 = bf16[32,4,128]{2,1,0} slice(%reshape.3367), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.3394 = f32[32,4,128]{2,1,0} convert(%slice.3369), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.3395 = f32[32,4,128]{2,1,0} power(%convert_element_type.3394, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3400 = f32[32,4]{1,0} reduce(%pow.3395, %constant.512), dimensions={2}, to_apply=%region_82.3399, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3401 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.3400), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3402 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.3401, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3403 = f32[32,4,1]{2,1,0} add(%div.3402, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3404 = f32[32,4,1]{2,1,0} rsqrt(%add.3403), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3405 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.3404), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3406 = f32[32,4]{1,0} reshape(%mul.3405), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3407 = f32[32,4,128]{2,1,0} broadcast(%mul.3406), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3408 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.3394, %mul.3407), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3409 = bf16[32,4,128]{2,1,0} convert(%mul.3408), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_12_self_attn_k_norm_weight__.44 = bf16[128]{0} parameter(43), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.12.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.3410 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_12_self_attn_k_norm_weight__.44), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3411 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.3410), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3412 = bf16[128]{0} reshape(%mul.3411), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3413 = bf16[32,4,128]{2,1,0} broadcast(%mul.3412), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3414 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.3409, %mul.3413), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3448 = bf16[32,4,64]{2,1,0} slice(%mul.3414), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3446 = bf16[32,1,64]{2,1,0} reshape(%slice.3420), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3450 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3446), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3451 = bf16[32,64]{1,0} reshape(%mul.3450), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3452 = bf16[32,4,64]{2,1,0} broadcast(%mul.3451), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3453 = bf16[32,4,64]{2,1,0} multiply(%slice.3448, %mul.3452), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3449 = bf16[32,4,64]{2,1,0} slice(%mul.3414), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3447 = bf16[32,1,64]{2,1,0} reshape(%slice.3421), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3454 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3447), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3455 = bf16[32,64]{1,0} reshape(%mul.3454), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3456 = bf16[32,4,64]{2,1,0} broadcast(%mul.3455), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3457 = bf16[32,4,64]{2,1,0} multiply(%slice.3449, %mul.3456), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.3458 = bf16[32,4,64]{2,1,0} subtract(%mul.3453, %mul.3457), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.3459 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3446), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3460 = bf16[32,64]{1,0} reshape(%mul.3459), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3461 = bf16[32,4,64]{2,1,0} broadcast(%mul.3460), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3462 = bf16[32,4,64]{2,1,0} multiply(%slice.3449, %mul.3461), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3463 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3447), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3464 = bf16[32,64]{1,0} reshape(%mul.3463), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3465 = bf16[32,4,64]{2,1,0} broadcast(%mul.3464), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3466 = bf16[32,4,64]{2,1,0} multiply(%slice.3448, %mul.3465), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.3467 = bf16[32,4,64]{2,1,0} add(%mul.3462, %mul.3466), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.3468 = bf16[32,4,128]{2,1,0} concatenate(%sub.3458, %add.3467), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.3469 = bf16[32,512]{1,0} reshape(%concatenate.3468), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.3370 = bf16[32,4,128]{2,1,0} slice(%reshape.3367), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.3371 = bf16[32,512]{1,0} reshape(%slice.3370), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.3470 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_12_.448, %reshape.3445, %reshape.3469, %reshape.3371, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.3471 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.3470), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_13_.449 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(448), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[13]"}
  %jit__jax_attn_func_.3472 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.3470), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_12_self_attn_o_proj_weight__.45 = bf16[2048,4096]{1,0} parameter(44), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.12.self_attn.o_proj.weight\']"}
  %dot_general.3473 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.3472, %params_and_buffers__vllm_model_language_model_model_layers_12_self_attn_o_proj_weight__.45), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.3474 = f32[32,2048]{1,0} convert(%dot_general.3473), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3345 = bf16[32,2048]{1,0} convert(%add.3344), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3475 = f32[32,2048]{1,0} convert(%convert_element_type.3345), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.3476 = f32[32,2048]{1,0} add(%convert_element_type.3474, %convert_element_type.3475), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.3478 = f32[32,2048]{1,0} power(%add.3476, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3483 = f32[32]{0} reduce(%pow.3478, %constant.512), dimensions={1}, to_apply=%region_83.3482, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3484 = f32[32,1]{1,0} reshape(%reduce_sum.3483), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3485 = f32[32,1]{1,0} divide(%broadcast_in_dim.3484, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3486 = f32[32,1]{1,0} add(%div.3485, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3487 = f32[32,1]{1,0} rsqrt(%add.3486), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3488 = f32[32,1]{1,0} broadcast(%rsqrt.3487), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3489 = f32[32]{0} reshape(%mul.3488), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3490 = f32[32,2048]{1,0} broadcast(%mul.3489), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3491 = f32[32,2048]{1,0} multiply(%add.3476, %mul.3490), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3492 = bf16[32,2048]{1,0} convert(%mul.3491), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_12_post_attention_layernorm_weight__.43 = bf16[2048]{0} parameter(42), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.12.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.3493 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_12_post_attention_layernorm_weight__.43), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3494 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.3493), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3495 = bf16[2048]{0} reshape(%mul.3494), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3496 = bf16[32,2048]{1,0} broadcast(%mul.3495), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3497 = bf16[32,2048]{1,0} multiply(%convert_element_type.3492, %mul.3496), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_12_mlp_experts_w13_weight__.40 = bf16[128,1536,2048]{2,1,0} parameter(39), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.12.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_12_mlp_experts_w2_weight__.41 = bf16[128,2048,768]{2,1,0} parameter(40), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.12.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_12_mlp_gate_weight__.42 = bf16[128,2048]{1,0} parameter(41), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.12.mlp.gate.weight\']"}
  %dot_general.3498 = bf16[32,128]{1,0} dot(%mul.3497, %params_and_buffers__vllm_model_language_model_model_layers_12_mlp_gate_weight__.42), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.3499 = bf16[32,2048]{1,0} call(%mul.3497, %params_and_buffers__vllm_model_language_model_model_layers_12_mlp_experts_w13_weight__.40, %params_and_buffers__vllm_model_language_model_model_layers_12_mlp_experts_w2_weight__.41, %dot_general.3498), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.3500 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.3499), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3477 = bf16[32,2048]{1,0} convert(%add.3476), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3501 = f32[32,2048]{1,0} convert(%convert_element_type.3477), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.3502 = f32[32,2048]{1,0} add(%convert_element_type.3500, %convert_element_type.3501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.3504 = f32[32,2048]{1,0} power(%add.3502, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3509 = f32[32]{0} reduce(%pow.3504, %constant.512), dimensions={1}, to_apply=%region_84.3508, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3510 = f32[32,1]{1,0} reshape(%reduce_sum.3509), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3511 = f32[32,1]{1,0} divide(%broadcast_in_dim.3510, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3512 = f32[32,1]{1,0} add(%div.3511, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3513 = f32[32,1]{1,0} rsqrt(%add.3512), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3514 = f32[32,1]{1,0} broadcast(%rsqrt.3513), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3515 = f32[32]{0} reshape(%mul.3514), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3516 = f32[32,2048]{1,0} broadcast(%mul.3515), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3517 = f32[32,2048]{1,0} multiply(%add.3502, %mul.3516), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3518 = bf16[32,2048]{1,0} convert(%mul.3517), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_13_input_layernorm_weight__.48 = bf16[2048]{0} parameter(47), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.13.input_layernorm.weight\']"}
  %broadcast_in_dim.3519 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_13_input_layernorm_weight__.48), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3520 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.3519), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3521 = bf16[2048]{0} reshape(%mul.3520), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3522 = bf16[32,2048]{1,0} broadcast(%mul.3521), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3523 = bf16[32,2048]{1,0} multiply(%convert_element_type.3518, %mul.3522), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_13_self_attn_qkv_proj_weight__.56 = bf16[5120,2048]{1,0} parameter(55), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.13.self_attn.qkv_proj.weight\']"}
  %dot_general.3524 = bf16[32,5120]{1,0} dot(%mul.3523, %params_and_buffers__vllm_model_language_model_model_layers_13_self_attn_qkv_proj_weight__.56), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.3525 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.3524), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.3526 = bf16[32,4,1024]{2,1,0} slice(%reshape.3525), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.3530 = bf16[32,32,128]{2,1,0} reshape(%slice.3526), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.3531 = f32[32,32,128]{2,1,0} convert(%reshape.3530), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.3532 = f32[32,32,128]{2,1,0} power(%convert_element_type.3531, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3537 = f32[32,32]{1,0} reduce(%pow.3532, %constant.512), dimensions={2}, to_apply=%region_85.3536, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3538 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.3537), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3539 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.3538, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3540 = f32[32,32,1]{2,1,0} add(%div.3539, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3541 = f32[32,32,1]{2,1,0} rsqrt(%add.3540), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3542 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.3541), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3543 = f32[32,32]{1,0} reshape(%mul.3542), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3544 = f32[32,32,128]{2,1,0} broadcast(%mul.3543), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3545 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.3531, %mul.3544), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3546 = bf16[32,32,128]{2,1,0} convert(%mul.3545), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_13_self_attn_q_norm_weight__.55 = bf16[128]{0} parameter(54), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.13.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.3547 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_13_self_attn_q_norm_weight__.55), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3548 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.3547), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3549 = bf16[128]{0} reshape(%mul.3548), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3550 = bf16[32,32,128]{2,1,0} broadcast(%mul.3549), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3551 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.3546, %mul.3550), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3582 = bf16[32,32,64]{2,1,0} slice(%mul.3551), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.3573 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.3574 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.3575 = s32[32]{0} select(%lt.3573, %add.3574, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.3576 = s32[32,1]{1,0} reshape(%select_n.3575), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.3577 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.3576), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.3578 = bf16[32,64]{1,0} slice(%gather.3577), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3580 = bf16[32,1,64]{2,1,0} reshape(%slice.3578), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3584 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3580), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3585 = bf16[32,64]{1,0} reshape(%mul.3584), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3586 = bf16[32,32,64]{2,1,0} broadcast(%mul.3585), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3587 = bf16[32,32,64]{2,1,0} multiply(%slice.3582, %mul.3586), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3583 = bf16[32,32,64]{2,1,0} slice(%mul.3551), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.3579 = bf16[32,64]{1,0} slice(%gather.3577), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3581 = bf16[32,1,64]{2,1,0} reshape(%slice.3579), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3588 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3581), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3589 = bf16[32,64]{1,0} reshape(%mul.3588), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3590 = bf16[32,32,64]{2,1,0} broadcast(%mul.3589), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3591 = bf16[32,32,64]{2,1,0} multiply(%slice.3583, %mul.3590), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.3592 = bf16[32,32,64]{2,1,0} subtract(%mul.3587, %mul.3591), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.3593 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3580), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3594 = bf16[32,64]{1,0} reshape(%mul.3593), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3595 = bf16[32,32,64]{2,1,0} broadcast(%mul.3594), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3596 = bf16[32,32,64]{2,1,0} multiply(%slice.3583, %mul.3595), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3597 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3581), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3598 = bf16[32,64]{1,0} reshape(%mul.3597), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3599 = bf16[32,32,64]{2,1,0} broadcast(%mul.3598), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3600 = bf16[32,32,64]{2,1,0} multiply(%slice.3582, %mul.3599), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.3601 = bf16[32,32,64]{2,1,0} add(%mul.3596, %mul.3600), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.3602 = bf16[32,32,128]{2,1,0} concatenate(%sub.3592, %add.3601), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.3603 = bf16[32,4096]{1,0} reshape(%concatenate.3602), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.3527 = bf16[32,4,128]{2,1,0} slice(%reshape.3525), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.3552 = f32[32,4,128]{2,1,0} convert(%slice.3527), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.3553 = f32[32,4,128]{2,1,0} power(%convert_element_type.3552, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3558 = f32[32,4]{1,0} reduce(%pow.3553, %constant.512), dimensions={2}, to_apply=%region_86.3557, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3559 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.3558), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3560 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.3559, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3561 = f32[32,4,1]{2,1,0} add(%div.3560, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3562 = f32[32,4,1]{2,1,0} rsqrt(%add.3561), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3563 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.3562), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3564 = f32[32,4]{1,0} reshape(%mul.3563), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3565 = f32[32,4,128]{2,1,0} broadcast(%mul.3564), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3566 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.3552, %mul.3565), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3567 = bf16[32,4,128]{2,1,0} convert(%mul.3566), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_13_self_attn_k_norm_weight__.53 = bf16[128]{0} parameter(52), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.13.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.3568 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_13_self_attn_k_norm_weight__.53), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3569 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.3568), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3570 = bf16[128]{0} reshape(%mul.3569), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3571 = bf16[32,4,128]{2,1,0} broadcast(%mul.3570), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3572 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.3567, %mul.3571), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3606 = bf16[32,4,64]{2,1,0} slice(%mul.3572), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3604 = bf16[32,1,64]{2,1,0} reshape(%slice.3578), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3608 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3604), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3609 = bf16[32,64]{1,0} reshape(%mul.3608), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3610 = bf16[32,4,64]{2,1,0} broadcast(%mul.3609), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3611 = bf16[32,4,64]{2,1,0} multiply(%slice.3606, %mul.3610), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3607 = bf16[32,4,64]{2,1,0} slice(%mul.3572), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3605 = bf16[32,1,64]{2,1,0} reshape(%slice.3579), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3612 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3605), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3613 = bf16[32,64]{1,0} reshape(%mul.3612), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3614 = bf16[32,4,64]{2,1,0} broadcast(%mul.3613), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3615 = bf16[32,4,64]{2,1,0} multiply(%slice.3607, %mul.3614), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.3616 = bf16[32,4,64]{2,1,0} subtract(%mul.3611, %mul.3615), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.3617 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3604), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3618 = bf16[32,64]{1,0} reshape(%mul.3617), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3619 = bf16[32,4,64]{2,1,0} broadcast(%mul.3618), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3620 = bf16[32,4,64]{2,1,0} multiply(%slice.3607, %mul.3619), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3621 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3605), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3622 = bf16[32,64]{1,0} reshape(%mul.3621), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3623 = bf16[32,4,64]{2,1,0} broadcast(%mul.3622), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3624 = bf16[32,4,64]{2,1,0} multiply(%slice.3606, %mul.3623), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.3625 = bf16[32,4,64]{2,1,0} add(%mul.3620, %mul.3624), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.3626 = bf16[32,4,128]{2,1,0} concatenate(%sub.3616, %add.3625), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.3627 = bf16[32,512]{1,0} reshape(%concatenate.3626), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.3528 = bf16[32,4,128]{2,1,0} slice(%reshape.3525), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.3529 = bf16[32,512]{1,0} reshape(%slice.3528), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.3628 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_13_.449, %reshape.3603, %reshape.3627, %reshape.3529, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.3629 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.3628), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_14_.450 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(449), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[14]"}
  %jit__jax_attn_func_.3630 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.3628), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_13_self_attn_o_proj_weight__.54 = bf16[2048,4096]{1,0} parameter(53), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.13.self_attn.o_proj.weight\']"}
  %dot_general.3631 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.3630, %params_and_buffers__vllm_model_language_model_model_layers_13_self_attn_o_proj_weight__.54), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.3632 = f32[32,2048]{1,0} convert(%dot_general.3631), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3503 = bf16[32,2048]{1,0} convert(%add.3502), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3633 = f32[32,2048]{1,0} convert(%convert_element_type.3503), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.3634 = f32[32,2048]{1,0} add(%convert_element_type.3632, %convert_element_type.3633), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.3636 = f32[32,2048]{1,0} power(%add.3634, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3641 = f32[32]{0} reduce(%pow.3636, %constant.512), dimensions={1}, to_apply=%region_87.3640, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3642 = f32[32,1]{1,0} reshape(%reduce_sum.3641), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3643 = f32[32,1]{1,0} divide(%broadcast_in_dim.3642, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3644 = f32[32,1]{1,0} add(%div.3643, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3645 = f32[32,1]{1,0} rsqrt(%add.3644), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3646 = f32[32,1]{1,0} broadcast(%rsqrt.3645), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3647 = f32[32]{0} reshape(%mul.3646), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3648 = f32[32,2048]{1,0} broadcast(%mul.3647), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3649 = f32[32,2048]{1,0} multiply(%add.3634, %mul.3648), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3650 = bf16[32,2048]{1,0} convert(%mul.3649), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_13_post_attention_layernorm_weight__.52 = bf16[2048]{0} parameter(51), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.13.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.3651 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_13_post_attention_layernorm_weight__.52), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3652 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.3651), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3653 = bf16[2048]{0} reshape(%mul.3652), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3654 = bf16[32,2048]{1,0} broadcast(%mul.3653), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3655 = bf16[32,2048]{1,0} multiply(%convert_element_type.3650, %mul.3654), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_13_mlp_experts_w13_weight__.49 = bf16[128,1536,2048]{2,1,0} parameter(48), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.13.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_13_mlp_experts_w2_weight__.50 = bf16[128,2048,768]{2,1,0} parameter(49), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.13.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_13_mlp_gate_weight__.51 = bf16[128,2048]{1,0} parameter(50), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.13.mlp.gate.weight\']"}
  %dot_general.3656 = bf16[32,128]{1,0} dot(%mul.3655, %params_and_buffers__vllm_model_language_model_model_layers_13_mlp_gate_weight__.51), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.3657 = bf16[32,2048]{1,0} call(%mul.3655, %params_and_buffers__vllm_model_language_model_model_layers_13_mlp_experts_w13_weight__.49, %params_and_buffers__vllm_model_language_model_model_layers_13_mlp_experts_w2_weight__.50, %dot_general.3656), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.3658 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.3657), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3635 = bf16[32,2048]{1,0} convert(%add.3634), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3659 = f32[32,2048]{1,0} convert(%convert_element_type.3635), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.3660 = f32[32,2048]{1,0} add(%convert_element_type.3658, %convert_element_type.3659), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.3662 = f32[32,2048]{1,0} power(%add.3660, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3667 = f32[32]{0} reduce(%pow.3662, %constant.512), dimensions={1}, to_apply=%region_88.3666, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3668 = f32[32,1]{1,0} reshape(%reduce_sum.3667), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3669 = f32[32,1]{1,0} divide(%broadcast_in_dim.3668, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3670 = f32[32,1]{1,0} add(%div.3669, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3671 = f32[32,1]{1,0} rsqrt(%add.3670), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3672 = f32[32,1]{1,0} broadcast(%rsqrt.3671), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3673 = f32[32]{0} reshape(%mul.3672), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3674 = f32[32,2048]{1,0} broadcast(%mul.3673), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3675 = f32[32,2048]{1,0} multiply(%add.3660, %mul.3674), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3676 = bf16[32,2048]{1,0} convert(%mul.3675), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_14_input_layernorm_weight__.57 = bf16[2048]{0} parameter(56), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.14.input_layernorm.weight\']"}
  %broadcast_in_dim.3677 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_14_input_layernorm_weight__.57), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3678 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.3677), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3679 = bf16[2048]{0} reshape(%mul.3678), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3680 = bf16[32,2048]{1,0} broadcast(%mul.3679), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3681 = bf16[32,2048]{1,0} multiply(%convert_element_type.3676, %mul.3680), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_14_self_attn_qkv_proj_weight__.65 = bf16[5120,2048]{1,0} parameter(64), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.14.self_attn.qkv_proj.weight\']"}
  %dot_general.3682 = bf16[32,5120]{1,0} dot(%mul.3681, %params_and_buffers__vllm_model_language_model_model_layers_14_self_attn_qkv_proj_weight__.65), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.3683 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.3682), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.3684 = bf16[32,4,1024]{2,1,0} slice(%reshape.3683), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.3688 = bf16[32,32,128]{2,1,0} reshape(%slice.3684), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.3689 = f32[32,32,128]{2,1,0} convert(%reshape.3688), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.3690 = f32[32,32,128]{2,1,0} power(%convert_element_type.3689, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3695 = f32[32,32]{1,0} reduce(%pow.3690, %constant.512), dimensions={2}, to_apply=%region_89.3694, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3696 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.3695), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3697 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.3696, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3698 = f32[32,32,1]{2,1,0} add(%div.3697, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3699 = f32[32,32,1]{2,1,0} rsqrt(%add.3698), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3700 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.3699), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3701 = f32[32,32]{1,0} reshape(%mul.3700), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3702 = f32[32,32,128]{2,1,0} broadcast(%mul.3701), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3703 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.3689, %mul.3702), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3704 = bf16[32,32,128]{2,1,0} convert(%mul.3703), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_14_self_attn_q_norm_weight__.64 = bf16[128]{0} parameter(63), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.14.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.3705 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_14_self_attn_q_norm_weight__.64), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3706 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.3705), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3707 = bf16[128]{0} reshape(%mul.3706), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3708 = bf16[32,32,128]{2,1,0} broadcast(%mul.3707), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3709 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.3704, %mul.3708), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3740 = bf16[32,32,64]{2,1,0} slice(%mul.3709), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.3731 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.3732 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.3733 = s32[32]{0} select(%lt.3731, %add.3732, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.3734 = s32[32,1]{1,0} reshape(%select_n.3733), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.3735 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.3734), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.3736 = bf16[32,64]{1,0} slice(%gather.3735), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3738 = bf16[32,1,64]{2,1,0} reshape(%slice.3736), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3742 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3738), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3743 = bf16[32,64]{1,0} reshape(%mul.3742), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3744 = bf16[32,32,64]{2,1,0} broadcast(%mul.3743), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3745 = bf16[32,32,64]{2,1,0} multiply(%slice.3740, %mul.3744), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3741 = bf16[32,32,64]{2,1,0} slice(%mul.3709), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.3737 = bf16[32,64]{1,0} slice(%gather.3735), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3739 = bf16[32,1,64]{2,1,0} reshape(%slice.3737), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3746 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3739), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3747 = bf16[32,64]{1,0} reshape(%mul.3746), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3748 = bf16[32,32,64]{2,1,0} broadcast(%mul.3747), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3749 = bf16[32,32,64]{2,1,0} multiply(%slice.3741, %mul.3748), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.3750 = bf16[32,32,64]{2,1,0} subtract(%mul.3745, %mul.3749), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.3751 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3738), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3752 = bf16[32,64]{1,0} reshape(%mul.3751), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3753 = bf16[32,32,64]{2,1,0} broadcast(%mul.3752), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3754 = bf16[32,32,64]{2,1,0} multiply(%slice.3741, %mul.3753), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3755 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3739), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3756 = bf16[32,64]{1,0} reshape(%mul.3755), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3757 = bf16[32,32,64]{2,1,0} broadcast(%mul.3756), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3758 = bf16[32,32,64]{2,1,0} multiply(%slice.3740, %mul.3757), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.3759 = bf16[32,32,64]{2,1,0} add(%mul.3754, %mul.3758), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.3760 = bf16[32,32,128]{2,1,0} concatenate(%sub.3750, %add.3759), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.3761 = bf16[32,4096]{1,0} reshape(%concatenate.3760), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.3685 = bf16[32,4,128]{2,1,0} slice(%reshape.3683), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.3710 = f32[32,4,128]{2,1,0} convert(%slice.3685), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.3711 = f32[32,4,128]{2,1,0} power(%convert_element_type.3710, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3716 = f32[32,4]{1,0} reduce(%pow.3711, %constant.512), dimensions={2}, to_apply=%region_90.3715, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3717 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.3716), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3718 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.3717, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3719 = f32[32,4,1]{2,1,0} add(%div.3718, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3720 = f32[32,4,1]{2,1,0} rsqrt(%add.3719), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3721 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.3720), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3722 = f32[32,4]{1,0} reshape(%mul.3721), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3723 = f32[32,4,128]{2,1,0} broadcast(%mul.3722), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3724 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.3710, %mul.3723), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3725 = bf16[32,4,128]{2,1,0} convert(%mul.3724), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_14_self_attn_k_norm_weight__.62 = bf16[128]{0} parameter(61), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.14.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.3726 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_14_self_attn_k_norm_weight__.62), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3727 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.3726), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3728 = bf16[128]{0} reshape(%mul.3727), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3729 = bf16[32,4,128]{2,1,0} broadcast(%mul.3728), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3730 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.3725, %mul.3729), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3764 = bf16[32,4,64]{2,1,0} slice(%mul.3730), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3762 = bf16[32,1,64]{2,1,0} reshape(%slice.3736), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3766 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3762), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3767 = bf16[32,64]{1,0} reshape(%mul.3766), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3768 = bf16[32,4,64]{2,1,0} broadcast(%mul.3767), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3769 = bf16[32,4,64]{2,1,0} multiply(%slice.3764, %mul.3768), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3765 = bf16[32,4,64]{2,1,0} slice(%mul.3730), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3763 = bf16[32,1,64]{2,1,0} reshape(%slice.3737), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3770 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3763), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3771 = bf16[32,64]{1,0} reshape(%mul.3770), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3772 = bf16[32,4,64]{2,1,0} broadcast(%mul.3771), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3773 = bf16[32,4,64]{2,1,0} multiply(%slice.3765, %mul.3772), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.3774 = bf16[32,4,64]{2,1,0} subtract(%mul.3769, %mul.3773), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.3775 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3762), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3776 = bf16[32,64]{1,0} reshape(%mul.3775), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3777 = bf16[32,4,64]{2,1,0} broadcast(%mul.3776), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3778 = bf16[32,4,64]{2,1,0} multiply(%slice.3765, %mul.3777), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3779 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3763), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3780 = bf16[32,64]{1,0} reshape(%mul.3779), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3781 = bf16[32,4,64]{2,1,0} broadcast(%mul.3780), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3782 = bf16[32,4,64]{2,1,0} multiply(%slice.3764, %mul.3781), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.3783 = bf16[32,4,64]{2,1,0} add(%mul.3778, %mul.3782), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.3784 = bf16[32,4,128]{2,1,0} concatenate(%sub.3774, %add.3783), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.3785 = bf16[32,512]{1,0} reshape(%concatenate.3784), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.3686 = bf16[32,4,128]{2,1,0} slice(%reshape.3683), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.3687 = bf16[32,512]{1,0} reshape(%slice.3686), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.3786 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_14_.450, %reshape.3761, %reshape.3785, %reshape.3687, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.3787 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.3786), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_15_.451 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(450), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[15]"}
  %jit__jax_attn_func_.3788 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.3786), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_14_self_attn_o_proj_weight__.63 = bf16[2048,4096]{1,0} parameter(62), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.14.self_attn.o_proj.weight\']"}
  %dot_general.3789 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.3788, %params_and_buffers__vllm_model_language_model_model_layers_14_self_attn_o_proj_weight__.63), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.3790 = f32[32,2048]{1,0} convert(%dot_general.3789), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3661 = bf16[32,2048]{1,0} convert(%add.3660), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3791 = f32[32,2048]{1,0} convert(%convert_element_type.3661), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.3792 = f32[32,2048]{1,0} add(%convert_element_type.3790, %convert_element_type.3791), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.3794 = f32[32,2048]{1,0} power(%add.3792, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3799 = f32[32]{0} reduce(%pow.3794, %constant.512), dimensions={1}, to_apply=%region_91.3798, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3800 = f32[32,1]{1,0} reshape(%reduce_sum.3799), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3801 = f32[32,1]{1,0} divide(%broadcast_in_dim.3800, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3802 = f32[32,1]{1,0} add(%div.3801, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3803 = f32[32,1]{1,0} rsqrt(%add.3802), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3804 = f32[32,1]{1,0} broadcast(%rsqrt.3803), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3805 = f32[32]{0} reshape(%mul.3804), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3806 = f32[32,2048]{1,0} broadcast(%mul.3805), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3807 = f32[32,2048]{1,0} multiply(%add.3792, %mul.3806), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3808 = bf16[32,2048]{1,0} convert(%mul.3807), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_14_post_attention_layernorm_weight__.61 = bf16[2048]{0} parameter(60), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.14.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.3809 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_14_post_attention_layernorm_weight__.61), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3810 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.3809), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3811 = bf16[2048]{0} reshape(%mul.3810), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3812 = bf16[32,2048]{1,0} broadcast(%mul.3811), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3813 = bf16[32,2048]{1,0} multiply(%convert_element_type.3808, %mul.3812), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_14_mlp_experts_w13_weight__.58 = bf16[128,1536,2048]{2,1,0} parameter(57), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.14.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_14_mlp_experts_w2_weight__.59 = bf16[128,2048,768]{2,1,0} parameter(58), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.14.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_14_mlp_gate_weight__.60 = bf16[128,2048]{1,0} parameter(59), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.14.mlp.gate.weight\']"}
  %dot_general.3814 = bf16[32,128]{1,0} dot(%mul.3813, %params_and_buffers__vllm_model_language_model_model_layers_14_mlp_gate_weight__.60), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.3815 = bf16[32,2048]{1,0} call(%mul.3813, %params_and_buffers__vllm_model_language_model_model_layers_14_mlp_experts_w13_weight__.58, %params_and_buffers__vllm_model_language_model_model_layers_14_mlp_experts_w2_weight__.59, %dot_general.3814), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.3816 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.3815), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3793 = bf16[32,2048]{1,0} convert(%add.3792), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3817 = f32[32,2048]{1,0} convert(%convert_element_type.3793), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.3818 = f32[32,2048]{1,0} add(%convert_element_type.3816, %convert_element_type.3817), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.3820 = f32[32,2048]{1,0} power(%add.3818, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3825 = f32[32]{0} reduce(%pow.3820, %constant.512), dimensions={1}, to_apply=%region_92.3824, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3826 = f32[32,1]{1,0} reshape(%reduce_sum.3825), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3827 = f32[32,1]{1,0} divide(%broadcast_in_dim.3826, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3828 = f32[32,1]{1,0} add(%div.3827, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3829 = f32[32,1]{1,0} rsqrt(%add.3828), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3830 = f32[32,1]{1,0} broadcast(%rsqrt.3829), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3831 = f32[32]{0} reshape(%mul.3830), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3832 = f32[32,2048]{1,0} broadcast(%mul.3831), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3833 = f32[32,2048]{1,0} multiply(%add.3818, %mul.3832), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3834 = bf16[32,2048]{1,0} convert(%mul.3833), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_15_input_layernorm_weight__.66 = bf16[2048]{0} parameter(65), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.15.input_layernorm.weight\']"}
  %broadcast_in_dim.3835 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_15_input_layernorm_weight__.66), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3836 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.3835), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3837 = bf16[2048]{0} reshape(%mul.3836), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3838 = bf16[32,2048]{1,0} broadcast(%mul.3837), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3839 = bf16[32,2048]{1,0} multiply(%convert_element_type.3834, %mul.3838), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_15_self_attn_qkv_proj_weight__.74 = bf16[5120,2048]{1,0} parameter(73), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.15.self_attn.qkv_proj.weight\']"}
  %dot_general.3840 = bf16[32,5120]{1,0} dot(%mul.3839, %params_and_buffers__vllm_model_language_model_model_layers_15_self_attn_qkv_proj_weight__.74), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.3841 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.3840), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.3842 = bf16[32,4,1024]{2,1,0} slice(%reshape.3841), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.3846 = bf16[32,32,128]{2,1,0} reshape(%slice.3842), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.3847 = f32[32,32,128]{2,1,0} convert(%reshape.3846), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.3848 = f32[32,32,128]{2,1,0} power(%convert_element_type.3847, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3853 = f32[32,32]{1,0} reduce(%pow.3848, %constant.512), dimensions={2}, to_apply=%region_93.3852, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3854 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.3853), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3855 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.3854, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3856 = f32[32,32,1]{2,1,0} add(%div.3855, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3857 = f32[32,32,1]{2,1,0} rsqrt(%add.3856), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3858 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.3857), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3859 = f32[32,32]{1,0} reshape(%mul.3858), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3860 = f32[32,32,128]{2,1,0} broadcast(%mul.3859), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3861 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.3847, %mul.3860), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3862 = bf16[32,32,128]{2,1,0} convert(%mul.3861), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_15_self_attn_q_norm_weight__.73 = bf16[128]{0} parameter(72), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.15.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.3863 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_15_self_attn_q_norm_weight__.73), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3864 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.3863), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3865 = bf16[128]{0} reshape(%mul.3864), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3866 = bf16[32,32,128]{2,1,0} broadcast(%mul.3865), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3867 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.3862, %mul.3866), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3898 = bf16[32,32,64]{2,1,0} slice(%mul.3867), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.3889 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.3890 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.3891 = s32[32]{0} select(%lt.3889, %add.3890, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.3892 = s32[32,1]{1,0} reshape(%select_n.3891), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.3893 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.3892), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.3894 = bf16[32,64]{1,0} slice(%gather.3893), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3896 = bf16[32,1,64]{2,1,0} reshape(%slice.3894), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3900 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3896), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3901 = bf16[32,64]{1,0} reshape(%mul.3900), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3902 = bf16[32,32,64]{2,1,0} broadcast(%mul.3901), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3903 = bf16[32,32,64]{2,1,0} multiply(%slice.3898, %mul.3902), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3899 = bf16[32,32,64]{2,1,0} slice(%mul.3867), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.3895 = bf16[32,64]{1,0} slice(%gather.3893), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3897 = bf16[32,1,64]{2,1,0} reshape(%slice.3895), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3904 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3897), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3905 = bf16[32,64]{1,0} reshape(%mul.3904), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3906 = bf16[32,32,64]{2,1,0} broadcast(%mul.3905), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3907 = bf16[32,32,64]{2,1,0} multiply(%slice.3899, %mul.3906), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.3908 = bf16[32,32,64]{2,1,0} subtract(%mul.3903, %mul.3907), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.3909 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3896), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3910 = bf16[32,64]{1,0} reshape(%mul.3909), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3911 = bf16[32,32,64]{2,1,0} broadcast(%mul.3910), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3912 = bf16[32,32,64]{2,1,0} multiply(%slice.3899, %mul.3911), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3913 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3897), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3914 = bf16[32,64]{1,0} reshape(%mul.3913), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3915 = bf16[32,32,64]{2,1,0} broadcast(%mul.3914), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3916 = bf16[32,32,64]{2,1,0} multiply(%slice.3898, %mul.3915), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.3917 = bf16[32,32,64]{2,1,0} add(%mul.3912, %mul.3916), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.3918 = bf16[32,32,128]{2,1,0} concatenate(%sub.3908, %add.3917), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.3919 = bf16[32,4096]{1,0} reshape(%concatenate.3918), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.3843 = bf16[32,4,128]{2,1,0} slice(%reshape.3841), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.3868 = f32[32,4,128]{2,1,0} convert(%slice.3843), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.3869 = f32[32,4,128]{2,1,0} power(%convert_element_type.3868, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3874 = f32[32,4]{1,0} reduce(%pow.3869, %constant.512), dimensions={2}, to_apply=%region_94.3873, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3875 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.3874), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3876 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.3875, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3877 = f32[32,4,1]{2,1,0} add(%div.3876, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3878 = f32[32,4,1]{2,1,0} rsqrt(%add.3877), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3879 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.3878), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3880 = f32[32,4]{1,0} reshape(%mul.3879), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3881 = f32[32,4,128]{2,1,0} broadcast(%mul.3880), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3882 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.3868, %mul.3881), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3883 = bf16[32,4,128]{2,1,0} convert(%mul.3882), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_15_self_attn_k_norm_weight__.71 = bf16[128]{0} parameter(70), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.15.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.3884 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_15_self_attn_k_norm_weight__.71), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3885 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.3884), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3886 = bf16[128]{0} reshape(%mul.3885), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3887 = bf16[32,4,128]{2,1,0} broadcast(%mul.3886), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3888 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.3883, %mul.3887), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3922 = bf16[32,4,64]{2,1,0} slice(%mul.3888), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3920 = bf16[32,1,64]{2,1,0} reshape(%slice.3894), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3924 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3920), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3925 = bf16[32,64]{1,0} reshape(%mul.3924), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3926 = bf16[32,4,64]{2,1,0} broadcast(%mul.3925), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3927 = bf16[32,4,64]{2,1,0} multiply(%slice.3922, %mul.3926), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.3923 = bf16[32,4,64]{2,1,0} slice(%mul.3888), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.3921 = bf16[32,1,64]{2,1,0} reshape(%slice.3895), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.3928 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3921), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3929 = bf16[32,64]{1,0} reshape(%mul.3928), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3930 = bf16[32,4,64]{2,1,0} broadcast(%mul.3929), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3931 = bf16[32,4,64]{2,1,0} multiply(%slice.3923, %mul.3930), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.3932 = bf16[32,4,64]{2,1,0} subtract(%mul.3927, %mul.3931), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.3933 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3920), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3934 = bf16[32,64]{1,0} reshape(%mul.3933), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3935 = bf16[32,4,64]{2,1,0} broadcast(%mul.3934), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3936 = bf16[32,4,64]{2,1,0} multiply(%slice.3923, %mul.3935), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3937 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.3921), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3938 = bf16[32,64]{1,0} reshape(%mul.3937), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3939 = bf16[32,4,64]{2,1,0} broadcast(%mul.3938), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3940 = bf16[32,4,64]{2,1,0} multiply(%slice.3922, %mul.3939), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.3941 = bf16[32,4,64]{2,1,0} add(%mul.3936, %mul.3940), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.3942 = bf16[32,4,128]{2,1,0} concatenate(%sub.3932, %add.3941), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.3943 = bf16[32,512]{1,0} reshape(%concatenate.3942), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.3844 = bf16[32,4,128]{2,1,0} slice(%reshape.3841), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.3845 = bf16[32,512]{1,0} reshape(%slice.3844), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.3944 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_15_.451, %reshape.3919, %reshape.3943, %reshape.3845, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.3945 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.3944), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_16_.452 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(451), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[16]"}
  %jit__jax_attn_func_.3946 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.3944), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_15_self_attn_o_proj_weight__.72 = bf16[2048,4096]{1,0} parameter(71), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.15.self_attn.o_proj.weight\']"}
  %dot_general.3947 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.3946, %params_and_buffers__vllm_model_language_model_model_layers_15_self_attn_o_proj_weight__.72), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.3948 = f32[32,2048]{1,0} convert(%dot_general.3947), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3819 = bf16[32,2048]{1,0} convert(%add.3818), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3949 = f32[32,2048]{1,0} convert(%convert_element_type.3819), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.3950 = f32[32,2048]{1,0} add(%convert_element_type.3948, %convert_element_type.3949), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.3952 = f32[32,2048]{1,0} power(%add.3950, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3957 = f32[32]{0} reduce(%pow.3952, %constant.512), dimensions={1}, to_apply=%region_95.3956, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3958 = f32[32,1]{1,0} reshape(%reduce_sum.3957), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3959 = f32[32,1]{1,0} divide(%broadcast_in_dim.3958, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3960 = f32[32,1]{1,0} add(%div.3959, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3961 = f32[32,1]{1,0} rsqrt(%add.3960), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3962 = f32[32,1]{1,0} broadcast(%rsqrt.3961), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3963 = f32[32]{0} reshape(%mul.3962), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3964 = f32[32,2048]{1,0} broadcast(%mul.3963), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3965 = f32[32,2048]{1,0} multiply(%add.3950, %mul.3964), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3966 = bf16[32,2048]{1,0} convert(%mul.3965), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_15_post_attention_layernorm_weight__.70 = bf16[2048]{0} parameter(69), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.15.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.3967 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_15_post_attention_layernorm_weight__.70), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3968 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.3967), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3969 = bf16[2048]{0} reshape(%mul.3968), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3970 = bf16[32,2048]{1,0} broadcast(%mul.3969), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3971 = bf16[32,2048]{1,0} multiply(%convert_element_type.3966, %mul.3970), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_15_mlp_experts_w13_weight__.67 = bf16[128,1536,2048]{2,1,0} parameter(66), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.15.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_15_mlp_experts_w2_weight__.68 = bf16[128,2048,768]{2,1,0} parameter(67), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.15.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_15_mlp_gate_weight__.69 = bf16[128,2048]{1,0} parameter(68), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.15.mlp.gate.weight\']"}
  %dot_general.3972 = bf16[32,128]{1,0} dot(%mul.3971, %params_and_buffers__vllm_model_language_model_model_layers_15_mlp_gate_weight__.69), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.3973 = bf16[32,2048]{1,0} call(%mul.3971, %params_and_buffers__vllm_model_language_model_model_layers_15_mlp_experts_w13_weight__.67, %params_and_buffers__vllm_model_language_model_model_layers_15_mlp_experts_w2_weight__.68, %dot_general.3972), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.3974 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.3973), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3951 = bf16[32,2048]{1,0} convert(%add.3950), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3975 = f32[32,2048]{1,0} convert(%convert_element_type.3951), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.3976 = f32[32,2048]{1,0} add(%convert_element_type.3974, %convert_element_type.3975), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.3978 = f32[32,2048]{1,0} power(%add.3976, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.3983 = f32[32]{0} reduce(%pow.3978, %constant.512), dimensions={1}, to_apply=%region_96.3982, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.3984 = f32[32,1]{1,0} reshape(%reduce_sum.3983), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.3985 = f32[32,1]{1,0} divide(%broadcast_in_dim.3984, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.3986 = f32[32,1]{1,0} add(%div.3985, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.3987 = f32[32,1]{1,0} rsqrt(%add.3986), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.3988 = f32[32,1]{1,0} broadcast(%rsqrt.3987), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3989 = f32[32]{0} reshape(%mul.3988), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3990 = f32[32,2048]{1,0} broadcast(%mul.3989), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3991 = f32[32,2048]{1,0} multiply(%add.3976, %mul.3990), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.3992 = bf16[32,2048]{1,0} convert(%mul.3991), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_16_input_layernorm_weight__.75 = bf16[2048]{0} parameter(74), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.16.input_layernorm.weight\']"}
  %broadcast_in_dim.3993 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_16_input_layernorm_weight__.75), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3994 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.3993), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3995 = bf16[2048]{0} reshape(%mul.3994), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3996 = bf16[32,2048]{1,0} broadcast(%mul.3995), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.3997 = bf16[32,2048]{1,0} multiply(%convert_element_type.3992, %mul.3996), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_16_self_attn_qkv_proj_weight__.83 = bf16[5120,2048]{1,0} parameter(82), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.16.self_attn.qkv_proj.weight\']"}
  %dot_general.3998 = bf16[32,5120]{1,0} dot(%mul.3997, %params_and_buffers__vllm_model_language_model_model_layers_16_self_attn_qkv_proj_weight__.83), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.3999 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.3998), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.4000 = bf16[32,4,1024]{2,1,0} slice(%reshape.3999), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.4004 = bf16[32,32,128]{2,1,0} reshape(%slice.4000), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.4005 = f32[32,32,128]{2,1,0} convert(%reshape.4004), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.4006 = f32[32,32,128]{2,1,0} power(%convert_element_type.4005, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4011 = f32[32,32]{1,0} reduce(%pow.4006, %constant.512), dimensions={2}, to_apply=%region_97.4010, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4012 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.4011), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4013 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.4012, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4014 = f32[32,32,1]{2,1,0} add(%div.4013, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4015 = f32[32,32,1]{2,1,0} rsqrt(%add.4014), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4016 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.4015), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4017 = f32[32,32]{1,0} reshape(%mul.4016), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4018 = f32[32,32,128]{2,1,0} broadcast(%mul.4017), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4019 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.4005, %mul.4018), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4020 = bf16[32,32,128]{2,1,0} convert(%mul.4019), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_16_self_attn_q_norm_weight__.82 = bf16[128]{0} parameter(81), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.16.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.4021 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_16_self_attn_q_norm_weight__.82), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4022 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.4021), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4023 = bf16[128]{0} reshape(%mul.4022), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4024 = bf16[32,32,128]{2,1,0} broadcast(%mul.4023), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4025 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.4020, %mul.4024), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4056 = bf16[32,32,64]{2,1,0} slice(%mul.4025), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.4047 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.4048 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.4049 = s32[32]{0} select(%lt.4047, %add.4048, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.4050 = s32[32,1]{1,0} reshape(%select_n.4049), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.4051 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.4050), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.4052 = bf16[32,64]{1,0} slice(%gather.4051), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4054 = bf16[32,1,64]{2,1,0} reshape(%slice.4052), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4058 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4054), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4059 = bf16[32,64]{1,0} reshape(%mul.4058), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4060 = bf16[32,32,64]{2,1,0} broadcast(%mul.4059), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4061 = bf16[32,32,64]{2,1,0} multiply(%slice.4056, %mul.4060), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4057 = bf16[32,32,64]{2,1,0} slice(%mul.4025), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.4053 = bf16[32,64]{1,0} slice(%gather.4051), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4055 = bf16[32,1,64]{2,1,0} reshape(%slice.4053), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4062 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4055), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4063 = bf16[32,64]{1,0} reshape(%mul.4062), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4064 = bf16[32,32,64]{2,1,0} broadcast(%mul.4063), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4065 = bf16[32,32,64]{2,1,0} multiply(%slice.4057, %mul.4064), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.4066 = bf16[32,32,64]{2,1,0} subtract(%mul.4061, %mul.4065), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.4067 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4054), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4068 = bf16[32,64]{1,0} reshape(%mul.4067), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4069 = bf16[32,32,64]{2,1,0} broadcast(%mul.4068), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4070 = bf16[32,32,64]{2,1,0} multiply(%slice.4057, %mul.4069), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4071 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4055), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4072 = bf16[32,64]{1,0} reshape(%mul.4071), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4073 = bf16[32,32,64]{2,1,0} broadcast(%mul.4072), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4074 = bf16[32,32,64]{2,1,0} multiply(%slice.4056, %mul.4073), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.4075 = bf16[32,32,64]{2,1,0} add(%mul.4070, %mul.4074), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.4076 = bf16[32,32,128]{2,1,0} concatenate(%sub.4066, %add.4075), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.4077 = bf16[32,4096]{1,0} reshape(%concatenate.4076), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.4001 = bf16[32,4,128]{2,1,0} slice(%reshape.3999), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.4026 = f32[32,4,128]{2,1,0} convert(%slice.4001), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.4027 = f32[32,4,128]{2,1,0} power(%convert_element_type.4026, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4032 = f32[32,4]{1,0} reduce(%pow.4027, %constant.512), dimensions={2}, to_apply=%region_98.4031, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4033 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.4032), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4034 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.4033, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4035 = f32[32,4,1]{2,1,0} add(%div.4034, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4036 = f32[32,4,1]{2,1,0} rsqrt(%add.4035), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4037 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.4036), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4038 = f32[32,4]{1,0} reshape(%mul.4037), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4039 = f32[32,4,128]{2,1,0} broadcast(%mul.4038), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4040 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.4026, %mul.4039), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4041 = bf16[32,4,128]{2,1,0} convert(%mul.4040), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_16_self_attn_k_norm_weight__.80 = bf16[128]{0} parameter(79), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.16.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.4042 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_16_self_attn_k_norm_weight__.80), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4043 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.4042), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4044 = bf16[128]{0} reshape(%mul.4043), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4045 = bf16[32,4,128]{2,1,0} broadcast(%mul.4044), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4046 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.4041, %mul.4045), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4080 = bf16[32,4,64]{2,1,0} slice(%mul.4046), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4078 = bf16[32,1,64]{2,1,0} reshape(%slice.4052), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4082 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4078), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4083 = bf16[32,64]{1,0} reshape(%mul.4082), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4084 = bf16[32,4,64]{2,1,0} broadcast(%mul.4083), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4085 = bf16[32,4,64]{2,1,0} multiply(%slice.4080, %mul.4084), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4081 = bf16[32,4,64]{2,1,0} slice(%mul.4046), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4079 = bf16[32,1,64]{2,1,0} reshape(%slice.4053), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4086 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4079), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4087 = bf16[32,64]{1,0} reshape(%mul.4086), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4088 = bf16[32,4,64]{2,1,0} broadcast(%mul.4087), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4089 = bf16[32,4,64]{2,1,0} multiply(%slice.4081, %mul.4088), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.4090 = bf16[32,4,64]{2,1,0} subtract(%mul.4085, %mul.4089), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.4091 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4078), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4092 = bf16[32,64]{1,0} reshape(%mul.4091), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4093 = bf16[32,4,64]{2,1,0} broadcast(%mul.4092), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4094 = bf16[32,4,64]{2,1,0} multiply(%slice.4081, %mul.4093), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4095 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4079), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4096 = bf16[32,64]{1,0} reshape(%mul.4095), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4097 = bf16[32,4,64]{2,1,0} broadcast(%mul.4096), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4098 = bf16[32,4,64]{2,1,0} multiply(%slice.4080, %mul.4097), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.4099 = bf16[32,4,64]{2,1,0} add(%mul.4094, %mul.4098), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.4100 = bf16[32,4,128]{2,1,0} concatenate(%sub.4090, %add.4099), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.4101 = bf16[32,512]{1,0} reshape(%concatenate.4100), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.4002 = bf16[32,4,128]{2,1,0} slice(%reshape.3999), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.4003 = bf16[32,512]{1,0} reshape(%slice.4002), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.4102 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_16_.452, %reshape.4077, %reshape.4101, %reshape.4003, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.4103 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.4102), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_17_.453 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(452), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[17]"}
  %jit__jax_attn_func_.4104 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.4102), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_16_self_attn_o_proj_weight__.81 = bf16[2048,4096]{1,0} parameter(80), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.16.self_attn.o_proj.weight\']"}
  %dot_general.4105 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.4104, %params_and_buffers__vllm_model_language_model_model_layers_16_self_attn_o_proj_weight__.81), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.4106 = f32[32,2048]{1,0} convert(%dot_general.4105), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.3977 = bf16[32,2048]{1,0} convert(%add.3976), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4107 = f32[32,2048]{1,0} convert(%convert_element_type.3977), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.4108 = f32[32,2048]{1,0} add(%convert_element_type.4106, %convert_element_type.4107), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.4110 = f32[32,2048]{1,0} power(%add.4108, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4115 = f32[32]{0} reduce(%pow.4110, %constant.512), dimensions={1}, to_apply=%region_99.4114, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4116 = f32[32,1]{1,0} reshape(%reduce_sum.4115), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4117 = f32[32,1]{1,0} divide(%broadcast_in_dim.4116, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4118 = f32[32,1]{1,0} add(%div.4117, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4119 = f32[32,1]{1,0} rsqrt(%add.4118), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4120 = f32[32,1]{1,0} broadcast(%rsqrt.4119), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4121 = f32[32]{0} reshape(%mul.4120), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4122 = f32[32,2048]{1,0} broadcast(%mul.4121), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4123 = f32[32,2048]{1,0} multiply(%add.4108, %mul.4122), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4124 = bf16[32,2048]{1,0} convert(%mul.4123), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_16_post_attention_layernorm_weight__.79 = bf16[2048]{0} parameter(78), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.16.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.4125 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_16_post_attention_layernorm_weight__.79), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4126 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.4125), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4127 = bf16[2048]{0} reshape(%mul.4126), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4128 = bf16[32,2048]{1,0} broadcast(%mul.4127), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4129 = bf16[32,2048]{1,0} multiply(%convert_element_type.4124, %mul.4128), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_16_mlp_experts_w13_weight__.76 = bf16[128,1536,2048]{2,1,0} parameter(75), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.16.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_16_mlp_experts_w2_weight__.77 = bf16[128,2048,768]{2,1,0} parameter(76), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.16.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_16_mlp_gate_weight__.78 = bf16[128,2048]{1,0} parameter(77), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.16.mlp.gate.weight\']"}
  %dot_general.4130 = bf16[32,128]{1,0} dot(%mul.4129, %params_and_buffers__vllm_model_language_model_model_layers_16_mlp_gate_weight__.78), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.4131 = bf16[32,2048]{1,0} call(%mul.4129, %params_and_buffers__vllm_model_language_model_model_layers_16_mlp_experts_w13_weight__.76, %params_and_buffers__vllm_model_language_model_model_layers_16_mlp_experts_w2_weight__.77, %dot_general.4130), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.4132 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.4131), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4109 = bf16[32,2048]{1,0} convert(%add.4108), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4133 = f32[32,2048]{1,0} convert(%convert_element_type.4109), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.4134 = f32[32,2048]{1,0} add(%convert_element_type.4132, %convert_element_type.4133), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.4136 = f32[32,2048]{1,0} power(%add.4134, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4141 = f32[32]{0} reduce(%pow.4136, %constant.512), dimensions={1}, to_apply=%region_100.4140, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4142 = f32[32,1]{1,0} reshape(%reduce_sum.4141), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4143 = f32[32,1]{1,0} divide(%broadcast_in_dim.4142, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4144 = f32[32,1]{1,0} add(%div.4143, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4145 = f32[32,1]{1,0} rsqrt(%add.4144), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4146 = f32[32,1]{1,0} broadcast(%rsqrt.4145), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4147 = f32[32]{0} reshape(%mul.4146), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4148 = f32[32,2048]{1,0} broadcast(%mul.4147), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4149 = f32[32,2048]{1,0} multiply(%add.4134, %mul.4148), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4150 = bf16[32,2048]{1,0} convert(%mul.4149), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_17_input_layernorm_weight__.84 = bf16[2048]{0} parameter(83), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.17.input_layernorm.weight\']"}
  %broadcast_in_dim.4151 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_17_input_layernorm_weight__.84), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4152 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.4151), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4153 = bf16[2048]{0} reshape(%mul.4152), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4154 = bf16[32,2048]{1,0} broadcast(%mul.4153), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4155 = bf16[32,2048]{1,0} multiply(%convert_element_type.4150, %mul.4154), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_17_self_attn_qkv_proj_weight__.92 = bf16[5120,2048]{1,0} parameter(91), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.17.self_attn.qkv_proj.weight\']"}
  %dot_general.4156 = bf16[32,5120]{1,0} dot(%mul.4155, %params_and_buffers__vllm_model_language_model_model_layers_17_self_attn_qkv_proj_weight__.92), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.4157 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.4156), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.4158 = bf16[32,4,1024]{2,1,0} slice(%reshape.4157), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.4162 = bf16[32,32,128]{2,1,0} reshape(%slice.4158), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.4163 = f32[32,32,128]{2,1,0} convert(%reshape.4162), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.4164 = f32[32,32,128]{2,1,0} power(%convert_element_type.4163, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4169 = f32[32,32]{1,0} reduce(%pow.4164, %constant.512), dimensions={2}, to_apply=%region_101.4168, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4170 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.4169), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4171 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.4170, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4172 = f32[32,32,1]{2,1,0} add(%div.4171, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4173 = f32[32,32,1]{2,1,0} rsqrt(%add.4172), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4174 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.4173), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4175 = f32[32,32]{1,0} reshape(%mul.4174), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4176 = f32[32,32,128]{2,1,0} broadcast(%mul.4175), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4177 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.4163, %mul.4176), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4178 = bf16[32,32,128]{2,1,0} convert(%mul.4177), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_17_self_attn_q_norm_weight__.91 = bf16[128]{0} parameter(90), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.17.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.4179 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_17_self_attn_q_norm_weight__.91), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4180 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.4179), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4181 = bf16[128]{0} reshape(%mul.4180), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4182 = bf16[32,32,128]{2,1,0} broadcast(%mul.4181), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4183 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.4178, %mul.4182), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4214 = bf16[32,32,64]{2,1,0} slice(%mul.4183), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.4205 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.4206 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.4207 = s32[32]{0} select(%lt.4205, %add.4206, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.4208 = s32[32,1]{1,0} reshape(%select_n.4207), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.4209 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.4208), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.4210 = bf16[32,64]{1,0} slice(%gather.4209), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4212 = bf16[32,1,64]{2,1,0} reshape(%slice.4210), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4216 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4212), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4217 = bf16[32,64]{1,0} reshape(%mul.4216), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4218 = bf16[32,32,64]{2,1,0} broadcast(%mul.4217), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4219 = bf16[32,32,64]{2,1,0} multiply(%slice.4214, %mul.4218), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4215 = bf16[32,32,64]{2,1,0} slice(%mul.4183), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.4211 = bf16[32,64]{1,0} slice(%gather.4209), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4213 = bf16[32,1,64]{2,1,0} reshape(%slice.4211), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4220 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4213), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4221 = bf16[32,64]{1,0} reshape(%mul.4220), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4222 = bf16[32,32,64]{2,1,0} broadcast(%mul.4221), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4223 = bf16[32,32,64]{2,1,0} multiply(%slice.4215, %mul.4222), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.4224 = bf16[32,32,64]{2,1,0} subtract(%mul.4219, %mul.4223), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.4225 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4212), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4226 = bf16[32,64]{1,0} reshape(%mul.4225), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4227 = bf16[32,32,64]{2,1,0} broadcast(%mul.4226), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4228 = bf16[32,32,64]{2,1,0} multiply(%slice.4215, %mul.4227), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4229 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4213), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4230 = bf16[32,64]{1,0} reshape(%mul.4229), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4231 = bf16[32,32,64]{2,1,0} broadcast(%mul.4230), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4232 = bf16[32,32,64]{2,1,0} multiply(%slice.4214, %mul.4231), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.4233 = bf16[32,32,64]{2,1,0} add(%mul.4228, %mul.4232), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.4234 = bf16[32,32,128]{2,1,0} concatenate(%sub.4224, %add.4233), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.4235 = bf16[32,4096]{1,0} reshape(%concatenate.4234), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.4159 = bf16[32,4,128]{2,1,0} slice(%reshape.4157), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.4184 = f32[32,4,128]{2,1,0} convert(%slice.4159), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.4185 = f32[32,4,128]{2,1,0} power(%convert_element_type.4184, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4190 = f32[32,4]{1,0} reduce(%pow.4185, %constant.512), dimensions={2}, to_apply=%region_102.4189, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4191 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.4190), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4192 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.4191, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4193 = f32[32,4,1]{2,1,0} add(%div.4192, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4194 = f32[32,4,1]{2,1,0} rsqrt(%add.4193), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4195 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.4194), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4196 = f32[32,4]{1,0} reshape(%mul.4195), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4197 = f32[32,4,128]{2,1,0} broadcast(%mul.4196), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4198 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.4184, %mul.4197), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4199 = bf16[32,4,128]{2,1,0} convert(%mul.4198), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_17_self_attn_k_norm_weight__.89 = bf16[128]{0} parameter(88), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.17.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.4200 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_17_self_attn_k_norm_weight__.89), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4201 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.4200), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4202 = bf16[128]{0} reshape(%mul.4201), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4203 = bf16[32,4,128]{2,1,0} broadcast(%mul.4202), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4204 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.4199, %mul.4203), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4238 = bf16[32,4,64]{2,1,0} slice(%mul.4204), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4236 = bf16[32,1,64]{2,1,0} reshape(%slice.4210), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4240 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4236), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4241 = bf16[32,64]{1,0} reshape(%mul.4240), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4242 = bf16[32,4,64]{2,1,0} broadcast(%mul.4241), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4243 = bf16[32,4,64]{2,1,0} multiply(%slice.4238, %mul.4242), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4239 = bf16[32,4,64]{2,1,0} slice(%mul.4204), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4237 = bf16[32,1,64]{2,1,0} reshape(%slice.4211), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4244 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4237), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4245 = bf16[32,64]{1,0} reshape(%mul.4244), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4246 = bf16[32,4,64]{2,1,0} broadcast(%mul.4245), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4247 = bf16[32,4,64]{2,1,0} multiply(%slice.4239, %mul.4246), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.4248 = bf16[32,4,64]{2,1,0} subtract(%mul.4243, %mul.4247), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.4249 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4236), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4250 = bf16[32,64]{1,0} reshape(%mul.4249), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4251 = bf16[32,4,64]{2,1,0} broadcast(%mul.4250), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4252 = bf16[32,4,64]{2,1,0} multiply(%slice.4239, %mul.4251), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4253 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4237), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4254 = bf16[32,64]{1,0} reshape(%mul.4253), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4255 = bf16[32,4,64]{2,1,0} broadcast(%mul.4254), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4256 = bf16[32,4,64]{2,1,0} multiply(%slice.4238, %mul.4255), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.4257 = bf16[32,4,64]{2,1,0} add(%mul.4252, %mul.4256), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.4258 = bf16[32,4,128]{2,1,0} concatenate(%sub.4248, %add.4257), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.4259 = bf16[32,512]{1,0} reshape(%concatenate.4258), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.4160 = bf16[32,4,128]{2,1,0} slice(%reshape.4157), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.4161 = bf16[32,512]{1,0} reshape(%slice.4160), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.4260 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_17_.453, %reshape.4235, %reshape.4259, %reshape.4161, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.4261 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.4260), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_18_.454 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(453), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[18]"}
  %jit__jax_attn_func_.4262 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.4260), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_17_self_attn_o_proj_weight__.90 = bf16[2048,4096]{1,0} parameter(89), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.17.self_attn.o_proj.weight\']"}
  %dot_general.4263 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.4262, %params_and_buffers__vllm_model_language_model_model_layers_17_self_attn_o_proj_weight__.90), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.4264 = f32[32,2048]{1,0} convert(%dot_general.4263), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4135 = bf16[32,2048]{1,0} convert(%add.4134), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4265 = f32[32,2048]{1,0} convert(%convert_element_type.4135), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.4266 = f32[32,2048]{1,0} add(%convert_element_type.4264, %convert_element_type.4265), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.4268 = f32[32,2048]{1,0} power(%add.4266, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4273 = f32[32]{0} reduce(%pow.4268, %constant.512), dimensions={1}, to_apply=%region_103.4272, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4274 = f32[32,1]{1,0} reshape(%reduce_sum.4273), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4275 = f32[32,1]{1,0} divide(%broadcast_in_dim.4274, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4276 = f32[32,1]{1,0} add(%div.4275, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4277 = f32[32,1]{1,0} rsqrt(%add.4276), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4278 = f32[32,1]{1,0} broadcast(%rsqrt.4277), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4279 = f32[32]{0} reshape(%mul.4278), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4280 = f32[32,2048]{1,0} broadcast(%mul.4279), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4281 = f32[32,2048]{1,0} multiply(%add.4266, %mul.4280), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4282 = bf16[32,2048]{1,0} convert(%mul.4281), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_17_post_attention_layernorm_weight__.88 = bf16[2048]{0} parameter(87), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.17.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.4283 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_17_post_attention_layernorm_weight__.88), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4284 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.4283), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4285 = bf16[2048]{0} reshape(%mul.4284), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4286 = bf16[32,2048]{1,0} broadcast(%mul.4285), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4287 = bf16[32,2048]{1,0} multiply(%convert_element_type.4282, %mul.4286), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_17_mlp_experts_w13_weight__.85 = bf16[128,1536,2048]{2,1,0} parameter(84), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.17.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_17_mlp_experts_w2_weight__.86 = bf16[128,2048,768]{2,1,0} parameter(85), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.17.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_17_mlp_gate_weight__.87 = bf16[128,2048]{1,0} parameter(86), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.17.mlp.gate.weight\']"}
  %dot_general.4288 = bf16[32,128]{1,0} dot(%mul.4287, %params_and_buffers__vllm_model_language_model_model_layers_17_mlp_gate_weight__.87), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.4289 = bf16[32,2048]{1,0} call(%mul.4287, %params_and_buffers__vllm_model_language_model_model_layers_17_mlp_experts_w13_weight__.85, %params_and_buffers__vllm_model_language_model_model_layers_17_mlp_experts_w2_weight__.86, %dot_general.4288), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.4290 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.4289), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4267 = bf16[32,2048]{1,0} convert(%add.4266), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4291 = f32[32,2048]{1,0} convert(%convert_element_type.4267), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.4292 = f32[32,2048]{1,0} add(%convert_element_type.4290, %convert_element_type.4291), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.4294 = f32[32,2048]{1,0} power(%add.4292, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4299 = f32[32]{0} reduce(%pow.4294, %constant.512), dimensions={1}, to_apply=%region_104.4298, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4300 = f32[32,1]{1,0} reshape(%reduce_sum.4299), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4301 = f32[32,1]{1,0} divide(%broadcast_in_dim.4300, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4302 = f32[32,1]{1,0} add(%div.4301, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4303 = f32[32,1]{1,0} rsqrt(%add.4302), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4304 = f32[32,1]{1,0} broadcast(%rsqrt.4303), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4305 = f32[32]{0} reshape(%mul.4304), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4306 = f32[32,2048]{1,0} broadcast(%mul.4305), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4307 = f32[32,2048]{1,0} multiply(%add.4292, %mul.4306), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4308 = bf16[32,2048]{1,0} convert(%mul.4307), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_18_input_layernorm_weight__.93 = bf16[2048]{0} parameter(92), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.18.input_layernorm.weight\']"}
  %broadcast_in_dim.4309 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_18_input_layernorm_weight__.93), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4310 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.4309), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4311 = bf16[2048]{0} reshape(%mul.4310), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4312 = bf16[32,2048]{1,0} broadcast(%mul.4311), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4313 = bf16[32,2048]{1,0} multiply(%convert_element_type.4308, %mul.4312), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_18_self_attn_qkv_proj_weight__.101 = bf16[5120,2048]{1,0} parameter(100), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.18.self_attn.qkv_proj.weight\']"}
  %dot_general.4314 = bf16[32,5120]{1,0} dot(%mul.4313, %params_and_buffers__vllm_model_language_model_model_layers_18_self_attn_qkv_proj_weight__.101), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.4315 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.4314), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.4316 = bf16[32,4,1024]{2,1,0} slice(%reshape.4315), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.4320 = bf16[32,32,128]{2,1,0} reshape(%slice.4316), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.4321 = f32[32,32,128]{2,1,0} convert(%reshape.4320), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.4322 = f32[32,32,128]{2,1,0} power(%convert_element_type.4321, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4327 = f32[32,32]{1,0} reduce(%pow.4322, %constant.512), dimensions={2}, to_apply=%region_105.4326, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4328 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.4327), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4329 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.4328, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4330 = f32[32,32,1]{2,1,0} add(%div.4329, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4331 = f32[32,32,1]{2,1,0} rsqrt(%add.4330), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4332 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.4331), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4333 = f32[32,32]{1,0} reshape(%mul.4332), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4334 = f32[32,32,128]{2,1,0} broadcast(%mul.4333), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4335 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.4321, %mul.4334), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4336 = bf16[32,32,128]{2,1,0} convert(%mul.4335), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_18_self_attn_q_norm_weight__.100 = bf16[128]{0} parameter(99), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.18.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.4337 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_18_self_attn_q_norm_weight__.100), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4338 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.4337), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4339 = bf16[128]{0} reshape(%mul.4338), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4340 = bf16[32,32,128]{2,1,0} broadcast(%mul.4339), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4341 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.4336, %mul.4340), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4372 = bf16[32,32,64]{2,1,0} slice(%mul.4341), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.4363 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.4364 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.4365 = s32[32]{0} select(%lt.4363, %add.4364, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.4366 = s32[32,1]{1,0} reshape(%select_n.4365), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.4367 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.4366), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.4368 = bf16[32,64]{1,0} slice(%gather.4367), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4370 = bf16[32,1,64]{2,1,0} reshape(%slice.4368), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4374 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4370), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4375 = bf16[32,64]{1,0} reshape(%mul.4374), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4376 = bf16[32,32,64]{2,1,0} broadcast(%mul.4375), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4377 = bf16[32,32,64]{2,1,0} multiply(%slice.4372, %mul.4376), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4373 = bf16[32,32,64]{2,1,0} slice(%mul.4341), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.4369 = bf16[32,64]{1,0} slice(%gather.4367), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4371 = bf16[32,1,64]{2,1,0} reshape(%slice.4369), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4378 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4371), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4379 = bf16[32,64]{1,0} reshape(%mul.4378), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4380 = bf16[32,32,64]{2,1,0} broadcast(%mul.4379), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4381 = bf16[32,32,64]{2,1,0} multiply(%slice.4373, %mul.4380), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.4382 = bf16[32,32,64]{2,1,0} subtract(%mul.4377, %mul.4381), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.4383 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4370), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4384 = bf16[32,64]{1,0} reshape(%mul.4383), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4385 = bf16[32,32,64]{2,1,0} broadcast(%mul.4384), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4386 = bf16[32,32,64]{2,1,0} multiply(%slice.4373, %mul.4385), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4387 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4371), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4388 = bf16[32,64]{1,0} reshape(%mul.4387), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4389 = bf16[32,32,64]{2,1,0} broadcast(%mul.4388), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4390 = bf16[32,32,64]{2,1,0} multiply(%slice.4372, %mul.4389), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.4391 = bf16[32,32,64]{2,1,0} add(%mul.4386, %mul.4390), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.4392 = bf16[32,32,128]{2,1,0} concatenate(%sub.4382, %add.4391), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.4393 = bf16[32,4096]{1,0} reshape(%concatenate.4392), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.4317 = bf16[32,4,128]{2,1,0} slice(%reshape.4315), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.4342 = f32[32,4,128]{2,1,0} convert(%slice.4317), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.4343 = f32[32,4,128]{2,1,0} power(%convert_element_type.4342, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4348 = f32[32,4]{1,0} reduce(%pow.4343, %constant.512), dimensions={2}, to_apply=%region_106.4347, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4349 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.4348), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4350 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.4349, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4351 = f32[32,4,1]{2,1,0} add(%div.4350, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4352 = f32[32,4,1]{2,1,0} rsqrt(%add.4351), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4353 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.4352), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4354 = f32[32,4]{1,0} reshape(%mul.4353), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4355 = f32[32,4,128]{2,1,0} broadcast(%mul.4354), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4356 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.4342, %mul.4355), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4357 = bf16[32,4,128]{2,1,0} convert(%mul.4356), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_18_self_attn_k_norm_weight__.98 = bf16[128]{0} parameter(97), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.18.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.4358 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_18_self_attn_k_norm_weight__.98), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4359 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.4358), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4360 = bf16[128]{0} reshape(%mul.4359), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4361 = bf16[32,4,128]{2,1,0} broadcast(%mul.4360), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4362 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.4357, %mul.4361), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4396 = bf16[32,4,64]{2,1,0} slice(%mul.4362), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4394 = bf16[32,1,64]{2,1,0} reshape(%slice.4368), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4398 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4394), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4399 = bf16[32,64]{1,0} reshape(%mul.4398), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4400 = bf16[32,4,64]{2,1,0} broadcast(%mul.4399), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4401 = bf16[32,4,64]{2,1,0} multiply(%slice.4396, %mul.4400), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4397 = bf16[32,4,64]{2,1,0} slice(%mul.4362), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4395 = bf16[32,1,64]{2,1,0} reshape(%slice.4369), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4402 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4395), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4403 = bf16[32,64]{1,0} reshape(%mul.4402), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4404 = bf16[32,4,64]{2,1,0} broadcast(%mul.4403), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4405 = bf16[32,4,64]{2,1,0} multiply(%slice.4397, %mul.4404), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.4406 = bf16[32,4,64]{2,1,0} subtract(%mul.4401, %mul.4405), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.4407 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4394), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4408 = bf16[32,64]{1,0} reshape(%mul.4407), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4409 = bf16[32,4,64]{2,1,0} broadcast(%mul.4408), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4410 = bf16[32,4,64]{2,1,0} multiply(%slice.4397, %mul.4409), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4411 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4395), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4412 = bf16[32,64]{1,0} reshape(%mul.4411), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4413 = bf16[32,4,64]{2,1,0} broadcast(%mul.4412), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4414 = bf16[32,4,64]{2,1,0} multiply(%slice.4396, %mul.4413), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.4415 = bf16[32,4,64]{2,1,0} add(%mul.4410, %mul.4414), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.4416 = bf16[32,4,128]{2,1,0} concatenate(%sub.4406, %add.4415), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.4417 = bf16[32,512]{1,0} reshape(%concatenate.4416), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.4318 = bf16[32,4,128]{2,1,0} slice(%reshape.4315), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.4319 = bf16[32,512]{1,0} reshape(%slice.4318), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.4418 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_18_.454, %reshape.4393, %reshape.4417, %reshape.4319, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.4419 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.4418), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_19_.455 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(454), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[19]"}
  %jit__jax_attn_func_.4420 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.4418), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_18_self_attn_o_proj_weight__.99 = bf16[2048,4096]{1,0} parameter(98), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.18.self_attn.o_proj.weight\']"}
  %dot_general.4421 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.4420, %params_and_buffers__vllm_model_language_model_model_layers_18_self_attn_o_proj_weight__.99), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.4422 = f32[32,2048]{1,0} convert(%dot_general.4421), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4293 = bf16[32,2048]{1,0} convert(%add.4292), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4423 = f32[32,2048]{1,0} convert(%convert_element_type.4293), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.4424 = f32[32,2048]{1,0} add(%convert_element_type.4422, %convert_element_type.4423), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.4426 = f32[32,2048]{1,0} power(%add.4424, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4431 = f32[32]{0} reduce(%pow.4426, %constant.512), dimensions={1}, to_apply=%region_107.4430, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4432 = f32[32,1]{1,0} reshape(%reduce_sum.4431), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4433 = f32[32,1]{1,0} divide(%broadcast_in_dim.4432, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4434 = f32[32,1]{1,0} add(%div.4433, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4435 = f32[32,1]{1,0} rsqrt(%add.4434), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4436 = f32[32,1]{1,0} broadcast(%rsqrt.4435), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4437 = f32[32]{0} reshape(%mul.4436), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4438 = f32[32,2048]{1,0} broadcast(%mul.4437), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4439 = f32[32,2048]{1,0} multiply(%add.4424, %mul.4438), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4440 = bf16[32,2048]{1,0} convert(%mul.4439), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_18_post_attention_layernorm_weight__.97 = bf16[2048]{0} parameter(96), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.18.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.4441 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_18_post_attention_layernorm_weight__.97), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4442 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.4441), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4443 = bf16[2048]{0} reshape(%mul.4442), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4444 = bf16[32,2048]{1,0} broadcast(%mul.4443), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4445 = bf16[32,2048]{1,0} multiply(%convert_element_type.4440, %mul.4444), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_18_mlp_experts_w13_weight__.94 = bf16[128,1536,2048]{2,1,0} parameter(93), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.18.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_18_mlp_experts_w2_weight__.95 = bf16[128,2048,768]{2,1,0} parameter(94), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.18.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_18_mlp_gate_weight__.96 = bf16[128,2048]{1,0} parameter(95), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.18.mlp.gate.weight\']"}
  %dot_general.4446 = bf16[32,128]{1,0} dot(%mul.4445, %params_and_buffers__vllm_model_language_model_model_layers_18_mlp_gate_weight__.96), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.4447 = bf16[32,2048]{1,0} call(%mul.4445, %params_and_buffers__vllm_model_language_model_model_layers_18_mlp_experts_w13_weight__.94, %params_and_buffers__vllm_model_language_model_model_layers_18_mlp_experts_w2_weight__.95, %dot_general.4446), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.4448 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.4447), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4425 = bf16[32,2048]{1,0} convert(%add.4424), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4449 = f32[32,2048]{1,0} convert(%convert_element_type.4425), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.4450 = f32[32,2048]{1,0} add(%convert_element_type.4448, %convert_element_type.4449), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.4452 = f32[32,2048]{1,0} power(%add.4450, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4457 = f32[32]{0} reduce(%pow.4452, %constant.512), dimensions={1}, to_apply=%region_108.4456, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4458 = f32[32,1]{1,0} reshape(%reduce_sum.4457), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4459 = f32[32,1]{1,0} divide(%broadcast_in_dim.4458, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4460 = f32[32,1]{1,0} add(%div.4459, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4461 = f32[32,1]{1,0} rsqrt(%add.4460), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4462 = f32[32,1]{1,0} broadcast(%rsqrt.4461), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4463 = f32[32]{0} reshape(%mul.4462), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4464 = f32[32,2048]{1,0} broadcast(%mul.4463), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4465 = f32[32,2048]{1,0} multiply(%add.4450, %mul.4464), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4466 = bf16[32,2048]{1,0} convert(%mul.4465), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_19_input_layernorm_weight__.102 = bf16[2048]{0} parameter(101), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.19.input_layernorm.weight\']"}
  %broadcast_in_dim.4467 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_19_input_layernorm_weight__.102), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4468 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.4467), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4469 = bf16[2048]{0} reshape(%mul.4468), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4470 = bf16[32,2048]{1,0} broadcast(%mul.4469), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4471 = bf16[32,2048]{1,0} multiply(%convert_element_type.4466, %mul.4470), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_19_self_attn_qkv_proj_weight__.110 = bf16[5120,2048]{1,0} parameter(109), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.19.self_attn.qkv_proj.weight\']"}
  %dot_general.4472 = bf16[32,5120]{1,0} dot(%mul.4471, %params_and_buffers__vllm_model_language_model_model_layers_19_self_attn_qkv_proj_weight__.110), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.4473 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.4472), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.4474 = bf16[32,4,1024]{2,1,0} slice(%reshape.4473), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.4478 = bf16[32,32,128]{2,1,0} reshape(%slice.4474), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.4479 = f32[32,32,128]{2,1,0} convert(%reshape.4478), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.4480 = f32[32,32,128]{2,1,0} power(%convert_element_type.4479, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4485 = f32[32,32]{1,0} reduce(%pow.4480, %constant.512), dimensions={2}, to_apply=%region_109.4484, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4486 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.4485), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4487 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.4486, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4488 = f32[32,32,1]{2,1,0} add(%div.4487, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4489 = f32[32,32,1]{2,1,0} rsqrt(%add.4488), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4490 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.4489), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4491 = f32[32,32]{1,0} reshape(%mul.4490), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4492 = f32[32,32,128]{2,1,0} broadcast(%mul.4491), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4493 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.4479, %mul.4492), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4494 = bf16[32,32,128]{2,1,0} convert(%mul.4493), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_19_self_attn_q_norm_weight__.109 = bf16[128]{0} parameter(108), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.19.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.4495 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_19_self_attn_q_norm_weight__.109), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4496 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.4495), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4497 = bf16[128]{0} reshape(%mul.4496), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4498 = bf16[32,32,128]{2,1,0} broadcast(%mul.4497), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4499 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.4494, %mul.4498), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4530 = bf16[32,32,64]{2,1,0} slice(%mul.4499), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.4521 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.4522 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.4523 = s32[32]{0} select(%lt.4521, %add.4522, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.4524 = s32[32,1]{1,0} reshape(%select_n.4523), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.4525 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.4524), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.4526 = bf16[32,64]{1,0} slice(%gather.4525), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4528 = bf16[32,1,64]{2,1,0} reshape(%slice.4526), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4532 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4528), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4533 = bf16[32,64]{1,0} reshape(%mul.4532), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4534 = bf16[32,32,64]{2,1,0} broadcast(%mul.4533), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4535 = bf16[32,32,64]{2,1,0} multiply(%slice.4530, %mul.4534), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4531 = bf16[32,32,64]{2,1,0} slice(%mul.4499), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.4527 = bf16[32,64]{1,0} slice(%gather.4525), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4529 = bf16[32,1,64]{2,1,0} reshape(%slice.4527), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4536 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4529), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4537 = bf16[32,64]{1,0} reshape(%mul.4536), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4538 = bf16[32,32,64]{2,1,0} broadcast(%mul.4537), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4539 = bf16[32,32,64]{2,1,0} multiply(%slice.4531, %mul.4538), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.4540 = bf16[32,32,64]{2,1,0} subtract(%mul.4535, %mul.4539), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.4541 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4528), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4542 = bf16[32,64]{1,0} reshape(%mul.4541), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4543 = bf16[32,32,64]{2,1,0} broadcast(%mul.4542), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4544 = bf16[32,32,64]{2,1,0} multiply(%slice.4531, %mul.4543), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4545 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4529), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4546 = bf16[32,64]{1,0} reshape(%mul.4545), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4547 = bf16[32,32,64]{2,1,0} broadcast(%mul.4546), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4548 = bf16[32,32,64]{2,1,0} multiply(%slice.4530, %mul.4547), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.4549 = bf16[32,32,64]{2,1,0} add(%mul.4544, %mul.4548), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.4550 = bf16[32,32,128]{2,1,0} concatenate(%sub.4540, %add.4549), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.4551 = bf16[32,4096]{1,0} reshape(%concatenate.4550), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.4475 = bf16[32,4,128]{2,1,0} slice(%reshape.4473), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.4500 = f32[32,4,128]{2,1,0} convert(%slice.4475), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.4501 = f32[32,4,128]{2,1,0} power(%convert_element_type.4500, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4506 = f32[32,4]{1,0} reduce(%pow.4501, %constant.512), dimensions={2}, to_apply=%region_110.4505, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4507 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.4506), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4508 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.4507, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4509 = f32[32,4,1]{2,1,0} add(%div.4508, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4510 = f32[32,4,1]{2,1,0} rsqrt(%add.4509), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4511 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.4510), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4512 = f32[32,4]{1,0} reshape(%mul.4511), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4513 = f32[32,4,128]{2,1,0} broadcast(%mul.4512), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4514 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.4500, %mul.4513), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4515 = bf16[32,4,128]{2,1,0} convert(%mul.4514), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_19_self_attn_k_norm_weight__.107 = bf16[128]{0} parameter(106), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.19.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.4516 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_19_self_attn_k_norm_weight__.107), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4517 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.4516), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4518 = bf16[128]{0} reshape(%mul.4517), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4519 = bf16[32,4,128]{2,1,0} broadcast(%mul.4518), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4520 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.4515, %mul.4519), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4554 = bf16[32,4,64]{2,1,0} slice(%mul.4520), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4552 = bf16[32,1,64]{2,1,0} reshape(%slice.4526), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4556 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4552), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4557 = bf16[32,64]{1,0} reshape(%mul.4556), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4558 = bf16[32,4,64]{2,1,0} broadcast(%mul.4557), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4559 = bf16[32,4,64]{2,1,0} multiply(%slice.4554, %mul.4558), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4555 = bf16[32,4,64]{2,1,0} slice(%mul.4520), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4553 = bf16[32,1,64]{2,1,0} reshape(%slice.4527), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4560 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4553), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4561 = bf16[32,64]{1,0} reshape(%mul.4560), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4562 = bf16[32,4,64]{2,1,0} broadcast(%mul.4561), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4563 = bf16[32,4,64]{2,1,0} multiply(%slice.4555, %mul.4562), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.4564 = bf16[32,4,64]{2,1,0} subtract(%mul.4559, %mul.4563), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.4565 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4552), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4566 = bf16[32,64]{1,0} reshape(%mul.4565), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4567 = bf16[32,4,64]{2,1,0} broadcast(%mul.4566), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4568 = bf16[32,4,64]{2,1,0} multiply(%slice.4555, %mul.4567), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4569 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4553), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4570 = bf16[32,64]{1,0} reshape(%mul.4569), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4571 = bf16[32,4,64]{2,1,0} broadcast(%mul.4570), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4572 = bf16[32,4,64]{2,1,0} multiply(%slice.4554, %mul.4571), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.4573 = bf16[32,4,64]{2,1,0} add(%mul.4568, %mul.4572), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.4574 = bf16[32,4,128]{2,1,0} concatenate(%sub.4564, %add.4573), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.4575 = bf16[32,512]{1,0} reshape(%concatenate.4574), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.4476 = bf16[32,4,128]{2,1,0} slice(%reshape.4473), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.4477 = bf16[32,512]{1,0} reshape(%slice.4476), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.4576 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_19_.455, %reshape.4551, %reshape.4575, %reshape.4477, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.4577 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.4576), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_20_.456 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(455), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[20]"}
  %jit__jax_attn_func_.4578 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.4576), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_19_self_attn_o_proj_weight__.108 = bf16[2048,4096]{1,0} parameter(107), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.19.self_attn.o_proj.weight\']"}
  %dot_general.4579 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.4578, %params_and_buffers__vllm_model_language_model_model_layers_19_self_attn_o_proj_weight__.108), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.4580 = f32[32,2048]{1,0} convert(%dot_general.4579), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4451 = bf16[32,2048]{1,0} convert(%add.4450), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4581 = f32[32,2048]{1,0} convert(%convert_element_type.4451), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.4582 = f32[32,2048]{1,0} add(%convert_element_type.4580, %convert_element_type.4581), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.4584 = f32[32,2048]{1,0} power(%add.4582, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4589 = f32[32]{0} reduce(%pow.4584, %constant.512), dimensions={1}, to_apply=%region_111.4588, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4590 = f32[32,1]{1,0} reshape(%reduce_sum.4589), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4591 = f32[32,1]{1,0} divide(%broadcast_in_dim.4590, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4592 = f32[32,1]{1,0} add(%div.4591, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4593 = f32[32,1]{1,0} rsqrt(%add.4592), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4594 = f32[32,1]{1,0} broadcast(%rsqrt.4593), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4595 = f32[32]{0} reshape(%mul.4594), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4596 = f32[32,2048]{1,0} broadcast(%mul.4595), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4597 = f32[32,2048]{1,0} multiply(%add.4582, %mul.4596), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4598 = bf16[32,2048]{1,0} convert(%mul.4597), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_19_post_attention_layernorm_weight__.106 = bf16[2048]{0} parameter(105), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.19.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.4599 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_19_post_attention_layernorm_weight__.106), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4600 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.4599), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4601 = bf16[2048]{0} reshape(%mul.4600), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4602 = bf16[32,2048]{1,0} broadcast(%mul.4601), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4603 = bf16[32,2048]{1,0} multiply(%convert_element_type.4598, %mul.4602), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_19_mlp_experts_w13_weight__.103 = bf16[128,1536,2048]{2,1,0} parameter(102), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.19.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_19_mlp_experts_w2_weight__.104 = bf16[128,2048,768]{2,1,0} parameter(103), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.19.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_19_mlp_gate_weight__.105 = bf16[128,2048]{1,0} parameter(104), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.19.mlp.gate.weight\']"}
  %dot_general.4604 = bf16[32,128]{1,0} dot(%mul.4603, %params_and_buffers__vllm_model_language_model_model_layers_19_mlp_gate_weight__.105), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.4605 = bf16[32,2048]{1,0} call(%mul.4603, %params_and_buffers__vllm_model_language_model_model_layers_19_mlp_experts_w13_weight__.103, %params_and_buffers__vllm_model_language_model_model_layers_19_mlp_experts_w2_weight__.104, %dot_general.4604), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.4606 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.4605), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4583 = bf16[32,2048]{1,0} convert(%add.4582), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4607 = f32[32,2048]{1,0} convert(%convert_element_type.4583), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.4608 = f32[32,2048]{1,0} add(%convert_element_type.4606, %convert_element_type.4607), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.4610 = f32[32,2048]{1,0} power(%add.4608, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4615 = f32[32]{0} reduce(%pow.4610, %constant.512), dimensions={1}, to_apply=%region_112.4614, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4616 = f32[32,1]{1,0} reshape(%reduce_sum.4615), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4617 = f32[32,1]{1,0} divide(%broadcast_in_dim.4616, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4618 = f32[32,1]{1,0} add(%div.4617, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4619 = f32[32,1]{1,0} rsqrt(%add.4618), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4620 = f32[32,1]{1,0} broadcast(%rsqrt.4619), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4621 = f32[32]{0} reshape(%mul.4620), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4622 = f32[32,2048]{1,0} broadcast(%mul.4621), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4623 = f32[32,2048]{1,0} multiply(%add.4608, %mul.4622), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4624 = bf16[32,2048]{1,0} convert(%mul.4623), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_20_input_layernorm_weight__.120 = bf16[2048]{0} parameter(119), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.20.input_layernorm.weight\']"}
  %broadcast_in_dim.4625 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_20_input_layernorm_weight__.120), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4626 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.4625), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4627 = bf16[2048]{0} reshape(%mul.4626), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4628 = bf16[32,2048]{1,0} broadcast(%mul.4627), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4629 = bf16[32,2048]{1,0} multiply(%convert_element_type.4624, %mul.4628), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_20_self_attn_qkv_proj_weight__.128 = bf16[5120,2048]{1,0} parameter(127), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.20.self_attn.qkv_proj.weight\']"}
  %dot_general.4630 = bf16[32,5120]{1,0} dot(%mul.4629, %params_and_buffers__vllm_model_language_model_model_layers_20_self_attn_qkv_proj_weight__.128), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.4631 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.4630), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.4632 = bf16[32,4,1024]{2,1,0} slice(%reshape.4631), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.4636 = bf16[32,32,128]{2,1,0} reshape(%slice.4632), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.4637 = f32[32,32,128]{2,1,0} convert(%reshape.4636), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.4638 = f32[32,32,128]{2,1,0} power(%convert_element_type.4637, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4643 = f32[32,32]{1,0} reduce(%pow.4638, %constant.512), dimensions={2}, to_apply=%region_113.4642, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4644 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.4643), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4645 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.4644, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4646 = f32[32,32,1]{2,1,0} add(%div.4645, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4647 = f32[32,32,1]{2,1,0} rsqrt(%add.4646), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4648 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.4647), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4649 = f32[32,32]{1,0} reshape(%mul.4648), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4650 = f32[32,32,128]{2,1,0} broadcast(%mul.4649), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4651 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.4637, %mul.4650), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4652 = bf16[32,32,128]{2,1,0} convert(%mul.4651), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_20_self_attn_q_norm_weight__.127 = bf16[128]{0} parameter(126), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.20.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.4653 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_20_self_attn_q_norm_weight__.127), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4654 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.4653), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4655 = bf16[128]{0} reshape(%mul.4654), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4656 = bf16[32,32,128]{2,1,0} broadcast(%mul.4655), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4657 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.4652, %mul.4656), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4688 = bf16[32,32,64]{2,1,0} slice(%mul.4657), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.4679 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.4680 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.4681 = s32[32]{0} select(%lt.4679, %add.4680, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.4682 = s32[32,1]{1,0} reshape(%select_n.4681), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.4683 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.4682), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.4684 = bf16[32,64]{1,0} slice(%gather.4683), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4686 = bf16[32,1,64]{2,1,0} reshape(%slice.4684), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4690 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4686), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4691 = bf16[32,64]{1,0} reshape(%mul.4690), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4692 = bf16[32,32,64]{2,1,0} broadcast(%mul.4691), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4693 = bf16[32,32,64]{2,1,0} multiply(%slice.4688, %mul.4692), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4689 = bf16[32,32,64]{2,1,0} slice(%mul.4657), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.4685 = bf16[32,64]{1,0} slice(%gather.4683), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4687 = bf16[32,1,64]{2,1,0} reshape(%slice.4685), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4694 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4687), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4695 = bf16[32,64]{1,0} reshape(%mul.4694), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4696 = bf16[32,32,64]{2,1,0} broadcast(%mul.4695), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4697 = bf16[32,32,64]{2,1,0} multiply(%slice.4689, %mul.4696), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.4698 = bf16[32,32,64]{2,1,0} subtract(%mul.4693, %mul.4697), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.4699 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4686), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4700 = bf16[32,64]{1,0} reshape(%mul.4699), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4701 = bf16[32,32,64]{2,1,0} broadcast(%mul.4700), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4702 = bf16[32,32,64]{2,1,0} multiply(%slice.4689, %mul.4701), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4703 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4687), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4704 = bf16[32,64]{1,0} reshape(%mul.4703), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4705 = bf16[32,32,64]{2,1,0} broadcast(%mul.4704), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4706 = bf16[32,32,64]{2,1,0} multiply(%slice.4688, %mul.4705), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.4707 = bf16[32,32,64]{2,1,0} add(%mul.4702, %mul.4706), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.4708 = bf16[32,32,128]{2,1,0} concatenate(%sub.4698, %add.4707), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.4709 = bf16[32,4096]{1,0} reshape(%concatenate.4708), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.4633 = bf16[32,4,128]{2,1,0} slice(%reshape.4631), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.4658 = f32[32,4,128]{2,1,0} convert(%slice.4633), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.4659 = f32[32,4,128]{2,1,0} power(%convert_element_type.4658, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4664 = f32[32,4]{1,0} reduce(%pow.4659, %constant.512), dimensions={2}, to_apply=%region_114.4663, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4665 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.4664), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4666 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.4665, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4667 = f32[32,4,1]{2,1,0} add(%div.4666, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4668 = f32[32,4,1]{2,1,0} rsqrt(%add.4667), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4669 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.4668), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4670 = f32[32,4]{1,0} reshape(%mul.4669), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4671 = f32[32,4,128]{2,1,0} broadcast(%mul.4670), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4672 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.4658, %mul.4671), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4673 = bf16[32,4,128]{2,1,0} convert(%mul.4672), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_20_self_attn_k_norm_weight__.125 = bf16[128]{0} parameter(124), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.20.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.4674 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_20_self_attn_k_norm_weight__.125), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4675 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.4674), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4676 = bf16[128]{0} reshape(%mul.4675), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4677 = bf16[32,4,128]{2,1,0} broadcast(%mul.4676), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4678 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.4673, %mul.4677), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4712 = bf16[32,4,64]{2,1,0} slice(%mul.4678), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4710 = bf16[32,1,64]{2,1,0} reshape(%slice.4684), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4714 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4710), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4715 = bf16[32,64]{1,0} reshape(%mul.4714), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4716 = bf16[32,4,64]{2,1,0} broadcast(%mul.4715), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4717 = bf16[32,4,64]{2,1,0} multiply(%slice.4712, %mul.4716), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4713 = bf16[32,4,64]{2,1,0} slice(%mul.4678), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4711 = bf16[32,1,64]{2,1,0} reshape(%slice.4685), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4718 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4711), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4719 = bf16[32,64]{1,0} reshape(%mul.4718), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4720 = bf16[32,4,64]{2,1,0} broadcast(%mul.4719), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4721 = bf16[32,4,64]{2,1,0} multiply(%slice.4713, %mul.4720), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.4722 = bf16[32,4,64]{2,1,0} subtract(%mul.4717, %mul.4721), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.4723 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4710), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4724 = bf16[32,64]{1,0} reshape(%mul.4723), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4725 = bf16[32,4,64]{2,1,0} broadcast(%mul.4724), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4726 = bf16[32,4,64]{2,1,0} multiply(%slice.4713, %mul.4725), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4727 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4711), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4728 = bf16[32,64]{1,0} reshape(%mul.4727), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4729 = bf16[32,4,64]{2,1,0} broadcast(%mul.4728), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4730 = bf16[32,4,64]{2,1,0} multiply(%slice.4712, %mul.4729), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.4731 = bf16[32,4,64]{2,1,0} add(%mul.4726, %mul.4730), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.4732 = bf16[32,4,128]{2,1,0} concatenate(%sub.4722, %add.4731), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.4733 = bf16[32,512]{1,0} reshape(%concatenate.4732), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.4634 = bf16[32,4,128]{2,1,0} slice(%reshape.4631), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.4635 = bf16[32,512]{1,0} reshape(%slice.4634), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.4734 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_20_.456, %reshape.4709, %reshape.4733, %reshape.4635, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.4735 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.4734), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_21_.457 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(456), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[21]"}
  %jit__jax_attn_func_.4736 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.4734), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_20_self_attn_o_proj_weight__.126 = bf16[2048,4096]{1,0} parameter(125), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.20.self_attn.o_proj.weight\']"}
  %dot_general.4737 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.4736, %params_and_buffers__vllm_model_language_model_model_layers_20_self_attn_o_proj_weight__.126), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.4738 = f32[32,2048]{1,0} convert(%dot_general.4737), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4609 = bf16[32,2048]{1,0} convert(%add.4608), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4739 = f32[32,2048]{1,0} convert(%convert_element_type.4609), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.4740 = f32[32,2048]{1,0} add(%convert_element_type.4738, %convert_element_type.4739), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.4742 = f32[32,2048]{1,0} power(%add.4740, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4747 = f32[32]{0} reduce(%pow.4742, %constant.512), dimensions={1}, to_apply=%region_115.4746, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4748 = f32[32,1]{1,0} reshape(%reduce_sum.4747), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4749 = f32[32,1]{1,0} divide(%broadcast_in_dim.4748, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4750 = f32[32,1]{1,0} add(%div.4749, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4751 = f32[32,1]{1,0} rsqrt(%add.4750), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4752 = f32[32,1]{1,0} broadcast(%rsqrt.4751), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4753 = f32[32]{0} reshape(%mul.4752), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4754 = f32[32,2048]{1,0} broadcast(%mul.4753), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4755 = f32[32,2048]{1,0} multiply(%add.4740, %mul.4754), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4756 = bf16[32,2048]{1,0} convert(%mul.4755), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_20_post_attention_layernorm_weight__.124 = bf16[2048]{0} parameter(123), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.20.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.4757 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_20_post_attention_layernorm_weight__.124), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4758 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.4757), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4759 = bf16[2048]{0} reshape(%mul.4758), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4760 = bf16[32,2048]{1,0} broadcast(%mul.4759), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4761 = bf16[32,2048]{1,0} multiply(%convert_element_type.4756, %mul.4760), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_20_mlp_experts_w13_weight__.121 = bf16[128,1536,2048]{2,1,0} parameter(120), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.20.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_20_mlp_experts_w2_weight__.122 = bf16[128,2048,768]{2,1,0} parameter(121), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.20.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_20_mlp_gate_weight__.123 = bf16[128,2048]{1,0} parameter(122), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.20.mlp.gate.weight\']"}
  %dot_general.4762 = bf16[32,128]{1,0} dot(%mul.4761, %params_and_buffers__vllm_model_language_model_model_layers_20_mlp_gate_weight__.123), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.4763 = bf16[32,2048]{1,0} call(%mul.4761, %params_and_buffers__vllm_model_language_model_model_layers_20_mlp_experts_w13_weight__.121, %params_and_buffers__vllm_model_language_model_model_layers_20_mlp_experts_w2_weight__.122, %dot_general.4762), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.4764 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.4763), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4741 = bf16[32,2048]{1,0} convert(%add.4740), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4765 = f32[32,2048]{1,0} convert(%convert_element_type.4741), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.4766 = f32[32,2048]{1,0} add(%convert_element_type.4764, %convert_element_type.4765), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.4768 = f32[32,2048]{1,0} power(%add.4766, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4773 = f32[32]{0} reduce(%pow.4768, %constant.512), dimensions={1}, to_apply=%region_116.4772, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4774 = f32[32,1]{1,0} reshape(%reduce_sum.4773), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4775 = f32[32,1]{1,0} divide(%broadcast_in_dim.4774, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4776 = f32[32,1]{1,0} add(%div.4775, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4777 = f32[32,1]{1,0} rsqrt(%add.4776), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4778 = f32[32,1]{1,0} broadcast(%rsqrt.4777), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4779 = f32[32]{0} reshape(%mul.4778), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4780 = f32[32,2048]{1,0} broadcast(%mul.4779), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4781 = f32[32,2048]{1,0} multiply(%add.4766, %mul.4780), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4782 = bf16[32,2048]{1,0} convert(%mul.4781), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_21_input_layernorm_weight__.129 = bf16[2048]{0} parameter(128), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.21.input_layernorm.weight\']"}
  %broadcast_in_dim.4783 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_21_input_layernorm_weight__.129), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4784 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.4783), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4785 = bf16[2048]{0} reshape(%mul.4784), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4786 = bf16[32,2048]{1,0} broadcast(%mul.4785), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4787 = bf16[32,2048]{1,0} multiply(%convert_element_type.4782, %mul.4786), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_21_self_attn_qkv_proj_weight__.137 = bf16[5120,2048]{1,0} parameter(136), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.21.self_attn.qkv_proj.weight\']"}
  %dot_general.4788 = bf16[32,5120]{1,0} dot(%mul.4787, %params_and_buffers__vllm_model_language_model_model_layers_21_self_attn_qkv_proj_weight__.137), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.4789 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.4788), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.4790 = bf16[32,4,1024]{2,1,0} slice(%reshape.4789), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.4794 = bf16[32,32,128]{2,1,0} reshape(%slice.4790), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.4795 = f32[32,32,128]{2,1,0} convert(%reshape.4794), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.4796 = f32[32,32,128]{2,1,0} power(%convert_element_type.4795, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4801 = f32[32,32]{1,0} reduce(%pow.4796, %constant.512), dimensions={2}, to_apply=%region_117.4800, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4802 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.4801), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4803 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.4802, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4804 = f32[32,32,1]{2,1,0} add(%div.4803, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4805 = f32[32,32,1]{2,1,0} rsqrt(%add.4804), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4806 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.4805), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4807 = f32[32,32]{1,0} reshape(%mul.4806), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4808 = f32[32,32,128]{2,1,0} broadcast(%mul.4807), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4809 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.4795, %mul.4808), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4810 = bf16[32,32,128]{2,1,0} convert(%mul.4809), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_21_self_attn_q_norm_weight__.136 = bf16[128]{0} parameter(135), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.21.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.4811 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_21_self_attn_q_norm_weight__.136), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4812 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.4811), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4813 = bf16[128]{0} reshape(%mul.4812), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4814 = bf16[32,32,128]{2,1,0} broadcast(%mul.4813), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4815 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.4810, %mul.4814), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4846 = bf16[32,32,64]{2,1,0} slice(%mul.4815), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.4837 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.4838 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.4839 = s32[32]{0} select(%lt.4837, %add.4838, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.4840 = s32[32,1]{1,0} reshape(%select_n.4839), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.4841 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.4840), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.4842 = bf16[32,64]{1,0} slice(%gather.4841), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4844 = bf16[32,1,64]{2,1,0} reshape(%slice.4842), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4848 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4844), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4849 = bf16[32,64]{1,0} reshape(%mul.4848), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4850 = bf16[32,32,64]{2,1,0} broadcast(%mul.4849), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4851 = bf16[32,32,64]{2,1,0} multiply(%slice.4846, %mul.4850), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4847 = bf16[32,32,64]{2,1,0} slice(%mul.4815), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.4843 = bf16[32,64]{1,0} slice(%gather.4841), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4845 = bf16[32,1,64]{2,1,0} reshape(%slice.4843), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4852 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4845), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4853 = bf16[32,64]{1,0} reshape(%mul.4852), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4854 = bf16[32,32,64]{2,1,0} broadcast(%mul.4853), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4855 = bf16[32,32,64]{2,1,0} multiply(%slice.4847, %mul.4854), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.4856 = bf16[32,32,64]{2,1,0} subtract(%mul.4851, %mul.4855), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.4857 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4844), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4858 = bf16[32,64]{1,0} reshape(%mul.4857), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4859 = bf16[32,32,64]{2,1,0} broadcast(%mul.4858), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4860 = bf16[32,32,64]{2,1,0} multiply(%slice.4847, %mul.4859), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4861 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4845), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4862 = bf16[32,64]{1,0} reshape(%mul.4861), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4863 = bf16[32,32,64]{2,1,0} broadcast(%mul.4862), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4864 = bf16[32,32,64]{2,1,0} multiply(%slice.4846, %mul.4863), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.4865 = bf16[32,32,64]{2,1,0} add(%mul.4860, %mul.4864), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.4866 = bf16[32,32,128]{2,1,0} concatenate(%sub.4856, %add.4865), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.4867 = bf16[32,4096]{1,0} reshape(%concatenate.4866), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.4791 = bf16[32,4,128]{2,1,0} slice(%reshape.4789), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.4816 = f32[32,4,128]{2,1,0} convert(%slice.4791), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.4817 = f32[32,4,128]{2,1,0} power(%convert_element_type.4816, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4822 = f32[32,4]{1,0} reduce(%pow.4817, %constant.512), dimensions={2}, to_apply=%region_118.4821, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4823 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.4822), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4824 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.4823, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4825 = f32[32,4,1]{2,1,0} add(%div.4824, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4826 = f32[32,4,1]{2,1,0} rsqrt(%add.4825), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4827 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.4826), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4828 = f32[32,4]{1,0} reshape(%mul.4827), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4829 = f32[32,4,128]{2,1,0} broadcast(%mul.4828), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4830 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.4816, %mul.4829), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4831 = bf16[32,4,128]{2,1,0} convert(%mul.4830), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_21_self_attn_k_norm_weight__.134 = bf16[128]{0} parameter(133), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.21.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.4832 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_21_self_attn_k_norm_weight__.134), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4833 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.4832), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4834 = bf16[128]{0} reshape(%mul.4833), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4835 = bf16[32,4,128]{2,1,0} broadcast(%mul.4834), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4836 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.4831, %mul.4835), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4870 = bf16[32,4,64]{2,1,0} slice(%mul.4836), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4868 = bf16[32,1,64]{2,1,0} reshape(%slice.4842), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4872 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4868), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4873 = bf16[32,64]{1,0} reshape(%mul.4872), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4874 = bf16[32,4,64]{2,1,0} broadcast(%mul.4873), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4875 = bf16[32,4,64]{2,1,0} multiply(%slice.4870, %mul.4874), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.4871 = bf16[32,4,64]{2,1,0} slice(%mul.4836), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.4869 = bf16[32,1,64]{2,1,0} reshape(%slice.4843), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.4876 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4869), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4877 = bf16[32,64]{1,0} reshape(%mul.4876), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4878 = bf16[32,4,64]{2,1,0} broadcast(%mul.4877), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4879 = bf16[32,4,64]{2,1,0} multiply(%slice.4871, %mul.4878), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.4880 = bf16[32,4,64]{2,1,0} subtract(%mul.4875, %mul.4879), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.4881 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4868), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4882 = bf16[32,64]{1,0} reshape(%mul.4881), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4883 = bf16[32,4,64]{2,1,0} broadcast(%mul.4882), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4884 = bf16[32,4,64]{2,1,0} multiply(%slice.4871, %mul.4883), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4885 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.4869), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4886 = bf16[32,64]{1,0} reshape(%mul.4885), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4887 = bf16[32,4,64]{2,1,0} broadcast(%mul.4886), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4888 = bf16[32,4,64]{2,1,0} multiply(%slice.4870, %mul.4887), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.4889 = bf16[32,4,64]{2,1,0} add(%mul.4884, %mul.4888), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.4890 = bf16[32,4,128]{2,1,0} concatenate(%sub.4880, %add.4889), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.4891 = bf16[32,512]{1,0} reshape(%concatenate.4890), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.4792 = bf16[32,4,128]{2,1,0} slice(%reshape.4789), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.4793 = bf16[32,512]{1,0} reshape(%slice.4792), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.4892 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_21_.457, %reshape.4867, %reshape.4891, %reshape.4793, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.4893 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.4892), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_22_.458 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(457), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[22]"}
  %jit__jax_attn_func_.4894 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.4892), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_21_self_attn_o_proj_weight__.135 = bf16[2048,4096]{1,0} parameter(134), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.21.self_attn.o_proj.weight\']"}
  %dot_general.4895 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.4894, %params_and_buffers__vllm_model_language_model_model_layers_21_self_attn_o_proj_weight__.135), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.4896 = f32[32,2048]{1,0} convert(%dot_general.4895), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4767 = bf16[32,2048]{1,0} convert(%add.4766), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4897 = f32[32,2048]{1,0} convert(%convert_element_type.4767), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.4898 = f32[32,2048]{1,0} add(%convert_element_type.4896, %convert_element_type.4897), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.4900 = f32[32,2048]{1,0} power(%add.4898, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4905 = f32[32]{0} reduce(%pow.4900, %constant.512), dimensions={1}, to_apply=%region_119.4904, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4906 = f32[32,1]{1,0} reshape(%reduce_sum.4905), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4907 = f32[32,1]{1,0} divide(%broadcast_in_dim.4906, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4908 = f32[32,1]{1,0} add(%div.4907, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4909 = f32[32,1]{1,0} rsqrt(%add.4908), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4910 = f32[32,1]{1,0} broadcast(%rsqrt.4909), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4911 = f32[32]{0} reshape(%mul.4910), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4912 = f32[32,2048]{1,0} broadcast(%mul.4911), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4913 = f32[32,2048]{1,0} multiply(%add.4898, %mul.4912), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4914 = bf16[32,2048]{1,0} convert(%mul.4913), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_21_post_attention_layernorm_weight__.133 = bf16[2048]{0} parameter(132), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.21.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.4915 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_21_post_attention_layernorm_weight__.133), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4916 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.4915), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4917 = bf16[2048]{0} reshape(%mul.4916), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4918 = bf16[32,2048]{1,0} broadcast(%mul.4917), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4919 = bf16[32,2048]{1,0} multiply(%convert_element_type.4914, %mul.4918), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_21_mlp_experts_w13_weight__.130 = bf16[128,1536,2048]{2,1,0} parameter(129), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.21.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_21_mlp_experts_w2_weight__.131 = bf16[128,2048,768]{2,1,0} parameter(130), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.21.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_21_mlp_gate_weight__.132 = bf16[128,2048]{1,0} parameter(131), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.21.mlp.gate.weight\']"}
  %dot_general.4920 = bf16[32,128]{1,0} dot(%mul.4919, %params_and_buffers__vllm_model_language_model_model_layers_21_mlp_gate_weight__.132), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.4921 = bf16[32,2048]{1,0} call(%mul.4919, %params_and_buffers__vllm_model_language_model_model_layers_21_mlp_experts_w13_weight__.130, %params_and_buffers__vllm_model_language_model_model_layers_21_mlp_experts_w2_weight__.131, %dot_general.4920), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.4922 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.4921), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4899 = bf16[32,2048]{1,0} convert(%add.4898), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4923 = f32[32,2048]{1,0} convert(%convert_element_type.4899), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.4924 = f32[32,2048]{1,0} add(%convert_element_type.4922, %convert_element_type.4923), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.4926 = f32[32,2048]{1,0} power(%add.4924, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4931 = f32[32]{0} reduce(%pow.4926, %constant.512), dimensions={1}, to_apply=%region_120.4930, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4932 = f32[32,1]{1,0} reshape(%reduce_sum.4931), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4933 = f32[32,1]{1,0} divide(%broadcast_in_dim.4932, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4934 = f32[32,1]{1,0} add(%div.4933, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4935 = f32[32,1]{1,0} rsqrt(%add.4934), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4936 = f32[32,1]{1,0} broadcast(%rsqrt.4935), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4937 = f32[32]{0} reshape(%mul.4936), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4938 = f32[32,2048]{1,0} broadcast(%mul.4937), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4939 = f32[32,2048]{1,0} multiply(%add.4924, %mul.4938), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4940 = bf16[32,2048]{1,0} convert(%mul.4939), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_22_input_layernorm_weight__.138 = bf16[2048]{0} parameter(137), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.22.input_layernorm.weight\']"}
  %broadcast_in_dim.4941 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_22_input_layernorm_weight__.138), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4942 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.4941), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4943 = bf16[2048]{0} reshape(%mul.4942), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4944 = bf16[32,2048]{1,0} broadcast(%mul.4943), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4945 = bf16[32,2048]{1,0} multiply(%convert_element_type.4940, %mul.4944), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_22_self_attn_qkv_proj_weight__.146 = bf16[5120,2048]{1,0} parameter(145), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.22.self_attn.qkv_proj.weight\']"}
  %dot_general.4946 = bf16[32,5120]{1,0} dot(%mul.4945, %params_and_buffers__vllm_model_language_model_model_layers_22_self_attn_qkv_proj_weight__.146), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.4947 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.4946), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.4948 = bf16[32,4,1024]{2,1,0} slice(%reshape.4947), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.4952 = bf16[32,32,128]{2,1,0} reshape(%slice.4948), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.4953 = f32[32,32,128]{2,1,0} convert(%reshape.4952), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.4954 = f32[32,32,128]{2,1,0} power(%convert_element_type.4953, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4959 = f32[32,32]{1,0} reduce(%pow.4954, %constant.512), dimensions={2}, to_apply=%region_121.4958, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4960 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.4959), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4961 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.4960, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4962 = f32[32,32,1]{2,1,0} add(%div.4961, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4963 = f32[32,32,1]{2,1,0} rsqrt(%add.4962), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4964 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.4963), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4965 = f32[32,32]{1,0} reshape(%mul.4964), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4966 = f32[32,32,128]{2,1,0} broadcast(%mul.4965), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4967 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.4953, %mul.4966), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4968 = bf16[32,32,128]{2,1,0} convert(%mul.4967), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_22_self_attn_q_norm_weight__.145 = bf16[128]{0} parameter(144), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.22.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.4969 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_22_self_attn_q_norm_weight__.145), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4970 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.4969), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4971 = bf16[128]{0} reshape(%mul.4970), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4972 = bf16[32,32,128]{2,1,0} broadcast(%mul.4971), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4973 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.4968, %mul.4972), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5004 = bf16[32,32,64]{2,1,0} slice(%mul.4973), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.4995 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.4996 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.4997 = s32[32]{0} select(%lt.4995, %add.4996, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.4998 = s32[32,1]{1,0} reshape(%select_n.4997), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.4999 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.4998), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.5000 = bf16[32,64]{1,0} slice(%gather.4999), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5002 = bf16[32,1,64]{2,1,0} reshape(%slice.5000), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5006 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5002), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5007 = bf16[32,64]{1,0} reshape(%mul.5006), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5008 = bf16[32,32,64]{2,1,0} broadcast(%mul.5007), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5009 = bf16[32,32,64]{2,1,0} multiply(%slice.5004, %mul.5008), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5005 = bf16[32,32,64]{2,1,0} slice(%mul.4973), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.5001 = bf16[32,64]{1,0} slice(%gather.4999), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5003 = bf16[32,1,64]{2,1,0} reshape(%slice.5001), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5010 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5003), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5011 = bf16[32,64]{1,0} reshape(%mul.5010), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5012 = bf16[32,32,64]{2,1,0} broadcast(%mul.5011), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5013 = bf16[32,32,64]{2,1,0} multiply(%slice.5005, %mul.5012), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.5014 = bf16[32,32,64]{2,1,0} subtract(%mul.5009, %mul.5013), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.5015 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5002), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5016 = bf16[32,64]{1,0} reshape(%mul.5015), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5017 = bf16[32,32,64]{2,1,0} broadcast(%mul.5016), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5018 = bf16[32,32,64]{2,1,0} multiply(%slice.5005, %mul.5017), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5019 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5003), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5020 = bf16[32,64]{1,0} reshape(%mul.5019), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5021 = bf16[32,32,64]{2,1,0} broadcast(%mul.5020), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5022 = bf16[32,32,64]{2,1,0} multiply(%slice.5004, %mul.5021), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.5023 = bf16[32,32,64]{2,1,0} add(%mul.5018, %mul.5022), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.5024 = bf16[32,32,128]{2,1,0} concatenate(%sub.5014, %add.5023), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.5025 = bf16[32,4096]{1,0} reshape(%concatenate.5024), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.4949 = bf16[32,4,128]{2,1,0} slice(%reshape.4947), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.4974 = f32[32,4,128]{2,1,0} convert(%slice.4949), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.4975 = f32[32,4,128]{2,1,0} power(%convert_element_type.4974, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.4980 = f32[32,4]{1,0} reduce(%pow.4975, %constant.512), dimensions={2}, to_apply=%region_122.4979, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.4981 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.4980), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.4982 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.4981, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.4983 = f32[32,4,1]{2,1,0} add(%div.4982, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.4984 = f32[32,4,1]{2,1,0} rsqrt(%add.4983), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.4985 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.4984), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4986 = f32[32,4]{1,0} reshape(%mul.4985), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4987 = f32[32,4,128]{2,1,0} broadcast(%mul.4986), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4988 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.4974, %mul.4987), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.4989 = bf16[32,4,128]{2,1,0} convert(%mul.4988), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_22_self_attn_k_norm_weight__.143 = bf16[128]{0} parameter(142), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.22.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.4990 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_22_self_attn_k_norm_weight__.143), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4991 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.4990), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4992 = bf16[128]{0} reshape(%mul.4991), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4993 = bf16[32,4,128]{2,1,0} broadcast(%mul.4992), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.4994 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.4989, %mul.4993), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5028 = bf16[32,4,64]{2,1,0} slice(%mul.4994), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5026 = bf16[32,1,64]{2,1,0} reshape(%slice.5000), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5030 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5026), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5031 = bf16[32,64]{1,0} reshape(%mul.5030), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5032 = bf16[32,4,64]{2,1,0} broadcast(%mul.5031), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5033 = bf16[32,4,64]{2,1,0} multiply(%slice.5028, %mul.5032), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5029 = bf16[32,4,64]{2,1,0} slice(%mul.4994), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5027 = bf16[32,1,64]{2,1,0} reshape(%slice.5001), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5034 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5027), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5035 = bf16[32,64]{1,0} reshape(%mul.5034), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5036 = bf16[32,4,64]{2,1,0} broadcast(%mul.5035), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5037 = bf16[32,4,64]{2,1,0} multiply(%slice.5029, %mul.5036), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.5038 = bf16[32,4,64]{2,1,0} subtract(%mul.5033, %mul.5037), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.5039 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5026), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5040 = bf16[32,64]{1,0} reshape(%mul.5039), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5041 = bf16[32,4,64]{2,1,0} broadcast(%mul.5040), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5042 = bf16[32,4,64]{2,1,0} multiply(%slice.5029, %mul.5041), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5043 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5027), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5044 = bf16[32,64]{1,0} reshape(%mul.5043), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5045 = bf16[32,4,64]{2,1,0} broadcast(%mul.5044), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5046 = bf16[32,4,64]{2,1,0} multiply(%slice.5028, %mul.5045), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.5047 = bf16[32,4,64]{2,1,0} add(%mul.5042, %mul.5046), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.5048 = bf16[32,4,128]{2,1,0} concatenate(%sub.5038, %add.5047), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.5049 = bf16[32,512]{1,0} reshape(%concatenate.5048), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.4950 = bf16[32,4,128]{2,1,0} slice(%reshape.4947), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.4951 = bf16[32,512]{1,0} reshape(%slice.4950), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.5050 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_22_.458, %reshape.5025, %reshape.5049, %reshape.4951, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.5051 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.5050), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_23_.459 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(458), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[23]"}
  %jit__jax_attn_func_.5052 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.5050), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_22_self_attn_o_proj_weight__.144 = bf16[2048,4096]{1,0} parameter(143), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.22.self_attn.o_proj.weight\']"}
  %dot_general.5053 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.5052, %params_and_buffers__vllm_model_language_model_model_layers_22_self_attn_o_proj_weight__.144), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.5054 = f32[32,2048]{1,0} convert(%dot_general.5053), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.4925 = bf16[32,2048]{1,0} convert(%add.4924), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5055 = f32[32,2048]{1,0} convert(%convert_element_type.4925), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.5056 = f32[32,2048]{1,0} add(%convert_element_type.5054, %convert_element_type.5055), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.5058 = f32[32,2048]{1,0} power(%add.5056, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5063 = f32[32]{0} reduce(%pow.5058, %constant.512), dimensions={1}, to_apply=%region_123.5062, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5064 = f32[32,1]{1,0} reshape(%reduce_sum.5063), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5065 = f32[32,1]{1,0} divide(%broadcast_in_dim.5064, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5066 = f32[32,1]{1,0} add(%div.5065, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5067 = f32[32,1]{1,0} rsqrt(%add.5066), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5068 = f32[32,1]{1,0} broadcast(%rsqrt.5067), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5069 = f32[32]{0} reshape(%mul.5068), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5070 = f32[32,2048]{1,0} broadcast(%mul.5069), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5071 = f32[32,2048]{1,0} multiply(%add.5056, %mul.5070), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5072 = bf16[32,2048]{1,0} convert(%mul.5071), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_22_post_attention_layernorm_weight__.142 = bf16[2048]{0} parameter(141), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.22.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.5073 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_22_post_attention_layernorm_weight__.142), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5074 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.5073), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5075 = bf16[2048]{0} reshape(%mul.5074), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5076 = bf16[32,2048]{1,0} broadcast(%mul.5075), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5077 = bf16[32,2048]{1,0} multiply(%convert_element_type.5072, %mul.5076), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_22_mlp_experts_w13_weight__.139 = bf16[128,1536,2048]{2,1,0} parameter(138), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.22.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_22_mlp_experts_w2_weight__.140 = bf16[128,2048,768]{2,1,0} parameter(139), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.22.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_22_mlp_gate_weight__.141 = bf16[128,2048]{1,0} parameter(140), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.22.mlp.gate.weight\']"}
  %dot_general.5078 = bf16[32,128]{1,0} dot(%mul.5077, %params_and_buffers__vllm_model_language_model_model_layers_22_mlp_gate_weight__.141), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.5079 = bf16[32,2048]{1,0} call(%mul.5077, %params_and_buffers__vllm_model_language_model_model_layers_22_mlp_experts_w13_weight__.139, %params_and_buffers__vllm_model_language_model_model_layers_22_mlp_experts_w2_weight__.140, %dot_general.5078), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.5080 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.5079), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5057 = bf16[32,2048]{1,0} convert(%add.5056), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5081 = f32[32,2048]{1,0} convert(%convert_element_type.5057), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.5082 = f32[32,2048]{1,0} add(%convert_element_type.5080, %convert_element_type.5081), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.5084 = f32[32,2048]{1,0} power(%add.5082, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5089 = f32[32]{0} reduce(%pow.5084, %constant.512), dimensions={1}, to_apply=%region_124.5088, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5090 = f32[32,1]{1,0} reshape(%reduce_sum.5089), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5091 = f32[32,1]{1,0} divide(%broadcast_in_dim.5090, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5092 = f32[32,1]{1,0} add(%div.5091, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5093 = f32[32,1]{1,0} rsqrt(%add.5092), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5094 = f32[32,1]{1,0} broadcast(%rsqrt.5093), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5095 = f32[32]{0} reshape(%mul.5094), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5096 = f32[32,2048]{1,0} broadcast(%mul.5095), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5097 = f32[32,2048]{1,0} multiply(%add.5082, %mul.5096), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5098 = bf16[32,2048]{1,0} convert(%mul.5097), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_23_input_layernorm_weight__.147 = bf16[2048]{0} parameter(146), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.23.input_layernorm.weight\']"}
  %broadcast_in_dim.5099 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_23_input_layernorm_weight__.147), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5100 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.5099), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5101 = bf16[2048]{0} reshape(%mul.5100), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5102 = bf16[32,2048]{1,0} broadcast(%mul.5101), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5103 = bf16[32,2048]{1,0} multiply(%convert_element_type.5098, %mul.5102), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_23_self_attn_qkv_proj_weight__.155 = bf16[5120,2048]{1,0} parameter(154), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.23.self_attn.qkv_proj.weight\']"}
  %dot_general.5104 = bf16[32,5120]{1,0} dot(%mul.5103, %params_and_buffers__vllm_model_language_model_model_layers_23_self_attn_qkv_proj_weight__.155), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.5105 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.5104), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.5106 = bf16[32,4,1024]{2,1,0} slice(%reshape.5105), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.5110 = bf16[32,32,128]{2,1,0} reshape(%slice.5106), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.5111 = f32[32,32,128]{2,1,0} convert(%reshape.5110), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.5112 = f32[32,32,128]{2,1,0} power(%convert_element_type.5111, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5117 = f32[32,32]{1,0} reduce(%pow.5112, %constant.512), dimensions={2}, to_apply=%region_125.5116, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5118 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.5117), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5119 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.5118, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5120 = f32[32,32,1]{2,1,0} add(%div.5119, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5121 = f32[32,32,1]{2,1,0} rsqrt(%add.5120), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5122 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.5121), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5123 = f32[32,32]{1,0} reshape(%mul.5122), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5124 = f32[32,32,128]{2,1,0} broadcast(%mul.5123), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5125 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.5111, %mul.5124), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5126 = bf16[32,32,128]{2,1,0} convert(%mul.5125), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_23_self_attn_q_norm_weight__.154 = bf16[128]{0} parameter(153), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.23.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.5127 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_23_self_attn_q_norm_weight__.154), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5128 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.5127), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5129 = bf16[128]{0} reshape(%mul.5128), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5130 = bf16[32,32,128]{2,1,0} broadcast(%mul.5129), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5131 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.5126, %mul.5130), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5162 = bf16[32,32,64]{2,1,0} slice(%mul.5131), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.5153 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.5154 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.5155 = s32[32]{0} select(%lt.5153, %add.5154, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.5156 = s32[32,1]{1,0} reshape(%select_n.5155), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.5157 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.5156), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.5158 = bf16[32,64]{1,0} slice(%gather.5157), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5160 = bf16[32,1,64]{2,1,0} reshape(%slice.5158), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5164 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5160), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5165 = bf16[32,64]{1,0} reshape(%mul.5164), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5166 = bf16[32,32,64]{2,1,0} broadcast(%mul.5165), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5167 = bf16[32,32,64]{2,1,0} multiply(%slice.5162, %mul.5166), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5163 = bf16[32,32,64]{2,1,0} slice(%mul.5131), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.5159 = bf16[32,64]{1,0} slice(%gather.5157), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5161 = bf16[32,1,64]{2,1,0} reshape(%slice.5159), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5168 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5161), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5169 = bf16[32,64]{1,0} reshape(%mul.5168), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5170 = bf16[32,32,64]{2,1,0} broadcast(%mul.5169), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5171 = bf16[32,32,64]{2,1,0} multiply(%slice.5163, %mul.5170), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.5172 = bf16[32,32,64]{2,1,0} subtract(%mul.5167, %mul.5171), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.5173 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5160), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5174 = bf16[32,64]{1,0} reshape(%mul.5173), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5175 = bf16[32,32,64]{2,1,0} broadcast(%mul.5174), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5176 = bf16[32,32,64]{2,1,0} multiply(%slice.5163, %mul.5175), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5177 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5161), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5178 = bf16[32,64]{1,0} reshape(%mul.5177), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5179 = bf16[32,32,64]{2,1,0} broadcast(%mul.5178), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5180 = bf16[32,32,64]{2,1,0} multiply(%slice.5162, %mul.5179), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.5181 = bf16[32,32,64]{2,1,0} add(%mul.5176, %mul.5180), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.5182 = bf16[32,32,128]{2,1,0} concatenate(%sub.5172, %add.5181), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.5183 = bf16[32,4096]{1,0} reshape(%concatenate.5182), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.5107 = bf16[32,4,128]{2,1,0} slice(%reshape.5105), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.5132 = f32[32,4,128]{2,1,0} convert(%slice.5107), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.5133 = f32[32,4,128]{2,1,0} power(%convert_element_type.5132, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5138 = f32[32,4]{1,0} reduce(%pow.5133, %constant.512), dimensions={2}, to_apply=%region_126.5137, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5139 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.5138), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5140 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.5139, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5141 = f32[32,4,1]{2,1,0} add(%div.5140, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5142 = f32[32,4,1]{2,1,0} rsqrt(%add.5141), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5143 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.5142), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5144 = f32[32,4]{1,0} reshape(%mul.5143), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5145 = f32[32,4,128]{2,1,0} broadcast(%mul.5144), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5146 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.5132, %mul.5145), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5147 = bf16[32,4,128]{2,1,0} convert(%mul.5146), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_23_self_attn_k_norm_weight__.152 = bf16[128]{0} parameter(151), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.23.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.5148 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_23_self_attn_k_norm_weight__.152), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5149 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.5148), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5150 = bf16[128]{0} reshape(%mul.5149), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5151 = bf16[32,4,128]{2,1,0} broadcast(%mul.5150), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5152 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.5147, %mul.5151), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5186 = bf16[32,4,64]{2,1,0} slice(%mul.5152), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5184 = bf16[32,1,64]{2,1,0} reshape(%slice.5158), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5188 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5184), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5189 = bf16[32,64]{1,0} reshape(%mul.5188), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5190 = bf16[32,4,64]{2,1,0} broadcast(%mul.5189), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5191 = bf16[32,4,64]{2,1,0} multiply(%slice.5186, %mul.5190), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5187 = bf16[32,4,64]{2,1,0} slice(%mul.5152), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5185 = bf16[32,1,64]{2,1,0} reshape(%slice.5159), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5192 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5185), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5193 = bf16[32,64]{1,0} reshape(%mul.5192), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5194 = bf16[32,4,64]{2,1,0} broadcast(%mul.5193), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5195 = bf16[32,4,64]{2,1,0} multiply(%slice.5187, %mul.5194), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.5196 = bf16[32,4,64]{2,1,0} subtract(%mul.5191, %mul.5195), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.5197 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5184), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5198 = bf16[32,64]{1,0} reshape(%mul.5197), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5199 = bf16[32,4,64]{2,1,0} broadcast(%mul.5198), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5200 = bf16[32,4,64]{2,1,0} multiply(%slice.5187, %mul.5199), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5201 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5185), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5202 = bf16[32,64]{1,0} reshape(%mul.5201), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5203 = bf16[32,4,64]{2,1,0} broadcast(%mul.5202), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5204 = bf16[32,4,64]{2,1,0} multiply(%slice.5186, %mul.5203), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.5205 = bf16[32,4,64]{2,1,0} add(%mul.5200, %mul.5204), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.5206 = bf16[32,4,128]{2,1,0} concatenate(%sub.5196, %add.5205), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.5207 = bf16[32,512]{1,0} reshape(%concatenate.5206), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.5108 = bf16[32,4,128]{2,1,0} slice(%reshape.5105), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.5109 = bf16[32,512]{1,0} reshape(%slice.5108), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.5208 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_23_.459, %reshape.5183, %reshape.5207, %reshape.5109, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.5209 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.5208), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_24_.460 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(459), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[24]"}
  %jit__jax_attn_func_.5210 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.5208), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_23_self_attn_o_proj_weight__.153 = bf16[2048,4096]{1,0} parameter(152), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.23.self_attn.o_proj.weight\']"}
  %dot_general.5211 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.5210, %params_and_buffers__vllm_model_language_model_model_layers_23_self_attn_o_proj_weight__.153), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.5212 = f32[32,2048]{1,0} convert(%dot_general.5211), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5083 = bf16[32,2048]{1,0} convert(%add.5082), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5213 = f32[32,2048]{1,0} convert(%convert_element_type.5083), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.5214 = f32[32,2048]{1,0} add(%convert_element_type.5212, %convert_element_type.5213), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.5216 = f32[32,2048]{1,0} power(%add.5214, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5221 = f32[32]{0} reduce(%pow.5216, %constant.512), dimensions={1}, to_apply=%region_127.5220, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5222 = f32[32,1]{1,0} reshape(%reduce_sum.5221), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5223 = f32[32,1]{1,0} divide(%broadcast_in_dim.5222, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5224 = f32[32,1]{1,0} add(%div.5223, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5225 = f32[32,1]{1,0} rsqrt(%add.5224), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5226 = f32[32,1]{1,0} broadcast(%rsqrt.5225), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5227 = f32[32]{0} reshape(%mul.5226), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5228 = f32[32,2048]{1,0} broadcast(%mul.5227), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5229 = f32[32,2048]{1,0} multiply(%add.5214, %mul.5228), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5230 = bf16[32,2048]{1,0} convert(%mul.5229), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_23_post_attention_layernorm_weight__.151 = bf16[2048]{0} parameter(150), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.23.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.5231 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_23_post_attention_layernorm_weight__.151), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5232 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.5231), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5233 = bf16[2048]{0} reshape(%mul.5232), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5234 = bf16[32,2048]{1,0} broadcast(%mul.5233), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5235 = bf16[32,2048]{1,0} multiply(%convert_element_type.5230, %mul.5234), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_23_mlp_experts_w13_weight__.148 = bf16[128,1536,2048]{2,1,0} parameter(147), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.23.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_23_mlp_experts_w2_weight__.149 = bf16[128,2048,768]{2,1,0} parameter(148), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.23.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_23_mlp_gate_weight__.150 = bf16[128,2048]{1,0} parameter(149), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.23.mlp.gate.weight\']"}
  %dot_general.5236 = bf16[32,128]{1,0} dot(%mul.5235, %params_and_buffers__vllm_model_language_model_model_layers_23_mlp_gate_weight__.150), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.5237 = bf16[32,2048]{1,0} call(%mul.5235, %params_and_buffers__vllm_model_language_model_model_layers_23_mlp_experts_w13_weight__.148, %params_and_buffers__vllm_model_language_model_model_layers_23_mlp_experts_w2_weight__.149, %dot_general.5236), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.5238 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.5237), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5215 = bf16[32,2048]{1,0} convert(%add.5214), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5239 = f32[32,2048]{1,0} convert(%convert_element_type.5215), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.5240 = f32[32,2048]{1,0} add(%convert_element_type.5238, %convert_element_type.5239), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.5242 = f32[32,2048]{1,0} power(%add.5240, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5247 = f32[32]{0} reduce(%pow.5242, %constant.512), dimensions={1}, to_apply=%region_128.5246, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5248 = f32[32,1]{1,0} reshape(%reduce_sum.5247), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5249 = f32[32,1]{1,0} divide(%broadcast_in_dim.5248, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5250 = f32[32,1]{1,0} add(%div.5249, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5251 = f32[32,1]{1,0} rsqrt(%add.5250), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5252 = f32[32,1]{1,0} broadcast(%rsqrt.5251), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5253 = f32[32]{0} reshape(%mul.5252), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5254 = f32[32,2048]{1,0} broadcast(%mul.5253), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5255 = f32[32,2048]{1,0} multiply(%add.5240, %mul.5254), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5256 = bf16[32,2048]{1,0} convert(%mul.5255), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_24_input_layernorm_weight__.156 = bf16[2048]{0} parameter(155), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.24.input_layernorm.weight\']"}
  %broadcast_in_dim.5257 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_24_input_layernorm_weight__.156), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5258 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.5257), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5259 = bf16[2048]{0} reshape(%mul.5258), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5260 = bf16[32,2048]{1,0} broadcast(%mul.5259), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5261 = bf16[32,2048]{1,0} multiply(%convert_element_type.5256, %mul.5260), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_24_self_attn_qkv_proj_weight__.164 = bf16[5120,2048]{1,0} parameter(163), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.24.self_attn.qkv_proj.weight\']"}
  %dot_general.5262 = bf16[32,5120]{1,0} dot(%mul.5261, %params_and_buffers__vllm_model_language_model_model_layers_24_self_attn_qkv_proj_weight__.164), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.5263 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.5262), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.5264 = bf16[32,4,1024]{2,1,0} slice(%reshape.5263), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.5268 = bf16[32,32,128]{2,1,0} reshape(%slice.5264), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.5269 = f32[32,32,128]{2,1,0} convert(%reshape.5268), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.5270 = f32[32,32,128]{2,1,0} power(%convert_element_type.5269, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5275 = f32[32,32]{1,0} reduce(%pow.5270, %constant.512), dimensions={2}, to_apply=%region_129.5274, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5276 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.5275), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5277 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.5276, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5278 = f32[32,32,1]{2,1,0} add(%div.5277, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5279 = f32[32,32,1]{2,1,0} rsqrt(%add.5278), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5280 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.5279), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5281 = f32[32,32]{1,0} reshape(%mul.5280), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5282 = f32[32,32,128]{2,1,0} broadcast(%mul.5281), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5283 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.5269, %mul.5282), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5284 = bf16[32,32,128]{2,1,0} convert(%mul.5283), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_24_self_attn_q_norm_weight__.163 = bf16[128]{0} parameter(162), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.24.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.5285 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_24_self_attn_q_norm_weight__.163), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5286 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.5285), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5287 = bf16[128]{0} reshape(%mul.5286), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5288 = bf16[32,32,128]{2,1,0} broadcast(%mul.5287), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5289 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.5284, %mul.5288), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5320 = bf16[32,32,64]{2,1,0} slice(%mul.5289), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.5311 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.5312 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.5313 = s32[32]{0} select(%lt.5311, %add.5312, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.5314 = s32[32,1]{1,0} reshape(%select_n.5313), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.5315 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.5314), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.5316 = bf16[32,64]{1,0} slice(%gather.5315), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5318 = bf16[32,1,64]{2,1,0} reshape(%slice.5316), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5322 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5318), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5323 = bf16[32,64]{1,0} reshape(%mul.5322), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5324 = bf16[32,32,64]{2,1,0} broadcast(%mul.5323), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5325 = bf16[32,32,64]{2,1,0} multiply(%slice.5320, %mul.5324), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5321 = bf16[32,32,64]{2,1,0} slice(%mul.5289), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.5317 = bf16[32,64]{1,0} slice(%gather.5315), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5319 = bf16[32,1,64]{2,1,0} reshape(%slice.5317), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5326 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5319), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5327 = bf16[32,64]{1,0} reshape(%mul.5326), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5328 = bf16[32,32,64]{2,1,0} broadcast(%mul.5327), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5329 = bf16[32,32,64]{2,1,0} multiply(%slice.5321, %mul.5328), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.5330 = bf16[32,32,64]{2,1,0} subtract(%mul.5325, %mul.5329), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.5331 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5318), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5332 = bf16[32,64]{1,0} reshape(%mul.5331), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5333 = bf16[32,32,64]{2,1,0} broadcast(%mul.5332), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5334 = bf16[32,32,64]{2,1,0} multiply(%slice.5321, %mul.5333), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5335 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5319), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5336 = bf16[32,64]{1,0} reshape(%mul.5335), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5337 = bf16[32,32,64]{2,1,0} broadcast(%mul.5336), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5338 = bf16[32,32,64]{2,1,0} multiply(%slice.5320, %mul.5337), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.5339 = bf16[32,32,64]{2,1,0} add(%mul.5334, %mul.5338), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.5340 = bf16[32,32,128]{2,1,0} concatenate(%sub.5330, %add.5339), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.5341 = bf16[32,4096]{1,0} reshape(%concatenate.5340), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.5265 = bf16[32,4,128]{2,1,0} slice(%reshape.5263), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.5290 = f32[32,4,128]{2,1,0} convert(%slice.5265), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.5291 = f32[32,4,128]{2,1,0} power(%convert_element_type.5290, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5296 = f32[32,4]{1,0} reduce(%pow.5291, %constant.512), dimensions={2}, to_apply=%region_130.5295, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5297 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.5296), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5298 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.5297, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5299 = f32[32,4,1]{2,1,0} add(%div.5298, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5300 = f32[32,4,1]{2,1,0} rsqrt(%add.5299), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5301 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.5300), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5302 = f32[32,4]{1,0} reshape(%mul.5301), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5303 = f32[32,4,128]{2,1,0} broadcast(%mul.5302), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5304 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.5290, %mul.5303), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5305 = bf16[32,4,128]{2,1,0} convert(%mul.5304), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_24_self_attn_k_norm_weight__.161 = bf16[128]{0} parameter(160), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.24.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.5306 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_24_self_attn_k_norm_weight__.161), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5307 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.5306), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5308 = bf16[128]{0} reshape(%mul.5307), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5309 = bf16[32,4,128]{2,1,0} broadcast(%mul.5308), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5310 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.5305, %mul.5309), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5344 = bf16[32,4,64]{2,1,0} slice(%mul.5310), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5342 = bf16[32,1,64]{2,1,0} reshape(%slice.5316), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5346 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5342), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5347 = bf16[32,64]{1,0} reshape(%mul.5346), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5348 = bf16[32,4,64]{2,1,0} broadcast(%mul.5347), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5349 = bf16[32,4,64]{2,1,0} multiply(%slice.5344, %mul.5348), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5345 = bf16[32,4,64]{2,1,0} slice(%mul.5310), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5343 = bf16[32,1,64]{2,1,0} reshape(%slice.5317), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5350 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5343), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5351 = bf16[32,64]{1,0} reshape(%mul.5350), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5352 = bf16[32,4,64]{2,1,0} broadcast(%mul.5351), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5353 = bf16[32,4,64]{2,1,0} multiply(%slice.5345, %mul.5352), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.5354 = bf16[32,4,64]{2,1,0} subtract(%mul.5349, %mul.5353), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.5355 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5342), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5356 = bf16[32,64]{1,0} reshape(%mul.5355), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5357 = bf16[32,4,64]{2,1,0} broadcast(%mul.5356), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5358 = bf16[32,4,64]{2,1,0} multiply(%slice.5345, %mul.5357), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5359 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5343), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5360 = bf16[32,64]{1,0} reshape(%mul.5359), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5361 = bf16[32,4,64]{2,1,0} broadcast(%mul.5360), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5362 = bf16[32,4,64]{2,1,0} multiply(%slice.5344, %mul.5361), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.5363 = bf16[32,4,64]{2,1,0} add(%mul.5358, %mul.5362), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.5364 = bf16[32,4,128]{2,1,0} concatenate(%sub.5354, %add.5363), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.5365 = bf16[32,512]{1,0} reshape(%concatenate.5364), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.5266 = bf16[32,4,128]{2,1,0} slice(%reshape.5263), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.5267 = bf16[32,512]{1,0} reshape(%slice.5266), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.5366 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_24_.460, %reshape.5341, %reshape.5365, %reshape.5267, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.5367 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.5366), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_25_.461 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(460), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[25]"}
  %jit__jax_attn_func_.5368 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.5366), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_24_self_attn_o_proj_weight__.162 = bf16[2048,4096]{1,0} parameter(161), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.24.self_attn.o_proj.weight\']"}
  %dot_general.5369 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.5368, %params_and_buffers__vllm_model_language_model_model_layers_24_self_attn_o_proj_weight__.162), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.5370 = f32[32,2048]{1,0} convert(%dot_general.5369), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5241 = bf16[32,2048]{1,0} convert(%add.5240), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5371 = f32[32,2048]{1,0} convert(%convert_element_type.5241), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.5372 = f32[32,2048]{1,0} add(%convert_element_type.5370, %convert_element_type.5371), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.5374 = f32[32,2048]{1,0} power(%add.5372, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5379 = f32[32]{0} reduce(%pow.5374, %constant.512), dimensions={1}, to_apply=%region_131.5378, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5380 = f32[32,1]{1,0} reshape(%reduce_sum.5379), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5381 = f32[32,1]{1,0} divide(%broadcast_in_dim.5380, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5382 = f32[32,1]{1,0} add(%div.5381, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5383 = f32[32,1]{1,0} rsqrt(%add.5382), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5384 = f32[32,1]{1,0} broadcast(%rsqrt.5383), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5385 = f32[32]{0} reshape(%mul.5384), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5386 = f32[32,2048]{1,0} broadcast(%mul.5385), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5387 = f32[32,2048]{1,0} multiply(%add.5372, %mul.5386), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5388 = bf16[32,2048]{1,0} convert(%mul.5387), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_24_post_attention_layernorm_weight__.160 = bf16[2048]{0} parameter(159), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.24.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.5389 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_24_post_attention_layernorm_weight__.160), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5390 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.5389), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5391 = bf16[2048]{0} reshape(%mul.5390), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5392 = bf16[32,2048]{1,0} broadcast(%mul.5391), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5393 = bf16[32,2048]{1,0} multiply(%convert_element_type.5388, %mul.5392), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_24_mlp_experts_w13_weight__.157 = bf16[128,1536,2048]{2,1,0} parameter(156), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.24.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_24_mlp_experts_w2_weight__.158 = bf16[128,2048,768]{2,1,0} parameter(157), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.24.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_24_mlp_gate_weight__.159 = bf16[128,2048]{1,0} parameter(158), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.24.mlp.gate.weight\']"}
  %dot_general.5394 = bf16[32,128]{1,0} dot(%mul.5393, %params_and_buffers__vllm_model_language_model_model_layers_24_mlp_gate_weight__.159), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.5395 = bf16[32,2048]{1,0} call(%mul.5393, %params_and_buffers__vllm_model_language_model_model_layers_24_mlp_experts_w13_weight__.157, %params_and_buffers__vllm_model_language_model_model_layers_24_mlp_experts_w2_weight__.158, %dot_general.5394), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.5396 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.5395), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5373 = bf16[32,2048]{1,0} convert(%add.5372), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5397 = f32[32,2048]{1,0} convert(%convert_element_type.5373), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.5398 = f32[32,2048]{1,0} add(%convert_element_type.5396, %convert_element_type.5397), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.5400 = f32[32,2048]{1,0} power(%add.5398, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5405 = f32[32]{0} reduce(%pow.5400, %constant.512), dimensions={1}, to_apply=%region_132.5404, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5406 = f32[32,1]{1,0} reshape(%reduce_sum.5405), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5407 = f32[32,1]{1,0} divide(%broadcast_in_dim.5406, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5408 = f32[32,1]{1,0} add(%div.5407, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5409 = f32[32,1]{1,0} rsqrt(%add.5408), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5410 = f32[32,1]{1,0} broadcast(%rsqrt.5409), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5411 = f32[32]{0} reshape(%mul.5410), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5412 = f32[32,2048]{1,0} broadcast(%mul.5411), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5413 = f32[32,2048]{1,0} multiply(%add.5398, %mul.5412), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5414 = bf16[32,2048]{1,0} convert(%mul.5413), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_25_input_layernorm_weight__.165 = bf16[2048]{0} parameter(164), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.25.input_layernorm.weight\']"}
  %broadcast_in_dim.5415 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_25_input_layernorm_weight__.165), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5416 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.5415), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5417 = bf16[2048]{0} reshape(%mul.5416), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5418 = bf16[32,2048]{1,0} broadcast(%mul.5417), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5419 = bf16[32,2048]{1,0} multiply(%convert_element_type.5414, %mul.5418), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_25_self_attn_qkv_proj_weight__.173 = bf16[5120,2048]{1,0} parameter(172), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.25.self_attn.qkv_proj.weight\']"}
  %dot_general.5420 = bf16[32,5120]{1,0} dot(%mul.5419, %params_and_buffers__vllm_model_language_model_model_layers_25_self_attn_qkv_proj_weight__.173), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.5421 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.5420), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.5422 = bf16[32,4,1024]{2,1,0} slice(%reshape.5421), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.5426 = bf16[32,32,128]{2,1,0} reshape(%slice.5422), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.5427 = f32[32,32,128]{2,1,0} convert(%reshape.5426), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.5428 = f32[32,32,128]{2,1,0} power(%convert_element_type.5427, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5433 = f32[32,32]{1,0} reduce(%pow.5428, %constant.512), dimensions={2}, to_apply=%region_133.5432, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5434 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.5433), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5435 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.5434, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5436 = f32[32,32,1]{2,1,0} add(%div.5435, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5437 = f32[32,32,1]{2,1,0} rsqrt(%add.5436), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5438 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.5437), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5439 = f32[32,32]{1,0} reshape(%mul.5438), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5440 = f32[32,32,128]{2,1,0} broadcast(%mul.5439), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5441 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.5427, %mul.5440), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5442 = bf16[32,32,128]{2,1,0} convert(%mul.5441), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_25_self_attn_q_norm_weight__.172 = bf16[128]{0} parameter(171), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.25.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.5443 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_25_self_attn_q_norm_weight__.172), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5444 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.5443), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5445 = bf16[128]{0} reshape(%mul.5444), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5446 = bf16[32,32,128]{2,1,0} broadcast(%mul.5445), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5447 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.5442, %mul.5446), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5478 = bf16[32,32,64]{2,1,0} slice(%mul.5447), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.5469 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.5470 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.5471 = s32[32]{0} select(%lt.5469, %add.5470, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.5472 = s32[32,1]{1,0} reshape(%select_n.5471), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.5473 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.5472), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.5474 = bf16[32,64]{1,0} slice(%gather.5473), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5476 = bf16[32,1,64]{2,1,0} reshape(%slice.5474), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5480 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5476), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5481 = bf16[32,64]{1,0} reshape(%mul.5480), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5482 = bf16[32,32,64]{2,1,0} broadcast(%mul.5481), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5483 = bf16[32,32,64]{2,1,0} multiply(%slice.5478, %mul.5482), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5479 = bf16[32,32,64]{2,1,0} slice(%mul.5447), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.5475 = bf16[32,64]{1,0} slice(%gather.5473), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5477 = bf16[32,1,64]{2,1,0} reshape(%slice.5475), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5484 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5477), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5485 = bf16[32,64]{1,0} reshape(%mul.5484), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5486 = bf16[32,32,64]{2,1,0} broadcast(%mul.5485), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5487 = bf16[32,32,64]{2,1,0} multiply(%slice.5479, %mul.5486), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.5488 = bf16[32,32,64]{2,1,0} subtract(%mul.5483, %mul.5487), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.5489 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5476), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5490 = bf16[32,64]{1,0} reshape(%mul.5489), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5491 = bf16[32,32,64]{2,1,0} broadcast(%mul.5490), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5492 = bf16[32,32,64]{2,1,0} multiply(%slice.5479, %mul.5491), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5493 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5477), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5494 = bf16[32,64]{1,0} reshape(%mul.5493), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5495 = bf16[32,32,64]{2,1,0} broadcast(%mul.5494), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5496 = bf16[32,32,64]{2,1,0} multiply(%slice.5478, %mul.5495), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.5497 = bf16[32,32,64]{2,1,0} add(%mul.5492, %mul.5496), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.5498 = bf16[32,32,128]{2,1,0} concatenate(%sub.5488, %add.5497), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.5499 = bf16[32,4096]{1,0} reshape(%concatenate.5498), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.5423 = bf16[32,4,128]{2,1,0} slice(%reshape.5421), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.5448 = f32[32,4,128]{2,1,0} convert(%slice.5423), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.5449 = f32[32,4,128]{2,1,0} power(%convert_element_type.5448, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5454 = f32[32,4]{1,0} reduce(%pow.5449, %constant.512), dimensions={2}, to_apply=%region_134.5453, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5455 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.5454), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5456 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.5455, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5457 = f32[32,4,1]{2,1,0} add(%div.5456, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5458 = f32[32,4,1]{2,1,0} rsqrt(%add.5457), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5459 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.5458), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5460 = f32[32,4]{1,0} reshape(%mul.5459), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5461 = f32[32,4,128]{2,1,0} broadcast(%mul.5460), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5462 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.5448, %mul.5461), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5463 = bf16[32,4,128]{2,1,0} convert(%mul.5462), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_25_self_attn_k_norm_weight__.170 = bf16[128]{0} parameter(169), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.25.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.5464 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_25_self_attn_k_norm_weight__.170), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5465 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.5464), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5466 = bf16[128]{0} reshape(%mul.5465), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5467 = bf16[32,4,128]{2,1,0} broadcast(%mul.5466), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5468 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.5463, %mul.5467), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5502 = bf16[32,4,64]{2,1,0} slice(%mul.5468), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5500 = bf16[32,1,64]{2,1,0} reshape(%slice.5474), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5504 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5500), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5505 = bf16[32,64]{1,0} reshape(%mul.5504), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5506 = bf16[32,4,64]{2,1,0} broadcast(%mul.5505), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5507 = bf16[32,4,64]{2,1,0} multiply(%slice.5502, %mul.5506), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5503 = bf16[32,4,64]{2,1,0} slice(%mul.5468), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5501 = bf16[32,1,64]{2,1,0} reshape(%slice.5475), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5508 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5501), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5509 = bf16[32,64]{1,0} reshape(%mul.5508), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5510 = bf16[32,4,64]{2,1,0} broadcast(%mul.5509), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5511 = bf16[32,4,64]{2,1,0} multiply(%slice.5503, %mul.5510), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.5512 = bf16[32,4,64]{2,1,0} subtract(%mul.5507, %mul.5511), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.5513 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5500), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5514 = bf16[32,64]{1,0} reshape(%mul.5513), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5515 = bf16[32,4,64]{2,1,0} broadcast(%mul.5514), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5516 = bf16[32,4,64]{2,1,0} multiply(%slice.5503, %mul.5515), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5517 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5501), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5518 = bf16[32,64]{1,0} reshape(%mul.5517), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5519 = bf16[32,4,64]{2,1,0} broadcast(%mul.5518), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5520 = bf16[32,4,64]{2,1,0} multiply(%slice.5502, %mul.5519), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.5521 = bf16[32,4,64]{2,1,0} add(%mul.5516, %mul.5520), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.5522 = bf16[32,4,128]{2,1,0} concatenate(%sub.5512, %add.5521), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.5523 = bf16[32,512]{1,0} reshape(%concatenate.5522), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.5424 = bf16[32,4,128]{2,1,0} slice(%reshape.5421), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.5425 = bf16[32,512]{1,0} reshape(%slice.5424), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.5524 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_25_.461, %reshape.5499, %reshape.5523, %reshape.5425, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.5525 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.5524), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_26_.462 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(461), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[26]"}
  %jit__jax_attn_func_.5526 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.5524), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_25_self_attn_o_proj_weight__.171 = bf16[2048,4096]{1,0} parameter(170), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.25.self_attn.o_proj.weight\']"}
  %dot_general.5527 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.5526, %params_and_buffers__vllm_model_language_model_model_layers_25_self_attn_o_proj_weight__.171), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.5528 = f32[32,2048]{1,0} convert(%dot_general.5527), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5399 = bf16[32,2048]{1,0} convert(%add.5398), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5529 = f32[32,2048]{1,0} convert(%convert_element_type.5399), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.5530 = f32[32,2048]{1,0} add(%convert_element_type.5528, %convert_element_type.5529), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.5532 = f32[32,2048]{1,0} power(%add.5530, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5537 = f32[32]{0} reduce(%pow.5532, %constant.512), dimensions={1}, to_apply=%region_135.5536, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5538 = f32[32,1]{1,0} reshape(%reduce_sum.5537), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5539 = f32[32,1]{1,0} divide(%broadcast_in_dim.5538, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5540 = f32[32,1]{1,0} add(%div.5539, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5541 = f32[32,1]{1,0} rsqrt(%add.5540), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5542 = f32[32,1]{1,0} broadcast(%rsqrt.5541), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5543 = f32[32]{0} reshape(%mul.5542), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5544 = f32[32,2048]{1,0} broadcast(%mul.5543), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5545 = f32[32,2048]{1,0} multiply(%add.5530, %mul.5544), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5546 = bf16[32,2048]{1,0} convert(%mul.5545), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_25_post_attention_layernorm_weight__.169 = bf16[2048]{0} parameter(168), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.25.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.5547 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_25_post_attention_layernorm_weight__.169), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5548 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.5547), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5549 = bf16[2048]{0} reshape(%mul.5548), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5550 = bf16[32,2048]{1,0} broadcast(%mul.5549), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5551 = bf16[32,2048]{1,0} multiply(%convert_element_type.5546, %mul.5550), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_25_mlp_experts_w13_weight__.166 = bf16[128,1536,2048]{2,1,0} parameter(165), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.25.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_25_mlp_experts_w2_weight__.167 = bf16[128,2048,768]{2,1,0} parameter(166), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.25.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_25_mlp_gate_weight__.168 = bf16[128,2048]{1,0} parameter(167), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.25.mlp.gate.weight\']"}
  %dot_general.5552 = bf16[32,128]{1,0} dot(%mul.5551, %params_and_buffers__vllm_model_language_model_model_layers_25_mlp_gate_weight__.168), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.5553 = bf16[32,2048]{1,0} call(%mul.5551, %params_and_buffers__vllm_model_language_model_model_layers_25_mlp_experts_w13_weight__.166, %params_and_buffers__vllm_model_language_model_model_layers_25_mlp_experts_w2_weight__.167, %dot_general.5552), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.5554 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.5553), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5531 = bf16[32,2048]{1,0} convert(%add.5530), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5555 = f32[32,2048]{1,0} convert(%convert_element_type.5531), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.5556 = f32[32,2048]{1,0} add(%convert_element_type.5554, %convert_element_type.5555), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.5558 = f32[32,2048]{1,0} power(%add.5556, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5563 = f32[32]{0} reduce(%pow.5558, %constant.512), dimensions={1}, to_apply=%region_136.5562, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5564 = f32[32,1]{1,0} reshape(%reduce_sum.5563), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5565 = f32[32,1]{1,0} divide(%broadcast_in_dim.5564, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5566 = f32[32,1]{1,0} add(%div.5565, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5567 = f32[32,1]{1,0} rsqrt(%add.5566), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5568 = f32[32,1]{1,0} broadcast(%rsqrt.5567), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5569 = f32[32]{0} reshape(%mul.5568), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5570 = f32[32,2048]{1,0} broadcast(%mul.5569), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5571 = f32[32,2048]{1,0} multiply(%add.5556, %mul.5570), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5572 = bf16[32,2048]{1,0} convert(%mul.5571), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_26_input_layernorm_weight__.174 = bf16[2048]{0} parameter(173), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.26.input_layernorm.weight\']"}
  %broadcast_in_dim.5573 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_26_input_layernorm_weight__.174), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5574 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.5573), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5575 = bf16[2048]{0} reshape(%mul.5574), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5576 = bf16[32,2048]{1,0} broadcast(%mul.5575), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5577 = bf16[32,2048]{1,0} multiply(%convert_element_type.5572, %mul.5576), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_26_self_attn_qkv_proj_weight__.182 = bf16[5120,2048]{1,0} parameter(181), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.26.self_attn.qkv_proj.weight\']"}
  %dot_general.5578 = bf16[32,5120]{1,0} dot(%mul.5577, %params_and_buffers__vllm_model_language_model_model_layers_26_self_attn_qkv_proj_weight__.182), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.5579 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.5578), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.5580 = bf16[32,4,1024]{2,1,0} slice(%reshape.5579), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.5584 = bf16[32,32,128]{2,1,0} reshape(%slice.5580), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.5585 = f32[32,32,128]{2,1,0} convert(%reshape.5584), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.5586 = f32[32,32,128]{2,1,0} power(%convert_element_type.5585, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5591 = f32[32,32]{1,0} reduce(%pow.5586, %constant.512), dimensions={2}, to_apply=%region_137.5590, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5592 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.5591), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5593 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.5592, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5594 = f32[32,32,1]{2,1,0} add(%div.5593, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5595 = f32[32,32,1]{2,1,0} rsqrt(%add.5594), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5596 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.5595), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5597 = f32[32,32]{1,0} reshape(%mul.5596), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5598 = f32[32,32,128]{2,1,0} broadcast(%mul.5597), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5599 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.5585, %mul.5598), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5600 = bf16[32,32,128]{2,1,0} convert(%mul.5599), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_26_self_attn_q_norm_weight__.181 = bf16[128]{0} parameter(180), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.26.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.5601 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_26_self_attn_q_norm_weight__.181), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5602 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.5601), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5603 = bf16[128]{0} reshape(%mul.5602), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5604 = bf16[32,32,128]{2,1,0} broadcast(%mul.5603), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5605 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.5600, %mul.5604), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5636 = bf16[32,32,64]{2,1,0} slice(%mul.5605), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.5627 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.5628 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.5629 = s32[32]{0} select(%lt.5627, %add.5628, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.5630 = s32[32,1]{1,0} reshape(%select_n.5629), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.5631 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.5630), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.5632 = bf16[32,64]{1,0} slice(%gather.5631), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5634 = bf16[32,1,64]{2,1,0} reshape(%slice.5632), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5638 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5634), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5639 = bf16[32,64]{1,0} reshape(%mul.5638), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5640 = bf16[32,32,64]{2,1,0} broadcast(%mul.5639), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5641 = bf16[32,32,64]{2,1,0} multiply(%slice.5636, %mul.5640), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5637 = bf16[32,32,64]{2,1,0} slice(%mul.5605), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.5633 = bf16[32,64]{1,0} slice(%gather.5631), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5635 = bf16[32,1,64]{2,1,0} reshape(%slice.5633), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5642 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5635), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5643 = bf16[32,64]{1,0} reshape(%mul.5642), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5644 = bf16[32,32,64]{2,1,0} broadcast(%mul.5643), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5645 = bf16[32,32,64]{2,1,0} multiply(%slice.5637, %mul.5644), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.5646 = bf16[32,32,64]{2,1,0} subtract(%mul.5641, %mul.5645), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.5647 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5634), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5648 = bf16[32,64]{1,0} reshape(%mul.5647), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5649 = bf16[32,32,64]{2,1,0} broadcast(%mul.5648), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5650 = bf16[32,32,64]{2,1,0} multiply(%slice.5637, %mul.5649), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5651 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5635), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5652 = bf16[32,64]{1,0} reshape(%mul.5651), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5653 = bf16[32,32,64]{2,1,0} broadcast(%mul.5652), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5654 = bf16[32,32,64]{2,1,0} multiply(%slice.5636, %mul.5653), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.5655 = bf16[32,32,64]{2,1,0} add(%mul.5650, %mul.5654), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.5656 = bf16[32,32,128]{2,1,0} concatenate(%sub.5646, %add.5655), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.5657 = bf16[32,4096]{1,0} reshape(%concatenate.5656), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.5581 = bf16[32,4,128]{2,1,0} slice(%reshape.5579), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.5606 = f32[32,4,128]{2,1,0} convert(%slice.5581), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.5607 = f32[32,4,128]{2,1,0} power(%convert_element_type.5606, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5612 = f32[32,4]{1,0} reduce(%pow.5607, %constant.512), dimensions={2}, to_apply=%region_138.5611, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5613 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.5612), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5614 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.5613, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5615 = f32[32,4,1]{2,1,0} add(%div.5614, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5616 = f32[32,4,1]{2,1,0} rsqrt(%add.5615), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5617 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.5616), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5618 = f32[32,4]{1,0} reshape(%mul.5617), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5619 = f32[32,4,128]{2,1,0} broadcast(%mul.5618), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5620 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.5606, %mul.5619), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5621 = bf16[32,4,128]{2,1,0} convert(%mul.5620), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_26_self_attn_k_norm_weight__.179 = bf16[128]{0} parameter(178), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.26.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.5622 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_26_self_attn_k_norm_weight__.179), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5623 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.5622), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5624 = bf16[128]{0} reshape(%mul.5623), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5625 = bf16[32,4,128]{2,1,0} broadcast(%mul.5624), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5626 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.5621, %mul.5625), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5660 = bf16[32,4,64]{2,1,0} slice(%mul.5626), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5658 = bf16[32,1,64]{2,1,0} reshape(%slice.5632), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5662 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5658), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5663 = bf16[32,64]{1,0} reshape(%mul.5662), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5664 = bf16[32,4,64]{2,1,0} broadcast(%mul.5663), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5665 = bf16[32,4,64]{2,1,0} multiply(%slice.5660, %mul.5664), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5661 = bf16[32,4,64]{2,1,0} slice(%mul.5626), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5659 = bf16[32,1,64]{2,1,0} reshape(%slice.5633), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5666 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5659), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5667 = bf16[32,64]{1,0} reshape(%mul.5666), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5668 = bf16[32,4,64]{2,1,0} broadcast(%mul.5667), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5669 = bf16[32,4,64]{2,1,0} multiply(%slice.5661, %mul.5668), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.5670 = bf16[32,4,64]{2,1,0} subtract(%mul.5665, %mul.5669), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.5671 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5658), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5672 = bf16[32,64]{1,0} reshape(%mul.5671), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5673 = bf16[32,4,64]{2,1,0} broadcast(%mul.5672), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5674 = bf16[32,4,64]{2,1,0} multiply(%slice.5661, %mul.5673), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5675 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5659), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5676 = bf16[32,64]{1,0} reshape(%mul.5675), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5677 = bf16[32,4,64]{2,1,0} broadcast(%mul.5676), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5678 = bf16[32,4,64]{2,1,0} multiply(%slice.5660, %mul.5677), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.5679 = bf16[32,4,64]{2,1,0} add(%mul.5674, %mul.5678), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.5680 = bf16[32,4,128]{2,1,0} concatenate(%sub.5670, %add.5679), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.5681 = bf16[32,512]{1,0} reshape(%concatenate.5680), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.5582 = bf16[32,4,128]{2,1,0} slice(%reshape.5579), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.5583 = bf16[32,512]{1,0} reshape(%slice.5582), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.5682 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_26_.462, %reshape.5657, %reshape.5681, %reshape.5583, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.5683 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.5682), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_27_.463 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(462), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[27]"}
  %jit__jax_attn_func_.5684 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.5682), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_26_self_attn_o_proj_weight__.180 = bf16[2048,4096]{1,0} parameter(179), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.26.self_attn.o_proj.weight\']"}
  %dot_general.5685 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.5684, %params_and_buffers__vllm_model_language_model_model_layers_26_self_attn_o_proj_weight__.180), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.5686 = f32[32,2048]{1,0} convert(%dot_general.5685), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5557 = bf16[32,2048]{1,0} convert(%add.5556), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5687 = f32[32,2048]{1,0} convert(%convert_element_type.5557), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.5688 = f32[32,2048]{1,0} add(%convert_element_type.5686, %convert_element_type.5687), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.5690 = f32[32,2048]{1,0} power(%add.5688, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5695 = f32[32]{0} reduce(%pow.5690, %constant.512), dimensions={1}, to_apply=%region_139.5694, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5696 = f32[32,1]{1,0} reshape(%reduce_sum.5695), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5697 = f32[32,1]{1,0} divide(%broadcast_in_dim.5696, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5698 = f32[32,1]{1,0} add(%div.5697, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5699 = f32[32,1]{1,0} rsqrt(%add.5698), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5700 = f32[32,1]{1,0} broadcast(%rsqrt.5699), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5701 = f32[32]{0} reshape(%mul.5700), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5702 = f32[32,2048]{1,0} broadcast(%mul.5701), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5703 = f32[32,2048]{1,0} multiply(%add.5688, %mul.5702), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5704 = bf16[32,2048]{1,0} convert(%mul.5703), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_26_post_attention_layernorm_weight__.178 = bf16[2048]{0} parameter(177), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.26.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.5705 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_26_post_attention_layernorm_weight__.178), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5706 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.5705), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5707 = bf16[2048]{0} reshape(%mul.5706), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5708 = bf16[32,2048]{1,0} broadcast(%mul.5707), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5709 = bf16[32,2048]{1,0} multiply(%convert_element_type.5704, %mul.5708), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_26_mlp_experts_w13_weight__.175 = bf16[128,1536,2048]{2,1,0} parameter(174), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.26.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_26_mlp_experts_w2_weight__.176 = bf16[128,2048,768]{2,1,0} parameter(175), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.26.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_26_mlp_gate_weight__.177 = bf16[128,2048]{1,0} parameter(176), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.26.mlp.gate.weight\']"}
  %dot_general.5710 = bf16[32,128]{1,0} dot(%mul.5709, %params_and_buffers__vllm_model_language_model_model_layers_26_mlp_gate_weight__.177), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.5711 = bf16[32,2048]{1,0} call(%mul.5709, %params_and_buffers__vllm_model_language_model_model_layers_26_mlp_experts_w13_weight__.175, %params_and_buffers__vllm_model_language_model_model_layers_26_mlp_experts_w2_weight__.176, %dot_general.5710), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.5712 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.5711), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5689 = bf16[32,2048]{1,0} convert(%add.5688), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5713 = f32[32,2048]{1,0} convert(%convert_element_type.5689), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.5714 = f32[32,2048]{1,0} add(%convert_element_type.5712, %convert_element_type.5713), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.5716 = f32[32,2048]{1,0} power(%add.5714, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5721 = f32[32]{0} reduce(%pow.5716, %constant.512), dimensions={1}, to_apply=%region_140.5720, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5722 = f32[32,1]{1,0} reshape(%reduce_sum.5721), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5723 = f32[32,1]{1,0} divide(%broadcast_in_dim.5722, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5724 = f32[32,1]{1,0} add(%div.5723, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5725 = f32[32,1]{1,0} rsqrt(%add.5724), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5726 = f32[32,1]{1,0} broadcast(%rsqrt.5725), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5727 = f32[32]{0} reshape(%mul.5726), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5728 = f32[32,2048]{1,0} broadcast(%mul.5727), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5729 = f32[32,2048]{1,0} multiply(%add.5714, %mul.5728), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5730 = bf16[32,2048]{1,0} convert(%mul.5729), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_27_input_layernorm_weight__.183 = bf16[2048]{0} parameter(182), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.27.input_layernorm.weight\']"}
  %broadcast_in_dim.5731 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_27_input_layernorm_weight__.183), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5732 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.5731), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5733 = bf16[2048]{0} reshape(%mul.5732), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5734 = bf16[32,2048]{1,0} broadcast(%mul.5733), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5735 = bf16[32,2048]{1,0} multiply(%convert_element_type.5730, %mul.5734), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_27_self_attn_qkv_proj_weight__.191 = bf16[5120,2048]{1,0} parameter(190), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.27.self_attn.qkv_proj.weight\']"}
  %dot_general.5736 = bf16[32,5120]{1,0} dot(%mul.5735, %params_and_buffers__vllm_model_language_model_model_layers_27_self_attn_qkv_proj_weight__.191), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.5737 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.5736), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.5738 = bf16[32,4,1024]{2,1,0} slice(%reshape.5737), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.5742 = bf16[32,32,128]{2,1,0} reshape(%slice.5738), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.5743 = f32[32,32,128]{2,1,0} convert(%reshape.5742), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.5744 = f32[32,32,128]{2,1,0} power(%convert_element_type.5743, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5749 = f32[32,32]{1,0} reduce(%pow.5744, %constant.512), dimensions={2}, to_apply=%region_141.5748, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5750 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.5749), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5751 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.5750, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5752 = f32[32,32,1]{2,1,0} add(%div.5751, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5753 = f32[32,32,1]{2,1,0} rsqrt(%add.5752), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5754 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.5753), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5755 = f32[32,32]{1,0} reshape(%mul.5754), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5756 = f32[32,32,128]{2,1,0} broadcast(%mul.5755), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5757 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.5743, %mul.5756), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5758 = bf16[32,32,128]{2,1,0} convert(%mul.5757), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_27_self_attn_q_norm_weight__.190 = bf16[128]{0} parameter(189), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.27.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.5759 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_27_self_attn_q_norm_weight__.190), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5760 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.5759), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5761 = bf16[128]{0} reshape(%mul.5760), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5762 = bf16[32,32,128]{2,1,0} broadcast(%mul.5761), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5763 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.5758, %mul.5762), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5794 = bf16[32,32,64]{2,1,0} slice(%mul.5763), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.5785 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.5786 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.5787 = s32[32]{0} select(%lt.5785, %add.5786, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.5788 = s32[32,1]{1,0} reshape(%select_n.5787), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.5789 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.5788), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.5790 = bf16[32,64]{1,0} slice(%gather.5789), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5792 = bf16[32,1,64]{2,1,0} reshape(%slice.5790), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5796 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5792), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5797 = bf16[32,64]{1,0} reshape(%mul.5796), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5798 = bf16[32,32,64]{2,1,0} broadcast(%mul.5797), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5799 = bf16[32,32,64]{2,1,0} multiply(%slice.5794, %mul.5798), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5795 = bf16[32,32,64]{2,1,0} slice(%mul.5763), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.5791 = bf16[32,64]{1,0} slice(%gather.5789), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5793 = bf16[32,1,64]{2,1,0} reshape(%slice.5791), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5800 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5793), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5801 = bf16[32,64]{1,0} reshape(%mul.5800), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5802 = bf16[32,32,64]{2,1,0} broadcast(%mul.5801), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5803 = bf16[32,32,64]{2,1,0} multiply(%slice.5795, %mul.5802), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.5804 = bf16[32,32,64]{2,1,0} subtract(%mul.5799, %mul.5803), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.5805 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5792), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5806 = bf16[32,64]{1,0} reshape(%mul.5805), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5807 = bf16[32,32,64]{2,1,0} broadcast(%mul.5806), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5808 = bf16[32,32,64]{2,1,0} multiply(%slice.5795, %mul.5807), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5809 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5793), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5810 = bf16[32,64]{1,0} reshape(%mul.5809), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5811 = bf16[32,32,64]{2,1,0} broadcast(%mul.5810), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5812 = bf16[32,32,64]{2,1,0} multiply(%slice.5794, %mul.5811), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.5813 = bf16[32,32,64]{2,1,0} add(%mul.5808, %mul.5812), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.5814 = bf16[32,32,128]{2,1,0} concatenate(%sub.5804, %add.5813), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.5815 = bf16[32,4096]{1,0} reshape(%concatenate.5814), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.5739 = bf16[32,4,128]{2,1,0} slice(%reshape.5737), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.5764 = f32[32,4,128]{2,1,0} convert(%slice.5739), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.5765 = f32[32,4,128]{2,1,0} power(%convert_element_type.5764, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5770 = f32[32,4]{1,0} reduce(%pow.5765, %constant.512), dimensions={2}, to_apply=%region_142.5769, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5771 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.5770), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5772 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.5771, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5773 = f32[32,4,1]{2,1,0} add(%div.5772, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5774 = f32[32,4,1]{2,1,0} rsqrt(%add.5773), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5775 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.5774), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5776 = f32[32,4]{1,0} reshape(%mul.5775), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5777 = f32[32,4,128]{2,1,0} broadcast(%mul.5776), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5778 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.5764, %mul.5777), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5779 = bf16[32,4,128]{2,1,0} convert(%mul.5778), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_27_self_attn_k_norm_weight__.188 = bf16[128]{0} parameter(187), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.27.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.5780 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_27_self_attn_k_norm_weight__.188), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5781 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.5780), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5782 = bf16[128]{0} reshape(%mul.5781), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5783 = bf16[32,4,128]{2,1,0} broadcast(%mul.5782), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5784 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.5779, %mul.5783), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5818 = bf16[32,4,64]{2,1,0} slice(%mul.5784), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5816 = bf16[32,1,64]{2,1,0} reshape(%slice.5790), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5820 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5816), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5821 = bf16[32,64]{1,0} reshape(%mul.5820), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5822 = bf16[32,4,64]{2,1,0} broadcast(%mul.5821), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5823 = bf16[32,4,64]{2,1,0} multiply(%slice.5818, %mul.5822), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5819 = bf16[32,4,64]{2,1,0} slice(%mul.5784), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5817 = bf16[32,1,64]{2,1,0} reshape(%slice.5791), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5824 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5817), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5825 = bf16[32,64]{1,0} reshape(%mul.5824), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5826 = bf16[32,4,64]{2,1,0} broadcast(%mul.5825), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5827 = bf16[32,4,64]{2,1,0} multiply(%slice.5819, %mul.5826), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.5828 = bf16[32,4,64]{2,1,0} subtract(%mul.5823, %mul.5827), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.5829 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5816), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5830 = bf16[32,64]{1,0} reshape(%mul.5829), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5831 = bf16[32,4,64]{2,1,0} broadcast(%mul.5830), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5832 = bf16[32,4,64]{2,1,0} multiply(%slice.5819, %mul.5831), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5833 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5817), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5834 = bf16[32,64]{1,0} reshape(%mul.5833), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5835 = bf16[32,4,64]{2,1,0} broadcast(%mul.5834), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5836 = bf16[32,4,64]{2,1,0} multiply(%slice.5818, %mul.5835), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.5837 = bf16[32,4,64]{2,1,0} add(%mul.5832, %mul.5836), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.5838 = bf16[32,4,128]{2,1,0} concatenate(%sub.5828, %add.5837), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.5839 = bf16[32,512]{1,0} reshape(%concatenate.5838), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.5740 = bf16[32,4,128]{2,1,0} slice(%reshape.5737), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.5741 = bf16[32,512]{1,0} reshape(%slice.5740), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.5840 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_27_.463, %reshape.5815, %reshape.5839, %reshape.5741, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.5841 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.5840), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_28_.464 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(463), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[28]"}
  %jit__jax_attn_func_.5842 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.5840), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_27_self_attn_o_proj_weight__.189 = bf16[2048,4096]{1,0} parameter(188), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.27.self_attn.o_proj.weight\']"}
  %dot_general.5843 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.5842, %params_and_buffers__vllm_model_language_model_model_layers_27_self_attn_o_proj_weight__.189), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.5844 = f32[32,2048]{1,0} convert(%dot_general.5843), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5715 = bf16[32,2048]{1,0} convert(%add.5714), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5845 = f32[32,2048]{1,0} convert(%convert_element_type.5715), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.5846 = f32[32,2048]{1,0} add(%convert_element_type.5844, %convert_element_type.5845), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.5848 = f32[32,2048]{1,0} power(%add.5846, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5853 = f32[32]{0} reduce(%pow.5848, %constant.512), dimensions={1}, to_apply=%region_143.5852, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5854 = f32[32,1]{1,0} reshape(%reduce_sum.5853), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5855 = f32[32,1]{1,0} divide(%broadcast_in_dim.5854, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5856 = f32[32,1]{1,0} add(%div.5855, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5857 = f32[32,1]{1,0} rsqrt(%add.5856), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5858 = f32[32,1]{1,0} broadcast(%rsqrt.5857), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5859 = f32[32]{0} reshape(%mul.5858), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5860 = f32[32,2048]{1,0} broadcast(%mul.5859), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5861 = f32[32,2048]{1,0} multiply(%add.5846, %mul.5860), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5862 = bf16[32,2048]{1,0} convert(%mul.5861), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_27_post_attention_layernorm_weight__.187 = bf16[2048]{0} parameter(186), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.27.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.5863 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_27_post_attention_layernorm_weight__.187), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5864 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.5863), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5865 = bf16[2048]{0} reshape(%mul.5864), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5866 = bf16[32,2048]{1,0} broadcast(%mul.5865), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5867 = bf16[32,2048]{1,0} multiply(%convert_element_type.5862, %mul.5866), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_27_mlp_experts_w13_weight__.184 = bf16[128,1536,2048]{2,1,0} parameter(183), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.27.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_27_mlp_experts_w2_weight__.185 = bf16[128,2048,768]{2,1,0} parameter(184), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.27.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_27_mlp_gate_weight__.186 = bf16[128,2048]{1,0} parameter(185), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.27.mlp.gate.weight\']"}
  %dot_general.5868 = bf16[32,128]{1,0} dot(%mul.5867, %params_and_buffers__vllm_model_language_model_model_layers_27_mlp_gate_weight__.186), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.5869 = bf16[32,2048]{1,0} call(%mul.5867, %params_and_buffers__vllm_model_language_model_model_layers_27_mlp_experts_w13_weight__.184, %params_and_buffers__vllm_model_language_model_model_layers_27_mlp_experts_w2_weight__.185, %dot_general.5868), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.5870 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.5869), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5847 = bf16[32,2048]{1,0} convert(%add.5846), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5871 = f32[32,2048]{1,0} convert(%convert_element_type.5847), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.5872 = f32[32,2048]{1,0} add(%convert_element_type.5870, %convert_element_type.5871), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.5874 = f32[32,2048]{1,0} power(%add.5872, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5879 = f32[32]{0} reduce(%pow.5874, %constant.512), dimensions={1}, to_apply=%region_144.5878, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5880 = f32[32,1]{1,0} reshape(%reduce_sum.5879), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5881 = f32[32,1]{1,0} divide(%broadcast_in_dim.5880, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5882 = f32[32,1]{1,0} add(%div.5881, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5883 = f32[32,1]{1,0} rsqrt(%add.5882), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5884 = f32[32,1]{1,0} broadcast(%rsqrt.5883), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5885 = f32[32]{0} reshape(%mul.5884), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5886 = f32[32,2048]{1,0} broadcast(%mul.5885), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5887 = f32[32,2048]{1,0} multiply(%add.5872, %mul.5886), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5888 = bf16[32,2048]{1,0} convert(%mul.5887), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_28_input_layernorm_weight__.192 = bf16[2048]{0} parameter(191), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.28.input_layernorm.weight\']"}
  %broadcast_in_dim.5889 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_28_input_layernorm_weight__.192), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5890 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.5889), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5891 = bf16[2048]{0} reshape(%mul.5890), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5892 = bf16[32,2048]{1,0} broadcast(%mul.5891), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5893 = bf16[32,2048]{1,0} multiply(%convert_element_type.5888, %mul.5892), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_28_self_attn_qkv_proj_weight__.200 = bf16[5120,2048]{1,0} parameter(199), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.28.self_attn.qkv_proj.weight\']"}
  %dot_general.5894 = bf16[32,5120]{1,0} dot(%mul.5893, %params_and_buffers__vllm_model_language_model_model_layers_28_self_attn_qkv_proj_weight__.200), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.5895 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.5894), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.5896 = bf16[32,4,1024]{2,1,0} slice(%reshape.5895), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.5900 = bf16[32,32,128]{2,1,0} reshape(%slice.5896), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.5901 = f32[32,32,128]{2,1,0} convert(%reshape.5900), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.5902 = f32[32,32,128]{2,1,0} power(%convert_element_type.5901, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5907 = f32[32,32]{1,0} reduce(%pow.5902, %constant.512), dimensions={2}, to_apply=%region_145.5906, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5908 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.5907), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5909 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.5908, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5910 = f32[32,32,1]{2,1,0} add(%div.5909, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5911 = f32[32,32,1]{2,1,0} rsqrt(%add.5910), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5912 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.5911), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5913 = f32[32,32]{1,0} reshape(%mul.5912), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5914 = f32[32,32,128]{2,1,0} broadcast(%mul.5913), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5915 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.5901, %mul.5914), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5916 = bf16[32,32,128]{2,1,0} convert(%mul.5915), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_28_self_attn_q_norm_weight__.199 = bf16[128]{0} parameter(198), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.28.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.5917 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_28_self_attn_q_norm_weight__.199), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5918 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.5917), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5919 = bf16[128]{0} reshape(%mul.5918), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5920 = bf16[32,32,128]{2,1,0} broadcast(%mul.5919), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5921 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.5916, %mul.5920), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5952 = bf16[32,32,64]{2,1,0} slice(%mul.5921), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.5943 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.5944 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.5945 = s32[32]{0} select(%lt.5943, %add.5944, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.5946 = s32[32,1]{1,0} reshape(%select_n.5945), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.5947 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.5946), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.5948 = bf16[32,64]{1,0} slice(%gather.5947), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5950 = bf16[32,1,64]{2,1,0} reshape(%slice.5948), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5954 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5950), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5955 = bf16[32,64]{1,0} reshape(%mul.5954), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5956 = bf16[32,32,64]{2,1,0} broadcast(%mul.5955), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5957 = bf16[32,32,64]{2,1,0} multiply(%slice.5952, %mul.5956), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5953 = bf16[32,32,64]{2,1,0} slice(%mul.5921), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.5949 = bf16[32,64]{1,0} slice(%gather.5947), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5951 = bf16[32,1,64]{2,1,0} reshape(%slice.5949), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5958 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5951), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5959 = bf16[32,64]{1,0} reshape(%mul.5958), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5960 = bf16[32,32,64]{2,1,0} broadcast(%mul.5959), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5961 = bf16[32,32,64]{2,1,0} multiply(%slice.5953, %mul.5960), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.5962 = bf16[32,32,64]{2,1,0} subtract(%mul.5957, %mul.5961), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.5963 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5950), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5964 = bf16[32,64]{1,0} reshape(%mul.5963), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5965 = bf16[32,32,64]{2,1,0} broadcast(%mul.5964), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5966 = bf16[32,32,64]{2,1,0} multiply(%slice.5953, %mul.5965), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5967 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5951), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5968 = bf16[32,64]{1,0} reshape(%mul.5967), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5969 = bf16[32,32,64]{2,1,0} broadcast(%mul.5968), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5970 = bf16[32,32,64]{2,1,0} multiply(%slice.5952, %mul.5969), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.5971 = bf16[32,32,64]{2,1,0} add(%mul.5966, %mul.5970), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.5972 = bf16[32,32,128]{2,1,0} concatenate(%sub.5962, %add.5971), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.5973 = bf16[32,4096]{1,0} reshape(%concatenate.5972), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.5897 = bf16[32,4,128]{2,1,0} slice(%reshape.5895), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.5922 = f32[32,4,128]{2,1,0} convert(%slice.5897), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.5923 = f32[32,4,128]{2,1,0} power(%convert_element_type.5922, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.5928 = f32[32,4]{1,0} reduce(%pow.5923, %constant.512), dimensions={2}, to_apply=%region_146.5927, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.5929 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.5928), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.5930 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.5929, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.5931 = f32[32,4,1]{2,1,0} add(%div.5930, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.5932 = f32[32,4,1]{2,1,0} rsqrt(%add.5931), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.5933 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.5932), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5934 = f32[32,4]{1,0} reshape(%mul.5933), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5935 = f32[32,4,128]{2,1,0} broadcast(%mul.5934), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5936 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.5922, %mul.5935), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.5937 = bf16[32,4,128]{2,1,0} convert(%mul.5936), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_28_self_attn_k_norm_weight__.197 = bf16[128]{0} parameter(196), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.28.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.5938 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_28_self_attn_k_norm_weight__.197), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5939 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.5938), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5940 = bf16[128]{0} reshape(%mul.5939), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5941 = bf16[32,4,128]{2,1,0} broadcast(%mul.5940), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5942 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.5937, %mul.5941), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5976 = bf16[32,4,64]{2,1,0} slice(%mul.5942), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5974 = bf16[32,1,64]{2,1,0} reshape(%slice.5948), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5978 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5974), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5979 = bf16[32,64]{1,0} reshape(%mul.5978), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5980 = bf16[32,4,64]{2,1,0} broadcast(%mul.5979), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5981 = bf16[32,4,64]{2,1,0} multiply(%slice.5976, %mul.5980), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.5977 = bf16[32,4,64]{2,1,0} slice(%mul.5942), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.5975 = bf16[32,1,64]{2,1,0} reshape(%slice.5949), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.5982 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5975), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5983 = bf16[32,64]{1,0} reshape(%mul.5982), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5984 = bf16[32,4,64]{2,1,0} broadcast(%mul.5983), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5985 = bf16[32,4,64]{2,1,0} multiply(%slice.5977, %mul.5984), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.5986 = bf16[32,4,64]{2,1,0} subtract(%mul.5981, %mul.5985), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.5987 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5974), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5988 = bf16[32,64]{1,0} reshape(%mul.5987), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5989 = bf16[32,4,64]{2,1,0} broadcast(%mul.5988), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5990 = bf16[32,4,64]{2,1,0} multiply(%slice.5977, %mul.5989), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5991 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.5975), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5992 = bf16[32,64]{1,0} reshape(%mul.5991), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5993 = bf16[32,4,64]{2,1,0} broadcast(%mul.5992), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.5994 = bf16[32,4,64]{2,1,0} multiply(%slice.5976, %mul.5993), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.5995 = bf16[32,4,64]{2,1,0} add(%mul.5990, %mul.5994), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.5996 = bf16[32,4,128]{2,1,0} concatenate(%sub.5986, %add.5995), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.5997 = bf16[32,512]{1,0} reshape(%concatenate.5996), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.5898 = bf16[32,4,128]{2,1,0} slice(%reshape.5895), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.5899 = bf16[32,512]{1,0} reshape(%slice.5898), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.5998 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_28_.464, %reshape.5973, %reshape.5997, %reshape.5899, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.5999 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.5998), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_29_.465 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(464), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[29]"}
  %jit__jax_attn_func_.6000 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.5998), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_28_self_attn_o_proj_weight__.198 = bf16[2048,4096]{1,0} parameter(197), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.28.self_attn.o_proj.weight\']"}
  %dot_general.6001 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.6000, %params_and_buffers__vllm_model_language_model_model_layers_28_self_attn_o_proj_weight__.198), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.6002 = f32[32,2048]{1,0} convert(%dot_general.6001), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.5873 = bf16[32,2048]{1,0} convert(%add.5872), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6003 = f32[32,2048]{1,0} convert(%convert_element_type.5873), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.6004 = f32[32,2048]{1,0} add(%convert_element_type.6002, %convert_element_type.6003), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.6006 = f32[32,2048]{1,0} power(%add.6004, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6011 = f32[32]{0} reduce(%pow.6006, %constant.512), dimensions={1}, to_apply=%region_147.6010, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6012 = f32[32,1]{1,0} reshape(%reduce_sum.6011), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6013 = f32[32,1]{1,0} divide(%broadcast_in_dim.6012, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6014 = f32[32,1]{1,0} add(%div.6013, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6015 = f32[32,1]{1,0} rsqrt(%add.6014), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6016 = f32[32,1]{1,0} broadcast(%rsqrt.6015), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6017 = f32[32]{0} reshape(%mul.6016), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6018 = f32[32,2048]{1,0} broadcast(%mul.6017), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6019 = f32[32,2048]{1,0} multiply(%add.6004, %mul.6018), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6020 = bf16[32,2048]{1,0} convert(%mul.6019), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_28_post_attention_layernorm_weight__.196 = bf16[2048]{0} parameter(195), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.28.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.6021 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_28_post_attention_layernorm_weight__.196), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6022 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.6021), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6023 = bf16[2048]{0} reshape(%mul.6022), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6024 = bf16[32,2048]{1,0} broadcast(%mul.6023), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6025 = bf16[32,2048]{1,0} multiply(%convert_element_type.6020, %mul.6024), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_28_mlp_experts_w13_weight__.193 = bf16[128,1536,2048]{2,1,0} parameter(192), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.28.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_28_mlp_experts_w2_weight__.194 = bf16[128,2048,768]{2,1,0} parameter(193), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.28.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_28_mlp_gate_weight__.195 = bf16[128,2048]{1,0} parameter(194), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.28.mlp.gate.weight\']"}
  %dot_general.6026 = bf16[32,128]{1,0} dot(%mul.6025, %params_and_buffers__vllm_model_language_model_model_layers_28_mlp_gate_weight__.195), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.6027 = bf16[32,2048]{1,0} call(%mul.6025, %params_and_buffers__vllm_model_language_model_model_layers_28_mlp_experts_w13_weight__.193, %params_and_buffers__vllm_model_language_model_model_layers_28_mlp_experts_w2_weight__.194, %dot_general.6026), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.6028 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.6027), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6005 = bf16[32,2048]{1,0} convert(%add.6004), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6029 = f32[32,2048]{1,0} convert(%convert_element_type.6005), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.6030 = f32[32,2048]{1,0} add(%convert_element_type.6028, %convert_element_type.6029), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.6032 = f32[32,2048]{1,0} power(%add.6030, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6037 = f32[32]{0} reduce(%pow.6032, %constant.512), dimensions={1}, to_apply=%region_148.6036, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6038 = f32[32,1]{1,0} reshape(%reduce_sum.6037), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6039 = f32[32,1]{1,0} divide(%broadcast_in_dim.6038, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6040 = f32[32,1]{1,0} add(%div.6039, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6041 = f32[32,1]{1,0} rsqrt(%add.6040), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6042 = f32[32,1]{1,0} broadcast(%rsqrt.6041), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6043 = f32[32]{0} reshape(%mul.6042), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6044 = f32[32,2048]{1,0} broadcast(%mul.6043), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6045 = f32[32,2048]{1,0} multiply(%add.6030, %mul.6044), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6046 = bf16[32,2048]{1,0} convert(%mul.6045), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_29_input_layernorm_weight__.201 = bf16[2048]{0} parameter(200), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.29.input_layernorm.weight\']"}
  %broadcast_in_dim.6047 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_29_input_layernorm_weight__.201), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6048 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.6047), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6049 = bf16[2048]{0} reshape(%mul.6048), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6050 = bf16[32,2048]{1,0} broadcast(%mul.6049), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6051 = bf16[32,2048]{1,0} multiply(%convert_element_type.6046, %mul.6050), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_29_self_attn_qkv_proj_weight__.209 = bf16[5120,2048]{1,0} parameter(208), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.29.self_attn.qkv_proj.weight\']"}
  %dot_general.6052 = bf16[32,5120]{1,0} dot(%mul.6051, %params_and_buffers__vllm_model_language_model_model_layers_29_self_attn_qkv_proj_weight__.209), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.6053 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.6052), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.6054 = bf16[32,4,1024]{2,1,0} slice(%reshape.6053), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.6058 = bf16[32,32,128]{2,1,0} reshape(%slice.6054), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.6059 = f32[32,32,128]{2,1,0} convert(%reshape.6058), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.6060 = f32[32,32,128]{2,1,0} power(%convert_element_type.6059, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6065 = f32[32,32]{1,0} reduce(%pow.6060, %constant.512), dimensions={2}, to_apply=%region_149.6064, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6066 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.6065), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6067 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.6066, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6068 = f32[32,32,1]{2,1,0} add(%div.6067, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6069 = f32[32,32,1]{2,1,0} rsqrt(%add.6068), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6070 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.6069), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6071 = f32[32,32]{1,0} reshape(%mul.6070), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6072 = f32[32,32,128]{2,1,0} broadcast(%mul.6071), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6073 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.6059, %mul.6072), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6074 = bf16[32,32,128]{2,1,0} convert(%mul.6073), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_29_self_attn_q_norm_weight__.208 = bf16[128]{0} parameter(207), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.29.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.6075 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_29_self_attn_q_norm_weight__.208), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6076 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.6075), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6077 = bf16[128]{0} reshape(%mul.6076), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6078 = bf16[32,32,128]{2,1,0} broadcast(%mul.6077), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6079 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.6074, %mul.6078), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6110 = bf16[32,32,64]{2,1,0} slice(%mul.6079), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.6101 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.6102 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.6103 = s32[32]{0} select(%lt.6101, %add.6102, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.6104 = s32[32,1]{1,0} reshape(%select_n.6103), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.6105 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.6104), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.6106 = bf16[32,64]{1,0} slice(%gather.6105), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6108 = bf16[32,1,64]{2,1,0} reshape(%slice.6106), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6112 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6108), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6113 = bf16[32,64]{1,0} reshape(%mul.6112), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6114 = bf16[32,32,64]{2,1,0} broadcast(%mul.6113), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6115 = bf16[32,32,64]{2,1,0} multiply(%slice.6110, %mul.6114), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6111 = bf16[32,32,64]{2,1,0} slice(%mul.6079), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.6107 = bf16[32,64]{1,0} slice(%gather.6105), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6109 = bf16[32,1,64]{2,1,0} reshape(%slice.6107), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6116 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6109), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6117 = bf16[32,64]{1,0} reshape(%mul.6116), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6118 = bf16[32,32,64]{2,1,0} broadcast(%mul.6117), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6119 = bf16[32,32,64]{2,1,0} multiply(%slice.6111, %mul.6118), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.6120 = bf16[32,32,64]{2,1,0} subtract(%mul.6115, %mul.6119), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.6121 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6108), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6122 = bf16[32,64]{1,0} reshape(%mul.6121), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6123 = bf16[32,32,64]{2,1,0} broadcast(%mul.6122), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6124 = bf16[32,32,64]{2,1,0} multiply(%slice.6111, %mul.6123), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6125 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6109), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6126 = bf16[32,64]{1,0} reshape(%mul.6125), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6127 = bf16[32,32,64]{2,1,0} broadcast(%mul.6126), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6128 = bf16[32,32,64]{2,1,0} multiply(%slice.6110, %mul.6127), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.6129 = bf16[32,32,64]{2,1,0} add(%mul.6124, %mul.6128), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.6130 = bf16[32,32,128]{2,1,0} concatenate(%sub.6120, %add.6129), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.6131 = bf16[32,4096]{1,0} reshape(%concatenate.6130), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.6055 = bf16[32,4,128]{2,1,0} slice(%reshape.6053), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.6080 = f32[32,4,128]{2,1,0} convert(%slice.6055), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.6081 = f32[32,4,128]{2,1,0} power(%convert_element_type.6080, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6086 = f32[32,4]{1,0} reduce(%pow.6081, %constant.512), dimensions={2}, to_apply=%region_150.6085, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6087 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.6086), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6088 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.6087, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6089 = f32[32,4,1]{2,1,0} add(%div.6088, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6090 = f32[32,4,1]{2,1,0} rsqrt(%add.6089), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6091 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.6090), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6092 = f32[32,4]{1,0} reshape(%mul.6091), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6093 = f32[32,4,128]{2,1,0} broadcast(%mul.6092), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6094 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.6080, %mul.6093), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6095 = bf16[32,4,128]{2,1,0} convert(%mul.6094), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_29_self_attn_k_norm_weight__.206 = bf16[128]{0} parameter(205), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.29.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.6096 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_29_self_attn_k_norm_weight__.206), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6097 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.6096), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6098 = bf16[128]{0} reshape(%mul.6097), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6099 = bf16[32,4,128]{2,1,0} broadcast(%mul.6098), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6100 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.6095, %mul.6099), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6134 = bf16[32,4,64]{2,1,0} slice(%mul.6100), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6132 = bf16[32,1,64]{2,1,0} reshape(%slice.6106), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6136 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6132), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6137 = bf16[32,64]{1,0} reshape(%mul.6136), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6138 = bf16[32,4,64]{2,1,0} broadcast(%mul.6137), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6139 = bf16[32,4,64]{2,1,0} multiply(%slice.6134, %mul.6138), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6135 = bf16[32,4,64]{2,1,0} slice(%mul.6100), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6133 = bf16[32,1,64]{2,1,0} reshape(%slice.6107), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6140 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6133), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6141 = bf16[32,64]{1,0} reshape(%mul.6140), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6142 = bf16[32,4,64]{2,1,0} broadcast(%mul.6141), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6143 = bf16[32,4,64]{2,1,0} multiply(%slice.6135, %mul.6142), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.6144 = bf16[32,4,64]{2,1,0} subtract(%mul.6139, %mul.6143), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.6145 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6132), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6146 = bf16[32,64]{1,0} reshape(%mul.6145), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6147 = bf16[32,4,64]{2,1,0} broadcast(%mul.6146), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6148 = bf16[32,4,64]{2,1,0} multiply(%slice.6135, %mul.6147), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6149 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6133), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6150 = bf16[32,64]{1,0} reshape(%mul.6149), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6151 = bf16[32,4,64]{2,1,0} broadcast(%mul.6150), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6152 = bf16[32,4,64]{2,1,0} multiply(%slice.6134, %mul.6151), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.6153 = bf16[32,4,64]{2,1,0} add(%mul.6148, %mul.6152), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.6154 = bf16[32,4,128]{2,1,0} concatenate(%sub.6144, %add.6153), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.6155 = bf16[32,512]{1,0} reshape(%concatenate.6154), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.6056 = bf16[32,4,128]{2,1,0} slice(%reshape.6053), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.6057 = bf16[32,512]{1,0} reshape(%slice.6056), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.6156 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_29_.465, %reshape.6131, %reshape.6155, %reshape.6057, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.6157 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.6156), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_30_.466 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(465), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[30]"}
  %jit__jax_attn_func_.6158 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.6156), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_29_self_attn_o_proj_weight__.207 = bf16[2048,4096]{1,0} parameter(206), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.29.self_attn.o_proj.weight\']"}
  %dot_general.6159 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.6158, %params_and_buffers__vllm_model_language_model_model_layers_29_self_attn_o_proj_weight__.207), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.6160 = f32[32,2048]{1,0} convert(%dot_general.6159), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6031 = bf16[32,2048]{1,0} convert(%add.6030), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6161 = f32[32,2048]{1,0} convert(%convert_element_type.6031), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.6162 = f32[32,2048]{1,0} add(%convert_element_type.6160, %convert_element_type.6161), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.6164 = f32[32,2048]{1,0} power(%add.6162, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6169 = f32[32]{0} reduce(%pow.6164, %constant.512), dimensions={1}, to_apply=%region_151.6168, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6170 = f32[32,1]{1,0} reshape(%reduce_sum.6169), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6171 = f32[32,1]{1,0} divide(%broadcast_in_dim.6170, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6172 = f32[32,1]{1,0} add(%div.6171, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6173 = f32[32,1]{1,0} rsqrt(%add.6172), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6174 = f32[32,1]{1,0} broadcast(%rsqrt.6173), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6175 = f32[32]{0} reshape(%mul.6174), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6176 = f32[32,2048]{1,0} broadcast(%mul.6175), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6177 = f32[32,2048]{1,0} multiply(%add.6162, %mul.6176), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6178 = bf16[32,2048]{1,0} convert(%mul.6177), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_29_post_attention_layernorm_weight__.205 = bf16[2048]{0} parameter(204), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.29.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.6179 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_29_post_attention_layernorm_weight__.205), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6180 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.6179), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6181 = bf16[2048]{0} reshape(%mul.6180), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6182 = bf16[32,2048]{1,0} broadcast(%mul.6181), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6183 = bf16[32,2048]{1,0} multiply(%convert_element_type.6178, %mul.6182), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_29_mlp_experts_w13_weight__.202 = bf16[128,1536,2048]{2,1,0} parameter(201), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.29.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_29_mlp_experts_w2_weight__.203 = bf16[128,2048,768]{2,1,0} parameter(202), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.29.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_29_mlp_gate_weight__.204 = bf16[128,2048]{1,0} parameter(203), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.29.mlp.gate.weight\']"}
  %dot_general.6184 = bf16[32,128]{1,0} dot(%mul.6183, %params_and_buffers__vllm_model_language_model_model_layers_29_mlp_gate_weight__.204), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.6185 = bf16[32,2048]{1,0} call(%mul.6183, %params_and_buffers__vllm_model_language_model_model_layers_29_mlp_experts_w13_weight__.202, %params_and_buffers__vllm_model_language_model_model_layers_29_mlp_experts_w2_weight__.203, %dot_general.6184), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.6186 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.6185), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6163 = bf16[32,2048]{1,0} convert(%add.6162), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6187 = f32[32,2048]{1,0} convert(%convert_element_type.6163), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.6188 = f32[32,2048]{1,0} add(%convert_element_type.6186, %convert_element_type.6187), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.6190 = f32[32,2048]{1,0} power(%add.6188, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6195 = f32[32]{0} reduce(%pow.6190, %constant.512), dimensions={1}, to_apply=%region_152.6194, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6196 = f32[32,1]{1,0} reshape(%reduce_sum.6195), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6197 = f32[32,1]{1,0} divide(%broadcast_in_dim.6196, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6198 = f32[32,1]{1,0} add(%div.6197, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6199 = f32[32,1]{1,0} rsqrt(%add.6198), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6200 = f32[32,1]{1,0} broadcast(%rsqrt.6199), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6201 = f32[32]{0} reshape(%mul.6200), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6202 = f32[32,2048]{1,0} broadcast(%mul.6201), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6203 = f32[32,2048]{1,0} multiply(%add.6188, %mul.6202), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6204 = bf16[32,2048]{1,0} convert(%mul.6203), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_30_input_layernorm_weight__.219 = bf16[2048]{0} parameter(218), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.30.input_layernorm.weight\']"}
  %broadcast_in_dim.6205 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_30_input_layernorm_weight__.219), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6206 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.6205), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6207 = bf16[2048]{0} reshape(%mul.6206), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6208 = bf16[32,2048]{1,0} broadcast(%mul.6207), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6209 = bf16[32,2048]{1,0} multiply(%convert_element_type.6204, %mul.6208), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_30_self_attn_qkv_proj_weight__.227 = bf16[5120,2048]{1,0} parameter(226), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.30.self_attn.qkv_proj.weight\']"}
  %dot_general.6210 = bf16[32,5120]{1,0} dot(%mul.6209, %params_and_buffers__vllm_model_language_model_model_layers_30_self_attn_qkv_proj_weight__.227), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.6211 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.6210), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.6212 = bf16[32,4,1024]{2,1,0} slice(%reshape.6211), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.6216 = bf16[32,32,128]{2,1,0} reshape(%slice.6212), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.6217 = f32[32,32,128]{2,1,0} convert(%reshape.6216), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.6218 = f32[32,32,128]{2,1,0} power(%convert_element_type.6217, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6223 = f32[32,32]{1,0} reduce(%pow.6218, %constant.512), dimensions={2}, to_apply=%region_153.6222, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6224 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.6223), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6225 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.6224, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6226 = f32[32,32,1]{2,1,0} add(%div.6225, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6227 = f32[32,32,1]{2,1,0} rsqrt(%add.6226), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6228 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.6227), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6229 = f32[32,32]{1,0} reshape(%mul.6228), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6230 = f32[32,32,128]{2,1,0} broadcast(%mul.6229), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6231 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.6217, %mul.6230), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6232 = bf16[32,32,128]{2,1,0} convert(%mul.6231), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_30_self_attn_q_norm_weight__.226 = bf16[128]{0} parameter(225), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.30.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.6233 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_30_self_attn_q_norm_weight__.226), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6234 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.6233), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6235 = bf16[128]{0} reshape(%mul.6234), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6236 = bf16[32,32,128]{2,1,0} broadcast(%mul.6235), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6237 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.6232, %mul.6236), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6268 = bf16[32,32,64]{2,1,0} slice(%mul.6237), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.6259 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.6260 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.6261 = s32[32]{0} select(%lt.6259, %add.6260, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.6262 = s32[32,1]{1,0} reshape(%select_n.6261), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.6263 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.6262), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.6264 = bf16[32,64]{1,0} slice(%gather.6263), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6266 = bf16[32,1,64]{2,1,0} reshape(%slice.6264), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6270 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6266), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6271 = bf16[32,64]{1,0} reshape(%mul.6270), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6272 = bf16[32,32,64]{2,1,0} broadcast(%mul.6271), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6273 = bf16[32,32,64]{2,1,0} multiply(%slice.6268, %mul.6272), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6269 = bf16[32,32,64]{2,1,0} slice(%mul.6237), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.6265 = bf16[32,64]{1,0} slice(%gather.6263), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6267 = bf16[32,1,64]{2,1,0} reshape(%slice.6265), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6274 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6267), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6275 = bf16[32,64]{1,0} reshape(%mul.6274), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6276 = bf16[32,32,64]{2,1,0} broadcast(%mul.6275), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6277 = bf16[32,32,64]{2,1,0} multiply(%slice.6269, %mul.6276), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.6278 = bf16[32,32,64]{2,1,0} subtract(%mul.6273, %mul.6277), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.6279 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6266), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6280 = bf16[32,64]{1,0} reshape(%mul.6279), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6281 = bf16[32,32,64]{2,1,0} broadcast(%mul.6280), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6282 = bf16[32,32,64]{2,1,0} multiply(%slice.6269, %mul.6281), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6283 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6267), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6284 = bf16[32,64]{1,0} reshape(%mul.6283), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6285 = bf16[32,32,64]{2,1,0} broadcast(%mul.6284), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6286 = bf16[32,32,64]{2,1,0} multiply(%slice.6268, %mul.6285), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.6287 = bf16[32,32,64]{2,1,0} add(%mul.6282, %mul.6286), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.6288 = bf16[32,32,128]{2,1,0} concatenate(%sub.6278, %add.6287), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.6289 = bf16[32,4096]{1,0} reshape(%concatenate.6288), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.6213 = bf16[32,4,128]{2,1,0} slice(%reshape.6211), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.6238 = f32[32,4,128]{2,1,0} convert(%slice.6213), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.6239 = f32[32,4,128]{2,1,0} power(%convert_element_type.6238, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6244 = f32[32,4]{1,0} reduce(%pow.6239, %constant.512), dimensions={2}, to_apply=%region_154.6243, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6245 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.6244), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6246 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.6245, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6247 = f32[32,4,1]{2,1,0} add(%div.6246, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6248 = f32[32,4,1]{2,1,0} rsqrt(%add.6247), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6249 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.6248), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6250 = f32[32,4]{1,0} reshape(%mul.6249), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6251 = f32[32,4,128]{2,1,0} broadcast(%mul.6250), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6252 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.6238, %mul.6251), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6253 = bf16[32,4,128]{2,1,0} convert(%mul.6252), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_30_self_attn_k_norm_weight__.224 = bf16[128]{0} parameter(223), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.30.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.6254 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_30_self_attn_k_norm_weight__.224), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6255 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.6254), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6256 = bf16[128]{0} reshape(%mul.6255), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6257 = bf16[32,4,128]{2,1,0} broadcast(%mul.6256), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6258 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.6253, %mul.6257), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6292 = bf16[32,4,64]{2,1,0} slice(%mul.6258), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6290 = bf16[32,1,64]{2,1,0} reshape(%slice.6264), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6294 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6290), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6295 = bf16[32,64]{1,0} reshape(%mul.6294), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6296 = bf16[32,4,64]{2,1,0} broadcast(%mul.6295), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6297 = bf16[32,4,64]{2,1,0} multiply(%slice.6292, %mul.6296), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6293 = bf16[32,4,64]{2,1,0} slice(%mul.6258), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6291 = bf16[32,1,64]{2,1,0} reshape(%slice.6265), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6298 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6291), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6299 = bf16[32,64]{1,0} reshape(%mul.6298), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6300 = bf16[32,4,64]{2,1,0} broadcast(%mul.6299), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6301 = bf16[32,4,64]{2,1,0} multiply(%slice.6293, %mul.6300), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.6302 = bf16[32,4,64]{2,1,0} subtract(%mul.6297, %mul.6301), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.6303 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6290), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6304 = bf16[32,64]{1,0} reshape(%mul.6303), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6305 = bf16[32,4,64]{2,1,0} broadcast(%mul.6304), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6306 = bf16[32,4,64]{2,1,0} multiply(%slice.6293, %mul.6305), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6307 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6291), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6308 = bf16[32,64]{1,0} reshape(%mul.6307), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6309 = bf16[32,4,64]{2,1,0} broadcast(%mul.6308), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6310 = bf16[32,4,64]{2,1,0} multiply(%slice.6292, %mul.6309), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.6311 = bf16[32,4,64]{2,1,0} add(%mul.6306, %mul.6310), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.6312 = bf16[32,4,128]{2,1,0} concatenate(%sub.6302, %add.6311), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.6313 = bf16[32,512]{1,0} reshape(%concatenate.6312), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.6214 = bf16[32,4,128]{2,1,0} slice(%reshape.6211), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.6215 = bf16[32,512]{1,0} reshape(%slice.6214), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.6314 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_30_.466, %reshape.6289, %reshape.6313, %reshape.6215, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.6315 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.6314), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_31_.467 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(466), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[31]"}
  %jit__jax_attn_func_.6316 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.6314), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_30_self_attn_o_proj_weight__.225 = bf16[2048,4096]{1,0} parameter(224), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.30.self_attn.o_proj.weight\']"}
  %dot_general.6317 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.6316, %params_and_buffers__vllm_model_language_model_model_layers_30_self_attn_o_proj_weight__.225), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.6318 = f32[32,2048]{1,0} convert(%dot_general.6317), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6189 = bf16[32,2048]{1,0} convert(%add.6188), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6319 = f32[32,2048]{1,0} convert(%convert_element_type.6189), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.6320 = f32[32,2048]{1,0} add(%convert_element_type.6318, %convert_element_type.6319), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.6322 = f32[32,2048]{1,0} power(%add.6320, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6327 = f32[32]{0} reduce(%pow.6322, %constant.512), dimensions={1}, to_apply=%region_155.6326, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6328 = f32[32,1]{1,0} reshape(%reduce_sum.6327), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6329 = f32[32,1]{1,0} divide(%broadcast_in_dim.6328, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6330 = f32[32,1]{1,0} add(%div.6329, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6331 = f32[32,1]{1,0} rsqrt(%add.6330), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6332 = f32[32,1]{1,0} broadcast(%rsqrt.6331), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6333 = f32[32]{0} reshape(%mul.6332), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6334 = f32[32,2048]{1,0} broadcast(%mul.6333), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6335 = f32[32,2048]{1,0} multiply(%add.6320, %mul.6334), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6336 = bf16[32,2048]{1,0} convert(%mul.6335), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_30_post_attention_layernorm_weight__.223 = bf16[2048]{0} parameter(222), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.30.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.6337 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_30_post_attention_layernorm_weight__.223), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6338 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.6337), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6339 = bf16[2048]{0} reshape(%mul.6338), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6340 = bf16[32,2048]{1,0} broadcast(%mul.6339), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6341 = bf16[32,2048]{1,0} multiply(%convert_element_type.6336, %mul.6340), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_30_mlp_experts_w13_weight__.220 = bf16[128,1536,2048]{2,1,0} parameter(219), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.30.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_30_mlp_experts_w2_weight__.221 = bf16[128,2048,768]{2,1,0} parameter(220), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.30.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_30_mlp_gate_weight__.222 = bf16[128,2048]{1,0} parameter(221), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.30.mlp.gate.weight\']"}
  %dot_general.6342 = bf16[32,128]{1,0} dot(%mul.6341, %params_and_buffers__vllm_model_language_model_model_layers_30_mlp_gate_weight__.222), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.6343 = bf16[32,2048]{1,0} call(%mul.6341, %params_and_buffers__vllm_model_language_model_model_layers_30_mlp_experts_w13_weight__.220, %params_and_buffers__vllm_model_language_model_model_layers_30_mlp_experts_w2_weight__.221, %dot_general.6342), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.6344 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.6343), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6321 = bf16[32,2048]{1,0} convert(%add.6320), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6345 = f32[32,2048]{1,0} convert(%convert_element_type.6321), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.6346 = f32[32,2048]{1,0} add(%convert_element_type.6344, %convert_element_type.6345), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.6348 = f32[32,2048]{1,0} power(%add.6346, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6353 = f32[32]{0} reduce(%pow.6348, %constant.512), dimensions={1}, to_apply=%region_156.6352, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6354 = f32[32,1]{1,0} reshape(%reduce_sum.6353), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6355 = f32[32,1]{1,0} divide(%broadcast_in_dim.6354, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6356 = f32[32,1]{1,0} add(%div.6355, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6357 = f32[32,1]{1,0} rsqrt(%add.6356), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6358 = f32[32,1]{1,0} broadcast(%rsqrt.6357), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6359 = f32[32]{0} reshape(%mul.6358), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6360 = f32[32,2048]{1,0} broadcast(%mul.6359), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6361 = f32[32,2048]{1,0} multiply(%add.6346, %mul.6360), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6362 = bf16[32,2048]{1,0} convert(%mul.6361), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_31_input_layernorm_weight__.228 = bf16[2048]{0} parameter(227), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.31.input_layernorm.weight\']"}
  %broadcast_in_dim.6363 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_31_input_layernorm_weight__.228), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6364 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.6363), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6365 = bf16[2048]{0} reshape(%mul.6364), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6366 = bf16[32,2048]{1,0} broadcast(%mul.6365), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6367 = bf16[32,2048]{1,0} multiply(%convert_element_type.6362, %mul.6366), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_31_self_attn_qkv_proj_weight__.236 = bf16[5120,2048]{1,0} parameter(235), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.31.self_attn.qkv_proj.weight\']"}
  %dot_general.6368 = bf16[32,5120]{1,0} dot(%mul.6367, %params_and_buffers__vllm_model_language_model_model_layers_31_self_attn_qkv_proj_weight__.236), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.6369 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.6368), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.6370 = bf16[32,4,1024]{2,1,0} slice(%reshape.6369), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.6374 = bf16[32,32,128]{2,1,0} reshape(%slice.6370), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.6375 = f32[32,32,128]{2,1,0} convert(%reshape.6374), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.6376 = f32[32,32,128]{2,1,0} power(%convert_element_type.6375, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6381 = f32[32,32]{1,0} reduce(%pow.6376, %constant.512), dimensions={2}, to_apply=%region_157.6380, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6382 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.6381), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6383 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.6382, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6384 = f32[32,32,1]{2,1,0} add(%div.6383, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6385 = f32[32,32,1]{2,1,0} rsqrt(%add.6384), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6386 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.6385), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6387 = f32[32,32]{1,0} reshape(%mul.6386), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6388 = f32[32,32,128]{2,1,0} broadcast(%mul.6387), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6389 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.6375, %mul.6388), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6390 = bf16[32,32,128]{2,1,0} convert(%mul.6389), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_31_self_attn_q_norm_weight__.235 = bf16[128]{0} parameter(234), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.31.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.6391 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_31_self_attn_q_norm_weight__.235), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6392 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.6391), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6393 = bf16[128]{0} reshape(%mul.6392), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6394 = bf16[32,32,128]{2,1,0} broadcast(%mul.6393), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6395 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.6390, %mul.6394), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6426 = bf16[32,32,64]{2,1,0} slice(%mul.6395), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.6417 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.6418 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.6419 = s32[32]{0} select(%lt.6417, %add.6418, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.6420 = s32[32,1]{1,0} reshape(%select_n.6419), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.6421 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.6420), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.6422 = bf16[32,64]{1,0} slice(%gather.6421), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6424 = bf16[32,1,64]{2,1,0} reshape(%slice.6422), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6428 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6424), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6429 = bf16[32,64]{1,0} reshape(%mul.6428), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6430 = bf16[32,32,64]{2,1,0} broadcast(%mul.6429), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6431 = bf16[32,32,64]{2,1,0} multiply(%slice.6426, %mul.6430), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6427 = bf16[32,32,64]{2,1,0} slice(%mul.6395), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.6423 = bf16[32,64]{1,0} slice(%gather.6421), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6425 = bf16[32,1,64]{2,1,0} reshape(%slice.6423), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6432 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6425), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6433 = bf16[32,64]{1,0} reshape(%mul.6432), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6434 = bf16[32,32,64]{2,1,0} broadcast(%mul.6433), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6435 = bf16[32,32,64]{2,1,0} multiply(%slice.6427, %mul.6434), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.6436 = bf16[32,32,64]{2,1,0} subtract(%mul.6431, %mul.6435), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.6437 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6424), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6438 = bf16[32,64]{1,0} reshape(%mul.6437), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6439 = bf16[32,32,64]{2,1,0} broadcast(%mul.6438), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6440 = bf16[32,32,64]{2,1,0} multiply(%slice.6427, %mul.6439), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6441 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6425), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6442 = bf16[32,64]{1,0} reshape(%mul.6441), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6443 = bf16[32,32,64]{2,1,0} broadcast(%mul.6442), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6444 = bf16[32,32,64]{2,1,0} multiply(%slice.6426, %mul.6443), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.6445 = bf16[32,32,64]{2,1,0} add(%mul.6440, %mul.6444), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.6446 = bf16[32,32,128]{2,1,0} concatenate(%sub.6436, %add.6445), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.6447 = bf16[32,4096]{1,0} reshape(%concatenate.6446), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.6371 = bf16[32,4,128]{2,1,0} slice(%reshape.6369), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.6396 = f32[32,4,128]{2,1,0} convert(%slice.6371), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.6397 = f32[32,4,128]{2,1,0} power(%convert_element_type.6396, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6402 = f32[32,4]{1,0} reduce(%pow.6397, %constant.512), dimensions={2}, to_apply=%region_158.6401, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6403 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.6402), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6404 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.6403, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6405 = f32[32,4,1]{2,1,0} add(%div.6404, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6406 = f32[32,4,1]{2,1,0} rsqrt(%add.6405), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6407 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.6406), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6408 = f32[32,4]{1,0} reshape(%mul.6407), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6409 = f32[32,4,128]{2,1,0} broadcast(%mul.6408), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6410 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.6396, %mul.6409), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6411 = bf16[32,4,128]{2,1,0} convert(%mul.6410), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_31_self_attn_k_norm_weight__.233 = bf16[128]{0} parameter(232), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.31.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.6412 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_31_self_attn_k_norm_weight__.233), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6413 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.6412), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6414 = bf16[128]{0} reshape(%mul.6413), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6415 = bf16[32,4,128]{2,1,0} broadcast(%mul.6414), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6416 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.6411, %mul.6415), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6450 = bf16[32,4,64]{2,1,0} slice(%mul.6416), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6448 = bf16[32,1,64]{2,1,0} reshape(%slice.6422), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6452 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6448), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6453 = bf16[32,64]{1,0} reshape(%mul.6452), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6454 = bf16[32,4,64]{2,1,0} broadcast(%mul.6453), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6455 = bf16[32,4,64]{2,1,0} multiply(%slice.6450, %mul.6454), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6451 = bf16[32,4,64]{2,1,0} slice(%mul.6416), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6449 = bf16[32,1,64]{2,1,0} reshape(%slice.6423), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6456 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6449), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6457 = bf16[32,64]{1,0} reshape(%mul.6456), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6458 = bf16[32,4,64]{2,1,0} broadcast(%mul.6457), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6459 = bf16[32,4,64]{2,1,0} multiply(%slice.6451, %mul.6458), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.6460 = bf16[32,4,64]{2,1,0} subtract(%mul.6455, %mul.6459), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.6461 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6448), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6462 = bf16[32,64]{1,0} reshape(%mul.6461), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6463 = bf16[32,4,64]{2,1,0} broadcast(%mul.6462), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6464 = bf16[32,4,64]{2,1,0} multiply(%slice.6451, %mul.6463), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6465 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6449), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6466 = bf16[32,64]{1,0} reshape(%mul.6465), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6467 = bf16[32,4,64]{2,1,0} broadcast(%mul.6466), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6468 = bf16[32,4,64]{2,1,0} multiply(%slice.6450, %mul.6467), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.6469 = bf16[32,4,64]{2,1,0} add(%mul.6464, %mul.6468), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.6470 = bf16[32,4,128]{2,1,0} concatenate(%sub.6460, %add.6469), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.6471 = bf16[32,512]{1,0} reshape(%concatenate.6470), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.6372 = bf16[32,4,128]{2,1,0} slice(%reshape.6369), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.6373 = bf16[32,512]{1,0} reshape(%slice.6372), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.6472 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_31_.467, %reshape.6447, %reshape.6471, %reshape.6373, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.6473 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.6472), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_32_.468 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(467), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[32]"}
  %jit__jax_attn_func_.6474 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.6472), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_31_self_attn_o_proj_weight__.234 = bf16[2048,4096]{1,0} parameter(233), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.31.self_attn.o_proj.weight\']"}
  %dot_general.6475 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.6474, %params_and_buffers__vllm_model_language_model_model_layers_31_self_attn_o_proj_weight__.234), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.6476 = f32[32,2048]{1,0} convert(%dot_general.6475), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6347 = bf16[32,2048]{1,0} convert(%add.6346), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6477 = f32[32,2048]{1,0} convert(%convert_element_type.6347), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.6478 = f32[32,2048]{1,0} add(%convert_element_type.6476, %convert_element_type.6477), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.6480 = f32[32,2048]{1,0} power(%add.6478, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6485 = f32[32]{0} reduce(%pow.6480, %constant.512), dimensions={1}, to_apply=%region_159.6484, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6486 = f32[32,1]{1,0} reshape(%reduce_sum.6485), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6487 = f32[32,1]{1,0} divide(%broadcast_in_dim.6486, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6488 = f32[32,1]{1,0} add(%div.6487, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6489 = f32[32,1]{1,0} rsqrt(%add.6488), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6490 = f32[32,1]{1,0} broadcast(%rsqrt.6489), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6491 = f32[32]{0} reshape(%mul.6490), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6492 = f32[32,2048]{1,0} broadcast(%mul.6491), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6493 = f32[32,2048]{1,0} multiply(%add.6478, %mul.6492), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6494 = bf16[32,2048]{1,0} convert(%mul.6493), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_31_post_attention_layernorm_weight__.232 = bf16[2048]{0} parameter(231), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.31.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.6495 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_31_post_attention_layernorm_weight__.232), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6496 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.6495), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6497 = bf16[2048]{0} reshape(%mul.6496), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6498 = bf16[32,2048]{1,0} broadcast(%mul.6497), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6499 = bf16[32,2048]{1,0} multiply(%convert_element_type.6494, %mul.6498), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_31_mlp_experts_w13_weight__.229 = bf16[128,1536,2048]{2,1,0} parameter(228), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.31.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_31_mlp_experts_w2_weight__.230 = bf16[128,2048,768]{2,1,0} parameter(229), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.31.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_31_mlp_gate_weight__.231 = bf16[128,2048]{1,0} parameter(230), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.31.mlp.gate.weight\']"}
  %dot_general.6500 = bf16[32,128]{1,0} dot(%mul.6499, %params_and_buffers__vllm_model_language_model_model_layers_31_mlp_gate_weight__.231), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.6501 = bf16[32,2048]{1,0} call(%mul.6499, %params_and_buffers__vllm_model_language_model_model_layers_31_mlp_experts_w13_weight__.229, %params_and_buffers__vllm_model_language_model_model_layers_31_mlp_experts_w2_weight__.230, %dot_general.6500), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.6502 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.6501), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6479 = bf16[32,2048]{1,0} convert(%add.6478), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6503 = f32[32,2048]{1,0} convert(%convert_element_type.6479), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.6504 = f32[32,2048]{1,0} add(%convert_element_type.6502, %convert_element_type.6503), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.6506 = f32[32,2048]{1,0} power(%add.6504, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6511 = f32[32]{0} reduce(%pow.6506, %constant.512), dimensions={1}, to_apply=%region_160.6510, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6512 = f32[32,1]{1,0} reshape(%reduce_sum.6511), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6513 = f32[32,1]{1,0} divide(%broadcast_in_dim.6512, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6514 = f32[32,1]{1,0} add(%div.6513, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6515 = f32[32,1]{1,0} rsqrt(%add.6514), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6516 = f32[32,1]{1,0} broadcast(%rsqrt.6515), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6517 = f32[32]{0} reshape(%mul.6516), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6518 = f32[32,2048]{1,0} broadcast(%mul.6517), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6519 = f32[32,2048]{1,0} multiply(%add.6504, %mul.6518), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6520 = bf16[32,2048]{1,0} convert(%mul.6519), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_32_input_layernorm_weight__.237 = bf16[2048]{0} parameter(236), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.32.input_layernorm.weight\']"}
  %broadcast_in_dim.6521 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_32_input_layernorm_weight__.237), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6522 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.6521), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6523 = bf16[2048]{0} reshape(%mul.6522), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6524 = bf16[32,2048]{1,0} broadcast(%mul.6523), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6525 = bf16[32,2048]{1,0} multiply(%convert_element_type.6520, %mul.6524), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_32_self_attn_qkv_proj_weight__.245 = bf16[5120,2048]{1,0} parameter(244), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.32.self_attn.qkv_proj.weight\']"}
  %dot_general.6526 = bf16[32,5120]{1,0} dot(%mul.6525, %params_and_buffers__vllm_model_language_model_model_layers_32_self_attn_qkv_proj_weight__.245), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.6527 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.6526), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.6528 = bf16[32,4,1024]{2,1,0} slice(%reshape.6527), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.6532 = bf16[32,32,128]{2,1,0} reshape(%slice.6528), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.6533 = f32[32,32,128]{2,1,0} convert(%reshape.6532), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.6534 = f32[32,32,128]{2,1,0} power(%convert_element_type.6533, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6539 = f32[32,32]{1,0} reduce(%pow.6534, %constant.512), dimensions={2}, to_apply=%region_161.6538, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6540 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.6539), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6541 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.6540, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6542 = f32[32,32,1]{2,1,0} add(%div.6541, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6543 = f32[32,32,1]{2,1,0} rsqrt(%add.6542), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6544 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.6543), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6545 = f32[32,32]{1,0} reshape(%mul.6544), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6546 = f32[32,32,128]{2,1,0} broadcast(%mul.6545), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6547 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.6533, %mul.6546), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6548 = bf16[32,32,128]{2,1,0} convert(%mul.6547), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_32_self_attn_q_norm_weight__.244 = bf16[128]{0} parameter(243), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.32.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.6549 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_32_self_attn_q_norm_weight__.244), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6550 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.6549), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6551 = bf16[128]{0} reshape(%mul.6550), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6552 = bf16[32,32,128]{2,1,0} broadcast(%mul.6551), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6553 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.6548, %mul.6552), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6584 = bf16[32,32,64]{2,1,0} slice(%mul.6553), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.6575 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.6576 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.6577 = s32[32]{0} select(%lt.6575, %add.6576, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.6578 = s32[32,1]{1,0} reshape(%select_n.6577), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.6579 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.6578), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.6580 = bf16[32,64]{1,0} slice(%gather.6579), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6582 = bf16[32,1,64]{2,1,0} reshape(%slice.6580), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6586 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6582), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6587 = bf16[32,64]{1,0} reshape(%mul.6586), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6588 = bf16[32,32,64]{2,1,0} broadcast(%mul.6587), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6589 = bf16[32,32,64]{2,1,0} multiply(%slice.6584, %mul.6588), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6585 = bf16[32,32,64]{2,1,0} slice(%mul.6553), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.6581 = bf16[32,64]{1,0} slice(%gather.6579), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6583 = bf16[32,1,64]{2,1,0} reshape(%slice.6581), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6590 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6583), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6591 = bf16[32,64]{1,0} reshape(%mul.6590), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6592 = bf16[32,32,64]{2,1,0} broadcast(%mul.6591), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6593 = bf16[32,32,64]{2,1,0} multiply(%slice.6585, %mul.6592), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.6594 = bf16[32,32,64]{2,1,0} subtract(%mul.6589, %mul.6593), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.6595 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6582), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6596 = bf16[32,64]{1,0} reshape(%mul.6595), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6597 = bf16[32,32,64]{2,1,0} broadcast(%mul.6596), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6598 = bf16[32,32,64]{2,1,0} multiply(%slice.6585, %mul.6597), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6599 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6583), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6600 = bf16[32,64]{1,0} reshape(%mul.6599), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6601 = bf16[32,32,64]{2,1,0} broadcast(%mul.6600), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6602 = bf16[32,32,64]{2,1,0} multiply(%slice.6584, %mul.6601), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.6603 = bf16[32,32,64]{2,1,0} add(%mul.6598, %mul.6602), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.6604 = bf16[32,32,128]{2,1,0} concatenate(%sub.6594, %add.6603), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.6605 = bf16[32,4096]{1,0} reshape(%concatenate.6604), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.6529 = bf16[32,4,128]{2,1,0} slice(%reshape.6527), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.6554 = f32[32,4,128]{2,1,0} convert(%slice.6529), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.6555 = f32[32,4,128]{2,1,0} power(%convert_element_type.6554, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6560 = f32[32,4]{1,0} reduce(%pow.6555, %constant.512), dimensions={2}, to_apply=%region_162.6559, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6561 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.6560), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6562 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.6561, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6563 = f32[32,4,1]{2,1,0} add(%div.6562, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6564 = f32[32,4,1]{2,1,0} rsqrt(%add.6563), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6565 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.6564), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6566 = f32[32,4]{1,0} reshape(%mul.6565), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6567 = f32[32,4,128]{2,1,0} broadcast(%mul.6566), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6568 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.6554, %mul.6567), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6569 = bf16[32,4,128]{2,1,0} convert(%mul.6568), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_32_self_attn_k_norm_weight__.242 = bf16[128]{0} parameter(241), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.32.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.6570 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_32_self_attn_k_norm_weight__.242), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6571 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.6570), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6572 = bf16[128]{0} reshape(%mul.6571), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6573 = bf16[32,4,128]{2,1,0} broadcast(%mul.6572), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6574 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.6569, %mul.6573), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6608 = bf16[32,4,64]{2,1,0} slice(%mul.6574), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6606 = bf16[32,1,64]{2,1,0} reshape(%slice.6580), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6610 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6606), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6611 = bf16[32,64]{1,0} reshape(%mul.6610), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6612 = bf16[32,4,64]{2,1,0} broadcast(%mul.6611), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6613 = bf16[32,4,64]{2,1,0} multiply(%slice.6608, %mul.6612), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6609 = bf16[32,4,64]{2,1,0} slice(%mul.6574), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6607 = bf16[32,1,64]{2,1,0} reshape(%slice.6581), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6614 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6607), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6615 = bf16[32,64]{1,0} reshape(%mul.6614), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6616 = bf16[32,4,64]{2,1,0} broadcast(%mul.6615), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6617 = bf16[32,4,64]{2,1,0} multiply(%slice.6609, %mul.6616), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.6618 = bf16[32,4,64]{2,1,0} subtract(%mul.6613, %mul.6617), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.6619 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6606), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6620 = bf16[32,64]{1,0} reshape(%mul.6619), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6621 = bf16[32,4,64]{2,1,0} broadcast(%mul.6620), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6622 = bf16[32,4,64]{2,1,0} multiply(%slice.6609, %mul.6621), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6623 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6607), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6624 = bf16[32,64]{1,0} reshape(%mul.6623), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6625 = bf16[32,4,64]{2,1,0} broadcast(%mul.6624), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6626 = bf16[32,4,64]{2,1,0} multiply(%slice.6608, %mul.6625), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.6627 = bf16[32,4,64]{2,1,0} add(%mul.6622, %mul.6626), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.6628 = bf16[32,4,128]{2,1,0} concatenate(%sub.6618, %add.6627), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.6629 = bf16[32,512]{1,0} reshape(%concatenate.6628), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.6530 = bf16[32,4,128]{2,1,0} slice(%reshape.6527), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.6531 = bf16[32,512]{1,0} reshape(%slice.6530), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.6630 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_32_.468, %reshape.6605, %reshape.6629, %reshape.6531, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.6631 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.6630), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_33_.469 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(468), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[33]"}
  %jit__jax_attn_func_.6632 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.6630), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_32_self_attn_o_proj_weight__.243 = bf16[2048,4096]{1,0} parameter(242), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.32.self_attn.o_proj.weight\']"}
  %dot_general.6633 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.6632, %params_and_buffers__vllm_model_language_model_model_layers_32_self_attn_o_proj_weight__.243), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.6634 = f32[32,2048]{1,0} convert(%dot_general.6633), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6505 = bf16[32,2048]{1,0} convert(%add.6504), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6635 = f32[32,2048]{1,0} convert(%convert_element_type.6505), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.6636 = f32[32,2048]{1,0} add(%convert_element_type.6634, %convert_element_type.6635), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.6638 = f32[32,2048]{1,0} power(%add.6636, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6643 = f32[32]{0} reduce(%pow.6638, %constant.512), dimensions={1}, to_apply=%region_163.6642, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6644 = f32[32,1]{1,0} reshape(%reduce_sum.6643), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6645 = f32[32,1]{1,0} divide(%broadcast_in_dim.6644, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6646 = f32[32,1]{1,0} add(%div.6645, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6647 = f32[32,1]{1,0} rsqrt(%add.6646), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6648 = f32[32,1]{1,0} broadcast(%rsqrt.6647), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6649 = f32[32]{0} reshape(%mul.6648), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6650 = f32[32,2048]{1,0} broadcast(%mul.6649), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6651 = f32[32,2048]{1,0} multiply(%add.6636, %mul.6650), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6652 = bf16[32,2048]{1,0} convert(%mul.6651), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_32_post_attention_layernorm_weight__.241 = bf16[2048]{0} parameter(240), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.32.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.6653 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_32_post_attention_layernorm_weight__.241), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6654 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.6653), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6655 = bf16[2048]{0} reshape(%mul.6654), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6656 = bf16[32,2048]{1,0} broadcast(%mul.6655), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6657 = bf16[32,2048]{1,0} multiply(%convert_element_type.6652, %mul.6656), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_32_mlp_experts_w13_weight__.238 = bf16[128,1536,2048]{2,1,0} parameter(237), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.32.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_32_mlp_experts_w2_weight__.239 = bf16[128,2048,768]{2,1,0} parameter(238), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.32.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_32_mlp_gate_weight__.240 = bf16[128,2048]{1,0} parameter(239), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.32.mlp.gate.weight\']"}
  %dot_general.6658 = bf16[32,128]{1,0} dot(%mul.6657, %params_and_buffers__vllm_model_language_model_model_layers_32_mlp_gate_weight__.240), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.6659 = bf16[32,2048]{1,0} call(%mul.6657, %params_and_buffers__vllm_model_language_model_model_layers_32_mlp_experts_w13_weight__.238, %params_and_buffers__vllm_model_language_model_model_layers_32_mlp_experts_w2_weight__.239, %dot_general.6658), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.6660 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.6659), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6637 = bf16[32,2048]{1,0} convert(%add.6636), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6661 = f32[32,2048]{1,0} convert(%convert_element_type.6637), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.6662 = f32[32,2048]{1,0} add(%convert_element_type.6660, %convert_element_type.6661), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.6664 = f32[32,2048]{1,0} power(%add.6662, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6669 = f32[32]{0} reduce(%pow.6664, %constant.512), dimensions={1}, to_apply=%region_164.6668, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6670 = f32[32,1]{1,0} reshape(%reduce_sum.6669), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6671 = f32[32,1]{1,0} divide(%broadcast_in_dim.6670, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6672 = f32[32,1]{1,0} add(%div.6671, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6673 = f32[32,1]{1,0} rsqrt(%add.6672), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6674 = f32[32,1]{1,0} broadcast(%rsqrt.6673), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6675 = f32[32]{0} reshape(%mul.6674), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6676 = f32[32,2048]{1,0} broadcast(%mul.6675), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6677 = f32[32,2048]{1,0} multiply(%add.6662, %mul.6676), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6678 = bf16[32,2048]{1,0} convert(%mul.6677), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_33_input_layernorm_weight__.246 = bf16[2048]{0} parameter(245), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.33.input_layernorm.weight\']"}
  %broadcast_in_dim.6679 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_33_input_layernorm_weight__.246), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6680 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.6679), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6681 = bf16[2048]{0} reshape(%mul.6680), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6682 = bf16[32,2048]{1,0} broadcast(%mul.6681), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6683 = bf16[32,2048]{1,0} multiply(%convert_element_type.6678, %mul.6682), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_33_self_attn_qkv_proj_weight__.254 = bf16[5120,2048]{1,0} parameter(253), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.33.self_attn.qkv_proj.weight\']"}
  %dot_general.6684 = bf16[32,5120]{1,0} dot(%mul.6683, %params_and_buffers__vllm_model_language_model_model_layers_33_self_attn_qkv_proj_weight__.254), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.6685 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.6684), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.6686 = bf16[32,4,1024]{2,1,0} slice(%reshape.6685), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.6690 = bf16[32,32,128]{2,1,0} reshape(%slice.6686), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.6691 = f32[32,32,128]{2,1,0} convert(%reshape.6690), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.6692 = f32[32,32,128]{2,1,0} power(%convert_element_type.6691, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6697 = f32[32,32]{1,0} reduce(%pow.6692, %constant.512), dimensions={2}, to_apply=%region_165.6696, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6698 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.6697), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6699 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.6698, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6700 = f32[32,32,1]{2,1,0} add(%div.6699, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6701 = f32[32,32,1]{2,1,0} rsqrt(%add.6700), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6702 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.6701), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6703 = f32[32,32]{1,0} reshape(%mul.6702), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6704 = f32[32,32,128]{2,1,0} broadcast(%mul.6703), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6705 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.6691, %mul.6704), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6706 = bf16[32,32,128]{2,1,0} convert(%mul.6705), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_33_self_attn_q_norm_weight__.253 = bf16[128]{0} parameter(252), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.33.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.6707 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_33_self_attn_q_norm_weight__.253), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6708 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.6707), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6709 = bf16[128]{0} reshape(%mul.6708), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6710 = bf16[32,32,128]{2,1,0} broadcast(%mul.6709), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6711 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.6706, %mul.6710), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6742 = bf16[32,32,64]{2,1,0} slice(%mul.6711), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.6733 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.6734 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.6735 = s32[32]{0} select(%lt.6733, %add.6734, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.6736 = s32[32,1]{1,0} reshape(%select_n.6735), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.6737 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.6736), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.6738 = bf16[32,64]{1,0} slice(%gather.6737), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6740 = bf16[32,1,64]{2,1,0} reshape(%slice.6738), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6744 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6740), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6745 = bf16[32,64]{1,0} reshape(%mul.6744), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6746 = bf16[32,32,64]{2,1,0} broadcast(%mul.6745), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6747 = bf16[32,32,64]{2,1,0} multiply(%slice.6742, %mul.6746), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6743 = bf16[32,32,64]{2,1,0} slice(%mul.6711), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.6739 = bf16[32,64]{1,0} slice(%gather.6737), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6741 = bf16[32,1,64]{2,1,0} reshape(%slice.6739), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6748 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6741), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6749 = bf16[32,64]{1,0} reshape(%mul.6748), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6750 = bf16[32,32,64]{2,1,0} broadcast(%mul.6749), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6751 = bf16[32,32,64]{2,1,0} multiply(%slice.6743, %mul.6750), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.6752 = bf16[32,32,64]{2,1,0} subtract(%mul.6747, %mul.6751), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.6753 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6740), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6754 = bf16[32,64]{1,0} reshape(%mul.6753), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6755 = bf16[32,32,64]{2,1,0} broadcast(%mul.6754), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6756 = bf16[32,32,64]{2,1,0} multiply(%slice.6743, %mul.6755), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6757 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6741), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6758 = bf16[32,64]{1,0} reshape(%mul.6757), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6759 = bf16[32,32,64]{2,1,0} broadcast(%mul.6758), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6760 = bf16[32,32,64]{2,1,0} multiply(%slice.6742, %mul.6759), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.6761 = bf16[32,32,64]{2,1,0} add(%mul.6756, %mul.6760), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.6762 = bf16[32,32,128]{2,1,0} concatenate(%sub.6752, %add.6761), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.6763 = bf16[32,4096]{1,0} reshape(%concatenate.6762), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.6687 = bf16[32,4,128]{2,1,0} slice(%reshape.6685), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.6712 = f32[32,4,128]{2,1,0} convert(%slice.6687), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.6713 = f32[32,4,128]{2,1,0} power(%convert_element_type.6712, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6718 = f32[32,4]{1,0} reduce(%pow.6713, %constant.512), dimensions={2}, to_apply=%region_166.6717, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6719 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.6718), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6720 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.6719, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6721 = f32[32,4,1]{2,1,0} add(%div.6720, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6722 = f32[32,4,1]{2,1,0} rsqrt(%add.6721), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6723 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.6722), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6724 = f32[32,4]{1,0} reshape(%mul.6723), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6725 = f32[32,4,128]{2,1,0} broadcast(%mul.6724), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6726 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.6712, %mul.6725), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6727 = bf16[32,4,128]{2,1,0} convert(%mul.6726), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_33_self_attn_k_norm_weight__.251 = bf16[128]{0} parameter(250), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.33.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.6728 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_33_self_attn_k_norm_weight__.251), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6729 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.6728), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6730 = bf16[128]{0} reshape(%mul.6729), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6731 = bf16[32,4,128]{2,1,0} broadcast(%mul.6730), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6732 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.6727, %mul.6731), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6766 = bf16[32,4,64]{2,1,0} slice(%mul.6732), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6764 = bf16[32,1,64]{2,1,0} reshape(%slice.6738), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6768 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6764), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6769 = bf16[32,64]{1,0} reshape(%mul.6768), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6770 = bf16[32,4,64]{2,1,0} broadcast(%mul.6769), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6771 = bf16[32,4,64]{2,1,0} multiply(%slice.6766, %mul.6770), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6767 = bf16[32,4,64]{2,1,0} slice(%mul.6732), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6765 = bf16[32,1,64]{2,1,0} reshape(%slice.6739), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6772 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6765), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6773 = bf16[32,64]{1,0} reshape(%mul.6772), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6774 = bf16[32,4,64]{2,1,0} broadcast(%mul.6773), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6775 = bf16[32,4,64]{2,1,0} multiply(%slice.6767, %mul.6774), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.6776 = bf16[32,4,64]{2,1,0} subtract(%mul.6771, %mul.6775), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.6777 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6764), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6778 = bf16[32,64]{1,0} reshape(%mul.6777), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6779 = bf16[32,4,64]{2,1,0} broadcast(%mul.6778), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6780 = bf16[32,4,64]{2,1,0} multiply(%slice.6767, %mul.6779), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6781 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6765), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6782 = bf16[32,64]{1,0} reshape(%mul.6781), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6783 = bf16[32,4,64]{2,1,0} broadcast(%mul.6782), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6784 = bf16[32,4,64]{2,1,0} multiply(%slice.6766, %mul.6783), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.6785 = bf16[32,4,64]{2,1,0} add(%mul.6780, %mul.6784), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.6786 = bf16[32,4,128]{2,1,0} concatenate(%sub.6776, %add.6785), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.6787 = bf16[32,512]{1,0} reshape(%concatenate.6786), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.6688 = bf16[32,4,128]{2,1,0} slice(%reshape.6685), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.6689 = bf16[32,512]{1,0} reshape(%slice.6688), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.6788 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_33_.469, %reshape.6763, %reshape.6787, %reshape.6689, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.6789 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.6788), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_34_.470 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(469), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[34]"}
  %jit__jax_attn_func_.6790 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.6788), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_33_self_attn_o_proj_weight__.252 = bf16[2048,4096]{1,0} parameter(251), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.33.self_attn.o_proj.weight\']"}
  %dot_general.6791 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.6790, %params_and_buffers__vllm_model_language_model_model_layers_33_self_attn_o_proj_weight__.252), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.6792 = f32[32,2048]{1,0} convert(%dot_general.6791), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6663 = bf16[32,2048]{1,0} convert(%add.6662), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6793 = f32[32,2048]{1,0} convert(%convert_element_type.6663), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.6794 = f32[32,2048]{1,0} add(%convert_element_type.6792, %convert_element_type.6793), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.6796 = f32[32,2048]{1,0} power(%add.6794, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6801 = f32[32]{0} reduce(%pow.6796, %constant.512), dimensions={1}, to_apply=%region_167.6800, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6802 = f32[32,1]{1,0} reshape(%reduce_sum.6801), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6803 = f32[32,1]{1,0} divide(%broadcast_in_dim.6802, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6804 = f32[32,1]{1,0} add(%div.6803, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6805 = f32[32,1]{1,0} rsqrt(%add.6804), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6806 = f32[32,1]{1,0} broadcast(%rsqrt.6805), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6807 = f32[32]{0} reshape(%mul.6806), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6808 = f32[32,2048]{1,0} broadcast(%mul.6807), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6809 = f32[32,2048]{1,0} multiply(%add.6794, %mul.6808), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6810 = bf16[32,2048]{1,0} convert(%mul.6809), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_33_post_attention_layernorm_weight__.250 = bf16[2048]{0} parameter(249), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.33.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.6811 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_33_post_attention_layernorm_weight__.250), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6812 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.6811), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6813 = bf16[2048]{0} reshape(%mul.6812), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6814 = bf16[32,2048]{1,0} broadcast(%mul.6813), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6815 = bf16[32,2048]{1,0} multiply(%convert_element_type.6810, %mul.6814), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_33_mlp_experts_w13_weight__.247 = bf16[128,1536,2048]{2,1,0} parameter(246), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.33.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_33_mlp_experts_w2_weight__.248 = bf16[128,2048,768]{2,1,0} parameter(247), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.33.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_33_mlp_gate_weight__.249 = bf16[128,2048]{1,0} parameter(248), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.33.mlp.gate.weight\']"}
  %dot_general.6816 = bf16[32,128]{1,0} dot(%mul.6815, %params_and_buffers__vllm_model_language_model_model_layers_33_mlp_gate_weight__.249), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.6817 = bf16[32,2048]{1,0} call(%mul.6815, %params_and_buffers__vllm_model_language_model_model_layers_33_mlp_experts_w13_weight__.247, %params_and_buffers__vllm_model_language_model_model_layers_33_mlp_experts_w2_weight__.248, %dot_general.6816), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.6818 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.6817), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6795 = bf16[32,2048]{1,0} convert(%add.6794), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6819 = f32[32,2048]{1,0} convert(%convert_element_type.6795), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.6820 = f32[32,2048]{1,0} add(%convert_element_type.6818, %convert_element_type.6819), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.6822 = f32[32,2048]{1,0} power(%add.6820, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6827 = f32[32]{0} reduce(%pow.6822, %constant.512), dimensions={1}, to_apply=%region_168.6826, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6828 = f32[32,1]{1,0} reshape(%reduce_sum.6827), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6829 = f32[32,1]{1,0} divide(%broadcast_in_dim.6828, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6830 = f32[32,1]{1,0} add(%div.6829, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6831 = f32[32,1]{1,0} rsqrt(%add.6830), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6832 = f32[32,1]{1,0} broadcast(%rsqrt.6831), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6833 = f32[32]{0} reshape(%mul.6832), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6834 = f32[32,2048]{1,0} broadcast(%mul.6833), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6835 = f32[32,2048]{1,0} multiply(%add.6820, %mul.6834), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6836 = bf16[32,2048]{1,0} convert(%mul.6835), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_34_input_layernorm_weight__.255 = bf16[2048]{0} parameter(254), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.34.input_layernorm.weight\']"}
  %broadcast_in_dim.6837 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_34_input_layernorm_weight__.255), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6838 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.6837), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6839 = bf16[2048]{0} reshape(%mul.6838), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6840 = bf16[32,2048]{1,0} broadcast(%mul.6839), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6841 = bf16[32,2048]{1,0} multiply(%convert_element_type.6836, %mul.6840), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_34_self_attn_qkv_proj_weight__.263 = bf16[5120,2048]{1,0} parameter(262), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.34.self_attn.qkv_proj.weight\']"}
  %dot_general.6842 = bf16[32,5120]{1,0} dot(%mul.6841, %params_and_buffers__vllm_model_language_model_model_layers_34_self_attn_qkv_proj_weight__.263), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.6843 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.6842), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.6844 = bf16[32,4,1024]{2,1,0} slice(%reshape.6843), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.6848 = bf16[32,32,128]{2,1,0} reshape(%slice.6844), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.6849 = f32[32,32,128]{2,1,0} convert(%reshape.6848), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.6850 = f32[32,32,128]{2,1,0} power(%convert_element_type.6849, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6855 = f32[32,32]{1,0} reduce(%pow.6850, %constant.512), dimensions={2}, to_apply=%region_169.6854, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6856 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.6855), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6857 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.6856, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6858 = f32[32,32,1]{2,1,0} add(%div.6857, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6859 = f32[32,32,1]{2,1,0} rsqrt(%add.6858), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6860 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.6859), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6861 = f32[32,32]{1,0} reshape(%mul.6860), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6862 = f32[32,32,128]{2,1,0} broadcast(%mul.6861), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6863 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.6849, %mul.6862), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6864 = bf16[32,32,128]{2,1,0} convert(%mul.6863), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_34_self_attn_q_norm_weight__.262 = bf16[128]{0} parameter(261), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.34.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.6865 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_34_self_attn_q_norm_weight__.262), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6866 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.6865), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6867 = bf16[128]{0} reshape(%mul.6866), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6868 = bf16[32,32,128]{2,1,0} broadcast(%mul.6867), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6869 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.6864, %mul.6868), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6900 = bf16[32,32,64]{2,1,0} slice(%mul.6869), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.6891 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.6892 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.6893 = s32[32]{0} select(%lt.6891, %add.6892, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.6894 = s32[32,1]{1,0} reshape(%select_n.6893), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.6895 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.6894), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.6896 = bf16[32,64]{1,0} slice(%gather.6895), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6898 = bf16[32,1,64]{2,1,0} reshape(%slice.6896), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6902 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6898), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6903 = bf16[32,64]{1,0} reshape(%mul.6902), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6904 = bf16[32,32,64]{2,1,0} broadcast(%mul.6903), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6905 = bf16[32,32,64]{2,1,0} multiply(%slice.6900, %mul.6904), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6901 = bf16[32,32,64]{2,1,0} slice(%mul.6869), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.6897 = bf16[32,64]{1,0} slice(%gather.6895), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6899 = bf16[32,1,64]{2,1,0} reshape(%slice.6897), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6906 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6899), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6907 = bf16[32,64]{1,0} reshape(%mul.6906), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6908 = bf16[32,32,64]{2,1,0} broadcast(%mul.6907), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6909 = bf16[32,32,64]{2,1,0} multiply(%slice.6901, %mul.6908), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.6910 = bf16[32,32,64]{2,1,0} subtract(%mul.6905, %mul.6909), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.6911 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6898), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6912 = bf16[32,64]{1,0} reshape(%mul.6911), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6913 = bf16[32,32,64]{2,1,0} broadcast(%mul.6912), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6914 = bf16[32,32,64]{2,1,0} multiply(%slice.6901, %mul.6913), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6915 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6899), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6916 = bf16[32,64]{1,0} reshape(%mul.6915), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6917 = bf16[32,32,64]{2,1,0} broadcast(%mul.6916), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6918 = bf16[32,32,64]{2,1,0} multiply(%slice.6900, %mul.6917), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.6919 = bf16[32,32,64]{2,1,0} add(%mul.6914, %mul.6918), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.6920 = bf16[32,32,128]{2,1,0} concatenate(%sub.6910, %add.6919), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.6921 = bf16[32,4096]{1,0} reshape(%concatenate.6920), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.6845 = bf16[32,4,128]{2,1,0} slice(%reshape.6843), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.6870 = f32[32,4,128]{2,1,0} convert(%slice.6845), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.6871 = f32[32,4,128]{2,1,0} power(%convert_element_type.6870, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6876 = f32[32,4]{1,0} reduce(%pow.6871, %constant.512), dimensions={2}, to_apply=%region_170.6875, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6877 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.6876), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6878 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.6877, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6879 = f32[32,4,1]{2,1,0} add(%div.6878, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6880 = f32[32,4,1]{2,1,0} rsqrt(%add.6879), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6881 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.6880), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6882 = f32[32,4]{1,0} reshape(%mul.6881), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6883 = f32[32,4,128]{2,1,0} broadcast(%mul.6882), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6884 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.6870, %mul.6883), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6885 = bf16[32,4,128]{2,1,0} convert(%mul.6884), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_34_self_attn_k_norm_weight__.260 = bf16[128]{0} parameter(259), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.34.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.6886 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_34_self_attn_k_norm_weight__.260), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6887 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.6886), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6888 = bf16[128]{0} reshape(%mul.6887), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6889 = bf16[32,4,128]{2,1,0} broadcast(%mul.6888), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6890 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.6885, %mul.6889), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6924 = bf16[32,4,64]{2,1,0} slice(%mul.6890), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6922 = bf16[32,1,64]{2,1,0} reshape(%slice.6896), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6926 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6922), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6927 = bf16[32,64]{1,0} reshape(%mul.6926), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6928 = bf16[32,4,64]{2,1,0} broadcast(%mul.6927), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6929 = bf16[32,4,64]{2,1,0} multiply(%slice.6924, %mul.6928), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.6925 = bf16[32,4,64]{2,1,0} slice(%mul.6890), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.6923 = bf16[32,1,64]{2,1,0} reshape(%slice.6897), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.6930 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6923), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6931 = bf16[32,64]{1,0} reshape(%mul.6930), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6932 = bf16[32,4,64]{2,1,0} broadcast(%mul.6931), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6933 = bf16[32,4,64]{2,1,0} multiply(%slice.6925, %mul.6932), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.6934 = bf16[32,4,64]{2,1,0} subtract(%mul.6929, %mul.6933), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.6935 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6922), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6936 = bf16[32,64]{1,0} reshape(%mul.6935), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6937 = bf16[32,4,64]{2,1,0} broadcast(%mul.6936), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6938 = bf16[32,4,64]{2,1,0} multiply(%slice.6925, %mul.6937), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6939 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.6923), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6940 = bf16[32,64]{1,0} reshape(%mul.6939), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6941 = bf16[32,4,64]{2,1,0} broadcast(%mul.6940), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6942 = bf16[32,4,64]{2,1,0} multiply(%slice.6924, %mul.6941), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.6943 = bf16[32,4,64]{2,1,0} add(%mul.6938, %mul.6942), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.6944 = bf16[32,4,128]{2,1,0} concatenate(%sub.6934, %add.6943), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.6945 = bf16[32,512]{1,0} reshape(%concatenate.6944), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.6846 = bf16[32,4,128]{2,1,0} slice(%reshape.6843), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.6847 = bf16[32,512]{1,0} reshape(%slice.6846), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.6946 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_34_.470, %reshape.6921, %reshape.6945, %reshape.6847, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.6947 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.6946), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_35_.471 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(470), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[35]"}
  %jit__jax_attn_func_.6948 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.6946), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_34_self_attn_o_proj_weight__.261 = bf16[2048,4096]{1,0} parameter(260), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.34.self_attn.o_proj.weight\']"}
  %dot_general.6949 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.6948, %params_and_buffers__vllm_model_language_model_model_layers_34_self_attn_o_proj_weight__.261), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.6950 = f32[32,2048]{1,0} convert(%dot_general.6949), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6821 = bf16[32,2048]{1,0} convert(%add.6820), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6951 = f32[32,2048]{1,0} convert(%convert_element_type.6821), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.6952 = f32[32,2048]{1,0} add(%convert_element_type.6950, %convert_element_type.6951), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.6954 = f32[32,2048]{1,0} power(%add.6952, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6959 = f32[32]{0} reduce(%pow.6954, %constant.512), dimensions={1}, to_apply=%region_171.6958, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6960 = f32[32,1]{1,0} reshape(%reduce_sum.6959), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6961 = f32[32,1]{1,0} divide(%broadcast_in_dim.6960, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6962 = f32[32,1]{1,0} add(%div.6961, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6963 = f32[32,1]{1,0} rsqrt(%add.6962), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6964 = f32[32,1]{1,0} broadcast(%rsqrt.6963), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6965 = f32[32]{0} reshape(%mul.6964), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6966 = f32[32,2048]{1,0} broadcast(%mul.6965), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6967 = f32[32,2048]{1,0} multiply(%add.6952, %mul.6966), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6968 = bf16[32,2048]{1,0} convert(%mul.6967), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_34_post_attention_layernorm_weight__.259 = bf16[2048]{0} parameter(258), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.34.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.6969 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_34_post_attention_layernorm_weight__.259), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6970 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.6969), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6971 = bf16[2048]{0} reshape(%mul.6970), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6972 = bf16[32,2048]{1,0} broadcast(%mul.6971), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6973 = bf16[32,2048]{1,0} multiply(%convert_element_type.6968, %mul.6972), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_34_mlp_experts_w13_weight__.256 = bf16[128,1536,2048]{2,1,0} parameter(255), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.34.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_34_mlp_experts_w2_weight__.257 = bf16[128,2048,768]{2,1,0} parameter(256), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.34.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_34_mlp_gate_weight__.258 = bf16[128,2048]{1,0} parameter(257), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.34.mlp.gate.weight\']"}
  %dot_general.6974 = bf16[32,128]{1,0} dot(%mul.6973, %params_and_buffers__vllm_model_language_model_model_layers_34_mlp_gate_weight__.258), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.6975 = bf16[32,2048]{1,0} call(%mul.6973, %params_and_buffers__vllm_model_language_model_model_layers_34_mlp_experts_w13_weight__.256, %params_and_buffers__vllm_model_language_model_model_layers_34_mlp_experts_w2_weight__.257, %dot_general.6974), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.6976 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.6975), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6953 = bf16[32,2048]{1,0} convert(%add.6952), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6977 = f32[32,2048]{1,0} convert(%convert_element_type.6953), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.6978 = f32[32,2048]{1,0} add(%convert_element_type.6976, %convert_element_type.6977), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.6980 = f32[32,2048]{1,0} power(%add.6978, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.6985 = f32[32]{0} reduce(%pow.6980, %constant.512), dimensions={1}, to_apply=%region_172.6984, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.6986 = f32[32,1]{1,0} reshape(%reduce_sum.6985), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.6987 = f32[32,1]{1,0} divide(%broadcast_in_dim.6986, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.6988 = f32[32,1]{1,0} add(%div.6987, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.6989 = f32[32,1]{1,0} rsqrt(%add.6988), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.6990 = f32[32,1]{1,0} broadcast(%rsqrt.6989), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6991 = f32[32]{0} reshape(%mul.6990), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6992 = f32[32,2048]{1,0} broadcast(%mul.6991), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6993 = f32[32,2048]{1,0} multiply(%add.6978, %mul.6992), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.6994 = bf16[32,2048]{1,0} convert(%mul.6993), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_35_input_layernorm_weight__.264 = bf16[2048]{0} parameter(263), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.35.input_layernorm.weight\']"}
  %broadcast_in_dim.6995 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_35_input_layernorm_weight__.264), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6996 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.6995), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6997 = bf16[2048]{0} reshape(%mul.6996), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6998 = bf16[32,2048]{1,0} broadcast(%mul.6997), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.6999 = bf16[32,2048]{1,0} multiply(%convert_element_type.6994, %mul.6998), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_35_self_attn_qkv_proj_weight__.272 = bf16[5120,2048]{1,0} parameter(271), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.35.self_attn.qkv_proj.weight\']"}
  %dot_general.7000 = bf16[32,5120]{1,0} dot(%mul.6999, %params_and_buffers__vllm_model_language_model_model_layers_35_self_attn_qkv_proj_weight__.272), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.7001 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.7000), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.7002 = bf16[32,4,1024]{2,1,0} slice(%reshape.7001), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.7006 = bf16[32,32,128]{2,1,0} reshape(%slice.7002), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.7007 = f32[32,32,128]{2,1,0} convert(%reshape.7006), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.7008 = f32[32,32,128]{2,1,0} power(%convert_element_type.7007, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7013 = f32[32,32]{1,0} reduce(%pow.7008, %constant.512), dimensions={2}, to_apply=%region_173.7012, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7014 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.7013), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7015 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.7014, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7016 = f32[32,32,1]{2,1,0} add(%div.7015, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7017 = f32[32,32,1]{2,1,0} rsqrt(%add.7016), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7018 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.7017), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7019 = f32[32,32]{1,0} reshape(%mul.7018), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7020 = f32[32,32,128]{2,1,0} broadcast(%mul.7019), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7021 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.7007, %mul.7020), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7022 = bf16[32,32,128]{2,1,0} convert(%mul.7021), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_35_self_attn_q_norm_weight__.271 = bf16[128]{0} parameter(270), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.35.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.7023 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_35_self_attn_q_norm_weight__.271), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7024 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.7023), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7025 = bf16[128]{0} reshape(%mul.7024), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7026 = bf16[32,32,128]{2,1,0} broadcast(%mul.7025), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7027 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.7022, %mul.7026), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7058 = bf16[32,32,64]{2,1,0} slice(%mul.7027), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.7049 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.7050 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.7051 = s32[32]{0} select(%lt.7049, %add.7050, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.7052 = s32[32,1]{1,0} reshape(%select_n.7051), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.7053 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.7052), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.7054 = bf16[32,64]{1,0} slice(%gather.7053), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7056 = bf16[32,1,64]{2,1,0} reshape(%slice.7054), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7060 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7056), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7061 = bf16[32,64]{1,0} reshape(%mul.7060), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7062 = bf16[32,32,64]{2,1,0} broadcast(%mul.7061), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7063 = bf16[32,32,64]{2,1,0} multiply(%slice.7058, %mul.7062), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7059 = bf16[32,32,64]{2,1,0} slice(%mul.7027), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.7055 = bf16[32,64]{1,0} slice(%gather.7053), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7057 = bf16[32,1,64]{2,1,0} reshape(%slice.7055), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7064 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7057), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7065 = bf16[32,64]{1,0} reshape(%mul.7064), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7066 = bf16[32,32,64]{2,1,0} broadcast(%mul.7065), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7067 = bf16[32,32,64]{2,1,0} multiply(%slice.7059, %mul.7066), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.7068 = bf16[32,32,64]{2,1,0} subtract(%mul.7063, %mul.7067), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.7069 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7056), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7070 = bf16[32,64]{1,0} reshape(%mul.7069), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7071 = bf16[32,32,64]{2,1,0} broadcast(%mul.7070), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7072 = bf16[32,32,64]{2,1,0} multiply(%slice.7059, %mul.7071), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7073 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7057), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7074 = bf16[32,64]{1,0} reshape(%mul.7073), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7075 = bf16[32,32,64]{2,1,0} broadcast(%mul.7074), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7076 = bf16[32,32,64]{2,1,0} multiply(%slice.7058, %mul.7075), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.7077 = bf16[32,32,64]{2,1,0} add(%mul.7072, %mul.7076), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.7078 = bf16[32,32,128]{2,1,0} concatenate(%sub.7068, %add.7077), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.7079 = bf16[32,4096]{1,0} reshape(%concatenate.7078), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.7003 = bf16[32,4,128]{2,1,0} slice(%reshape.7001), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.7028 = f32[32,4,128]{2,1,0} convert(%slice.7003), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.7029 = f32[32,4,128]{2,1,0} power(%convert_element_type.7028, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7034 = f32[32,4]{1,0} reduce(%pow.7029, %constant.512), dimensions={2}, to_apply=%region_174.7033, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7035 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.7034), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7036 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.7035, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7037 = f32[32,4,1]{2,1,0} add(%div.7036, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7038 = f32[32,4,1]{2,1,0} rsqrt(%add.7037), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7039 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.7038), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7040 = f32[32,4]{1,0} reshape(%mul.7039), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7041 = f32[32,4,128]{2,1,0} broadcast(%mul.7040), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7042 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.7028, %mul.7041), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7043 = bf16[32,4,128]{2,1,0} convert(%mul.7042), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_35_self_attn_k_norm_weight__.269 = bf16[128]{0} parameter(268), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.35.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.7044 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_35_self_attn_k_norm_weight__.269), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7045 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.7044), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7046 = bf16[128]{0} reshape(%mul.7045), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7047 = bf16[32,4,128]{2,1,0} broadcast(%mul.7046), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7048 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.7043, %mul.7047), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7082 = bf16[32,4,64]{2,1,0} slice(%mul.7048), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7080 = bf16[32,1,64]{2,1,0} reshape(%slice.7054), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7084 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7080), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7085 = bf16[32,64]{1,0} reshape(%mul.7084), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7086 = bf16[32,4,64]{2,1,0} broadcast(%mul.7085), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7087 = bf16[32,4,64]{2,1,0} multiply(%slice.7082, %mul.7086), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7083 = bf16[32,4,64]{2,1,0} slice(%mul.7048), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7081 = bf16[32,1,64]{2,1,0} reshape(%slice.7055), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7088 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7081), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7089 = bf16[32,64]{1,0} reshape(%mul.7088), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7090 = bf16[32,4,64]{2,1,0} broadcast(%mul.7089), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7091 = bf16[32,4,64]{2,1,0} multiply(%slice.7083, %mul.7090), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.7092 = bf16[32,4,64]{2,1,0} subtract(%mul.7087, %mul.7091), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.7093 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7080), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7094 = bf16[32,64]{1,0} reshape(%mul.7093), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7095 = bf16[32,4,64]{2,1,0} broadcast(%mul.7094), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7096 = bf16[32,4,64]{2,1,0} multiply(%slice.7083, %mul.7095), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7097 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7081), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7098 = bf16[32,64]{1,0} reshape(%mul.7097), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7099 = bf16[32,4,64]{2,1,0} broadcast(%mul.7098), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7100 = bf16[32,4,64]{2,1,0} multiply(%slice.7082, %mul.7099), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.7101 = bf16[32,4,64]{2,1,0} add(%mul.7096, %mul.7100), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.7102 = bf16[32,4,128]{2,1,0} concatenate(%sub.7092, %add.7101), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.7103 = bf16[32,512]{1,0} reshape(%concatenate.7102), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.7004 = bf16[32,4,128]{2,1,0} slice(%reshape.7001), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.7005 = bf16[32,512]{1,0} reshape(%slice.7004), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.7104 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_35_.471, %reshape.7079, %reshape.7103, %reshape.7005, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.7105 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.7104), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_36_.472 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(471), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[36]"}
  %jit__jax_attn_func_.7106 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.7104), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_35_self_attn_o_proj_weight__.270 = bf16[2048,4096]{1,0} parameter(269), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.35.self_attn.o_proj.weight\']"}
  %dot_general.7107 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.7106, %params_and_buffers__vllm_model_language_model_model_layers_35_self_attn_o_proj_weight__.270), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.7108 = f32[32,2048]{1,0} convert(%dot_general.7107), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.6979 = bf16[32,2048]{1,0} convert(%add.6978), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7109 = f32[32,2048]{1,0} convert(%convert_element_type.6979), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.7110 = f32[32,2048]{1,0} add(%convert_element_type.7108, %convert_element_type.7109), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.7112 = f32[32,2048]{1,0} power(%add.7110, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7117 = f32[32]{0} reduce(%pow.7112, %constant.512), dimensions={1}, to_apply=%region_175.7116, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7118 = f32[32,1]{1,0} reshape(%reduce_sum.7117), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7119 = f32[32,1]{1,0} divide(%broadcast_in_dim.7118, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7120 = f32[32,1]{1,0} add(%div.7119, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7121 = f32[32,1]{1,0} rsqrt(%add.7120), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7122 = f32[32,1]{1,0} broadcast(%rsqrt.7121), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7123 = f32[32]{0} reshape(%mul.7122), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7124 = f32[32,2048]{1,0} broadcast(%mul.7123), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7125 = f32[32,2048]{1,0} multiply(%add.7110, %mul.7124), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7126 = bf16[32,2048]{1,0} convert(%mul.7125), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_35_post_attention_layernorm_weight__.268 = bf16[2048]{0} parameter(267), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.35.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.7127 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_35_post_attention_layernorm_weight__.268), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7128 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.7127), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7129 = bf16[2048]{0} reshape(%mul.7128), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7130 = bf16[32,2048]{1,0} broadcast(%mul.7129), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7131 = bf16[32,2048]{1,0} multiply(%convert_element_type.7126, %mul.7130), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_35_mlp_experts_w13_weight__.265 = bf16[128,1536,2048]{2,1,0} parameter(264), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.35.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_35_mlp_experts_w2_weight__.266 = bf16[128,2048,768]{2,1,0} parameter(265), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.35.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_35_mlp_gate_weight__.267 = bf16[128,2048]{1,0} parameter(266), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.35.mlp.gate.weight\']"}
  %dot_general.7132 = bf16[32,128]{1,0} dot(%mul.7131, %params_and_buffers__vllm_model_language_model_model_layers_35_mlp_gate_weight__.267), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.7133 = bf16[32,2048]{1,0} call(%mul.7131, %params_and_buffers__vllm_model_language_model_model_layers_35_mlp_experts_w13_weight__.265, %params_and_buffers__vllm_model_language_model_model_layers_35_mlp_experts_w2_weight__.266, %dot_general.7132), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.7134 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.7133), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7111 = bf16[32,2048]{1,0} convert(%add.7110), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7135 = f32[32,2048]{1,0} convert(%convert_element_type.7111), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.7136 = f32[32,2048]{1,0} add(%convert_element_type.7134, %convert_element_type.7135), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.7138 = f32[32,2048]{1,0} power(%add.7136, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7143 = f32[32]{0} reduce(%pow.7138, %constant.512), dimensions={1}, to_apply=%region_176.7142, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7144 = f32[32,1]{1,0} reshape(%reduce_sum.7143), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7145 = f32[32,1]{1,0} divide(%broadcast_in_dim.7144, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7146 = f32[32,1]{1,0} add(%div.7145, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7147 = f32[32,1]{1,0} rsqrt(%add.7146), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7148 = f32[32,1]{1,0} broadcast(%rsqrt.7147), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7149 = f32[32]{0} reshape(%mul.7148), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7150 = f32[32,2048]{1,0} broadcast(%mul.7149), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7151 = f32[32,2048]{1,0} multiply(%add.7136, %mul.7150), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7152 = bf16[32,2048]{1,0} convert(%mul.7151), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_36_input_layernorm_weight__.273 = bf16[2048]{0} parameter(272), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.36.input_layernorm.weight\']"}
  %broadcast_in_dim.7153 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_36_input_layernorm_weight__.273), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7154 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.7153), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7155 = bf16[2048]{0} reshape(%mul.7154), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7156 = bf16[32,2048]{1,0} broadcast(%mul.7155), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7157 = bf16[32,2048]{1,0} multiply(%convert_element_type.7152, %mul.7156), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_36_self_attn_qkv_proj_weight__.281 = bf16[5120,2048]{1,0} parameter(280), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.36.self_attn.qkv_proj.weight\']"}
  %dot_general.7158 = bf16[32,5120]{1,0} dot(%mul.7157, %params_and_buffers__vllm_model_language_model_model_layers_36_self_attn_qkv_proj_weight__.281), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.7159 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.7158), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.7160 = bf16[32,4,1024]{2,1,0} slice(%reshape.7159), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.7164 = bf16[32,32,128]{2,1,0} reshape(%slice.7160), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.7165 = f32[32,32,128]{2,1,0} convert(%reshape.7164), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.7166 = f32[32,32,128]{2,1,0} power(%convert_element_type.7165, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7171 = f32[32,32]{1,0} reduce(%pow.7166, %constant.512), dimensions={2}, to_apply=%region_177.7170, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7172 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.7171), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7173 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.7172, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7174 = f32[32,32,1]{2,1,0} add(%div.7173, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7175 = f32[32,32,1]{2,1,0} rsqrt(%add.7174), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7176 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.7175), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7177 = f32[32,32]{1,0} reshape(%mul.7176), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7178 = f32[32,32,128]{2,1,0} broadcast(%mul.7177), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7179 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.7165, %mul.7178), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7180 = bf16[32,32,128]{2,1,0} convert(%mul.7179), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_36_self_attn_q_norm_weight__.280 = bf16[128]{0} parameter(279), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.36.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.7181 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_36_self_attn_q_norm_weight__.280), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7182 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.7181), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7183 = bf16[128]{0} reshape(%mul.7182), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7184 = bf16[32,32,128]{2,1,0} broadcast(%mul.7183), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7185 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.7180, %mul.7184), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7216 = bf16[32,32,64]{2,1,0} slice(%mul.7185), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.7207 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.7208 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.7209 = s32[32]{0} select(%lt.7207, %add.7208, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.7210 = s32[32,1]{1,0} reshape(%select_n.7209), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.7211 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.7210), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.7212 = bf16[32,64]{1,0} slice(%gather.7211), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7214 = bf16[32,1,64]{2,1,0} reshape(%slice.7212), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7218 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7214), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7219 = bf16[32,64]{1,0} reshape(%mul.7218), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7220 = bf16[32,32,64]{2,1,0} broadcast(%mul.7219), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7221 = bf16[32,32,64]{2,1,0} multiply(%slice.7216, %mul.7220), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7217 = bf16[32,32,64]{2,1,0} slice(%mul.7185), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.7213 = bf16[32,64]{1,0} slice(%gather.7211), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7215 = bf16[32,1,64]{2,1,0} reshape(%slice.7213), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7222 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7215), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7223 = bf16[32,64]{1,0} reshape(%mul.7222), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7224 = bf16[32,32,64]{2,1,0} broadcast(%mul.7223), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7225 = bf16[32,32,64]{2,1,0} multiply(%slice.7217, %mul.7224), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.7226 = bf16[32,32,64]{2,1,0} subtract(%mul.7221, %mul.7225), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.7227 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7214), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7228 = bf16[32,64]{1,0} reshape(%mul.7227), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7229 = bf16[32,32,64]{2,1,0} broadcast(%mul.7228), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7230 = bf16[32,32,64]{2,1,0} multiply(%slice.7217, %mul.7229), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7231 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7215), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7232 = bf16[32,64]{1,0} reshape(%mul.7231), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7233 = bf16[32,32,64]{2,1,0} broadcast(%mul.7232), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7234 = bf16[32,32,64]{2,1,0} multiply(%slice.7216, %mul.7233), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.7235 = bf16[32,32,64]{2,1,0} add(%mul.7230, %mul.7234), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.7236 = bf16[32,32,128]{2,1,0} concatenate(%sub.7226, %add.7235), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.7237 = bf16[32,4096]{1,0} reshape(%concatenate.7236), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.7161 = bf16[32,4,128]{2,1,0} slice(%reshape.7159), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.7186 = f32[32,4,128]{2,1,0} convert(%slice.7161), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.7187 = f32[32,4,128]{2,1,0} power(%convert_element_type.7186, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7192 = f32[32,4]{1,0} reduce(%pow.7187, %constant.512), dimensions={2}, to_apply=%region_178.7191, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7193 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.7192), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7194 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.7193, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7195 = f32[32,4,1]{2,1,0} add(%div.7194, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7196 = f32[32,4,1]{2,1,0} rsqrt(%add.7195), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7197 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.7196), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7198 = f32[32,4]{1,0} reshape(%mul.7197), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7199 = f32[32,4,128]{2,1,0} broadcast(%mul.7198), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7200 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.7186, %mul.7199), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7201 = bf16[32,4,128]{2,1,0} convert(%mul.7200), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_36_self_attn_k_norm_weight__.278 = bf16[128]{0} parameter(277), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.36.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.7202 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_36_self_attn_k_norm_weight__.278), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7203 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.7202), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7204 = bf16[128]{0} reshape(%mul.7203), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7205 = bf16[32,4,128]{2,1,0} broadcast(%mul.7204), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7206 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.7201, %mul.7205), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7240 = bf16[32,4,64]{2,1,0} slice(%mul.7206), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7238 = bf16[32,1,64]{2,1,0} reshape(%slice.7212), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7242 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7238), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7243 = bf16[32,64]{1,0} reshape(%mul.7242), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7244 = bf16[32,4,64]{2,1,0} broadcast(%mul.7243), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7245 = bf16[32,4,64]{2,1,0} multiply(%slice.7240, %mul.7244), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7241 = bf16[32,4,64]{2,1,0} slice(%mul.7206), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7239 = bf16[32,1,64]{2,1,0} reshape(%slice.7213), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7246 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7239), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7247 = bf16[32,64]{1,0} reshape(%mul.7246), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7248 = bf16[32,4,64]{2,1,0} broadcast(%mul.7247), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7249 = bf16[32,4,64]{2,1,0} multiply(%slice.7241, %mul.7248), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.7250 = bf16[32,4,64]{2,1,0} subtract(%mul.7245, %mul.7249), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.7251 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7238), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7252 = bf16[32,64]{1,0} reshape(%mul.7251), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7253 = bf16[32,4,64]{2,1,0} broadcast(%mul.7252), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7254 = bf16[32,4,64]{2,1,0} multiply(%slice.7241, %mul.7253), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7255 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7239), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7256 = bf16[32,64]{1,0} reshape(%mul.7255), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7257 = bf16[32,4,64]{2,1,0} broadcast(%mul.7256), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7258 = bf16[32,4,64]{2,1,0} multiply(%slice.7240, %mul.7257), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.7259 = bf16[32,4,64]{2,1,0} add(%mul.7254, %mul.7258), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.7260 = bf16[32,4,128]{2,1,0} concatenate(%sub.7250, %add.7259), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.7261 = bf16[32,512]{1,0} reshape(%concatenate.7260), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.7162 = bf16[32,4,128]{2,1,0} slice(%reshape.7159), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.7163 = bf16[32,512]{1,0} reshape(%slice.7162), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.7262 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_36_.472, %reshape.7237, %reshape.7261, %reshape.7163, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.7263 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.7262), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_37_.473 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(472), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[37]"}
  %jit__jax_attn_func_.7264 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.7262), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_36_self_attn_o_proj_weight__.279 = bf16[2048,4096]{1,0} parameter(278), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.36.self_attn.o_proj.weight\']"}
  %dot_general.7265 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.7264, %params_and_buffers__vllm_model_language_model_model_layers_36_self_attn_o_proj_weight__.279), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.7266 = f32[32,2048]{1,0} convert(%dot_general.7265), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7137 = bf16[32,2048]{1,0} convert(%add.7136), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7267 = f32[32,2048]{1,0} convert(%convert_element_type.7137), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.7268 = f32[32,2048]{1,0} add(%convert_element_type.7266, %convert_element_type.7267), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.7270 = f32[32,2048]{1,0} power(%add.7268, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7275 = f32[32]{0} reduce(%pow.7270, %constant.512), dimensions={1}, to_apply=%region_179.7274, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7276 = f32[32,1]{1,0} reshape(%reduce_sum.7275), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7277 = f32[32,1]{1,0} divide(%broadcast_in_dim.7276, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7278 = f32[32,1]{1,0} add(%div.7277, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7279 = f32[32,1]{1,0} rsqrt(%add.7278), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7280 = f32[32,1]{1,0} broadcast(%rsqrt.7279), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7281 = f32[32]{0} reshape(%mul.7280), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7282 = f32[32,2048]{1,0} broadcast(%mul.7281), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7283 = f32[32,2048]{1,0} multiply(%add.7268, %mul.7282), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7284 = bf16[32,2048]{1,0} convert(%mul.7283), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_36_post_attention_layernorm_weight__.277 = bf16[2048]{0} parameter(276), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.36.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.7285 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_36_post_attention_layernorm_weight__.277), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7286 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.7285), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7287 = bf16[2048]{0} reshape(%mul.7286), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7288 = bf16[32,2048]{1,0} broadcast(%mul.7287), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7289 = bf16[32,2048]{1,0} multiply(%convert_element_type.7284, %mul.7288), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_36_mlp_experts_w13_weight__.274 = bf16[128,1536,2048]{2,1,0} parameter(273), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.36.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_36_mlp_experts_w2_weight__.275 = bf16[128,2048,768]{2,1,0} parameter(274), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.36.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_36_mlp_gate_weight__.276 = bf16[128,2048]{1,0} parameter(275), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.36.mlp.gate.weight\']"}
  %dot_general.7290 = bf16[32,128]{1,0} dot(%mul.7289, %params_and_buffers__vllm_model_language_model_model_layers_36_mlp_gate_weight__.276), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.7291 = bf16[32,2048]{1,0} call(%mul.7289, %params_and_buffers__vllm_model_language_model_model_layers_36_mlp_experts_w13_weight__.274, %params_and_buffers__vllm_model_language_model_model_layers_36_mlp_experts_w2_weight__.275, %dot_general.7290), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.7292 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.7291), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7269 = bf16[32,2048]{1,0} convert(%add.7268), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7293 = f32[32,2048]{1,0} convert(%convert_element_type.7269), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.7294 = f32[32,2048]{1,0} add(%convert_element_type.7292, %convert_element_type.7293), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.7296 = f32[32,2048]{1,0} power(%add.7294, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7301 = f32[32]{0} reduce(%pow.7296, %constant.512), dimensions={1}, to_apply=%region_180.7300, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7302 = f32[32,1]{1,0} reshape(%reduce_sum.7301), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7303 = f32[32,1]{1,0} divide(%broadcast_in_dim.7302, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7304 = f32[32,1]{1,0} add(%div.7303, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7305 = f32[32,1]{1,0} rsqrt(%add.7304), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7306 = f32[32,1]{1,0} broadcast(%rsqrt.7305), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7307 = f32[32]{0} reshape(%mul.7306), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7308 = f32[32,2048]{1,0} broadcast(%mul.7307), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7309 = f32[32,2048]{1,0} multiply(%add.7294, %mul.7308), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7310 = bf16[32,2048]{1,0} convert(%mul.7309), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_37_input_layernorm_weight__.282 = bf16[2048]{0} parameter(281), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.37.input_layernorm.weight\']"}
  %broadcast_in_dim.7311 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_37_input_layernorm_weight__.282), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7312 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.7311), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7313 = bf16[2048]{0} reshape(%mul.7312), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7314 = bf16[32,2048]{1,0} broadcast(%mul.7313), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7315 = bf16[32,2048]{1,0} multiply(%convert_element_type.7310, %mul.7314), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_37_self_attn_qkv_proj_weight__.290 = bf16[5120,2048]{1,0} parameter(289), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.37.self_attn.qkv_proj.weight\']"}
  %dot_general.7316 = bf16[32,5120]{1,0} dot(%mul.7315, %params_and_buffers__vllm_model_language_model_model_layers_37_self_attn_qkv_proj_weight__.290), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.7317 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.7316), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.7318 = bf16[32,4,1024]{2,1,0} slice(%reshape.7317), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.7322 = bf16[32,32,128]{2,1,0} reshape(%slice.7318), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.7323 = f32[32,32,128]{2,1,0} convert(%reshape.7322), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.7324 = f32[32,32,128]{2,1,0} power(%convert_element_type.7323, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7329 = f32[32,32]{1,0} reduce(%pow.7324, %constant.512), dimensions={2}, to_apply=%region_181.7328, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7330 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.7329), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7331 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.7330, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7332 = f32[32,32,1]{2,1,0} add(%div.7331, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7333 = f32[32,32,1]{2,1,0} rsqrt(%add.7332), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7334 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.7333), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7335 = f32[32,32]{1,0} reshape(%mul.7334), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7336 = f32[32,32,128]{2,1,0} broadcast(%mul.7335), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7337 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.7323, %mul.7336), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7338 = bf16[32,32,128]{2,1,0} convert(%mul.7337), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_37_self_attn_q_norm_weight__.289 = bf16[128]{0} parameter(288), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.37.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.7339 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_37_self_attn_q_norm_weight__.289), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7340 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.7339), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7341 = bf16[128]{0} reshape(%mul.7340), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7342 = bf16[32,32,128]{2,1,0} broadcast(%mul.7341), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7343 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.7338, %mul.7342), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7374 = bf16[32,32,64]{2,1,0} slice(%mul.7343), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.7365 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.7366 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.7367 = s32[32]{0} select(%lt.7365, %add.7366, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.7368 = s32[32,1]{1,0} reshape(%select_n.7367), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.7369 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.7368), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.7370 = bf16[32,64]{1,0} slice(%gather.7369), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7372 = bf16[32,1,64]{2,1,0} reshape(%slice.7370), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7376 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7372), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7377 = bf16[32,64]{1,0} reshape(%mul.7376), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7378 = bf16[32,32,64]{2,1,0} broadcast(%mul.7377), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7379 = bf16[32,32,64]{2,1,0} multiply(%slice.7374, %mul.7378), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7375 = bf16[32,32,64]{2,1,0} slice(%mul.7343), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.7371 = bf16[32,64]{1,0} slice(%gather.7369), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7373 = bf16[32,1,64]{2,1,0} reshape(%slice.7371), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7380 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7373), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7381 = bf16[32,64]{1,0} reshape(%mul.7380), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7382 = bf16[32,32,64]{2,1,0} broadcast(%mul.7381), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7383 = bf16[32,32,64]{2,1,0} multiply(%slice.7375, %mul.7382), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.7384 = bf16[32,32,64]{2,1,0} subtract(%mul.7379, %mul.7383), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.7385 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7372), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7386 = bf16[32,64]{1,0} reshape(%mul.7385), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7387 = bf16[32,32,64]{2,1,0} broadcast(%mul.7386), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7388 = bf16[32,32,64]{2,1,0} multiply(%slice.7375, %mul.7387), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7389 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7373), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7390 = bf16[32,64]{1,0} reshape(%mul.7389), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7391 = bf16[32,32,64]{2,1,0} broadcast(%mul.7390), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7392 = bf16[32,32,64]{2,1,0} multiply(%slice.7374, %mul.7391), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.7393 = bf16[32,32,64]{2,1,0} add(%mul.7388, %mul.7392), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.7394 = bf16[32,32,128]{2,1,0} concatenate(%sub.7384, %add.7393), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.7395 = bf16[32,4096]{1,0} reshape(%concatenate.7394), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.7319 = bf16[32,4,128]{2,1,0} slice(%reshape.7317), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.7344 = f32[32,4,128]{2,1,0} convert(%slice.7319), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.7345 = f32[32,4,128]{2,1,0} power(%convert_element_type.7344, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7350 = f32[32,4]{1,0} reduce(%pow.7345, %constant.512), dimensions={2}, to_apply=%region_182.7349, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7351 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.7350), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7352 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.7351, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7353 = f32[32,4,1]{2,1,0} add(%div.7352, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7354 = f32[32,4,1]{2,1,0} rsqrt(%add.7353), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7355 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.7354), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7356 = f32[32,4]{1,0} reshape(%mul.7355), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7357 = f32[32,4,128]{2,1,0} broadcast(%mul.7356), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7358 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.7344, %mul.7357), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7359 = bf16[32,4,128]{2,1,0} convert(%mul.7358), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_37_self_attn_k_norm_weight__.287 = bf16[128]{0} parameter(286), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.37.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.7360 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_37_self_attn_k_norm_weight__.287), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7361 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.7360), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7362 = bf16[128]{0} reshape(%mul.7361), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7363 = bf16[32,4,128]{2,1,0} broadcast(%mul.7362), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7364 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.7359, %mul.7363), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7398 = bf16[32,4,64]{2,1,0} slice(%mul.7364), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7396 = bf16[32,1,64]{2,1,0} reshape(%slice.7370), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7400 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7396), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7401 = bf16[32,64]{1,0} reshape(%mul.7400), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7402 = bf16[32,4,64]{2,1,0} broadcast(%mul.7401), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7403 = bf16[32,4,64]{2,1,0} multiply(%slice.7398, %mul.7402), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7399 = bf16[32,4,64]{2,1,0} slice(%mul.7364), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7397 = bf16[32,1,64]{2,1,0} reshape(%slice.7371), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7404 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7397), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7405 = bf16[32,64]{1,0} reshape(%mul.7404), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7406 = bf16[32,4,64]{2,1,0} broadcast(%mul.7405), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7407 = bf16[32,4,64]{2,1,0} multiply(%slice.7399, %mul.7406), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.7408 = bf16[32,4,64]{2,1,0} subtract(%mul.7403, %mul.7407), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.7409 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7396), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7410 = bf16[32,64]{1,0} reshape(%mul.7409), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7411 = bf16[32,4,64]{2,1,0} broadcast(%mul.7410), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7412 = bf16[32,4,64]{2,1,0} multiply(%slice.7399, %mul.7411), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7413 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7397), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7414 = bf16[32,64]{1,0} reshape(%mul.7413), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7415 = bf16[32,4,64]{2,1,0} broadcast(%mul.7414), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7416 = bf16[32,4,64]{2,1,0} multiply(%slice.7398, %mul.7415), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.7417 = bf16[32,4,64]{2,1,0} add(%mul.7412, %mul.7416), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.7418 = bf16[32,4,128]{2,1,0} concatenate(%sub.7408, %add.7417), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.7419 = bf16[32,512]{1,0} reshape(%concatenate.7418), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.7320 = bf16[32,4,128]{2,1,0} slice(%reshape.7317), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.7321 = bf16[32,512]{1,0} reshape(%slice.7320), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.7420 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_37_.473, %reshape.7395, %reshape.7419, %reshape.7321, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.7421 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.7420), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_38_.474 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(473), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[38]"}
  %jit__jax_attn_func_.7422 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.7420), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_37_self_attn_o_proj_weight__.288 = bf16[2048,4096]{1,0} parameter(287), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.37.self_attn.o_proj.weight\']"}
  %dot_general.7423 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.7422, %params_and_buffers__vllm_model_language_model_model_layers_37_self_attn_o_proj_weight__.288), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.7424 = f32[32,2048]{1,0} convert(%dot_general.7423), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7295 = bf16[32,2048]{1,0} convert(%add.7294), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7425 = f32[32,2048]{1,0} convert(%convert_element_type.7295), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.7426 = f32[32,2048]{1,0} add(%convert_element_type.7424, %convert_element_type.7425), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.7428 = f32[32,2048]{1,0} power(%add.7426, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7433 = f32[32]{0} reduce(%pow.7428, %constant.512), dimensions={1}, to_apply=%region_183.7432, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7434 = f32[32,1]{1,0} reshape(%reduce_sum.7433), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7435 = f32[32,1]{1,0} divide(%broadcast_in_dim.7434, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7436 = f32[32,1]{1,0} add(%div.7435, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7437 = f32[32,1]{1,0} rsqrt(%add.7436), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7438 = f32[32,1]{1,0} broadcast(%rsqrt.7437), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7439 = f32[32]{0} reshape(%mul.7438), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7440 = f32[32,2048]{1,0} broadcast(%mul.7439), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7441 = f32[32,2048]{1,0} multiply(%add.7426, %mul.7440), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7442 = bf16[32,2048]{1,0} convert(%mul.7441), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_37_post_attention_layernorm_weight__.286 = bf16[2048]{0} parameter(285), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.37.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.7443 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_37_post_attention_layernorm_weight__.286), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7444 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.7443), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7445 = bf16[2048]{0} reshape(%mul.7444), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7446 = bf16[32,2048]{1,0} broadcast(%mul.7445), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7447 = bf16[32,2048]{1,0} multiply(%convert_element_type.7442, %mul.7446), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_37_mlp_experts_w13_weight__.283 = bf16[128,1536,2048]{2,1,0} parameter(282), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.37.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_37_mlp_experts_w2_weight__.284 = bf16[128,2048,768]{2,1,0} parameter(283), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.37.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_37_mlp_gate_weight__.285 = bf16[128,2048]{1,0} parameter(284), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.37.mlp.gate.weight\']"}
  %dot_general.7448 = bf16[32,128]{1,0} dot(%mul.7447, %params_and_buffers__vllm_model_language_model_model_layers_37_mlp_gate_weight__.285), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.7449 = bf16[32,2048]{1,0} call(%mul.7447, %params_and_buffers__vllm_model_language_model_model_layers_37_mlp_experts_w13_weight__.283, %params_and_buffers__vllm_model_language_model_model_layers_37_mlp_experts_w2_weight__.284, %dot_general.7448), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.7450 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.7449), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7427 = bf16[32,2048]{1,0} convert(%add.7426), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7451 = f32[32,2048]{1,0} convert(%convert_element_type.7427), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.7452 = f32[32,2048]{1,0} add(%convert_element_type.7450, %convert_element_type.7451), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.7454 = f32[32,2048]{1,0} power(%add.7452, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7459 = f32[32]{0} reduce(%pow.7454, %constant.512), dimensions={1}, to_apply=%region_184.7458, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7460 = f32[32,1]{1,0} reshape(%reduce_sum.7459), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7461 = f32[32,1]{1,0} divide(%broadcast_in_dim.7460, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7462 = f32[32,1]{1,0} add(%div.7461, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7463 = f32[32,1]{1,0} rsqrt(%add.7462), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7464 = f32[32,1]{1,0} broadcast(%rsqrt.7463), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7465 = f32[32]{0} reshape(%mul.7464), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7466 = f32[32,2048]{1,0} broadcast(%mul.7465), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7467 = f32[32,2048]{1,0} multiply(%add.7452, %mul.7466), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7468 = bf16[32,2048]{1,0} convert(%mul.7467), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_38_input_layernorm_weight__.291 = bf16[2048]{0} parameter(290), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.38.input_layernorm.weight\']"}
  %broadcast_in_dim.7469 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_38_input_layernorm_weight__.291), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7470 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.7469), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7471 = bf16[2048]{0} reshape(%mul.7470), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7472 = bf16[32,2048]{1,0} broadcast(%mul.7471), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7473 = bf16[32,2048]{1,0} multiply(%convert_element_type.7468, %mul.7472), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_38_self_attn_qkv_proj_weight__.299 = bf16[5120,2048]{1,0} parameter(298), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.38.self_attn.qkv_proj.weight\']"}
  %dot_general.7474 = bf16[32,5120]{1,0} dot(%mul.7473, %params_and_buffers__vllm_model_language_model_model_layers_38_self_attn_qkv_proj_weight__.299), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.7475 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.7474), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.7476 = bf16[32,4,1024]{2,1,0} slice(%reshape.7475), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.7480 = bf16[32,32,128]{2,1,0} reshape(%slice.7476), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.7481 = f32[32,32,128]{2,1,0} convert(%reshape.7480), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.7482 = f32[32,32,128]{2,1,0} power(%convert_element_type.7481, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7487 = f32[32,32]{1,0} reduce(%pow.7482, %constant.512), dimensions={2}, to_apply=%region_185.7486, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7488 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.7487), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7489 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.7488, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7490 = f32[32,32,1]{2,1,0} add(%div.7489, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7491 = f32[32,32,1]{2,1,0} rsqrt(%add.7490), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7492 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.7491), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7493 = f32[32,32]{1,0} reshape(%mul.7492), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7494 = f32[32,32,128]{2,1,0} broadcast(%mul.7493), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7495 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.7481, %mul.7494), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7496 = bf16[32,32,128]{2,1,0} convert(%mul.7495), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_38_self_attn_q_norm_weight__.298 = bf16[128]{0} parameter(297), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.38.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.7497 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_38_self_attn_q_norm_weight__.298), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7498 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.7497), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7499 = bf16[128]{0} reshape(%mul.7498), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7500 = bf16[32,32,128]{2,1,0} broadcast(%mul.7499), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7501 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.7496, %mul.7500), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7532 = bf16[32,32,64]{2,1,0} slice(%mul.7501), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.7523 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.7524 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.7525 = s32[32]{0} select(%lt.7523, %add.7524, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.7526 = s32[32,1]{1,0} reshape(%select_n.7525), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.7527 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.7526), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.7528 = bf16[32,64]{1,0} slice(%gather.7527), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7530 = bf16[32,1,64]{2,1,0} reshape(%slice.7528), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7534 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7530), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7535 = bf16[32,64]{1,0} reshape(%mul.7534), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7536 = bf16[32,32,64]{2,1,0} broadcast(%mul.7535), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7537 = bf16[32,32,64]{2,1,0} multiply(%slice.7532, %mul.7536), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7533 = bf16[32,32,64]{2,1,0} slice(%mul.7501), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.7529 = bf16[32,64]{1,0} slice(%gather.7527), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7531 = bf16[32,1,64]{2,1,0} reshape(%slice.7529), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7538 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7531), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7539 = bf16[32,64]{1,0} reshape(%mul.7538), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7540 = bf16[32,32,64]{2,1,0} broadcast(%mul.7539), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7541 = bf16[32,32,64]{2,1,0} multiply(%slice.7533, %mul.7540), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.7542 = bf16[32,32,64]{2,1,0} subtract(%mul.7537, %mul.7541), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.7543 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7530), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7544 = bf16[32,64]{1,0} reshape(%mul.7543), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7545 = bf16[32,32,64]{2,1,0} broadcast(%mul.7544), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7546 = bf16[32,32,64]{2,1,0} multiply(%slice.7533, %mul.7545), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7547 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7531), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7548 = bf16[32,64]{1,0} reshape(%mul.7547), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7549 = bf16[32,32,64]{2,1,0} broadcast(%mul.7548), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7550 = bf16[32,32,64]{2,1,0} multiply(%slice.7532, %mul.7549), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.7551 = bf16[32,32,64]{2,1,0} add(%mul.7546, %mul.7550), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.7552 = bf16[32,32,128]{2,1,0} concatenate(%sub.7542, %add.7551), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.7553 = bf16[32,4096]{1,0} reshape(%concatenate.7552), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.7477 = bf16[32,4,128]{2,1,0} slice(%reshape.7475), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.7502 = f32[32,4,128]{2,1,0} convert(%slice.7477), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.7503 = f32[32,4,128]{2,1,0} power(%convert_element_type.7502, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7508 = f32[32,4]{1,0} reduce(%pow.7503, %constant.512), dimensions={2}, to_apply=%region_186.7507, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7509 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.7508), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7510 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.7509, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7511 = f32[32,4,1]{2,1,0} add(%div.7510, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7512 = f32[32,4,1]{2,1,0} rsqrt(%add.7511), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7513 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.7512), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7514 = f32[32,4]{1,0} reshape(%mul.7513), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7515 = f32[32,4,128]{2,1,0} broadcast(%mul.7514), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7516 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.7502, %mul.7515), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7517 = bf16[32,4,128]{2,1,0} convert(%mul.7516), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_38_self_attn_k_norm_weight__.296 = bf16[128]{0} parameter(295), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.38.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.7518 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_38_self_attn_k_norm_weight__.296), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7519 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.7518), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7520 = bf16[128]{0} reshape(%mul.7519), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7521 = bf16[32,4,128]{2,1,0} broadcast(%mul.7520), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7522 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.7517, %mul.7521), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7556 = bf16[32,4,64]{2,1,0} slice(%mul.7522), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7554 = bf16[32,1,64]{2,1,0} reshape(%slice.7528), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7558 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7554), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7559 = bf16[32,64]{1,0} reshape(%mul.7558), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7560 = bf16[32,4,64]{2,1,0} broadcast(%mul.7559), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7561 = bf16[32,4,64]{2,1,0} multiply(%slice.7556, %mul.7560), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7557 = bf16[32,4,64]{2,1,0} slice(%mul.7522), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7555 = bf16[32,1,64]{2,1,0} reshape(%slice.7529), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7562 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7555), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7563 = bf16[32,64]{1,0} reshape(%mul.7562), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7564 = bf16[32,4,64]{2,1,0} broadcast(%mul.7563), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7565 = bf16[32,4,64]{2,1,0} multiply(%slice.7557, %mul.7564), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.7566 = bf16[32,4,64]{2,1,0} subtract(%mul.7561, %mul.7565), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.7567 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7554), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7568 = bf16[32,64]{1,0} reshape(%mul.7567), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7569 = bf16[32,4,64]{2,1,0} broadcast(%mul.7568), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7570 = bf16[32,4,64]{2,1,0} multiply(%slice.7557, %mul.7569), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7571 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7555), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7572 = bf16[32,64]{1,0} reshape(%mul.7571), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7573 = bf16[32,4,64]{2,1,0} broadcast(%mul.7572), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7574 = bf16[32,4,64]{2,1,0} multiply(%slice.7556, %mul.7573), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.7575 = bf16[32,4,64]{2,1,0} add(%mul.7570, %mul.7574), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.7576 = bf16[32,4,128]{2,1,0} concatenate(%sub.7566, %add.7575), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.7577 = bf16[32,512]{1,0} reshape(%concatenate.7576), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.7478 = bf16[32,4,128]{2,1,0} slice(%reshape.7475), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.7479 = bf16[32,512]{1,0} reshape(%slice.7478), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.7578 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_38_.474, %reshape.7553, %reshape.7577, %reshape.7479, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.7579 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.7578), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_39_.475 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(474), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[39]"}
  %jit__jax_attn_func_.7580 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.7578), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_38_self_attn_o_proj_weight__.297 = bf16[2048,4096]{1,0} parameter(296), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.38.self_attn.o_proj.weight\']"}
  %dot_general.7581 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.7580, %params_and_buffers__vllm_model_language_model_model_layers_38_self_attn_o_proj_weight__.297), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.7582 = f32[32,2048]{1,0} convert(%dot_general.7581), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7453 = bf16[32,2048]{1,0} convert(%add.7452), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7583 = f32[32,2048]{1,0} convert(%convert_element_type.7453), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.7584 = f32[32,2048]{1,0} add(%convert_element_type.7582, %convert_element_type.7583), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.7586 = f32[32,2048]{1,0} power(%add.7584, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7591 = f32[32]{0} reduce(%pow.7586, %constant.512), dimensions={1}, to_apply=%region_187.7590, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7592 = f32[32,1]{1,0} reshape(%reduce_sum.7591), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7593 = f32[32,1]{1,0} divide(%broadcast_in_dim.7592, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7594 = f32[32,1]{1,0} add(%div.7593, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7595 = f32[32,1]{1,0} rsqrt(%add.7594), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7596 = f32[32,1]{1,0} broadcast(%rsqrt.7595), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7597 = f32[32]{0} reshape(%mul.7596), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7598 = f32[32,2048]{1,0} broadcast(%mul.7597), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7599 = f32[32,2048]{1,0} multiply(%add.7584, %mul.7598), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7600 = bf16[32,2048]{1,0} convert(%mul.7599), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_38_post_attention_layernorm_weight__.295 = bf16[2048]{0} parameter(294), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.38.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.7601 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_38_post_attention_layernorm_weight__.295), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7602 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.7601), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7603 = bf16[2048]{0} reshape(%mul.7602), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7604 = bf16[32,2048]{1,0} broadcast(%mul.7603), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7605 = bf16[32,2048]{1,0} multiply(%convert_element_type.7600, %mul.7604), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_38_mlp_experts_w13_weight__.292 = bf16[128,1536,2048]{2,1,0} parameter(291), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.38.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_38_mlp_experts_w2_weight__.293 = bf16[128,2048,768]{2,1,0} parameter(292), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.38.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_38_mlp_gate_weight__.294 = bf16[128,2048]{1,0} parameter(293), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.38.mlp.gate.weight\']"}
  %dot_general.7606 = bf16[32,128]{1,0} dot(%mul.7605, %params_and_buffers__vllm_model_language_model_model_layers_38_mlp_gate_weight__.294), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.7607 = bf16[32,2048]{1,0} call(%mul.7605, %params_and_buffers__vllm_model_language_model_model_layers_38_mlp_experts_w13_weight__.292, %params_and_buffers__vllm_model_language_model_model_layers_38_mlp_experts_w2_weight__.293, %dot_general.7606), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.7608 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.7607), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7585 = bf16[32,2048]{1,0} convert(%add.7584), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7609 = f32[32,2048]{1,0} convert(%convert_element_type.7585), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.7610 = f32[32,2048]{1,0} add(%convert_element_type.7608, %convert_element_type.7609), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.7612 = f32[32,2048]{1,0} power(%add.7610, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7617 = f32[32]{0} reduce(%pow.7612, %constant.512), dimensions={1}, to_apply=%region_188.7616, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7618 = f32[32,1]{1,0} reshape(%reduce_sum.7617), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7619 = f32[32,1]{1,0} divide(%broadcast_in_dim.7618, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7620 = f32[32,1]{1,0} add(%div.7619, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7621 = f32[32,1]{1,0} rsqrt(%add.7620), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7622 = f32[32,1]{1,0} broadcast(%rsqrt.7621), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7623 = f32[32]{0} reshape(%mul.7622), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7624 = f32[32,2048]{1,0} broadcast(%mul.7623), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7625 = f32[32,2048]{1,0} multiply(%add.7610, %mul.7624), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7626 = bf16[32,2048]{1,0} convert(%mul.7625), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_39_input_layernorm_weight__.300 = bf16[2048]{0} parameter(299), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.39.input_layernorm.weight\']"}
  %broadcast_in_dim.7627 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_39_input_layernorm_weight__.300), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7628 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.7627), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7629 = bf16[2048]{0} reshape(%mul.7628), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7630 = bf16[32,2048]{1,0} broadcast(%mul.7629), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7631 = bf16[32,2048]{1,0} multiply(%convert_element_type.7626, %mul.7630), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_39_self_attn_qkv_proj_weight__.308 = bf16[5120,2048]{1,0} parameter(307), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.39.self_attn.qkv_proj.weight\']"}
  %dot_general.7632 = bf16[32,5120]{1,0} dot(%mul.7631, %params_and_buffers__vllm_model_language_model_model_layers_39_self_attn_qkv_proj_weight__.308), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.7633 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.7632), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.7634 = bf16[32,4,1024]{2,1,0} slice(%reshape.7633), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.7638 = bf16[32,32,128]{2,1,0} reshape(%slice.7634), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.7639 = f32[32,32,128]{2,1,0} convert(%reshape.7638), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.7640 = f32[32,32,128]{2,1,0} power(%convert_element_type.7639, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7645 = f32[32,32]{1,0} reduce(%pow.7640, %constant.512), dimensions={2}, to_apply=%region_189.7644, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7646 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.7645), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7647 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.7646, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7648 = f32[32,32,1]{2,1,0} add(%div.7647, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7649 = f32[32,32,1]{2,1,0} rsqrt(%add.7648), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7650 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.7649), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7651 = f32[32,32]{1,0} reshape(%mul.7650), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7652 = f32[32,32,128]{2,1,0} broadcast(%mul.7651), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7653 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.7639, %mul.7652), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7654 = bf16[32,32,128]{2,1,0} convert(%mul.7653), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_39_self_attn_q_norm_weight__.307 = bf16[128]{0} parameter(306), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.39.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.7655 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_39_self_attn_q_norm_weight__.307), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7656 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.7655), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7657 = bf16[128]{0} reshape(%mul.7656), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7658 = bf16[32,32,128]{2,1,0} broadcast(%mul.7657), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7659 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.7654, %mul.7658), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7690 = bf16[32,32,64]{2,1,0} slice(%mul.7659), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.7681 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.7682 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.7683 = s32[32]{0} select(%lt.7681, %add.7682, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.7684 = s32[32,1]{1,0} reshape(%select_n.7683), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.7685 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.7684), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.7686 = bf16[32,64]{1,0} slice(%gather.7685), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7688 = bf16[32,1,64]{2,1,0} reshape(%slice.7686), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7692 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7688), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7693 = bf16[32,64]{1,0} reshape(%mul.7692), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7694 = bf16[32,32,64]{2,1,0} broadcast(%mul.7693), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7695 = bf16[32,32,64]{2,1,0} multiply(%slice.7690, %mul.7694), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7691 = bf16[32,32,64]{2,1,0} slice(%mul.7659), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.7687 = bf16[32,64]{1,0} slice(%gather.7685), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7689 = bf16[32,1,64]{2,1,0} reshape(%slice.7687), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7696 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7689), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7697 = bf16[32,64]{1,0} reshape(%mul.7696), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7698 = bf16[32,32,64]{2,1,0} broadcast(%mul.7697), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7699 = bf16[32,32,64]{2,1,0} multiply(%slice.7691, %mul.7698), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.7700 = bf16[32,32,64]{2,1,0} subtract(%mul.7695, %mul.7699), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.7701 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7688), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7702 = bf16[32,64]{1,0} reshape(%mul.7701), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7703 = bf16[32,32,64]{2,1,0} broadcast(%mul.7702), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7704 = bf16[32,32,64]{2,1,0} multiply(%slice.7691, %mul.7703), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7705 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7689), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7706 = bf16[32,64]{1,0} reshape(%mul.7705), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7707 = bf16[32,32,64]{2,1,0} broadcast(%mul.7706), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7708 = bf16[32,32,64]{2,1,0} multiply(%slice.7690, %mul.7707), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.7709 = bf16[32,32,64]{2,1,0} add(%mul.7704, %mul.7708), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.7710 = bf16[32,32,128]{2,1,0} concatenate(%sub.7700, %add.7709), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.7711 = bf16[32,4096]{1,0} reshape(%concatenate.7710), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.7635 = bf16[32,4,128]{2,1,0} slice(%reshape.7633), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.7660 = f32[32,4,128]{2,1,0} convert(%slice.7635), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.7661 = f32[32,4,128]{2,1,0} power(%convert_element_type.7660, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7666 = f32[32,4]{1,0} reduce(%pow.7661, %constant.512), dimensions={2}, to_apply=%region_190.7665, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7667 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.7666), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7668 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.7667, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7669 = f32[32,4,1]{2,1,0} add(%div.7668, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7670 = f32[32,4,1]{2,1,0} rsqrt(%add.7669), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7671 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.7670), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7672 = f32[32,4]{1,0} reshape(%mul.7671), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7673 = f32[32,4,128]{2,1,0} broadcast(%mul.7672), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7674 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.7660, %mul.7673), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7675 = bf16[32,4,128]{2,1,0} convert(%mul.7674), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_39_self_attn_k_norm_weight__.305 = bf16[128]{0} parameter(304), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.39.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.7676 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_39_self_attn_k_norm_weight__.305), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7677 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.7676), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7678 = bf16[128]{0} reshape(%mul.7677), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7679 = bf16[32,4,128]{2,1,0} broadcast(%mul.7678), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7680 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.7675, %mul.7679), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7714 = bf16[32,4,64]{2,1,0} slice(%mul.7680), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7712 = bf16[32,1,64]{2,1,0} reshape(%slice.7686), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7716 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7712), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7717 = bf16[32,64]{1,0} reshape(%mul.7716), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7718 = bf16[32,4,64]{2,1,0} broadcast(%mul.7717), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7719 = bf16[32,4,64]{2,1,0} multiply(%slice.7714, %mul.7718), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7715 = bf16[32,4,64]{2,1,0} slice(%mul.7680), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7713 = bf16[32,1,64]{2,1,0} reshape(%slice.7687), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7720 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7713), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7721 = bf16[32,64]{1,0} reshape(%mul.7720), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7722 = bf16[32,4,64]{2,1,0} broadcast(%mul.7721), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7723 = bf16[32,4,64]{2,1,0} multiply(%slice.7715, %mul.7722), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.7724 = bf16[32,4,64]{2,1,0} subtract(%mul.7719, %mul.7723), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.7725 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7712), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7726 = bf16[32,64]{1,0} reshape(%mul.7725), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7727 = bf16[32,4,64]{2,1,0} broadcast(%mul.7726), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7728 = bf16[32,4,64]{2,1,0} multiply(%slice.7715, %mul.7727), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7729 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7713), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7730 = bf16[32,64]{1,0} reshape(%mul.7729), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7731 = bf16[32,4,64]{2,1,0} broadcast(%mul.7730), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7732 = bf16[32,4,64]{2,1,0} multiply(%slice.7714, %mul.7731), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.7733 = bf16[32,4,64]{2,1,0} add(%mul.7728, %mul.7732), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.7734 = bf16[32,4,128]{2,1,0} concatenate(%sub.7724, %add.7733), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.7735 = bf16[32,512]{1,0} reshape(%concatenate.7734), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.7636 = bf16[32,4,128]{2,1,0} slice(%reshape.7633), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.7637 = bf16[32,512]{1,0} reshape(%slice.7636), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.7736 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_39_.475, %reshape.7711, %reshape.7735, %reshape.7637, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.7737 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.7736), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_40_.476 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(475), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[40]"}
  %jit__jax_attn_func_.7738 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.7736), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_39_self_attn_o_proj_weight__.306 = bf16[2048,4096]{1,0} parameter(305), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.39.self_attn.o_proj.weight\']"}
  %dot_general.7739 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.7738, %params_and_buffers__vllm_model_language_model_model_layers_39_self_attn_o_proj_weight__.306), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.7740 = f32[32,2048]{1,0} convert(%dot_general.7739), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7611 = bf16[32,2048]{1,0} convert(%add.7610), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7741 = f32[32,2048]{1,0} convert(%convert_element_type.7611), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.7742 = f32[32,2048]{1,0} add(%convert_element_type.7740, %convert_element_type.7741), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.7744 = f32[32,2048]{1,0} power(%add.7742, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7749 = f32[32]{0} reduce(%pow.7744, %constant.512), dimensions={1}, to_apply=%region_191.7748, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7750 = f32[32,1]{1,0} reshape(%reduce_sum.7749), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7751 = f32[32,1]{1,0} divide(%broadcast_in_dim.7750, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7752 = f32[32,1]{1,0} add(%div.7751, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7753 = f32[32,1]{1,0} rsqrt(%add.7752), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7754 = f32[32,1]{1,0} broadcast(%rsqrt.7753), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7755 = f32[32]{0} reshape(%mul.7754), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7756 = f32[32,2048]{1,0} broadcast(%mul.7755), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7757 = f32[32,2048]{1,0} multiply(%add.7742, %mul.7756), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7758 = bf16[32,2048]{1,0} convert(%mul.7757), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_39_post_attention_layernorm_weight__.304 = bf16[2048]{0} parameter(303), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.39.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.7759 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_39_post_attention_layernorm_weight__.304), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7760 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.7759), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7761 = bf16[2048]{0} reshape(%mul.7760), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7762 = bf16[32,2048]{1,0} broadcast(%mul.7761), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7763 = bf16[32,2048]{1,0} multiply(%convert_element_type.7758, %mul.7762), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_39_mlp_experts_w13_weight__.301 = bf16[128,1536,2048]{2,1,0} parameter(300), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.39.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_39_mlp_experts_w2_weight__.302 = bf16[128,2048,768]{2,1,0} parameter(301), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.39.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_39_mlp_gate_weight__.303 = bf16[128,2048]{1,0} parameter(302), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.39.mlp.gate.weight\']"}
  %dot_general.7764 = bf16[32,128]{1,0} dot(%mul.7763, %params_and_buffers__vllm_model_language_model_model_layers_39_mlp_gate_weight__.303), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.7765 = bf16[32,2048]{1,0} call(%mul.7763, %params_and_buffers__vllm_model_language_model_model_layers_39_mlp_experts_w13_weight__.301, %params_and_buffers__vllm_model_language_model_model_layers_39_mlp_experts_w2_weight__.302, %dot_general.7764), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.7766 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.7765), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7743 = bf16[32,2048]{1,0} convert(%add.7742), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7767 = f32[32,2048]{1,0} convert(%convert_element_type.7743), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.7768 = f32[32,2048]{1,0} add(%convert_element_type.7766, %convert_element_type.7767), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.7770 = f32[32,2048]{1,0} power(%add.7768, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7775 = f32[32]{0} reduce(%pow.7770, %constant.512), dimensions={1}, to_apply=%region_192.7774, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7776 = f32[32,1]{1,0} reshape(%reduce_sum.7775), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7777 = f32[32,1]{1,0} divide(%broadcast_in_dim.7776, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7778 = f32[32,1]{1,0} add(%div.7777, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7779 = f32[32,1]{1,0} rsqrt(%add.7778), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7780 = f32[32,1]{1,0} broadcast(%rsqrt.7779), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7781 = f32[32]{0} reshape(%mul.7780), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7782 = f32[32,2048]{1,0} broadcast(%mul.7781), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7783 = f32[32,2048]{1,0} multiply(%add.7768, %mul.7782), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7784 = bf16[32,2048]{1,0} convert(%mul.7783), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_40_input_layernorm_weight__.318 = bf16[2048]{0} parameter(317), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.40.input_layernorm.weight\']"}
  %broadcast_in_dim.7785 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_40_input_layernorm_weight__.318), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7786 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.7785), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7787 = bf16[2048]{0} reshape(%mul.7786), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7788 = bf16[32,2048]{1,0} broadcast(%mul.7787), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7789 = bf16[32,2048]{1,0} multiply(%convert_element_type.7784, %mul.7788), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_40_self_attn_qkv_proj_weight__.326 = bf16[5120,2048]{1,0} parameter(325), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.40.self_attn.qkv_proj.weight\']"}
  %dot_general.7790 = bf16[32,5120]{1,0} dot(%mul.7789, %params_and_buffers__vllm_model_language_model_model_layers_40_self_attn_qkv_proj_weight__.326), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.7791 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.7790), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.7792 = bf16[32,4,1024]{2,1,0} slice(%reshape.7791), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.7796 = bf16[32,32,128]{2,1,0} reshape(%slice.7792), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.7797 = f32[32,32,128]{2,1,0} convert(%reshape.7796), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.7798 = f32[32,32,128]{2,1,0} power(%convert_element_type.7797, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7803 = f32[32,32]{1,0} reduce(%pow.7798, %constant.512), dimensions={2}, to_apply=%region_193.7802, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7804 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.7803), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7805 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.7804, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7806 = f32[32,32,1]{2,1,0} add(%div.7805, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7807 = f32[32,32,1]{2,1,0} rsqrt(%add.7806), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7808 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.7807), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7809 = f32[32,32]{1,0} reshape(%mul.7808), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7810 = f32[32,32,128]{2,1,0} broadcast(%mul.7809), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7811 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.7797, %mul.7810), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7812 = bf16[32,32,128]{2,1,0} convert(%mul.7811), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_40_self_attn_q_norm_weight__.325 = bf16[128]{0} parameter(324), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.40.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.7813 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_40_self_attn_q_norm_weight__.325), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7814 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.7813), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7815 = bf16[128]{0} reshape(%mul.7814), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7816 = bf16[32,32,128]{2,1,0} broadcast(%mul.7815), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7817 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.7812, %mul.7816), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7848 = bf16[32,32,64]{2,1,0} slice(%mul.7817), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.7839 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.7840 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.7841 = s32[32]{0} select(%lt.7839, %add.7840, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.7842 = s32[32,1]{1,0} reshape(%select_n.7841), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.7843 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.7842), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.7844 = bf16[32,64]{1,0} slice(%gather.7843), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7846 = bf16[32,1,64]{2,1,0} reshape(%slice.7844), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7850 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7846), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7851 = bf16[32,64]{1,0} reshape(%mul.7850), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7852 = bf16[32,32,64]{2,1,0} broadcast(%mul.7851), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7853 = bf16[32,32,64]{2,1,0} multiply(%slice.7848, %mul.7852), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7849 = bf16[32,32,64]{2,1,0} slice(%mul.7817), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.7845 = bf16[32,64]{1,0} slice(%gather.7843), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7847 = bf16[32,1,64]{2,1,0} reshape(%slice.7845), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7854 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7847), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7855 = bf16[32,64]{1,0} reshape(%mul.7854), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7856 = bf16[32,32,64]{2,1,0} broadcast(%mul.7855), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7857 = bf16[32,32,64]{2,1,0} multiply(%slice.7849, %mul.7856), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.7858 = bf16[32,32,64]{2,1,0} subtract(%mul.7853, %mul.7857), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.7859 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7846), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7860 = bf16[32,64]{1,0} reshape(%mul.7859), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7861 = bf16[32,32,64]{2,1,0} broadcast(%mul.7860), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7862 = bf16[32,32,64]{2,1,0} multiply(%slice.7849, %mul.7861), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7863 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7847), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7864 = bf16[32,64]{1,0} reshape(%mul.7863), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7865 = bf16[32,32,64]{2,1,0} broadcast(%mul.7864), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7866 = bf16[32,32,64]{2,1,0} multiply(%slice.7848, %mul.7865), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.7867 = bf16[32,32,64]{2,1,0} add(%mul.7862, %mul.7866), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.7868 = bf16[32,32,128]{2,1,0} concatenate(%sub.7858, %add.7867), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.7869 = bf16[32,4096]{1,0} reshape(%concatenate.7868), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.7793 = bf16[32,4,128]{2,1,0} slice(%reshape.7791), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.7818 = f32[32,4,128]{2,1,0} convert(%slice.7793), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.7819 = f32[32,4,128]{2,1,0} power(%convert_element_type.7818, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7824 = f32[32,4]{1,0} reduce(%pow.7819, %constant.512), dimensions={2}, to_apply=%region_194.7823, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7825 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.7824), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7826 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.7825, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7827 = f32[32,4,1]{2,1,0} add(%div.7826, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7828 = f32[32,4,1]{2,1,0} rsqrt(%add.7827), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7829 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.7828), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7830 = f32[32,4]{1,0} reshape(%mul.7829), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7831 = f32[32,4,128]{2,1,0} broadcast(%mul.7830), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7832 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.7818, %mul.7831), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7833 = bf16[32,4,128]{2,1,0} convert(%mul.7832), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_40_self_attn_k_norm_weight__.323 = bf16[128]{0} parameter(322), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.40.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.7834 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_40_self_attn_k_norm_weight__.323), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7835 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.7834), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7836 = bf16[128]{0} reshape(%mul.7835), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7837 = bf16[32,4,128]{2,1,0} broadcast(%mul.7836), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7838 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.7833, %mul.7837), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7872 = bf16[32,4,64]{2,1,0} slice(%mul.7838), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7870 = bf16[32,1,64]{2,1,0} reshape(%slice.7844), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7874 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7870), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7875 = bf16[32,64]{1,0} reshape(%mul.7874), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7876 = bf16[32,4,64]{2,1,0} broadcast(%mul.7875), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7877 = bf16[32,4,64]{2,1,0} multiply(%slice.7872, %mul.7876), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.7873 = bf16[32,4,64]{2,1,0} slice(%mul.7838), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.7871 = bf16[32,1,64]{2,1,0} reshape(%slice.7845), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.7878 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7871), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7879 = bf16[32,64]{1,0} reshape(%mul.7878), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7880 = bf16[32,4,64]{2,1,0} broadcast(%mul.7879), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7881 = bf16[32,4,64]{2,1,0} multiply(%slice.7873, %mul.7880), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.7882 = bf16[32,4,64]{2,1,0} subtract(%mul.7877, %mul.7881), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.7883 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7870), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7884 = bf16[32,64]{1,0} reshape(%mul.7883), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7885 = bf16[32,4,64]{2,1,0} broadcast(%mul.7884), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7886 = bf16[32,4,64]{2,1,0} multiply(%slice.7873, %mul.7885), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7887 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.7871), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7888 = bf16[32,64]{1,0} reshape(%mul.7887), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7889 = bf16[32,4,64]{2,1,0} broadcast(%mul.7888), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7890 = bf16[32,4,64]{2,1,0} multiply(%slice.7872, %mul.7889), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.7891 = bf16[32,4,64]{2,1,0} add(%mul.7886, %mul.7890), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.7892 = bf16[32,4,128]{2,1,0} concatenate(%sub.7882, %add.7891), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.7893 = bf16[32,512]{1,0} reshape(%concatenate.7892), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.7794 = bf16[32,4,128]{2,1,0} slice(%reshape.7791), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.7795 = bf16[32,512]{1,0} reshape(%slice.7794), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.7894 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_40_.476, %reshape.7869, %reshape.7893, %reshape.7795, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.7895 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.7894), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_41_.477 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(476), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[41]"}
  %jit__jax_attn_func_.7896 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.7894), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_40_self_attn_o_proj_weight__.324 = bf16[2048,4096]{1,0} parameter(323), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.40.self_attn.o_proj.weight\']"}
  %dot_general.7897 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.7896, %params_and_buffers__vllm_model_language_model_model_layers_40_self_attn_o_proj_weight__.324), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.7898 = f32[32,2048]{1,0} convert(%dot_general.7897), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7769 = bf16[32,2048]{1,0} convert(%add.7768), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7899 = f32[32,2048]{1,0} convert(%convert_element_type.7769), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.7900 = f32[32,2048]{1,0} add(%convert_element_type.7898, %convert_element_type.7899), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.7902 = f32[32,2048]{1,0} power(%add.7900, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7907 = f32[32]{0} reduce(%pow.7902, %constant.512), dimensions={1}, to_apply=%region_195.7906, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7908 = f32[32,1]{1,0} reshape(%reduce_sum.7907), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7909 = f32[32,1]{1,0} divide(%broadcast_in_dim.7908, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7910 = f32[32,1]{1,0} add(%div.7909, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7911 = f32[32,1]{1,0} rsqrt(%add.7910), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7912 = f32[32,1]{1,0} broadcast(%rsqrt.7911), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7913 = f32[32]{0} reshape(%mul.7912), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7914 = f32[32,2048]{1,0} broadcast(%mul.7913), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7915 = f32[32,2048]{1,0} multiply(%add.7900, %mul.7914), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7916 = bf16[32,2048]{1,0} convert(%mul.7915), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_40_post_attention_layernorm_weight__.322 = bf16[2048]{0} parameter(321), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.40.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.7917 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_40_post_attention_layernorm_weight__.322), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7918 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.7917), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7919 = bf16[2048]{0} reshape(%mul.7918), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7920 = bf16[32,2048]{1,0} broadcast(%mul.7919), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7921 = bf16[32,2048]{1,0} multiply(%convert_element_type.7916, %mul.7920), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_40_mlp_experts_w13_weight__.319 = bf16[128,1536,2048]{2,1,0} parameter(318), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.40.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_40_mlp_experts_w2_weight__.320 = bf16[128,2048,768]{2,1,0} parameter(319), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.40.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_40_mlp_gate_weight__.321 = bf16[128,2048]{1,0} parameter(320), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.40.mlp.gate.weight\']"}
  %dot_general.7922 = bf16[32,128]{1,0} dot(%mul.7921, %params_and_buffers__vllm_model_language_model_model_layers_40_mlp_gate_weight__.321), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.7923 = bf16[32,2048]{1,0} call(%mul.7921, %params_and_buffers__vllm_model_language_model_model_layers_40_mlp_experts_w13_weight__.319, %params_and_buffers__vllm_model_language_model_model_layers_40_mlp_experts_w2_weight__.320, %dot_general.7922), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.7924 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.7923), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7901 = bf16[32,2048]{1,0} convert(%add.7900), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7925 = f32[32,2048]{1,0} convert(%convert_element_type.7901), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.7926 = f32[32,2048]{1,0} add(%convert_element_type.7924, %convert_element_type.7925), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.7928 = f32[32,2048]{1,0} power(%add.7926, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7933 = f32[32]{0} reduce(%pow.7928, %constant.512), dimensions={1}, to_apply=%region_196.7932, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7934 = f32[32,1]{1,0} reshape(%reduce_sum.7933), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7935 = f32[32,1]{1,0} divide(%broadcast_in_dim.7934, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7936 = f32[32,1]{1,0} add(%div.7935, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7937 = f32[32,1]{1,0} rsqrt(%add.7936), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7938 = f32[32,1]{1,0} broadcast(%rsqrt.7937), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7939 = f32[32]{0} reshape(%mul.7938), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7940 = f32[32,2048]{1,0} broadcast(%mul.7939), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7941 = f32[32,2048]{1,0} multiply(%add.7926, %mul.7940), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7942 = bf16[32,2048]{1,0} convert(%mul.7941), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_41_input_layernorm_weight__.327 = bf16[2048]{0} parameter(326), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.41.input_layernorm.weight\']"}
  %broadcast_in_dim.7943 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_41_input_layernorm_weight__.327), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7944 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.7943), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7945 = bf16[2048]{0} reshape(%mul.7944), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7946 = bf16[32,2048]{1,0} broadcast(%mul.7945), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7947 = bf16[32,2048]{1,0} multiply(%convert_element_type.7942, %mul.7946), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_41_self_attn_qkv_proj_weight__.335 = bf16[5120,2048]{1,0} parameter(334), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.41.self_attn.qkv_proj.weight\']"}
  %dot_general.7948 = bf16[32,5120]{1,0} dot(%mul.7947, %params_and_buffers__vllm_model_language_model_model_layers_41_self_attn_qkv_proj_weight__.335), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.7949 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.7948), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.7950 = bf16[32,4,1024]{2,1,0} slice(%reshape.7949), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.7954 = bf16[32,32,128]{2,1,0} reshape(%slice.7950), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.7955 = f32[32,32,128]{2,1,0} convert(%reshape.7954), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.7956 = f32[32,32,128]{2,1,0} power(%convert_element_type.7955, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7961 = f32[32,32]{1,0} reduce(%pow.7956, %constant.512), dimensions={2}, to_apply=%region_197.7960, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7962 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.7961), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7963 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.7962, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7964 = f32[32,32,1]{2,1,0} add(%div.7963, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7965 = f32[32,32,1]{2,1,0} rsqrt(%add.7964), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7966 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.7965), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7967 = f32[32,32]{1,0} reshape(%mul.7966), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7968 = f32[32,32,128]{2,1,0} broadcast(%mul.7967), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7969 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.7955, %mul.7968), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7970 = bf16[32,32,128]{2,1,0} convert(%mul.7969), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_41_self_attn_q_norm_weight__.334 = bf16[128]{0} parameter(333), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.41.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.7971 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_41_self_attn_q_norm_weight__.334), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7972 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.7971), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7973 = bf16[128]{0} reshape(%mul.7972), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7974 = bf16[32,32,128]{2,1,0} broadcast(%mul.7973), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7975 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.7970, %mul.7974), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8006 = bf16[32,32,64]{2,1,0} slice(%mul.7975), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.7997 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.7998 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.7999 = s32[32]{0} select(%lt.7997, %add.7998, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.8000 = s32[32,1]{1,0} reshape(%select_n.7999), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.8001 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.8000), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.8002 = bf16[32,64]{1,0} slice(%gather.8001), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8004 = bf16[32,1,64]{2,1,0} reshape(%slice.8002), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8008 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8004), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8009 = bf16[32,64]{1,0} reshape(%mul.8008), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8010 = bf16[32,32,64]{2,1,0} broadcast(%mul.8009), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8011 = bf16[32,32,64]{2,1,0} multiply(%slice.8006, %mul.8010), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8007 = bf16[32,32,64]{2,1,0} slice(%mul.7975), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.8003 = bf16[32,64]{1,0} slice(%gather.8001), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8005 = bf16[32,1,64]{2,1,0} reshape(%slice.8003), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8012 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8005), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8013 = bf16[32,64]{1,0} reshape(%mul.8012), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8014 = bf16[32,32,64]{2,1,0} broadcast(%mul.8013), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8015 = bf16[32,32,64]{2,1,0} multiply(%slice.8007, %mul.8014), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.8016 = bf16[32,32,64]{2,1,0} subtract(%mul.8011, %mul.8015), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.8017 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8004), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8018 = bf16[32,64]{1,0} reshape(%mul.8017), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8019 = bf16[32,32,64]{2,1,0} broadcast(%mul.8018), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8020 = bf16[32,32,64]{2,1,0} multiply(%slice.8007, %mul.8019), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8021 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8005), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8022 = bf16[32,64]{1,0} reshape(%mul.8021), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8023 = bf16[32,32,64]{2,1,0} broadcast(%mul.8022), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8024 = bf16[32,32,64]{2,1,0} multiply(%slice.8006, %mul.8023), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.8025 = bf16[32,32,64]{2,1,0} add(%mul.8020, %mul.8024), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.8026 = bf16[32,32,128]{2,1,0} concatenate(%sub.8016, %add.8025), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.8027 = bf16[32,4096]{1,0} reshape(%concatenate.8026), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.7951 = bf16[32,4,128]{2,1,0} slice(%reshape.7949), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.7976 = f32[32,4,128]{2,1,0} convert(%slice.7951), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.7977 = f32[32,4,128]{2,1,0} power(%convert_element_type.7976, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.7982 = f32[32,4]{1,0} reduce(%pow.7977, %constant.512), dimensions={2}, to_apply=%region_198.7981, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.7983 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.7982), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.7984 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.7983, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.7985 = f32[32,4,1]{2,1,0} add(%div.7984, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.7986 = f32[32,4,1]{2,1,0} rsqrt(%add.7985), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.7987 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.7986), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7988 = f32[32,4]{1,0} reshape(%mul.7987), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7989 = f32[32,4,128]{2,1,0} broadcast(%mul.7988), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7990 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.7976, %mul.7989), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.7991 = bf16[32,4,128]{2,1,0} convert(%mul.7990), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_41_self_attn_k_norm_weight__.332 = bf16[128]{0} parameter(331), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.41.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.7992 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_41_self_attn_k_norm_weight__.332), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7993 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.7992), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7994 = bf16[128]{0} reshape(%mul.7993), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7995 = bf16[32,4,128]{2,1,0} broadcast(%mul.7994), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.7996 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.7991, %mul.7995), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8030 = bf16[32,4,64]{2,1,0} slice(%mul.7996), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8028 = bf16[32,1,64]{2,1,0} reshape(%slice.8002), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8032 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8028), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8033 = bf16[32,64]{1,0} reshape(%mul.8032), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8034 = bf16[32,4,64]{2,1,0} broadcast(%mul.8033), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8035 = bf16[32,4,64]{2,1,0} multiply(%slice.8030, %mul.8034), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8031 = bf16[32,4,64]{2,1,0} slice(%mul.7996), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8029 = bf16[32,1,64]{2,1,0} reshape(%slice.8003), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8036 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8029), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8037 = bf16[32,64]{1,0} reshape(%mul.8036), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8038 = bf16[32,4,64]{2,1,0} broadcast(%mul.8037), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8039 = bf16[32,4,64]{2,1,0} multiply(%slice.8031, %mul.8038), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.8040 = bf16[32,4,64]{2,1,0} subtract(%mul.8035, %mul.8039), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.8041 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8028), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8042 = bf16[32,64]{1,0} reshape(%mul.8041), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8043 = bf16[32,4,64]{2,1,0} broadcast(%mul.8042), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8044 = bf16[32,4,64]{2,1,0} multiply(%slice.8031, %mul.8043), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8045 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8029), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8046 = bf16[32,64]{1,0} reshape(%mul.8045), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8047 = bf16[32,4,64]{2,1,0} broadcast(%mul.8046), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8048 = bf16[32,4,64]{2,1,0} multiply(%slice.8030, %mul.8047), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.8049 = bf16[32,4,64]{2,1,0} add(%mul.8044, %mul.8048), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.8050 = bf16[32,4,128]{2,1,0} concatenate(%sub.8040, %add.8049), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.8051 = bf16[32,512]{1,0} reshape(%concatenate.8050), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.7952 = bf16[32,4,128]{2,1,0} slice(%reshape.7949), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.7953 = bf16[32,512]{1,0} reshape(%slice.7952), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.8052 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_41_.477, %reshape.8027, %reshape.8051, %reshape.7953, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.8053 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.8052), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_42_.478 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(477), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[42]"}
  %jit__jax_attn_func_.8054 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.8052), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_41_self_attn_o_proj_weight__.333 = bf16[2048,4096]{1,0} parameter(332), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.41.self_attn.o_proj.weight\']"}
  %dot_general.8055 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.8054, %params_and_buffers__vllm_model_language_model_model_layers_41_self_attn_o_proj_weight__.333), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.8056 = f32[32,2048]{1,0} convert(%dot_general.8055), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.7927 = bf16[32,2048]{1,0} convert(%add.7926), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8057 = f32[32,2048]{1,0} convert(%convert_element_type.7927), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.8058 = f32[32,2048]{1,0} add(%convert_element_type.8056, %convert_element_type.8057), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.8060 = f32[32,2048]{1,0} power(%add.8058, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8065 = f32[32]{0} reduce(%pow.8060, %constant.512), dimensions={1}, to_apply=%region_199.8064, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8066 = f32[32,1]{1,0} reshape(%reduce_sum.8065), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8067 = f32[32,1]{1,0} divide(%broadcast_in_dim.8066, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8068 = f32[32,1]{1,0} add(%div.8067, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8069 = f32[32,1]{1,0} rsqrt(%add.8068), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8070 = f32[32,1]{1,0} broadcast(%rsqrt.8069), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8071 = f32[32]{0} reshape(%mul.8070), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8072 = f32[32,2048]{1,0} broadcast(%mul.8071), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8073 = f32[32,2048]{1,0} multiply(%add.8058, %mul.8072), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8074 = bf16[32,2048]{1,0} convert(%mul.8073), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_41_post_attention_layernorm_weight__.331 = bf16[2048]{0} parameter(330), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.41.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.8075 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_41_post_attention_layernorm_weight__.331), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8076 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.8075), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8077 = bf16[2048]{0} reshape(%mul.8076), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8078 = bf16[32,2048]{1,0} broadcast(%mul.8077), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8079 = bf16[32,2048]{1,0} multiply(%convert_element_type.8074, %mul.8078), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_41_mlp_experts_w13_weight__.328 = bf16[128,1536,2048]{2,1,0} parameter(327), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.41.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_41_mlp_experts_w2_weight__.329 = bf16[128,2048,768]{2,1,0} parameter(328), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.41.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_41_mlp_gate_weight__.330 = bf16[128,2048]{1,0} parameter(329), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.41.mlp.gate.weight\']"}
  %dot_general.8080 = bf16[32,128]{1,0} dot(%mul.8079, %params_and_buffers__vllm_model_language_model_model_layers_41_mlp_gate_weight__.330), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.8081 = bf16[32,2048]{1,0} call(%mul.8079, %params_and_buffers__vllm_model_language_model_model_layers_41_mlp_experts_w13_weight__.328, %params_and_buffers__vllm_model_language_model_model_layers_41_mlp_experts_w2_weight__.329, %dot_general.8080), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.8082 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.8081), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8059 = bf16[32,2048]{1,0} convert(%add.8058), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8083 = f32[32,2048]{1,0} convert(%convert_element_type.8059), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.8084 = f32[32,2048]{1,0} add(%convert_element_type.8082, %convert_element_type.8083), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.8086 = f32[32,2048]{1,0} power(%add.8084, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8091 = f32[32]{0} reduce(%pow.8086, %constant.512), dimensions={1}, to_apply=%region_200.8090, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8092 = f32[32,1]{1,0} reshape(%reduce_sum.8091), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8093 = f32[32,1]{1,0} divide(%broadcast_in_dim.8092, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8094 = f32[32,1]{1,0} add(%div.8093, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8095 = f32[32,1]{1,0} rsqrt(%add.8094), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8096 = f32[32,1]{1,0} broadcast(%rsqrt.8095), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8097 = f32[32]{0} reshape(%mul.8096), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8098 = f32[32,2048]{1,0} broadcast(%mul.8097), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8099 = f32[32,2048]{1,0} multiply(%add.8084, %mul.8098), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8100 = bf16[32,2048]{1,0} convert(%mul.8099), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_42_input_layernorm_weight__.336 = bf16[2048]{0} parameter(335), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.42.input_layernorm.weight\']"}
  %broadcast_in_dim.8101 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_42_input_layernorm_weight__.336), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8102 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.8101), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8103 = bf16[2048]{0} reshape(%mul.8102), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8104 = bf16[32,2048]{1,0} broadcast(%mul.8103), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8105 = bf16[32,2048]{1,0} multiply(%convert_element_type.8100, %mul.8104), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_42_self_attn_qkv_proj_weight__.344 = bf16[5120,2048]{1,0} parameter(343), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.42.self_attn.qkv_proj.weight\']"}
  %dot_general.8106 = bf16[32,5120]{1,0} dot(%mul.8105, %params_and_buffers__vllm_model_language_model_model_layers_42_self_attn_qkv_proj_weight__.344), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.8107 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.8106), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.8108 = bf16[32,4,1024]{2,1,0} slice(%reshape.8107), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.8112 = bf16[32,32,128]{2,1,0} reshape(%slice.8108), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.8113 = f32[32,32,128]{2,1,0} convert(%reshape.8112), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.8114 = f32[32,32,128]{2,1,0} power(%convert_element_type.8113, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8119 = f32[32,32]{1,0} reduce(%pow.8114, %constant.512), dimensions={2}, to_apply=%region_201.8118, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8120 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.8119), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8121 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.8120, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8122 = f32[32,32,1]{2,1,0} add(%div.8121, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8123 = f32[32,32,1]{2,1,0} rsqrt(%add.8122), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8124 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.8123), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8125 = f32[32,32]{1,0} reshape(%mul.8124), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8126 = f32[32,32,128]{2,1,0} broadcast(%mul.8125), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8127 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.8113, %mul.8126), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8128 = bf16[32,32,128]{2,1,0} convert(%mul.8127), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_42_self_attn_q_norm_weight__.343 = bf16[128]{0} parameter(342), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.42.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.8129 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_42_self_attn_q_norm_weight__.343), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8130 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.8129), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8131 = bf16[128]{0} reshape(%mul.8130), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8132 = bf16[32,32,128]{2,1,0} broadcast(%mul.8131), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8133 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.8128, %mul.8132), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8164 = bf16[32,32,64]{2,1,0} slice(%mul.8133), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.8155 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.8156 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.8157 = s32[32]{0} select(%lt.8155, %add.8156, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.8158 = s32[32,1]{1,0} reshape(%select_n.8157), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.8159 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.8158), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.8160 = bf16[32,64]{1,0} slice(%gather.8159), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8162 = bf16[32,1,64]{2,1,0} reshape(%slice.8160), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8166 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8162), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8167 = bf16[32,64]{1,0} reshape(%mul.8166), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8168 = bf16[32,32,64]{2,1,0} broadcast(%mul.8167), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8169 = bf16[32,32,64]{2,1,0} multiply(%slice.8164, %mul.8168), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8165 = bf16[32,32,64]{2,1,0} slice(%mul.8133), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.8161 = bf16[32,64]{1,0} slice(%gather.8159), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8163 = bf16[32,1,64]{2,1,0} reshape(%slice.8161), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8170 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8163), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8171 = bf16[32,64]{1,0} reshape(%mul.8170), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8172 = bf16[32,32,64]{2,1,0} broadcast(%mul.8171), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8173 = bf16[32,32,64]{2,1,0} multiply(%slice.8165, %mul.8172), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.8174 = bf16[32,32,64]{2,1,0} subtract(%mul.8169, %mul.8173), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.8175 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8162), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8176 = bf16[32,64]{1,0} reshape(%mul.8175), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8177 = bf16[32,32,64]{2,1,0} broadcast(%mul.8176), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8178 = bf16[32,32,64]{2,1,0} multiply(%slice.8165, %mul.8177), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8179 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8163), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8180 = bf16[32,64]{1,0} reshape(%mul.8179), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8181 = bf16[32,32,64]{2,1,0} broadcast(%mul.8180), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8182 = bf16[32,32,64]{2,1,0} multiply(%slice.8164, %mul.8181), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.8183 = bf16[32,32,64]{2,1,0} add(%mul.8178, %mul.8182), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.8184 = bf16[32,32,128]{2,1,0} concatenate(%sub.8174, %add.8183), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.8185 = bf16[32,4096]{1,0} reshape(%concatenate.8184), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.8109 = bf16[32,4,128]{2,1,0} slice(%reshape.8107), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.8134 = f32[32,4,128]{2,1,0} convert(%slice.8109), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.8135 = f32[32,4,128]{2,1,0} power(%convert_element_type.8134, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8140 = f32[32,4]{1,0} reduce(%pow.8135, %constant.512), dimensions={2}, to_apply=%region_202.8139, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8141 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.8140), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8142 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.8141, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8143 = f32[32,4,1]{2,1,0} add(%div.8142, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8144 = f32[32,4,1]{2,1,0} rsqrt(%add.8143), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8145 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.8144), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8146 = f32[32,4]{1,0} reshape(%mul.8145), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8147 = f32[32,4,128]{2,1,0} broadcast(%mul.8146), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8148 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.8134, %mul.8147), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8149 = bf16[32,4,128]{2,1,0} convert(%mul.8148), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_42_self_attn_k_norm_weight__.341 = bf16[128]{0} parameter(340), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.42.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.8150 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_42_self_attn_k_norm_weight__.341), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8151 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.8150), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8152 = bf16[128]{0} reshape(%mul.8151), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8153 = bf16[32,4,128]{2,1,0} broadcast(%mul.8152), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8154 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.8149, %mul.8153), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8188 = bf16[32,4,64]{2,1,0} slice(%mul.8154), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8186 = bf16[32,1,64]{2,1,0} reshape(%slice.8160), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8190 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8186), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8191 = bf16[32,64]{1,0} reshape(%mul.8190), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8192 = bf16[32,4,64]{2,1,0} broadcast(%mul.8191), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8193 = bf16[32,4,64]{2,1,0} multiply(%slice.8188, %mul.8192), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8189 = bf16[32,4,64]{2,1,0} slice(%mul.8154), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8187 = bf16[32,1,64]{2,1,0} reshape(%slice.8161), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8194 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8187), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8195 = bf16[32,64]{1,0} reshape(%mul.8194), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8196 = bf16[32,4,64]{2,1,0} broadcast(%mul.8195), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8197 = bf16[32,4,64]{2,1,0} multiply(%slice.8189, %mul.8196), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.8198 = bf16[32,4,64]{2,1,0} subtract(%mul.8193, %mul.8197), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.8199 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8186), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8200 = bf16[32,64]{1,0} reshape(%mul.8199), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8201 = bf16[32,4,64]{2,1,0} broadcast(%mul.8200), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8202 = bf16[32,4,64]{2,1,0} multiply(%slice.8189, %mul.8201), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8203 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8187), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8204 = bf16[32,64]{1,0} reshape(%mul.8203), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8205 = bf16[32,4,64]{2,1,0} broadcast(%mul.8204), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8206 = bf16[32,4,64]{2,1,0} multiply(%slice.8188, %mul.8205), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.8207 = bf16[32,4,64]{2,1,0} add(%mul.8202, %mul.8206), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.8208 = bf16[32,4,128]{2,1,0} concatenate(%sub.8198, %add.8207), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.8209 = bf16[32,512]{1,0} reshape(%concatenate.8208), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.8110 = bf16[32,4,128]{2,1,0} slice(%reshape.8107), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.8111 = bf16[32,512]{1,0} reshape(%slice.8110), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.8210 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_42_.478, %reshape.8185, %reshape.8209, %reshape.8111, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.8211 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.8210), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_43_.479 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(478), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[43]"}
  %jit__jax_attn_func_.8212 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.8210), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_42_self_attn_o_proj_weight__.342 = bf16[2048,4096]{1,0} parameter(341), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.42.self_attn.o_proj.weight\']"}
  %dot_general.8213 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.8212, %params_and_buffers__vllm_model_language_model_model_layers_42_self_attn_o_proj_weight__.342), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.8214 = f32[32,2048]{1,0} convert(%dot_general.8213), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8085 = bf16[32,2048]{1,0} convert(%add.8084), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8215 = f32[32,2048]{1,0} convert(%convert_element_type.8085), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.8216 = f32[32,2048]{1,0} add(%convert_element_type.8214, %convert_element_type.8215), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.8218 = f32[32,2048]{1,0} power(%add.8216, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8223 = f32[32]{0} reduce(%pow.8218, %constant.512), dimensions={1}, to_apply=%region_203.8222, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8224 = f32[32,1]{1,0} reshape(%reduce_sum.8223), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8225 = f32[32,1]{1,0} divide(%broadcast_in_dim.8224, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8226 = f32[32,1]{1,0} add(%div.8225, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8227 = f32[32,1]{1,0} rsqrt(%add.8226), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8228 = f32[32,1]{1,0} broadcast(%rsqrt.8227), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8229 = f32[32]{0} reshape(%mul.8228), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8230 = f32[32,2048]{1,0} broadcast(%mul.8229), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8231 = f32[32,2048]{1,0} multiply(%add.8216, %mul.8230), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8232 = bf16[32,2048]{1,0} convert(%mul.8231), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_42_post_attention_layernorm_weight__.340 = bf16[2048]{0} parameter(339), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.42.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.8233 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_42_post_attention_layernorm_weight__.340), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8234 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.8233), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8235 = bf16[2048]{0} reshape(%mul.8234), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8236 = bf16[32,2048]{1,0} broadcast(%mul.8235), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8237 = bf16[32,2048]{1,0} multiply(%convert_element_type.8232, %mul.8236), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_42_mlp_experts_w13_weight__.337 = bf16[128,1536,2048]{2,1,0} parameter(336), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.42.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_42_mlp_experts_w2_weight__.338 = bf16[128,2048,768]{2,1,0} parameter(337), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.42.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_42_mlp_gate_weight__.339 = bf16[128,2048]{1,0} parameter(338), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.42.mlp.gate.weight\']"}
  %dot_general.8238 = bf16[32,128]{1,0} dot(%mul.8237, %params_and_buffers__vllm_model_language_model_model_layers_42_mlp_gate_weight__.339), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.8239 = bf16[32,2048]{1,0} call(%mul.8237, %params_and_buffers__vllm_model_language_model_model_layers_42_mlp_experts_w13_weight__.337, %params_and_buffers__vllm_model_language_model_model_layers_42_mlp_experts_w2_weight__.338, %dot_general.8238), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.8240 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.8239), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8217 = bf16[32,2048]{1,0} convert(%add.8216), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8241 = f32[32,2048]{1,0} convert(%convert_element_type.8217), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.8242 = f32[32,2048]{1,0} add(%convert_element_type.8240, %convert_element_type.8241), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.8244 = f32[32,2048]{1,0} power(%add.8242, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8249 = f32[32]{0} reduce(%pow.8244, %constant.512), dimensions={1}, to_apply=%region_204.8248, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8250 = f32[32,1]{1,0} reshape(%reduce_sum.8249), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8251 = f32[32,1]{1,0} divide(%broadcast_in_dim.8250, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8252 = f32[32,1]{1,0} add(%div.8251, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8253 = f32[32,1]{1,0} rsqrt(%add.8252), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8254 = f32[32,1]{1,0} broadcast(%rsqrt.8253), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8255 = f32[32]{0} reshape(%mul.8254), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8256 = f32[32,2048]{1,0} broadcast(%mul.8255), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8257 = f32[32,2048]{1,0} multiply(%add.8242, %mul.8256), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8258 = bf16[32,2048]{1,0} convert(%mul.8257), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_43_input_layernorm_weight__.345 = bf16[2048]{0} parameter(344), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.43.input_layernorm.weight\']"}
  %broadcast_in_dim.8259 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_43_input_layernorm_weight__.345), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8260 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.8259), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8261 = bf16[2048]{0} reshape(%mul.8260), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8262 = bf16[32,2048]{1,0} broadcast(%mul.8261), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8263 = bf16[32,2048]{1,0} multiply(%convert_element_type.8258, %mul.8262), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_43_self_attn_qkv_proj_weight__.353 = bf16[5120,2048]{1,0} parameter(352), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.43.self_attn.qkv_proj.weight\']"}
  %dot_general.8264 = bf16[32,5120]{1,0} dot(%mul.8263, %params_and_buffers__vllm_model_language_model_model_layers_43_self_attn_qkv_proj_weight__.353), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.8265 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.8264), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.8266 = bf16[32,4,1024]{2,1,0} slice(%reshape.8265), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.8270 = bf16[32,32,128]{2,1,0} reshape(%slice.8266), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.8271 = f32[32,32,128]{2,1,0} convert(%reshape.8270), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.8272 = f32[32,32,128]{2,1,0} power(%convert_element_type.8271, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8277 = f32[32,32]{1,0} reduce(%pow.8272, %constant.512), dimensions={2}, to_apply=%region_205.8276, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8278 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.8277), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8279 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.8278, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8280 = f32[32,32,1]{2,1,0} add(%div.8279, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8281 = f32[32,32,1]{2,1,0} rsqrt(%add.8280), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8282 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.8281), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8283 = f32[32,32]{1,0} reshape(%mul.8282), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8284 = f32[32,32,128]{2,1,0} broadcast(%mul.8283), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8285 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.8271, %mul.8284), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8286 = bf16[32,32,128]{2,1,0} convert(%mul.8285), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_43_self_attn_q_norm_weight__.352 = bf16[128]{0} parameter(351), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.43.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.8287 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_43_self_attn_q_norm_weight__.352), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8288 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.8287), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8289 = bf16[128]{0} reshape(%mul.8288), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8290 = bf16[32,32,128]{2,1,0} broadcast(%mul.8289), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8291 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.8286, %mul.8290), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8322 = bf16[32,32,64]{2,1,0} slice(%mul.8291), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.8313 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.8314 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.8315 = s32[32]{0} select(%lt.8313, %add.8314, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.8316 = s32[32,1]{1,0} reshape(%select_n.8315), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.8317 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.8316), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.8318 = bf16[32,64]{1,0} slice(%gather.8317), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8320 = bf16[32,1,64]{2,1,0} reshape(%slice.8318), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8324 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8320), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8325 = bf16[32,64]{1,0} reshape(%mul.8324), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8326 = bf16[32,32,64]{2,1,0} broadcast(%mul.8325), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8327 = bf16[32,32,64]{2,1,0} multiply(%slice.8322, %mul.8326), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8323 = bf16[32,32,64]{2,1,0} slice(%mul.8291), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.8319 = bf16[32,64]{1,0} slice(%gather.8317), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8321 = bf16[32,1,64]{2,1,0} reshape(%slice.8319), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8328 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8321), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8329 = bf16[32,64]{1,0} reshape(%mul.8328), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8330 = bf16[32,32,64]{2,1,0} broadcast(%mul.8329), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8331 = bf16[32,32,64]{2,1,0} multiply(%slice.8323, %mul.8330), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.8332 = bf16[32,32,64]{2,1,0} subtract(%mul.8327, %mul.8331), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.8333 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8320), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8334 = bf16[32,64]{1,0} reshape(%mul.8333), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8335 = bf16[32,32,64]{2,1,0} broadcast(%mul.8334), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8336 = bf16[32,32,64]{2,1,0} multiply(%slice.8323, %mul.8335), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8337 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8321), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8338 = bf16[32,64]{1,0} reshape(%mul.8337), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8339 = bf16[32,32,64]{2,1,0} broadcast(%mul.8338), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8340 = bf16[32,32,64]{2,1,0} multiply(%slice.8322, %mul.8339), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.8341 = bf16[32,32,64]{2,1,0} add(%mul.8336, %mul.8340), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.8342 = bf16[32,32,128]{2,1,0} concatenate(%sub.8332, %add.8341), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.8343 = bf16[32,4096]{1,0} reshape(%concatenate.8342), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.8267 = bf16[32,4,128]{2,1,0} slice(%reshape.8265), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.8292 = f32[32,4,128]{2,1,0} convert(%slice.8267), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.8293 = f32[32,4,128]{2,1,0} power(%convert_element_type.8292, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8298 = f32[32,4]{1,0} reduce(%pow.8293, %constant.512), dimensions={2}, to_apply=%region_206.8297, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8299 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.8298), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8300 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.8299, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8301 = f32[32,4,1]{2,1,0} add(%div.8300, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8302 = f32[32,4,1]{2,1,0} rsqrt(%add.8301), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8303 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.8302), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8304 = f32[32,4]{1,0} reshape(%mul.8303), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8305 = f32[32,4,128]{2,1,0} broadcast(%mul.8304), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8306 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.8292, %mul.8305), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8307 = bf16[32,4,128]{2,1,0} convert(%mul.8306), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_43_self_attn_k_norm_weight__.350 = bf16[128]{0} parameter(349), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.43.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.8308 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_43_self_attn_k_norm_weight__.350), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8309 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.8308), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8310 = bf16[128]{0} reshape(%mul.8309), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8311 = bf16[32,4,128]{2,1,0} broadcast(%mul.8310), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8312 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.8307, %mul.8311), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8346 = bf16[32,4,64]{2,1,0} slice(%mul.8312), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8344 = bf16[32,1,64]{2,1,0} reshape(%slice.8318), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8348 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8344), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8349 = bf16[32,64]{1,0} reshape(%mul.8348), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8350 = bf16[32,4,64]{2,1,0} broadcast(%mul.8349), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8351 = bf16[32,4,64]{2,1,0} multiply(%slice.8346, %mul.8350), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8347 = bf16[32,4,64]{2,1,0} slice(%mul.8312), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8345 = bf16[32,1,64]{2,1,0} reshape(%slice.8319), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8352 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8345), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8353 = bf16[32,64]{1,0} reshape(%mul.8352), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8354 = bf16[32,4,64]{2,1,0} broadcast(%mul.8353), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8355 = bf16[32,4,64]{2,1,0} multiply(%slice.8347, %mul.8354), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.8356 = bf16[32,4,64]{2,1,0} subtract(%mul.8351, %mul.8355), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.8357 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8344), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8358 = bf16[32,64]{1,0} reshape(%mul.8357), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8359 = bf16[32,4,64]{2,1,0} broadcast(%mul.8358), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8360 = bf16[32,4,64]{2,1,0} multiply(%slice.8347, %mul.8359), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8361 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8345), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8362 = bf16[32,64]{1,0} reshape(%mul.8361), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8363 = bf16[32,4,64]{2,1,0} broadcast(%mul.8362), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8364 = bf16[32,4,64]{2,1,0} multiply(%slice.8346, %mul.8363), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.8365 = bf16[32,4,64]{2,1,0} add(%mul.8360, %mul.8364), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.8366 = bf16[32,4,128]{2,1,0} concatenate(%sub.8356, %add.8365), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.8367 = bf16[32,512]{1,0} reshape(%concatenate.8366), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.8268 = bf16[32,4,128]{2,1,0} slice(%reshape.8265), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.8269 = bf16[32,512]{1,0} reshape(%slice.8268), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.8368 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_43_.479, %reshape.8343, %reshape.8367, %reshape.8269, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.8369 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.8368), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_44_.480 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(479), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[44]"}
  %jit__jax_attn_func_.8370 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.8368), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_43_self_attn_o_proj_weight__.351 = bf16[2048,4096]{1,0} parameter(350), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.43.self_attn.o_proj.weight\']"}
  %dot_general.8371 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.8370, %params_and_buffers__vllm_model_language_model_model_layers_43_self_attn_o_proj_weight__.351), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.8372 = f32[32,2048]{1,0} convert(%dot_general.8371), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8243 = bf16[32,2048]{1,0} convert(%add.8242), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8373 = f32[32,2048]{1,0} convert(%convert_element_type.8243), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.8374 = f32[32,2048]{1,0} add(%convert_element_type.8372, %convert_element_type.8373), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.8376 = f32[32,2048]{1,0} power(%add.8374, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8381 = f32[32]{0} reduce(%pow.8376, %constant.512), dimensions={1}, to_apply=%region_207.8380, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8382 = f32[32,1]{1,0} reshape(%reduce_sum.8381), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8383 = f32[32,1]{1,0} divide(%broadcast_in_dim.8382, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8384 = f32[32,1]{1,0} add(%div.8383, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8385 = f32[32,1]{1,0} rsqrt(%add.8384), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8386 = f32[32,1]{1,0} broadcast(%rsqrt.8385), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8387 = f32[32]{0} reshape(%mul.8386), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8388 = f32[32,2048]{1,0} broadcast(%mul.8387), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8389 = f32[32,2048]{1,0} multiply(%add.8374, %mul.8388), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8390 = bf16[32,2048]{1,0} convert(%mul.8389), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_43_post_attention_layernorm_weight__.349 = bf16[2048]{0} parameter(348), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.43.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.8391 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_43_post_attention_layernorm_weight__.349), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8392 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.8391), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8393 = bf16[2048]{0} reshape(%mul.8392), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8394 = bf16[32,2048]{1,0} broadcast(%mul.8393), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8395 = bf16[32,2048]{1,0} multiply(%convert_element_type.8390, %mul.8394), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_43_mlp_experts_w13_weight__.346 = bf16[128,1536,2048]{2,1,0} parameter(345), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.43.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_43_mlp_experts_w2_weight__.347 = bf16[128,2048,768]{2,1,0} parameter(346), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.43.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_43_mlp_gate_weight__.348 = bf16[128,2048]{1,0} parameter(347), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.43.mlp.gate.weight\']"}
  %dot_general.8396 = bf16[32,128]{1,0} dot(%mul.8395, %params_and_buffers__vllm_model_language_model_model_layers_43_mlp_gate_weight__.348), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.8397 = bf16[32,2048]{1,0} call(%mul.8395, %params_and_buffers__vllm_model_language_model_model_layers_43_mlp_experts_w13_weight__.346, %params_and_buffers__vllm_model_language_model_model_layers_43_mlp_experts_w2_weight__.347, %dot_general.8396), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.8398 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.8397), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8375 = bf16[32,2048]{1,0} convert(%add.8374), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8399 = f32[32,2048]{1,0} convert(%convert_element_type.8375), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.8400 = f32[32,2048]{1,0} add(%convert_element_type.8398, %convert_element_type.8399), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.8402 = f32[32,2048]{1,0} power(%add.8400, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8407 = f32[32]{0} reduce(%pow.8402, %constant.512), dimensions={1}, to_apply=%region_208.8406, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8408 = f32[32,1]{1,0} reshape(%reduce_sum.8407), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8409 = f32[32,1]{1,0} divide(%broadcast_in_dim.8408, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8410 = f32[32,1]{1,0} add(%div.8409, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8411 = f32[32,1]{1,0} rsqrt(%add.8410), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8412 = f32[32,1]{1,0} broadcast(%rsqrt.8411), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8413 = f32[32]{0} reshape(%mul.8412), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8414 = f32[32,2048]{1,0} broadcast(%mul.8413), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8415 = f32[32,2048]{1,0} multiply(%add.8400, %mul.8414), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8416 = bf16[32,2048]{1,0} convert(%mul.8415), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_44_input_layernorm_weight__.354 = bf16[2048]{0} parameter(353), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.44.input_layernorm.weight\']"}
  %broadcast_in_dim.8417 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_44_input_layernorm_weight__.354), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8418 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.8417), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8419 = bf16[2048]{0} reshape(%mul.8418), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8420 = bf16[32,2048]{1,0} broadcast(%mul.8419), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8421 = bf16[32,2048]{1,0} multiply(%convert_element_type.8416, %mul.8420), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_44_self_attn_qkv_proj_weight__.362 = bf16[5120,2048]{1,0} parameter(361), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.44.self_attn.qkv_proj.weight\']"}
  %dot_general.8422 = bf16[32,5120]{1,0} dot(%mul.8421, %params_and_buffers__vllm_model_language_model_model_layers_44_self_attn_qkv_proj_weight__.362), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.8423 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.8422), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.8424 = bf16[32,4,1024]{2,1,0} slice(%reshape.8423), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.8428 = bf16[32,32,128]{2,1,0} reshape(%slice.8424), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.8429 = f32[32,32,128]{2,1,0} convert(%reshape.8428), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.8430 = f32[32,32,128]{2,1,0} power(%convert_element_type.8429, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8435 = f32[32,32]{1,0} reduce(%pow.8430, %constant.512), dimensions={2}, to_apply=%region_209.8434, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8436 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.8435), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8437 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.8436, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8438 = f32[32,32,1]{2,1,0} add(%div.8437, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8439 = f32[32,32,1]{2,1,0} rsqrt(%add.8438), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8440 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.8439), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8441 = f32[32,32]{1,0} reshape(%mul.8440), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8442 = f32[32,32,128]{2,1,0} broadcast(%mul.8441), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8443 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.8429, %mul.8442), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8444 = bf16[32,32,128]{2,1,0} convert(%mul.8443), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_44_self_attn_q_norm_weight__.361 = bf16[128]{0} parameter(360), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.44.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.8445 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_44_self_attn_q_norm_weight__.361), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8446 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.8445), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8447 = bf16[128]{0} reshape(%mul.8446), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8448 = bf16[32,32,128]{2,1,0} broadcast(%mul.8447), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8449 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.8444, %mul.8448), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8480 = bf16[32,32,64]{2,1,0} slice(%mul.8449), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.8471 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.8472 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.8473 = s32[32]{0} select(%lt.8471, %add.8472, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.8474 = s32[32,1]{1,0} reshape(%select_n.8473), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.8475 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.8474), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.8476 = bf16[32,64]{1,0} slice(%gather.8475), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8478 = bf16[32,1,64]{2,1,0} reshape(%slice.8476), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8482 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8478), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8483 = bf16[32,64]{1,0} reshape(%mul.8482), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8484 = bf16[32,32,64]{2,1,0} broadcast(%mul.8483), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8485 = bf16[32,32,64]{2,1,0} multiply(%slice.8480, %mul.8484), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8481 = bf16[32,32,64]{2,1,0} slice(%mul.8449), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.8477 = bf16[32,64]{1,0} slice(%gather.8475), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8479 = bf16[32,1,64]{2,1,0} reshape(%slice.8477), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8486 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8479), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8487 = bf16[32,64]{1,0} reshape(%mul.8486), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8488 = bf16[32,32,64]{2,1,0} broadcast(%mul.8487), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8489 = bf16[32,32,64]{2,1,0} multiply(%slice.8481, %mul.8488), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.8490 = bf16[32,32,64]{2,1,0} subtract(%mul.8485, %mul.8489), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.8491 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8478), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8492 = bf16[32,64]{1,0} reshape(%mul.8491), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8493 = bf16[32,32,64]{2,1,0} broadcast(%mul.8492), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8494 = bf16[32,32,64]{2,1,0} multiply(%slice.8481, %mul.8493), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8495 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8479), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8496 = bf16[32,64]{1,0} reshape(%mul.8495), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8497 = bf16[32,32,64]{2,1,0} broadcast(%mul.8496), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8498 = bf16[32,32,64]{2,1,0} multiply(%slice.8480, %mul.8497), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.8499 = bf16[32,32,64]{2,1,0} add(%mul.8494, %mul.8498), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.8500 = bf16[32,32,128]{2,1,0} concatenate(%sub.8490, %add.8499), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.8501 = bf16[32,4096]{1,0} reshape(%concatenate.8500), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.8425 = bf16[32,4,128]{2,1,0} slice(%reshape.8423), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.8450 = f32[32,4,128]{2,1,0} convert(%slice.8425), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.8451 = f32[32,4,128]{2,1,0} power(%convert_element_type.8450, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8456 = f32[32,4]{1,0} reduce(%pow.8451, %constant.512), dimensions={2}, to_apply=%region_210.8455, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8457 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.8456), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8458 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.8457, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8459 = f32[32,4,1]{2,1,0} add(%div.8458, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8460 = f32[32,4,1]{2,1,0} rsqrt(%add.8459), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8461 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.8460), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8462 = f32[32,4]{1,0} reshape(%mul.8461), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8463 = f32[32,4,128]{2,1,0} broadcast(%mul.8462), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8464 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.8450, %mul.8463), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8465 = bf16[32,4,128]{2,1,0} convert(%mul.8464), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_44_self_attn_k_norm_weight__.359 = bf16[128]{0} parameter(358), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.44.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.8466 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_44_self_attn_k_norm_weight__.359), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8467 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.8466), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8468 = bf16[128]{0} reshape(%mul.8467), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8469 = bf16[32,4,128]{2,1,0} broadcast(%mul.8468), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8470 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.8465, %mul.8469), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8504 = bf16[32,4,64]{2,1,0} slice(%mul.8470), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8502 = bf16[32,1,64]{2,1,0} reshape(%slice.8476), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8506 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8502), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8507 = bf16[32,64]{1,0} reshape(%mul.8506), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8508 = bf16[32,4,64]{2,1,0} broadcast(%mul.8507), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8509 = bf16[32,4,64]{2,1,0} multiply(%slice.8504, %mul.8508), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8505 = bf16[32,4,64]{2,1,0} slice(%mul.8470), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8503 = bf16[32,1,64]{2,1,0} reshape(%slice.8477), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8510 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8503), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8511 = bf16[32,64]{1,0} reshape(%mul.8510), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8512 = bf16[32,4,64]{2,1,0} broadcast(%mul.8511), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8513 = bf16[32,4,64]{2,1,0} multiply(%slice.8505, %mul.8512), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.8514 = bf16[32,4,64]{2,1,0} subtract(%mul.8509, %mul.8513), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.8515 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8502), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8516 = bf16[32,64]{1,0} reshape(%mul.8515), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8517 = bf16[32,4,64]{2,1,0} broadcast(%mul.8516), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8518 = bf16[32,4,64]{2,1,0} multiply(%slice.8505, %mul.8517), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8519 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8503), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8520 = bf16[32,64]{1,0} reshape(%mul.8519), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8521 = bf16[32,4,64]{2,1,0} broadcast(%mul.8520), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8522 = bf16[32,4,64]{2,1,0} multiply(%slice.8504, %mul.8521), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.8523 = bf16[32,4,64]{2,1,0} add(%mul.8518, %mul.8522), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.8524 = bf16[32,4,128]{2,1,0} concatenate(%sub.8514, %add.8523), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.8525 = bf16[32,512]{1,0} reshape(%concatenate.8524), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.8426 = bf16[32,4,128]{2,1,0} slice(%reshape.8423), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.8427 = bf16[32,512]{1,0} reshape(%slice.8426), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.8526 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_44_.480, %reshape.8501, %reshape.8525, %reshape.8427, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.8527 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.8526), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_45_.481 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(480), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[45]"}
  %jit__jax_attn_func_.8528 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.8526), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_44_self_attn_o_proj_weight__.360 = bf16[2048,4096]{1,0} parameter(359), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.44.self_attn.o_proj.weight\']"}
  %dot_general.8529 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.8528, %params_and_buffers__vllm_model_language_model_model_layers_44_self_attn_o_proj_weight__.360), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.8530 = f32[32,2048]{1,0} convert(%dot_general.8529), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8401 = bf16[32,2048]{1,0} convert(%add.8400), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8531 = f32[32,2048]{1,0} convert(%convert_element_type.8401), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.8532 = f32[32,2048]{1,0} add(%convert_element_type.8530, %convert_element_type.8531), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.8534 = f32[32,2048]{1,0} power(%add.8532, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8539 = f32[32]{0} reduce(%pow.8534, %constant.512), dimensions={1}, to_apply=%region_211.8538, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8540 = f32[32,1]{1,0} reshape(%reduce_sum.8539), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8541 = f32[32,1]{1,0} divide(%broadcast_in_dim.8540, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8542 = f32[32,1]{1,0} add(%div.8541, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8543 = f32[32,1]{1,0} rsqrt(%add.8542), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8544 = f32[32,1]{1,0} broadcast(%rsqrt.8543), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8545 = f32[32]{0} reshape(%mul.8544), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8546 = f32[32,2048]{1,0} broadcast(%mul.8545), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8547 = f32[32,2048]{1,0} multiply(%add.8532, %mul.8546), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8548 = bf16[32,2048]{1,0} convert(%mul.8547), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_44_post_attention_layernorm_weight__.358 = bf16[2048]{0} parameter(357), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.44.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.8549 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_44_post_attention_layernorm_weight__.358), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8550 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.8549), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8551 = bf16[2048]{0} reshape(%mul.8550), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8552 = bf16[32,2048]{1,0} broadcast(%mul.8551), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8553 = bf16[32,2048]{1,0} multiply(%convert_element_type.8548, %mul.8552), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_44_mlp_experts_w13_weight__.355 = bf16[128,1536,2048]{2,1,0} parameter(354), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.44.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_44_mlp_experts_w2_weight__.356 = bf16[128,2048,768]{2,1,0} parameter(355), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.44.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_44_mlp_gate_weight__.357 = bf16[128,2048]{1,0} parameter(356), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.44.mlp.gate.weight\']"}
  %dot_general.8554 = bf16[32,128]{1,0} dot(%mul.8553, %params_and_buffers__vllm_model_language_model_model_layers_44_mlp_gate_weight__.357), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.8555 = bf16[32,2048]{1,0} call(%mul.8553, %params_and_buffers__vllm_model_language_model_model_layers_44_mlp_experts_w13_weight__.355, %params_and_buffers__vllm_model_language_model_model_layers_44_mlp_experts_w2_weight__.356, %dot_general.8554), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.8556 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.8555), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8533 = bf16[32,2048]{1,0} convert(%add.8532), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8557 = f32[32,2048]{1,0} convert(%convert_element_type.8533), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.8558 = f32[32,2048]{1,0} add(%convert_element_type.8556, %convert_element_type.8557), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.8560 = f32[32,2048]{1,0} power(%add.8558, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8565 = f32[32]{0} reduce(%pow.8560, %constant.512), dimensions={1}, to_apply=%region_212.8564, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8566 = f32[32,1]{1,0} reshape(%reduce_sum.8565), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8567 = f32[32,1]{1,0} divide(%broadcast_in_dim.8566, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8568 = f32[32,1]{1,0} add(%div.8567, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8569 = f32[32,1]{1,0} rsqrt(%add.8568), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8570 = f32[32,1]{1,0} broadcast(%rsqrt.8569), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8571 = f32[32]{0} reshape(%mul.8570), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8572 = f32[32,2048]{1,0} broadcast(%mul.8571), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8573 = f32[32,2048]{1,0} multiply(%add.8558, %mul.8572), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8574 = bf16[32,2048]{1,0} convert(%mul.8573), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_45_input_layernorm_weight__.363 = bf16[2048]{0} parameter(362), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.45.input_layernorm.weight\']"}
  %broadcast_in_dim.8575 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_45_input_layernorm_weight__.363), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8576 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.8575), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8577 = bf16[2048]{0} reshape(%mul.8576), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8578 = bf16[32,2048]{1,0} broadcast(%mul.8577), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8579 = bf16[32,2048]{1,0} multiply(%convert_element_type.8574, %mul.8578), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_45_self_attn_qkv_proj_weight__.371 = bf16[5120,2048]{1,0} parameter(370), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.45.self_attn.qkv_proj.weight\']"}
  %dot_general.8580 = bf16[32,5120]{1,0} dot(%mul.8579, %params_and_buffers__vllm_model_language_model_model_layers_45_self_attn_qkv_proj_weight__.371), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.8581 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.8580), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.8582 = bf16[32,4,1024]{2,1,0} slice(%reshape.8581), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.8586 = bf16[32,32,128]{2,1,0} reshape(%slice.8582), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.8587 = f32[32,32,128]{2,1,0} convert(%reshape.8586), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.8588 = f32[32,32,128]{2,1,0} power(%convert_element_type.8587, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8593 = f32[32,32]{1,0} reduce(%pow.8588, %constant.512), dimensions={2}, to_apply=%region_213.8592, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8594 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.8593), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8595 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.8594, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8596 = f32[32,32,1]{2,1,0} add(%div.8595, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8597 = f32[32,32,1]{2,1,0} rsqrt(%add.8596), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8598 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.8597), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8599 = f32[32,32]{1,0} reshape(%mul.8598), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8600 = f32[32,32,128]{2,1,0} broadcast(%mul.8599), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8601 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.8587, %mul.8600), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8602 = bf16[32,32,128]{2,1,0} convert(%mul.8601), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_45_self_attn_q_norm_weight__.370 = bf16[128]{0} parameter(369), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.45.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.8603 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_45_self_attn_q_norm_weight__.370), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8604 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.8603), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8605 = bf16[128]{0} reshape(%mul.8604), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8606 = bf16[32,32,128]{2,1,0} broadcast(%mul.8605), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8607 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.8602, %mul.8606), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8638 = bf16[32,32,64]{2,1,0} slice(%mul.8607), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.8629 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.8630 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.8631 = s32[32]{0} select(%lt.8629, %add.8630, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.8632 = s32[32,1]{1,0} reshape(%select_n.8631), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.8633 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.8632), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.8634 = bf16[32,64]{1,0} slice(%gather.8633), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8636 = bf16[32,1,64]{2,1,0} reshape(%slice.8634), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8640 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8636), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8641 = bf16[32,64]{1,0} reshape(%mul.8640), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8642 = bf16[32,32,64]{2,1,0} broadcast(%mul.8641), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8643 = bf16[32,32,64]{2,1,0} multiply(%slice.8638, %mul.8642), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8639 = bf16[32,32,64]{2,1,0} slice(%mul.8607), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.8635 = bf16[32,64]{1,0} slice(%gather.8633), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8637 = bf16[32,1,64]{2,1,0} reshape(%slice.8635), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8644 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8637), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8645 = bf16[32,64]{1,0} reshape(%mul.8644), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8646 = bf16[32,32,64]{2,1,0} broadcast(%mul.8645), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8647 = bf16[32,32,64]{2,1,0} multiply(%slice.8639, %mul.8646), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.8648 = bf16[32,32,64]{2,1,0} subtract(%mul.8643, %mul.8647), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.8649 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8636), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8650 = bf16[32,64]{1,0} reshape(%mul.8649), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8651 = bf16[32,32,64]{2,1,0} broadcast(%mul.8650), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8652 = bf16[32,32,64]{2,1,0} multiply(%slice.8639, %mul.8651), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8653 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8637), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8654 = bf16[32,64]{1,0} reshape(%mul.8653), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8655 = bf16[32,32,64]{2,1,0} broadcast(%mul.8654), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8656 = bf16[32,32,64]{2,1,0} multiply(%slice.8638, %mul.8655), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.8657 = bf16[32,32,64]{2,1,0} add(%mul.8652, %mul.8656), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.8658 = bf16[32,32,128]{2,1,0} concatenate(%sub.8648, %add.8657), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.8659 = bf16[32,4096]{1,0} reshape(%concatenate.8658), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.8583 = bf16[32,4,128]{2,1,0} slice(%reshape.8581), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.8608 = f32[32,4,128]{2,1,0} convert(%slice.8583), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.8609 = f32[32,4,128]{2,1,0} power(%convert_element_type.8608, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8614 = f32[32,4]{1,0} reduce(%pow.8609, %constant.512), dimensions={2}, to_apply=%region_214.8613, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8615 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.8614), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8616 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.8615, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8617 = f32[32,4,1]{2,1,0} add(%div.8616, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8618 = f32[32,4,1]{2,1,0} rsqrt(%add.8617), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8619 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.8618), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8620 = f32[32,4]{1,0} reshape(%mul.8619), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8621 = f32[32,4,128]{2,1,0} broadcast(%mul.8620), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8622 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.8608, %mul.8621), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8623 = bf16[32,4,128]{2,1,0} convert(%mul.8622), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_45_self_attn_k_norm_weight__.368 = bf16[128]{0} parameter(367), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.45.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.8624 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_45_self_attn_k_norm_weight__.368), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8625 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.8624), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8626 = bf16[128]{0} reshape(%mul.8625), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8627 = bf16[32,4,128]{2,1,0} broadcast(%mul.8626), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8628 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.8623, %mul.8627), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8662 = bf16[32,4,64]{2,1,0} slice(%mul.8628), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8660 = bf16[32,1,64]{2,1,0} reshape(%slice.8634), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8664 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8660), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8665 = bf16[32,64]{1,0} reshape(%mul.8664), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8666 = bf16[32,4,64]{2,1,0} broadcast(%mul.8665), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8667 = bf16[32,4,64]{2,1,0} multiply(%slice.8662, %mul.8666), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8663 = bf16[32,4,64]{2,1,0} slice(%mul.8628), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8661 = bf16[32,1,64]{2,1,0} reshape(%slice.8635), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8668 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8661), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8669 = bf16[32,64]{1,0} reshape(%mul.8668), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8670 = bf16[32,4,64]{2,1,0} broadcast(%mul.8669), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8671 = bf16[32,4,64]{2,1,0} multiply(%slice.8663, %mul.8670), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.8672 = bf16[32,4,64]{2,1,0} subtract(%mul.8667, %mul.8671), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.8673 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8660), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8674 = bf16[32,64]{1,0} reshape(%mul.8673), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8675 = bf16[32,4,64]{2,1,0} broadcast(%mul.8674), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8676 = bf16[32,4,64]{2,1,0} multiply(%slice.8663, %mul.8675), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8677 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8661), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8678 = bf16[32,64]{1,0} reshape(%mul.8677), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8679 = bf16[32,4,64]{2,1,0} broadcast(%mul.8678), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8680 = bf16[32,4,64]{2,1,0} multiply(%slice.8662, %mul.8679), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.8681 = bf16[32,4,64]{2,1,0} add(%mul.8676, %mul.8680), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.8682 = bf16[32,4,128]{2,1,0} concatenate(%sub.8672, %add.8681), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.8683 = bf16[32,512]{1,0} reshape(%concatenate.8682), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.8584 = bf16[32,4,128]{2,1,0} slice(%reshape.8581), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.8585 = bf16[32,512]{1,0} reshape(%slice.8584), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.8684 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_45_.481, %reshape.8659, %reshape.8683, %reshape.8585, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.8685 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.8684), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_46_.482 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(481), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[46]"}
  %jit__jax_attn_func_.8686 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.8684), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_45_self_attn_o_proj_weight__.369 = bf16[2048,4096]{1,0} parameter(368), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.45.self_attn.o_proj.weight\']"}
  %dot_general.8687 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.8686, %params_and_buffers__vllm_model_language_model_model_layers_45_self_attn_o_proj_weight__.369), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.8688 = f32[32,2048]{1,0} convert(%dot_general.8687), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8559 = bf16[32,2048]{1,0} convert(%add.8558), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8689 = f32[32,2048]{1,0} convert(%convert_element_type.8559), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.8690 = f32[32,2048]{1,0} add(%convert_element_type.8688, %convert_element_type.8689), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.8692 = f32[32,2048]{1,0} power(%add.8690, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8697 = f32[32]{0} reduce(%pow.8692, %constant.512), dimensions={1}, to_apply=%region_215.8696, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8698 = f32[32,1]{1,0} reshape(%reduce_sum.8697), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8699 = f32[32,1]{1,0} divide(%broadcast_in_dim.8698, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8700 = f32[32,1]{1,0} add(%div.8699, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8701 = f32[32,1]{1,0} rsqrt(%add.8700), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8702 = f32[32,1]{1,0} broadcast(%rsqrt.8701), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8703 = f32[32]{0} reshape(%mul.8702), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8704 = f32[32,2048]{1,0} broadcast(%mul.8703), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8705 = f32[32,2048]{1,0} multiply(%add.8690, %mul.8704), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8706 = bf16[32,2048]{1,0} convert(%mul.8705), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_45_post_attention_layernorm_weight__.367 = bf16[2048]{0} parameter(366), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.45.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.8707 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_45_post_attention_layernorm_weight__.367), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8708 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.8707), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8709 = bf16[2048]{0} reshape(%mul.8708), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8710 = bf16[32,2048]{1,0} broadcast(%mul.8709), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8711 = bf16[32,2048]{1,0} multiply(%convert_element_type.8706, %mul.8710), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_45_mlp_experts_w13_weight__.364 = bf16[128,1536,2048]{2,1,0} parameter(363), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.45.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_45_mlp_experts_w2_weight__.365 = bf16[128,2048,768]{2,1,0} parameter(364), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.45.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_45_mlp_gate_weight__.366 = bf16[128,2048]{1,0} parameter(365), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.45.mlp.gate.weight\']"}
  %dot_general.8712 = bf16[32,128]{1,0} dot(%mul.8711, %params_and_buffers__vllm_model_language_model_model_layers_45_mlp_gate_weight__.366), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.8713 = bf16[32,2048]{1,0} call(%mul.8711, %params_and_buffers__vllm_model_language_model_model_layers_45_mlp_experts_w13_weight__.364, %params_and_buffers__vllm_model_language_model_model_layers_45_mlp_experts_w2_weight__.365, %dot_general.8712), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.8714 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.8713), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8691 = bf16[32,2048]{1,0} convert(%add.8690), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8715 = f32[32,2048]{1,0} convert(%convert_element_type.8691), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.8716 = f32[32,2048]{1,0} add(%convert_element_type.8714, %convert_element_type.8715), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.8718 = f32[32,2048]{1,0} power(%add.8716, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8723 = f32[32]{0} reduce(%pow.8718, %constant.512), dimensions={1}, to_apply=%region_216.8722, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8724 = f32[32,1]{1,0} reshape(%reduce_sum.8723), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8725 = f32[32,1]{1,0} divide(%broadcast_in_dim.8724, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8726 = f32[32,1]{1,0} add(%div.8725, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8727 = f32[32,1]{1,0} rsqrt(%add.8726), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8728 = f32[32,1]{1,0} broadcast(%rsqrt.8727), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8729 = f32[32]{0} reshape(%mul.8728), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8730 = f32[32,2048]{1,0} broadcast(%mul.8729), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8731 = f32[32,2048]{1,0} multiply(%add.8716, %mul.8730), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8732 = bf16[32,2048]{1,0} convert(%mul.8731), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_46_input_layernorm_weight__.372 = bf16[2048]{0} parameter(371), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.46.input_layernorm.weight\']"}
  %broadcast_in_dim.8733 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_46_input_layernorm_weight__.372), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8734 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.8733), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8735 = bf16[2048]{0} reshape(%mul.8734), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8736 = bf16[32,2048]{1,0} broadcast(%mul.8735), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8737 = bf16[32,2048]{1,0} multiply(%convert_element_type.8732, %mul.8736), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_46_self_attn_qkv_proj_weight__.380 = bf16[5120,2048]{1,0} parameter(379), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.46.self_attn.qkv_proj.weight\']"}
  %dot_general.8738 = bf16[32,5120]{1,0} dot(%mul.8737, %params_and_buffers__vllm_model_language_model_model_layers_46_self_attn_qkv_proj_weight__.380), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.8739 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.8738), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.8740 = bf16[32,4,1024]{2,1,0} slice(%reshape.8739), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.8744 = bf16[32,32,128]{2,1,0} reshape(%slice.8740), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.8745 = f32[32,32,128]{2,1,0} convert(%reshape.8744), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.8746 = f32[32,32,128]{2,1,0} power(%convert_element_type.8745, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8751 = f32[32,32]{1,0} reduce(%pow.8746, %constant.512), dimensions={2}, to_apply=%region_217.8750, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8752 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.8751), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8753 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.8752, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8754 = f32[32,32,1]{2,1,0} add(%div.8753, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8755 = f32[32,32,1]{2,1,0} rsqrt(%add.8754), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8756 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.8755), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8757 = f32[32,32]{1,0} reshape(%mul.8756), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8758 = f32[32,32,128]{2,1,0} broadcast(%mul.8757), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8759 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.8745, %mul.8758), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8760 = bf16[32,32,128]{2,1,0} convert(%mul.8759), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_46_self_attn_q_norm_weight__.379 = bf16[128]{0} parameter(378), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.46.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.8761 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_46_self_attn_q_norm_weight__.379), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8762 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.8761), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8763 = bf16[128]{0} reshape(%mul.8762), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8764 = bf16[32,32,128]{2,1,0} broadcast(%mul.8763), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8765 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.8760, %mul.8764), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8796 = bf16[32,32,64]{2,1,0} slice(%mul.8765), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.8787 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.8788 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.8789 = s32[32]{0} select(%lt.8787, %add.8788, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.8790 = s32[32,1]{1,0} reshape(%select_n.8789), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.8791 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.8790), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.8792 = bf16[32,64]{1,0} slice(%gather.8791), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8794 = bf16[32,1,64]{2,1,0} reshape(%slice.8792), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8798 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8794), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8799 = bf16[32,64]{1,0} reshape(%mul.8798), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8800 = bf16[32,32,64]{2,1,0} broadcast(%mul.8799), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8801 = bf16[32,32,64]{2,1,0} multiply(%slice.8796, %mul.8800), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8797 = bf16[32,32,64]{2,1,0} slice(%mul.8765), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.8793 = bf16[32,64]{1,0} slice(%gather.8791), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8795 = bf16[32,1,64]{2,1,0} reshape(%slice.8793), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8802 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8795), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8803 = bf16[32,64]{1,0} reshape(%mul.8802), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8804 = bf16[32,32,64]{2,1,0} broadcast(%mul.8803), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8805 = bf16[32,32,64]{2,1,0} multiply(%slice.8797, %mul.8804), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.8806 = bf16[32,32,64]{2,1,0} subtract(%mul.8801, %mul.8805), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.8807 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8794), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8808 = bf16[32,64]{1,0} reshape(%mul.8807), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8809 = bf16[32,32,64]{2,1,0} broadcast(%mul.8808), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8810 = bf16[32,32,64]{2,1,0} multiply(%slice.8797, %mul.8809), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8811 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8795), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8812 = bf16[32,64]{1,0} reshape(%mul.8811), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8813 = bf16[32,32,64]{2,1,0} broadcast(%mul.8812), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8814 = bf16[32,32,64]{2,1,0} multiply(%slice.8796, %mul.8813), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.8815 = bf16[32,32,64]{2,1,0} add(%mul.8810, %mul.8814), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.8816 = bf16[32,32,128]{2,1,0} concatenate(%sub.8806, %add.8815), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.8817 = bf16[32,4096]{1,0} reshape(%concatenate.8816), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.8741 = bf16[32,4,128]{2,1,0} slice(%reshape.8739), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.8766 = f32[32,4,128]{2,1,0} convert(%slice.8741), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.8767 = f32[32,4,128]{2,1,0} power(%convert_element_type.8766, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8772 = f32[32,4]{1,0} reduce(%pow.8767, %constant.512), dimensions={2}, to_apply=%region_218.8771, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8773 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.8772), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8774 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.8773, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8775 = f32[32,4,1]{2,1,0} add(%div.8774, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8776 = f32[32,4,1]{2,1,0} rsqrt(%add.8775), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8777 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.8776), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8778 = f32[32,4]{1,0} reshape(%mul.8777), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8779 = f32[32,4,128]{2,1,0} broadcast(%mul.8778), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8780 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.8766, %mul.8779), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8781 = bf16[32,4,128]{2,1,0} convert(%mul.8780), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_46_self_attn_k_norm_weight__.377 = bf16[128]{0} parameter(376), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.46.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.8782 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_46_self_attn_k_norm_weight__.377), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8783 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.8782), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8784 = bf16[128]{0} reshape(%mul.8783), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8785 = bf16[32,4,128]{2,1,0} broadcast(%mul.8784), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8786 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.8781, %mul.8785), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8820 = bf16[32,4,64]{2,1,0} slice(%mul.8786), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8818 = bf16[32,1,64]{2,1,0} reshape(%slice.8792), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8822 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8818), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8823 = bf16[32,64]{1,0} reshape(%mul.8822), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8824 = bf16[32,4,64]{2,1,0} broadcast(%mul.8823), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8825 = bf16[32,4,64]{2,1,0} multiply(%slice.8820, %mul.8824), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8821 = bf16[32,4,64]{2,1,0} slice(%mul.8786), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8819 = bf16[32,1,64]{2,1,0} reshape(%slice.8793), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8826 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8819), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8827 = bf16[32,64]{1,0} reshape(%mul.8826), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8828 = bf16[32,4,64]{2,1,0} broadcast(%mul.8827), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8829 = bf16[32,4,64]{2,1,0} multiply(%slice.8821, %mul.8828), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.8830 = bf16[32,4,64]{2,1,0} subtract(%mul.8825, %mul.8829), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.8831 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8818), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8832 = bf16[32,64]{1,0} reshape(%mul.8831), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8833 = bf16[32,4,64]{2,1,0} broadcast(%mul.8832), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8834 = bf16[32,4,64]{2,1,0} multiply(%slice.8821, %mul.8833), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8835 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8819), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8836 = bf16[32,64]{1,0} reshape(%mul.8835), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8837 = bf16[32,4,64]{2,1,0} broadcast(%mul.8836), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8838 = bf16[32,4,64]{2,1,0} multiply(%slice.8820, %mul.8837), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.8839 = bf16[32,4,64]{2,1,0} add(%mul.8834, %mul.8838), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.8840 = bf16[32,4,128]{2,1,0} concatenate(%sub.8830, %add.8839), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.8841 = bf16[32,512]{1,0} reshape(%concatenate.8840), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.8742 = bf16[32,4,128]{2,1,0} slice(%reshape.8739), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.8743 = bf16[32,512]{1,0} reshape(%slice.8742), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.8842 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_46_.482, %reshape.8817, %reshape.8841, %reshape.8743, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.8843 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.8842), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %kv_caches_47_.483 = bf16[14813,32,4,2,128]{4,3,2,1,0} parameter(482), sharding={devices=[1,1,4,1,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}, {}, {}]>"}, metadata={op_name="kv_caches[47]"}
  %jit__jax_attn_func_.8844 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.8842), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_46_self_attn_o_proj_weight__.378 = bf16[2048,4096]{1,0} parameter(377), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.46.self_attn.o_proj.weight\']"}
  %dot_general.8845 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.8844, %params_and_buffers__vllm_model_language_model_model_layers_46_self_attn_o_proj_weight__.378), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.8846 = f32[32,2048]{1,0} convert(%dot_general.8845), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8717 = bf16[32,2048]{1,0} convert(%add.8716), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8847 = f32[32,2048]{1,0} convert(%convert_element_type.8717), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.8848 = f32[32,2048]{1,0} add(%convert_element_type.8846, %convert_element_type.8847), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.8850 = f32[32,2048]{1,0} power(%add.8848, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8855 = f32[32]{0} reduce(%pow.8850, %constant.512), dimensions={1}, to_apply=%region_219.8854, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8856 = f32[32,1]{1,0} reshape(%reduce_sum.8855), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8857 = f32[32,1]{1,0} divide(%broadcast_in_dim.8856, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8858 = f32[32,1]{1,0} add(%div.8857, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8859 = f32[32,1]{1,0} rsqrt(%add.8858), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8860 = f32[32,1]{1,0} broadcast(%rsqrt.8859), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8861 = f32[32]{0} reshape(%mul.8860), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8862 = f32[32,2048]{1,0} broadcast(%mul.8861), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8863 = f32[32,2048]{1,0} multiply(%add.8848, %mul.8862), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8864 = bf16[32,2048]{1,0} convert(%mul.8863), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_46_post_attention_layernorm_weight__.376 = bf16[2048]{0} parameter(375), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.46.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.8865 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_46_post_attention_layernorm_weight__.376), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8866 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.8865), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8867 = bf16[2048]{0} reshape(%mul.8866), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8868 = bf16[32,2048]{1,0} broadcast(%mul.8867), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8869 = bf16[32,2048]{1,0} multiply(%convert_element_type.8864, %mul.8868), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_46_mlp_experts_w13_weight__.373 = bf16[128,1536,2048]{2,1,0} parameter(372), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.46.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_46_mlp_experts_w2_weight__.374 = bf16[128,2048,768]{2,1,0} parameter(373), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.46.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_46_mlp_gate_weight__.375 = bf16[128,2048]{1,0} parameter(374), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.46.mlp.gate.weight\']"}
  %dot_general.8870 = bf16[32,128]{1,0} dot(%mul.8869, %params_and_buffers__vllm_model_language_model_model_layers_46_mlp_gate_weight__.375), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.8871 = bf16[32,2048]{1,0} call(%mul.8869, %params_and_buffers__vllm_model_language_model_model_layers_46_mlp_experts_w13_weight__.373, %params_and_buffers__vllm_model_language_model_model_layers_46_mlp_experts_w2_weight__.374, %dot_general.8870), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.8872 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.8871), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8849 = bf16[32,2048]{1,0} convert(%add.8848), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8873 = f32[32,2048]{1,0} convert(%convert_element_type.8849), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.8874 = f32[32,2048]{1,0} add(%convert_element_type.8872, %convert_element_type.8873), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.8876 = f32[32,2048]{1,0} power(%add.8874, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8881 = f32[32]{0} reduce(%pow.8876, %constant.512), dimensions={1}, to_apply=%region_220.8880, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8882 = f32[32,1]{1,0} reshape(%reduce_sum.8881), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8883 = f32[32,1]{1,0} divide(%broadcast_in_dim.8882, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8884 = f32[32,1]{1,0} add(%div.8883, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8885 = f32[32,1]{1,0} rsqrt(%add.8884), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8886 = f32[32,1]{1,0} broadcast(%rsqrt.8885), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8887 = f32[32]{0} reshape(%mul.8886), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8888 = f32[32,2048]{1,0} broadcast(%mul.8887), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8889 = f32[32,2048]{1,0} multiply(%add.8874, %mul.8888), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8890 = bf16[32,2048]{1,0} convert(%mul.8889), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_47_input_layernorm_weight__.381 = bf16[2048]{0} parameter(380), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.47.input_layernorm.weight\']"}
  %broadcast_in_dim.8891 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_47_input_layernorm_weight__.381), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8892 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.8891), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8893 = bf16[2048]{0} reshape(%mul.8892), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8894 = bf16[32,2048]{1,0} broadcast(%mul.8893), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8895 = bf16[32,2048]{1,0} multiply(%convert_element_type.8890, %mul.8894), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_47_self_attn_qkv_proj_weight__.389 = bf16[5120,2048]{1,0} parameter(388), sharding={devices=[4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.47.self_attn.qkv_proj.weight\']"}
  %dot_general.8896 = bf16[32,5120]{1,0} dot(%mul.8895, %params_and_buffers__vllm_model_language_model_model_layers_47_self_attn_qkv_proj_weight__.389), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/QKVParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %reshape.8897 = bf16[32,4,1280]{2,1,0} reshape(%dot_general.8896), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=97 source_end_line=97 source_column=21 source_end_column=54}
  %slice.8898 = bf16[32,4,1024]{2,1,0} slice(%reshape.8897), slice={[0:32], [0:4], [0:1024]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.8902 = bf16[32,32,128]{2,1,0} reshape(%slice.8898), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %convert_element_type.8903 = f32[32,32,128]{2,1,0} convert(%reshape.8902), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.8904 = f32[32,32,128]{2,1,0} power(%convert_element_type.8903, %broadcast.505), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8909 = f32[32,32]{1,0} reduce(%pow.8904, %constant.512), dimensions={2}, to_apply=%region_221.8908, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8910 = f32[32,32,1]{2,1,0} reshape(%reduce_sum.8909), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8911 = f32[32,32,1]{2,1,0} divide(%broadcast_in_dim.8910, %broadcast.503), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8912 = f32[32,32,1]{2,1,0} add(%div.8911, %broadcast.501), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8913 = f32[32,32,1]{2,1,0} rsqrt(%add.8912), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8914 = f32[32,32,1]{2,1,0} broadcast(%rsqrt.8913), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8915 = f32[32,32]{1,0} reshape(%mul.8914), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8916 = f32[32,32,128]{2,1,0} broadcast(%mul.8915), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8917 = f32[32,32,128]{2,1,0} multiply(%convert_element_type.8903, %mul.8916), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8918 = bf16[32,32,128]{2,1,0} convert(%mul.8917), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_47_self_attn_q_norm_weight__.388 = bf16[128]{0} parameter(387), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.47.self_attn.q_norm.weight\']"}
  %broadcast_in_dim.8919 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_47_self_attn_q_norm_weight__.388), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8920 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.8919), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8921 = bf16[128]{0} reshape(%mul.8920), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8922 = bf16[32,32,128]{2,1,0} broadcast(%mul.8921), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8923 = bf16[32,32,128]{2,1,0} multiply(%convert_element_type.8918, %mul.8922), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8954 = bf16[32,32,64]{2,1,0} slice(%mul.8923), slice={[0:32], [0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %lt.8945 = pred[32]{0} compare(%attn_metadata_input_positions.485, %broadcast.493), direction=LT, metadata={op_name="jit(step_fun)/__getitem__/lt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %add.8946 = s32[32]{0} add(%attn_metadata_input_positions.485, %broadcast.491), metadata={op_name="jit(step_fun)/__getitem__/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %select_n.8947 = s32[32]{0} select(%lt.8945, %add.8946, %attn_metadata_input_positions.485), metadata={op_name="jit(step_fun)/__getitem__/select_n" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %broadcast_in_dim.8948 = s32[32,1]{1,0} reshape(%select_n.8947), metadata={op_name="jit(step_fun)/__getitem__/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %gather.8949 = bf16[32,128]{1,0} gather(%params_and_buffers__vllm_model_language_model_model_layers_0_self_attn_rotary_emb_cos_sin_cache__.11, %broadcast_in_dim.8948), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_name="jit(step_fun)/__getitem__/gather" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jtorch.py" source_line=291 source_end_line=291 source_column=31 source_end_column=50}
  %slice.8950 = bf16[32,64]{1,0} slice(%gather.8949), slice={[0:32], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8952 = bf16[32,1,64]{2,1,0} reshape(%slice.8950), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8956 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8952), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8957 = bf16[32,64]{1,0} reshape(%mul.8956), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8958 = bf16[32,32,64]{2,1,0} broadcast(%mul.8957), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8959 = bf16[32,32,64]{2,1,0} multiply(%slice.8954, %mul.8958), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8955 = bf16[32,32,64]{2,1,0} slice(%mul.8923), slice={[0:32], [0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %slice.8951 = bf16[32,64]{1,0} slice(%gather.8949), slice={[0:32], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8953 = bf16[32,1,64]{2,1,0} reshape(%slice.8951), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8960 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8953), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8961 = bf16[32,64]{1,0} reshape(%mul.8960), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8962 = bf16[32,32,64]{2,1,0} broadcast(%mul.8961), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8963 = bf16[32,32,64]{2,1,0} multiply(%slice.8955, %mul.8962), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.8964 = bf16[32,32,64]{2,1,0} subtract(%mul.8959, %mul.8963), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.8965 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8952), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8966 = bf16[32,64]{1,0} reshape(%mul.8965), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8967 = bf16[32,32,64]{2,1,0} broadcast(%mul.8966), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8968 = bf16[32,32,64]{2,1,0} multiply(%slice.8955, %mul.8967), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8969 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8953), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8970 = bf16[32,64]{1,0} reshape(%mul.8969), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8971 = bf16[32,32,64]{2,1,0} broadcast(%mul.8970), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8972 = bf16[32,32,64]{2,1,0} multiply(%slice.8954, %mul.8971), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.8973 = bf16[32,32,64]{2,1,0} add(%mul.8968, %mul.8972), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.8974 = bf16[32,32,128]{2,1,0} concatenate(%sub.8964, %add.8973), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.8975 = bf16[32,4096]{1,0} reshape(%concatenate.8974), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.8899 = bf16[32,4,128]{2,1,0} slice(%reshape.8897), slice={[0:32], [0:4], [1024:1152]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %convert_element_type.8924 = f32[32,4,128]{2,1,0} convert(%slice.8899), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %pow.8925 = f32[32,4,128]{2,1,0} power(%convert_element_type.8924, %broadcast.499), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.8930 = f32[32,4]{1,0} reduce(%pow.8925, %constant.512), dimensions={2}, to_apply=%region_222.8929, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.8931 = f32[32,4,1]{2,1,0} reshape(%reduce_sum.8930), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.8932 = f32[32,4,1]{2,1,0} divide(%broadcast_in_dim.8931, %broadcast.497), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.8933 = f32[32,4,1]{2,1,0} add(%div.8932, %broadcast.495), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.8934 = f32[32,4,1]{2,1,0} rsqrt(%add.8933), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.8935 = f32[32,4,1]{2,1,0} broadcast(%rsqrt.8934), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8936 = f32[32,4]{1,0} reshape(%mul.8935), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8937 = f32[32,4,128]{2,1,0} broadcast(%mul.8936), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8938 = f32[32,4,128]{2,1,0} multiply(%convert_element_type.8924, %mul.8937), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.8939 = bf16[32,4,128]{2,1,0} convert(%mul.8938), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_47_self_attn_k_norm_weight__.386 = bf16[128]{0} parameter(385), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.47.self_attn.k_norm.weight\']"}
  %broadcast_in_dim.8940 = bf16[1,1,128]{2,1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_47_self_attn_k_norm_weight__.386), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8941 = bf16[1,1,128]{2,1,0} broadcast(%broadcast_in_dim.8940), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8942 = bf16[128]{0} reshape(%mul.8941), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8943 = bf16[32,4,128]{2,1,0} broadcast(%mul.8942), dimensions={2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8944 = bf16[32,4,128]{2,1,0} multiply(%convert_element_type.8939, %mul.8943), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8978 = bf16[32,4,64]{2,1,0} slice(%mul.8944), slice={[0:32], [0:4], [0:64]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8976 = bf16[32,1,64]{2,1,0} reshape(%slice.8950), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8980 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8976), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8981 = bf16[32,64]{1,0} reshape(%mul.8980), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8982 = bf16[32,4,64]{2,1,0} broadcast(%mul.8981), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8983 = bf16[32,4,64]{2,1,0} multiply(%slice.8978, %mul.8982), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %slice.8979 = bf16[32,4,64]{2,1,0} slice(%mul.8944), slice={[0:32], [0:4], [64:128]}, metadata={op_name="jit(step_fun)/aten::split.Tensor/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=784 source_end_line=784 source_column=6 source_end_column=42}
  %broadcast_in_dim.8977 = bf16[32,1,64]{2,1,0} reshape(%slice.8951), metadata={op_name="jit(step_fun)/aten::unsqueeze/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=801 source_end_line=801 source_column=9 source_end_column=35}
  %mul.8984 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8977), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8985 = bf16[32,64]{1,0} reshape(%mul.8984), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8986 = bf16[32,4,64]{2,1,0} broadcast(%mul.8985), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8987 = bf16[32,4,64]{2,1,0} multiply(%slice.8979, %mul.8986), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %sub.8988 = bf16[32,4,64]{2,1,0} subtract(%mul.8983, %mul.8987), metadata={op_name="jit(step_fun)/aten::sub.Tensor/sub" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=299 source_end_line=299 source_column=9 source_end_column=22}
  %mul.8989 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8976), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8990 = bf16[32,64]{1,0} reshape(%mul.8989), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8991 = bf16[32,4,64]{2,1,0} broadcast(%mul.8990), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8992 = bf16[32,4,64]{2,1,0} multiply(%slice.8979, %mul.8991), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8993 = bf16[32,1,64]{2,1,0} broadcast(%broadcast_in_dim.8977), dimensions={0,1,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8994 = bf16[32,64]{1,0} reshape(%mul.8993), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8995 = bf16[32,4,64]{2,1,0} broadcast(%mul.8994), dimensions={0,2}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.8996 = bf16[32,4,64]{2,1,0} multiply(%slice.8978, %mul.8995), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %add.8997 = bf16[32,4,64]{2,1,0} add(%mul.8992, %mul.8996), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %concatenate.8998 = bf16[32,4,128]{2,1,0} concatenate(%sub.8988, %add.8997), dimensions={2}, metadata={op_name="jit(step_fun)/aten::cat/concatenate" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=1211 source_end_line=1211 source_column=11 source_end_column=50}
  %reshape.8999 = bf16[32,512]{1,0} reshape(%concatenate.8998), metadata={op_name="jit(step_fun)/aten::view/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=55 source_end_line=55 source_column=9 source_end_column=30}
  %slice.8900 = bf16[32,4,128]{2,1,0} slice(%reshape.8897), slice={[0:32], [0:4], [1152:1280]}, metadata={op_name="jit(step_fun)/QKVParallelLinear/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=107 source_end_line=107 source_column=23 source_end_column=67}
  %reshape.8901 = bf16[32,512]{1,0} reshape(%slice.8900), metadata={op_name="jit(step_fun)/QKVParallelLinear/reshape" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=108 source_end_line=108 source_column=29 source_end_column=74}
  %jit__jax_attn_func_.9000 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,4096]{1,0}) call(%kv_caches_47_.483, %reshape.8975, %reshape.8999, %reshape.8901, %attn_metadata_block_tables.486, /*index=5*/%attn_metadata_seq_lens.487, %attn_metadata_query_start_loc.488, %attn_metadata_request_distribution.489), to_apply=%_jax_attn_func.763, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.9001 = bf16[14813,32,4,2,128]{4,3,2,1,0} get-tuple-element(%jit__jax_attn_func_.9000), index=0, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %jit__jax_attn_func_.9002 = bf16[32,4096]{1,0} get-tuple-element(%jit__jax_attn_func_.9000), index=1, metadata={op_name="jit(step_fun)/jit(_jax_attn_func)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/attention.py" source_line=118 source_end_line=122 source_column=32 source_end_column=64}
  %params_and_buffers__vllm_model_language_model_model_layers_47_self_attn_o_proj_weight__.387 = bf16[2048,4096]{1,0} parameter(386), sharding={devices=[1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.47.self_attn.o_proj.weight\']"}
  %dot_general.9003 = bf16[32,2048]{1,0} dot(%jit__jax_attn_func_.9002, %params_and_buffers__vllm_model_language_model_model_layers_47_self_attn_o_proj_weight__.387), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/RowParallelLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %convert_element_type.9004 = f32[32,2048]{1,0} convert(%dot_general.9003), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.8875 = bf16[32,2048]{1,0} convert(%add.8874), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.9005 = f32[32,2048]{1,0} convert(%convert_element_type.8875), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.9006 = f32[32,2048]{1,0} add(%convert_element_type.9004, %convert_element_type.9005), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.9008 = f32[32,2048]{1,0} power(%add.9006, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.9013 = f32[32]{0} reduce(%pow.9008, %constant.512), dimensions={1}, to_apply=%region_223.9012, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.9014 = f32[32,1]{1,0} reshape(%reduce_sum.9013), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.9015 = f32[32,1]{1,0} divide(%broadcast_in_dim.9014, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.9016 = f32[32,1]{1,0} add(%div.9015, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.9017 = f32[32,1]{1,0} rsqrt(%add.9016), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.9018 = f32[32,1]{1,0} broadcast(%rsqrt.9017), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.9019 = f32[32]{0} reshape(%mul.9018), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.9020 = f32[32,2048]{1,0} broadcast(%mul.9019), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.9021 = f32[32,2048]{1,0} multiply(%add.9006, %mul.9020), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.9022 = bf16[32,2048]{1,0} convert(%mul.9021), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_layers_47_post_attention_layernorm_weight__.385 = bf16[2048]{0} parameter(384), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.47.post_attention_layernorm.weight\']"}
  %broadcast_in_dim.9023 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_layers_47_post_attention_layernorm_weight__.385), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.9024 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.9023), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.9025 = bf16[2048]{0} reshape(%mul.9024), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.9026 = bf16[32,2048]{1,0} broadcast(%mul.9025), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.9027 = bf16[32,2048]{1,0} multiply(%convert_element_type.9022, %mul.9026), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %params_and_buffers__vllm_model_language_model_model_layers_47_mlp_experts_w13_weight__.382 = bf16[128,1536,2048]{2,1,0} parameter(381), sharding={devices=[1,4,1]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {\"model\"}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.47.mlp.experts.w13_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_47_mlp_experts_w2_weight__.383 = bf16[128,2048,768]{2,1,0} parameter(382), sharding={devices=[1,1,4]<=[4]}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}, {\"model\"}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.47.mlp.experts.w2_weight\']"}
  %params_and_buffers__vllm_model_language_model_model_layers_47_mlp_gate_weight__.384 = bf16[128,2048]{1,0} parameter(383), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}, {}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.layers.47.mlp.gate.weight\']"}
  %dot_general.9028 = bf16[32,128]{1,0} dot(%mul.9027, %params_and_buffers__vllm_model_language_model_model_layers_47_mlp_gate_weight__.384), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_name="jit(step_fun)/ReplicatedLinear/mn,pn->mp/dot_general" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=129 source_end_line=129 source_column=15 source_end_column=57}
  %jit_jax_fused_moe_func_padded_.9029 = bf16[32,2048]{1,0} call(%mul.9027, %params_and_buffers__vllm_model_language_model_model_layers_47_mlp_experts_w13_weight__.382, %params_and_buffers__vllm_model_language_model_model_layers_47_mlp_experts_w2_weight__.383, %dot_general.9028), to_apply=%jax_fused_moe_func_padded.1602, metadata={op_name="jit(step_fun)/jit(jax_fused_moe_func_padded)" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/quantization/unquantized.py" source_line=256 source_end_line=261 source_column=17 source_end_column=9}
  %convert_element_type.9030 = f32[32,2048]{1,0} convert(%jit_jax_fused_moe_func_padded_.9029), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.9007 = bf16[32,2048]{1,0} convert(%add.9006), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %convert_element_type.9031 = f32[32,2048]{1,0} convert(%convert_element_type.9007), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %add.9032 = f32[32,2048]{1,0} add(%convert_element_type.9030, %convert_element_type.9031), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %pow.9033 = f32[32,2048]{1,0} power(%add.9032, %broadcast.511), metadata={op_name="jit(step_fun)/aten::pow.Tensor_Scalar/pow" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=487 source_end_line=487 source_column=8 source_end_column=23}
  %reduce_sum.9038 = f32[32]{0} reduce(%pow.9033, %constant.512), dimensions={1}, to_apply=%region_224.9037, metadata={op_name="jit(step_fun)/aten::mean.dim/reduce_sum" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %broadcast_in_dim.9039 = f32[32,1]{1,0} reshape(%reduce_sum.9038), metadata={op_name="jit(step_fun)/aten::mean.dim/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %div.9040 = f32[32,1]{1,0} divide(%broadcast_in_dim.9039, %broadcast.509), metadata={op_name="jit(step_fun)/aten::mean.dim/div" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=265 source_end_line=265 source_column=9 source_end_column=43}
  %add.9041 = f32[32,1]{1,0} add(%div.9040, %broadcast.507), metadata={op_name="jit(step_fun)/aten::add.Tensor/add" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=65 source_end_line=65 source_column=8 source_end_column=21}
  %rsqrt.9042 = f32[32,1]{1,0} rsqrt(%add.9041), metadata={op_name="jit(step_fun)/aten::rsqrt/rsqrt" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=656 source_end_line=656 source_column=9 source_end_column=25}
  %mul.9043 = f32[32,1]{1,0} broadcast(%rsqrt.9042), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.9044 = f32[32]{0} reshape(%mul.9043), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.9045 = f32[32,2048]{1,0} broadcast(%mul.9044), dimensions={0}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.9046 = f32[32,2048]{1,0} multiply(%add.9032, %mul.9045), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %convert_element_type.9047 = bf16[32,2048]{1,0} convert(%mul.9046), metadata={op_name="jit(step_fun)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/tensor.py" source_line=154 source_end_line=154 source_column=10 source_end_column=51}
  %params_and_buffers__vllm_model_language_model_model_norm_weight__.435 = bf16[2048]{0} parameter(434), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@mesh, [{}]>"}, metadata={op_name="params_and_buffers[\'vllm_model.language_model.model.norm.weight\']"}
  %broadcast_in_dim.9048 = bf16[1,2048]{1,0} reshape(%params_and_buffers__vllm_model_language_model_model_norm_weight__.435), metadata={op_name="jit(step_fun)/aten::mul.Tensor/broadcast_in_dim" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.9049 = bf16[1,2048]{1,0} broadcast(%broadcast_in_dim.9048), dimensions={0,1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.9050 = bf16[2048]{0} reshape(%mul.9049), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.9051 = bf16[32,2048]{1,0} broadcast(%mul.9050), dimensions={1}, metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  %mul.9052 = bf16[32,2048]{1,0} multiply(%convert_element_type.9047, %mul.9051), metadata={op_name="jit(step_fun)/aten::mul.Tensor/mul" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/jaten.py" source_line=325 source_end_line=325 source_column=8 source_end_column=13}
  ROOT %tuple.9053 = (bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, /*index=5*/bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, /*index=10*/bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, /*index=15*/bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, /*index=20*/bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, /*index=25*/bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, /*index=30*/bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, /*index=35*/bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, /*index=40*/bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, /*index=45*/bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[14813,32,4,2,128]{4,3,2,1,0}, bf16[32,2048]{1,0}) tuple(%jit__jax_attn_func_.765, %jit__jax_attn_func_.1733, %jit__jax_attn_func_.1891, %jit__jax_attn_func_.2049, %jit__jax_attn_func_.2207, /*index=5*/%jit__jax_attn_func_.2365, %jit__jax_attn_func_.2523, %jit__jax_attn_func_.2681, %jit__jax_attn_func_.2839, %jit__jax_attn_func_.2997, /*index=10*/%jit__jax_attn_func_.3155, %jit__jax_attn_func_.3313, %jit__jax_attn_func_.3471, %jit__jax_attn_func_.3629, %jit__jax_attn_func_.3787, /*index=15*/%jit__jax_attn_func_.3945, %jit__jax_attn_func_.4103, %jit__jax_attn_func_.4261, %jit__jax_attn_func_.4419, %jit__jax_attn_func_.4577, /*index=20*/%jit__jax_attn_func_.4735, %jit__jax_attn_func_.4893, %jit__jax_attn_func_.5051, %jit__jax_attn_func_.5209, %jit__jax_attn_func_.5367, /*index=25*/%jit__jax_attn_func_.5525, %jit__jax_attn_func_.5683, %jit__jax_attn_func_.5841, %jit__jax_attn_func_.5999, %jit__jax_attn_func_.6157, /*index=30*/%jit__jax_attn_func_.6315, %jit__jax_attn_func_.6473, %jit__jax_attn_func_.6631, %jit__jax_attn_func_.6789, %jit__jax_attn_func_.6947, /*index=35*/%jit__jax_attn_func_.7105, %jit__jax_attn_func_.7263, %jit__jax_attn_func_.7421, %jit__jax_attn_func_.7579, %jit__jax_attn_func_.7737, /*index=40*/%jit__jax_attn_func_.7895, %jit__jax_attn_func_.8053, %jit__jax_attn_func_.8211, %jit__jax_attn_func_.8369, %jit__jax_attn_func_.8527, /*index=45*/%jit__jax_attn_func_.8685, %jit__jax_attn_func_.8843, %jit__jax_attn_func_.9001, %mul.9052)
}

