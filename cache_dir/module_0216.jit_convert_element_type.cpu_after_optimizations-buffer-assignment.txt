BufferAssignment:
allocation 0: size 39321600, parameter 0, shape |f32[1280,7680]| at ShapeIndex {}:
 value: <0 args_0_.1 @0> (size=39321600,offset=0): f32[1280,7680]{1,0}
allocation 1: size 19660800, output shape is |bf16[1280,7680]|, maybe-live-out:
 value: <1 convert_element_type.1 @0> (size=19660800,offset=0): bf16[1280,7680]{1,0}

Total bytes used: 58982400 (56.25MiB)

Used values:
<0 args_0_.1 @0>
 positions:
  args_0_.1
 uses:
  convert_element_type.1, operand 0
 from instruction: %args_0_.1 = f32[1280,7680]{1,0} parameter(0), metadata={op_name="args[0]"}
<1 convert_element_type.1 @0>
 positions:
  convert_element_type.1
 uses:
 from instruction: %convert_element_type.1 = bf16[1280,7680]{1,0} convert(%args_0_.1), metadata={op_name="jit(convert_element_type)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/mappings.py" source_line=46 source_end_line=46 source_column=12 source_end_column=57}, backend_config={"outer_dimension_partitions":["14"]}


HloLiveRange (max 2):
  InstructionSequence:
    0:args_0_.1
    1:convert_element_type.1
  BufferLiveRange:
    args_0_.1{}:0-2
    convert_element_type.1{}:1-2
  Live ranges at 1 (peak):
    args_0_.1{}: 39321600 bytes (cumulative: 39321600 bytes)
    convert_element_type.1{}: 19660800 bytes (cumulative: 58982400 bytes)
  Stack trace breakdown for peak usage: 58 982 400 bytes
    main.1 (100.0%, total: 58 982 400 bytes, current: 0 bytes, remaining: 58 982 400 bytes)
      ├── args[0] (66.7%, total: 39 321 600 bytes, current: 39 321 600 bytes, remaining: 19 660 800 bytes)
      └── jit(convert_element_type)/convert_element_type (33.3%, total: 19 660 800 bytes, current: 19 660 800 bytes, remaining: 0 bytes)
