HloModule jit__multi_slice, is_scheduled=true, entry_computation_layout={(bf16[152064,2048]{1,0})->(bf16[38016,2048]{1,0}, bf16[38016,2048]{1,0}, bf16[38016,2048]{1,0}, bf16[38016,2048]{1,0})}, allow_spmd_sharding_propagation_to_output={true,true,true,true}, frontend_attributes={xla.sdy.meshes={empty_mesh = #sdy.mesh<[]>}}

%fused_computation (param_0.2: bf16[152064,2048]) -> bf16[38016,2048] {
  %param_0.2 = bf16[152064,2048]{1,0} parameter(0)
  %convert.9 = f32[152064,2048]{1,0} convert(%param_0.2)
  %slice.0 = f32[38016,2048]{1,0} slice(%convert.9), slice={[114048:152064], [0:2048]}, metadata={op_name="jit(_multi_slice)/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/sharding.py" source_line=72 source_end_line=72 source_column=22 source_end_column=54}
  ROOT %convert.8 = bf16[38016,2048]{1,0} convert(%slice.0)
}

%fused_computation.1 (param_0.5: bf16[152064,2048]) -> bf16[38016,2048] {
  %param_0.5 = bf16[152064,2048]{1,0} parameter(0)
  %convert.11 = f32[152064,2048]{1,0} convert(%param_0.5)
  %slice.1 = f32[38016,2048]{1,0} slice(%convert.11), slice={[76032:114048], [0:2048]}, metadata={op_name="jit(_multi_slice)/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/sharding.py" source_line=72 source_end_line=72 source_column=22 source_end_column=54}
  ROOT %convert.10 = bf16[38016,2048]{1,0} convert(%slice.1)
}

%fused_computation.2 (param_0.8: bf16[152064,2048]) -> bf16[38016,2048] {
  %param_0.8 = bf16[152064,2048]{1,0} parameter(0)
  %convert.13 = f32[152064,2048]{1,0} convert(%param_0.8)
  %slice.2 = f32[38016,2048]{1,0} slice(%convert.13), slice={[38016:76032], [0:2048]}, metadata={op_name="jit(_multi_slice)/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/sharding.py" source_line=72 source_end_line=72 source_column=22 source_end_column=54}
  ROOT %convert.12 = bf16[38016,2048]{1,0} convert(%slice.2)
}

%fused_computation.3 (param_0.11: bf16[152064,2048]) -> bf16[38016,2048] {
  %param_0.11 = bf16[152064,2048]{1,0} parameter(0)
  %convert.15 = f32[152064,2048]{1,0} convert(%param_0.11)
  %slice.3 = f32[38016,2048]{1,0} slice(%convert.15), slice={[0:38016], [0:2048]}, metadata={op_name="jit(_multi_slice)/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/sharding.py" source_line=72 source_end_line=72 source_column=22 source_end_column=54}
  ROOT %convert.14 = bf16[38016,2048]{1,0} convert(%slice.3)
}

ENTRY %main.1 (self.1: bf16[152064,2048]) -> (bf16[38016,2048], bf16[38016,2048], bf16[38016,2048], bf16[38016,2048]) {
  %self.1 = bf16[152064,2048]{1,0} parameter(0), sharding={replicated}, frontend_attributes={xla.sdy.sharding="#sdy.sharding<@empty_mesh, [{}, {}]>"}, metadata={op_name="self"}
  %slice_convert_fusion.3 = bf16[38016,2048]{1,0} fusion(%self.1), kind=kLoop, calls=%fused_computation.3, backend_config={"outer_dimension_partitions":["14"]}
  %slice_convert_fusion = bf16[38016,2048]{1,0} fusion(%self.1), kind=kLoop, calls=%fused_computation, backend_config={"outer_dimension_partitions":["14"]}
  %slice_convert_fusion.1 = bf16[38016,2048]{1,0} fusion(%self.1), kind=kLoop, calls=%fused_computation.1, backend_config={"outer_dimension_partitions":["14"]}
  %slice_convert_fusion.2 = bf16[38016,2048]{1,0} fusion(%self.1), kind=kLoop, calls=%fused_computation.2, backend_config={"outer_dimension_partitions":["14"]}
  ROOT %tuple.1 = (bf16[38016,2048]{1,0}, bf16[38016,2048]{1,0}, bf16[38016,2048]{1,0}, bf16[38016,2048]{1,0}) tuple(%slice_convert_fusion.3, %slice_convert_fusion.2, %slice_convert_fusion.1, %slice_convert_fusion)
}

