BufferAssignment:
allocation 0: size 26214400, parameter 0, shape |f32[5120,1280]| at ShapeIndex {}:
 value: <0 args_0_.1 @0> (size=26214400,offset=0): f32[5120,1280]{1,0}
allocation 1: size 13107200, output shape is |bf16[5120,1280]|, maybe-live-out:
 value: <1 convert_element_type.1 @0> (size=13107200,offset=0): bf16[5120,1280]{1,0}

Total bytes used: 39321600 (37.50MiB)

Used values:
<0 args_0_.1 @0>
 positions:
  args_0_.1
 uses:
  convert_element_type.1, operand 0
 from instruction: %args_0_.1 = f32[5120,1280]{1,0} parameter(0), metadata={op_name="args[0]"}
<1 convert_element_type.1 @0>
 positions:
  convert_element_type.1
 uses:
 from instruction: %convert_element_type.1 = bf16[5120,1280]{1,0} convert(%args_0_.1), metadata={op_name="jit(convert_element_type)/convert_element_type" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/torchax/ops/mappings.py" source_line=46 source_end_line=46 source_column=12 source_end_column=57}, backend_config={"outer_dimension_partitions":["14"]}


HloLiveRange (max 2):
  InstructionSequence:
    0:args_0_.1
    1:convert_element_type.1
  BufferLiveRange:
    args_0_.1{}:0-2
    convert_element_type.1{}:1-2
  Live ranges at 1 (peak):
    args_0_.1{}: 26214400 bytes (cumulative: 26214400 bytes)
    convert_element_type.1{}: 13107200 bytes (cumulative: 39321600 bytes)
  Stack trace breakdown for peak usage: 39 321 600 bytes
    main.1 (100.0%, total: 39 321 600 bytes, current: 0 bytes, remaining: 39 321 600 bytes)
      ├── args[0] (66.7%, total: 26 214 400 bytes, current: 26 214 400 bytes, remaining: 13 107 200 bytes)
      └── jit(convert_element_type)/convert_element_type (33.3%, total: 13 107 200 bytes, current: 13 107 200 bytes, remaining: 0 bytes)
