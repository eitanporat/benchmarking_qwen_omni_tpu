HloModule jit__multi_slice, is_scheduled=true, entry_computation_layout={(bf16[2048,4096]{1,0})->(bf16[2048,1024]{1,0}, bf16[2048,1024]{1,0}, bf16[2048,1024]{1,0}, bf16[2048,1024]{1,0})}, allow_spmd_sharding_propagation_to_parameters={true}, allow_spmd_sharding_propagation_to_output={true,true,true,true}

%fused_computation (param_0.2: bf16[2048,4096]) -> bf16[2048,1024] {
  %param_0.2 = bf16[2048,4096]{1,0} parameter(0)
  %convert.9 = f32[2048,4096]{1,0} convert(%param_0.2)
  %slice.0 = f32[2048,1024]{1,0} slice(%convert.9), slice={[0:2048], [3072:4096]}, metadata={op_name="jit(_multi_slice)/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=133 source_end_line=133 source_column=17 source_end_column=49}
  ROOT %convert.8 = bf16[2048,1024]{1,0} convert(%slice.0)
}

%fused_computation.1 (param_0.5: bf16[2048,4096]) -> bf16[2048,1024] {
  %param_0.5 = bf16[2048,4096]{1,0} parameter(0)
  %convert.11 = f32[2048,4096]{1,0} convert(%param_0.5)
  %slice.1 = f32[2048,1024]{1,0} slice(%convert.11), slice={[0:2048], [2048:3072]}, metadata={op_name="jit(_multi_slice)/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=133 source_end_line=133 source_column=17 source_end_column=49}
  ROOT %convert.10 = bf16[2048,1024]{1,0} convert(%slice.1)
}

%fused_computation.2 (param_0.8: bf16[2048,4096]) -> bf16[2048,1024] {
  %param_0.8 = bf16[2048,4096]{1,0} parameter(0)
  %convert.13 = f32[2048,4096]{1,0} convert(%param_0.8)
  %slice.2 = f32[2048,1024]{1,0} slice(%convert.13), slice={[0:2048], [1024:2048]}, metadata={op_name="jit(_multi_slice)/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=133 source_end_line=133 source_column=17 source_end_column=49}
  ROOT %convert.12 = bf16[2048,1024]{1,0} convert(%slice.2)
}

%fused_computation.3 (param_0.11: bf16[2048,4096]) -> bf16[2048,1024] {
  %param_0.11 = bf16[2048,4096]{1,0} parameter(0)
  %convert.15 = f32[2048,4096]{1,0} convert(%param_0.11)
  %slice.3 = f32[2048,1024]{1,0} slice(%convert.15), slice={[0:2048], [0:1024]}, metadata={op_name="jit(_multi_slice)/slice" source_file="/home/eporat/benchmarking_qwen_omni_tpu/.venv/lib/python3.11/site-packages/tpu_inference/layers/vllm/linear_common.py" source_line=133 source_end_line=133 source_column=17 source_end_column=49}
  ROOT %convert.14 = bf16[2048,1024]{1,0} convert(%slice.3)
}

ENTRY %main.1 (self.1: bf16[2048,4096]) -> (bf16[2048,1024], bf16[2048,1024], bf16[2048,1024], bf16[2048,1024]) {
  %self.1 = bf16[2048,4096]{1,0} parameter(0), metadata={op_name="self"}
  %slice_convert_fusion.3 = bf16[2048,1024]{1,0} fusion(%self.1), kind=kLoop, calls=%fused_computation.3, backend_config={"outer_dimension_partitions":["14"]}
  %slice_convert_fusion = bf16[2048,1024]{1,0} fusion(%self.1), kind=kLoop, calls=%fused_computation, backend_config={"outer_dimension_partitions":["14"]}
  %slice_convert_fusion.1 = bf16[2048,1024]{1,0} fusion(%self.1), kind=kLoop, calls=%fused_computation.1, backend_config={"outer_dimension_partitions":["14"]}
  %slice_convert_fusion.2 = bf16[2048,1024]{1,0} fusion(%self.1), kind=kLoop, calls=%fused_computation.2, backend_config={"outer_dimension_partitions":["14"]}
  ROOT %tuple.1 = (bf16[2048,1024]{1,0}, bf16[2048,1024]{1,0}, bf16[2048,1024]{1,0}, bf16[2048,1024]{1,0}) tuple(%slice_convert_fusion.3, %slice_convert_fusion.2, %slice_convert_fusion.1, %slice_convert_fusion)
}

